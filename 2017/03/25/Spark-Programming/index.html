<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>Spark-Programming | PLM&#39;s Notes | 好好学习，天天笔记</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="Spark,RDD">
    <meta name="description" content="总览Spark程序 有一个驱动程序，会运行用户的主要功能，并且在集群上执行各种并行操作。 RDD RDD是跨集群节点分区的、并且可以并行计算的分布式数据集合。可以通过外部文件系统或者内部集合来创建。可以在内存中持久化一个RDD，并且在并行计算中有效地重用。RDD可以从节点故障中自动恢复。 共享变量 当一组任务在不同的节点上并行运行一个函数时，Spark会为函数中的每个变量发送一个副本到各个任务中去">
<meta name="keywords" content="Spark,RDD">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark-Programming">
<meta property="og:url" content="http://plmsmile.github.io/2017/03/25/Spark-Programming/index.html">
<meta property="og:site_name" content="PLM&#39;s Notes">
<meta property="og:description" content="总览Spark程序 有一个驱动程序，会运行用户的主要功能，并且在集群上执行各种并行操作。 RDD RDD是跨集群节点分区的、并且可以并行计算的分布式数据集合。可以通过外部文件系统或者内部集合来创建。可以在内存中持久化一个RDD，并且在并行计算中有效地重用。RDD可以从节点故障中自动恢复。 共享变量 当一组任务在不同的节点上并行运行一个函数时，Spark会为函数中的每个变量发送一个副本到各个任务中去">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2018-11-25T08:30:10.981Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark-Programming">
<meta name="twitter:description" content="总览Spark程序 有一个驱动程序，会运行用户的主要功能，并且在集群上执行各种并行操作。 RDD RDD是跨集群节点分区的、并且可以并行计算的分布式数据集合。可以通过外部文件系统或者内部集合来创建。可以在内存中持久化一个RDD，并且在并行计算中有效地重用。RDD可以从节点故障中自动恢复。 共享变量 当一组任务在不同的节点上并行运行一个函数时，Spark会为函数中的每个变量发送一个副本到各个任务中去">
    
        <link rel="alternate" type="application/atom+xml" title="PLM&#39;s Notes" href="/atom.xml">
    
    <link rel="shortcut icon" href="/img/favicon.png">
    <link rel="stylesheet" href="/css/style.css?v=1.7.2">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide">
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">PLM</h5>
          <a href="mailto:plmsmile@126.com" title="plmsmile@126.com" class="mail">plmsmile@126.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/">
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives">
                <i class="icon icon-lg icon-archives"></i>
                归档
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags">
                <i class="icon icon-lg icon-tags"></i>
                标签
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories">
                <i class="icon icon-lg icon-th-list"></i>
                类别
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/about">
                <i class="icon icon-lg icon-user"></i>
                关于我
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/plmsmile" target="_blank">
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">Spark-Programming</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">Spark-Programming</h1>
        <h5 class="subtitle">
            
                <time datetime="2017-03-25T10:07:35.000Z" itemprop="datePublished" class="page-time">
  2017-03-25
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/大数据/">大数据</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#总览"><span class="post-toc-number">1.</span> <span class="post-toc-text">总览</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#RDD"><span class="post-toc-number">2.</span> <span class="post-toc-text">RDD</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#创建RDD"><span class="post-toc-number">2.0.1.</span> <span class="post-toc-text">创建RDD</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#RDD操作"><span class="post-toc-number">2.0.2.</span> <span class="post-toc-text">RDD操作</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#传递函数给Spark"><span class="post-toc-number">2.0.3.</span> <span class="post-toc-text">传递函数给Spark</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#理解闭包"><span class="post-toc-number">2.0.4.</span> <span class="post-toc-text">理解闭包</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Shuffle操作"><span class="post-toc-number">2.0.5.</span> <span class="post-toc-text">Shuffle操作</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#RDD持久化"><span class="post-toc-number">2.0.6.</span> <span class="post-toc-text">RDD持久化</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#共享变量"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">共享变量</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#广播变量"><span class="post-toc-number">2.1.1.</span> <span class="post-toc-text">广播变量</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#累加器"><span class="post-toc-number">2.1.2.</span> <span class="post-toc-text">累加器</span></a></li></ol></li></ol>
        </nav>
    </aside>


<article id="post-Spark-Programming" class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">Spark-Programming</h1>
        <div class="post-meta">
            <time class="post-time" title="2017-03-25 18:07:35" datetime="2017-03-25T10:07:35.000Z" itemprop="datePublished">2017-03-25</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/大数据/">大数据</a></li></ul>



            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style="display:none">
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <h2 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h2><p><strong>Spark程序</strong></p>
<p>有一个驱动程序，会运行用户的主要功能，并且在集群上执行各种并行操作。</p>
<p><strong>RDD</strong></p>
<p>RDD是<code>跨集群节点分区</code>的、并且可以<code>并行计算</code>的分布式数据集合。可以通过外部文件系统或者内部集合来创建。可以在内存中<code>持久化</code>一个RDD，并且在并行计算中有效地<code>重用</code>。RDD可以从节点故障中<code>自动恢复</code>。</p>
<p><strong>共享变量</strong></p>
<p>当一组任务在不同的节点上并行运行一个函数时，Spark会为函数中的每个变量发送一个<code>副本</code>到各个任务中去(低效)。有时，变量需要在任务与任务、任务与驱动程序间共享。Spark有两种共享变量。</p>
<ul>
<li>累加器：将工作节点中的值聚合到驱动程序中</li>
<li>广播变量：在各个节点中cache一个<code>只读变量</code></li>
</ul>
<p><strong>SparkContext</strong></p>
<p>Spark的主要入口点。使用它可以连接到集群、创建RDD和广播变量。</p>
<h2 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h2><p>RDD是Spark中最核心的概念。</p>
<ul>
<li>这是一个<code>分布式的</code>、<code>容忍错误的</code>、<code>能并行操作</code>的<strong>数据集合</strong>。</li>
<li>RDD是一个分布式的不可变的对象集合，可以包含任意对象。</li>
<li>每个RDD都会被分为<strong>多个分区</strong>，这些分区运行在不同的节点上。</li>
<li>Spark会自动把RDD的数据分发到集群上，并且<strong>并行化执行</strong>相关操作。</li>
<li>记录如何转化、计算数据的指令列表。</li>
</ul>
<p>Spark中对数据的所有操作都是<strong>创建RDD</strong>、<strong>转化已有RDD</strong>、<strong>调用RDD操作进行求值</strong>。</p>
<h4 id="创建RDD"><a href="#创建RDD" class="headerlink" title="创建RDD"></a>创建RDD</h4><p>创建RDD有两种方式：驱动程序内部的集合，外部系统的数据集(如HDFS, HBase等)。</p>
<p><strong>集合</strong></p>
<p>从集合中创建RDD，会把集合中的元素复制去创建一个可以并行执行的分布式数据集。</p>
<p>Spark可以对这些并行集合进行分区，把这些数据切割到多个分区。Spark会为集群的每个分区运行一个Task。一般，我们需要为集群中的每个CPU分配2-4个分区。默认，Spark会根据集群尝试自动设置分区数。但我们也可以手动地设置分区数。(有的代码中也称partition为slice)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">rdd.reduce(<span class="keyword">lambda</span> x, y: x + y) <span class="comment"># 求和</span></span><br><span class="line">rdd2 = sc.parallelize([<span class="string">'Spark'</span>, <span class="string">'Hadoop'</span>, <span class="string">'ML'</span>, <span class="string">'Python'</span>, <span class="string">'Data'</span>], <span class="number">2</span>) <span class="comment"># 设置2个分区</span></span><br></pre></td></tr></table></figure>
<p><strong>外部数据集</strong></p>
<p>Spark可以从本地文件系统、HDFS、Cassandra、HBase、Amazon S3等创建数据。支持Text、SequenceFile和任何其他Hadoop的Input Format。</p>
<p>Spark读取文件<code>textFile</code>的一些说明：</p>
<ul>
<li>本地文件使用本地路径读取文件时，该文件也得在<strong>其它的worker node的相同路径上访问到</strong>。可以把文件复制过去或者使用network-mounted的文件共享系统。</li>
<li>支持文件 、文件夹、通配符、压缩文件(.gz)。</li>
<li>可以设置分区数。默认，Spark为文件的每一个块创建一个分区。(HDFS的block是128MB)。可以传递一个更大的值来请求更多的分区。</li>
</ul>
<h4 id="RDD操作"><a href="#RDD操作" class="headerlink" title="RDD操作"></a>RDD操作</h4><p>RDD主要有2个操作。</p>
<ul>
<li>转化操作：由一个RDD生成一个新的RDD(Dataset)。<strong>惰性求值</strong>。</li>
<li>行动操作：会对RDD(Dataset)计算出一个结果或者写到外部系统。会触发<strong>实际的计算</strong>。</li>
</ul>
<p>Spark会<strong>惰性计算</strong>这些RDD，只有第一次在一个行动操作中用到时才会真正计算。</p>
<p>一般，Spark会在每次行动操作时<strong>重新计算</strong>转换RDD。如果想<strong>复用</strong>，则用<code>persist</code>把RDD<strong>持久化缓存</strong>下来。可以持久化到内存、到磁盘、在多个节点上进行复制。这样，在下次查询时，集群可以更快地访问。</p>
<p>Spark程序大体步骤如下。</p>
<ul>
<li>从外部数据创建输入RDD。如<code>textFile</code></li>
<li>使用转化操作得到新的RDD。如<code>map</code>，<code>filter</code></li>
<li>对重用的中间结果RDD进行持久化。如<code>persist</code></li>
<li>使用行动操作来触发一次并行计算。如<code>count</code>, <code>first</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从外部创建一个rdd。此时并没有把数据加载到内存中。lines只是一个指向文件的指针</span></span><br><span class="line">lines = sc.textFile(<span class="string">"data.txt"</span>)</span><br><span class="line"><span class="comment"># 转化。没有进行真实的计算，因为惰性求值</span></span><br><span class="line">lineLengths = lines.map(<span class="keyword">lambda</span> s: len(s))</span><br><span class="line"><span class="comment"># 持久化</span></span><br><span class="line">lineLengths.persist()</span><br><span class="line"><span class="comment"># 行动。Spark把计算分解为一些任务，这些任务在单独的机器上进行运算。</span></span><br><span class="line"><span class="comment"># 每个机器只做属于自己map的部分，并且在本地reduce。返一个结果给DriverProgram</span></span><br><span class="line">totalLength = lineLengths.reduce(<span class="keyword">lambda</span> a, b: a + b)</span><br></pre></td></tr></table></figure>
<h4 id="传递函数给Spark"><a href="#传递函数给Spark" class="headerlink" title="传递函数给Spark"></a>传递函数给Spark</h4><p>Spark的API很多都依赖于传递函数来在集群上面运行。有下面3种方式可以使用：</p>
<ul>
<li>Lambda表达式：简单功能。不支持多语句函数、不支持没有返回值的语句。</li>
<li>本地def函数，调用spark。</li>
<li>模块的顶级函数。</li>
</ul>
<p><strong>代码较多时</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_func</span><span class="params">(s)</span>:</span></span><br><span class="line">    words = s.split(<span class="string">" "</span>)</span><br><span class="line">    <span class="keyword">return</span> len(words)</span><br><span class="line">len_rdd = sc.textFile(<span class="string">"word.txt"</span>).map(my_func)</span><br></pre></td></tr></table></figure>
<p><strong>对象方法时</strong></p>
<p>千万不要引用self，这样会把整个对象序列化发送过去。而我们其实只需要一个方法或者属性就可以了，我们可以copy一份<strong>局部变量</strong>传递过去。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SearchFunctions</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, query)</span>:</span></span><br><span class="line">        self.query = query</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">is_match</span><span class="params">(self, s)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.query <span class="keyword">in</span> s</span><br><span class="line">   	<span class="function"><span class="keyword">def</span> <span class="title">get_matches_func_ref</span><span class="params">(self, rdd)</span>:</span></span><br><span class="line">        <span class="string">"""问题: self.is_match引用了整个self</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> rdd.filter(self.is_match)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_matches_attr_ref</span><span class="params">(self, rdd)</span>:</span></span><br><span class="line">        <span class="string">"""问题：self.query引用了整个self</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> rdd.filter(<span class="keyword">lambda</span> s: self.query <span class="keyword">in</span> s)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_matches_no_ref</span><span class="params">(self, rdd)</span>:</span></span><br><span class="line">        <span class="string">"""正确做法：使用局部变量</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        query = self.query</span><br><span class="line">        <span class="keyword">return</span> rdd.filter(<span class="keyword">lambda</span> s: query <span class="keyword">in</span> s)</span><br></pre></td></tr></table></figure>
<h4 id="理解闭包"><a href="#理解闭包" class="headerlink" title="理解闭包"></a>理解闭包</h4><p>当在集群上面执行代码时，理解变量和方法的范围和生命周期是很重要并且困难的。先看一段代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">counter = <span class="number">0</span></span><br><span class="line">rdd = sc.parallelize(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Wrong: Don't do this!!请使用Accumulator</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">increment_counter</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> counter</span><br><span class="line">    counter += x</span><br><span class="line">rdd.foreach(increment_counter)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Counter value: "</span>, counter)</span><br></pre></td></tr></table></figure>
<p>执行job的时候，Spark会把处理RDD的操作分解为多个任务，每个任务会由一个<code>执行器executor</code>执行。执行前，Spark会计算任务的闭包。闭包其实就是一些变量和方法，为了计算RDD，它们对于执行器是可见的。Spark会把闭包序列化并且发送到每一个执行器。</p>
<p>发送给执行器的闭包里的变量其实是一个<strong>副本</strong>，这些执行器程序却看不到驱动器程序节点的内存中的变量(counter)，只能看到自己的副本。当foreach函数引用counter的时候，它使用的不是驱动器程序中的counter，而是自己的副本。</p>
<p>本地执行时，有时候foreach函数会在和driver同一个JVM里面执行，那么访问的就是最初的counter，也会对其进行修改。</p>
<p>一般，我们可以使用累加器<code>Accumulator</code>，它可以安全地修改一个变量。闭包不应该修改全局变量。如果要进行全局聚合，则应该使用<strong>累加器</strong>。</p>
<p>在本地模式，rdd.foreach(println)的时候，会打印出所有的RDD。但是在集群模式的时候，执行器会打印出它自己的那一部分，在driver中并没有。如果要在driver中打印，则需要collect().foreach()，但是只适用于数据量小的情况。因为collect会拿出所有的数据。</p>
<p><strong>键值对RDD</strong></p>
<p>详细的知识参见<a href="https://plmspark.github.io/2017/03/13/Spark-PairRDD/" target="_blank" rel="noopener">Spark的键值对RDD</a>。</p>
<h4 id="Shuffle操作"><a href="#Shuffle操作" class="headerlink" title="Shuffle操作"></a>Shuffle操作</h4><p><strong>shuffle说明</strong></p>
<p>Shuffle是Spark中重新分布数据的机制，因此它在分区之间分组也不同。主要是复制数据到执行器和机器上，这个很复杂而且很耗费。</p>
<p>以<code>reduceByKey</code>为例，一个key的所有value不一定在同一个partition甚至不在同一个machine，但是却需要把这些values放在一起进行计算。单个任务会在单个分区上执行。为了reduceByKey的reduce任务，需要获得所有的数据。Spark执行一个<code>all-to-all</code>操作，会在所有分区上，查找所有key的所有value，然后跨越分区汇总，去执行reduce任务。这就是shuffle。</p>
<p>shuffle后，分区的顺序和分区里的元素是确定的，但是分区里元素的顺序却不是确定的。可以去设置确定顺序。</p>
<p><strong>性能影响</strong></p>
<p>Shuffle涉及到磁盘IO、数据序列化、网络IO。组织data：一系列map任务；shuffle这些data；聚合data：一系列reduce任务。</p>
<p>一些map的结果会写到内存里，当太大时，会以分区排好序，然后写到单个文件里。在reduce端，task会读取相关的有序的block。</p>
<p>Shuffle操作会占用大量的堆内存，在传输data之前或者之后，都会使用内存中的数据结构去组织这些record。也就是说，在map端，会创建这些structures，在reduce端会生成这些structures。在内存中存不下时，就会写到磁盘中。</p>
<p>Shuffle操作会在磁盘上生成大量的中间文件，并且在RDD不再被使用并且被垃圾回收之前，这些文件都将被一直保留。因为lineage(血统,DAG图)要被重新计算的话，就不会再次shuffle了。如果保留RDD的引用或者垃圾回收不频繁，那么Spark会占用大量的磁盘空间。文件目录可由<code>spark.local.dir</code>配置。</p>
<p>我们可以在<a href="http://spark.apache.org/docs/latest/configuration.html" target="_blank" rel="noopener">Spark的配配置指南</a>中配置各种参数。</p>
<h4 id="RDD持久化"><a href="#RDD持久化" class="headerlink" title="RDD持久化"></a>RDD持久化</h4><p><strong>介绍</strong></p>
<p>Spark一个重要的特性是可以在操作的时候<strong>持久化缓存RDD到内存</strong>中。<code>Persist</code>一个RDD后，每个节点都会将这个RDD计算的所有分区存储在内存中，并且会在后续的计算中进行复用。这可以让future actions快很多(一般是10倍)。<strong>缓存</strong>是<code>迭代算法</code>和快速交互使用的关键工具。</p>
<p>持久化RDD可以使用<code>persist</code>或<code>cache</code>方法。会先进行行动操作计算，然后缓存到各个节点的内存中。Spark的缓存是<code>fault-tolerant</code>的，如果RDD的某些分区丢失了，它会自动使用产生这个RDD的transformation进行重新计算。</p>
<p><strong>类别</strong></p>
<p>出于不同的目的，持久化可以设置不同的级别。例如可以缓存到磁盘，缓存到内存(以序列化对象存储，节省空间)等，然后会复制到其他节点上。可以对<code>persist</code>传递<code>StorageLevel</code>对象进行设置缓存级别，而<code>cache</code>方法默认的是MEMORY_ONLY，下面是几个常用的。</p>
<ul>
<li><p>MEMORY_ONLY(default): RDD作为<code>反序列化的</code>Java对象存储在JVM中。如果not fit in memory，那么一些分区就不会存储，并且会在每次使用的时候<strong>重新计算</strong>。<strong>CPU时间快</strong>，但<strong>耗内存</strong>。</p>
</li>
<li><p>MEMORY_ONLY_SER: RDD作为<code>序列化的</code>Java对象存储在JVM中，每个分区一个字节数组。很<strong>省内存</strong>，可以选择一个快速的序列化器。<strong>CPU计算时间多</strong>。只是Java和Scala。</p>
</li>
<li><p>MEMORY_AND_DISK: <code>反序列化的</code>Java对象存在内存中。如果not fit in memory，那么把不适合在磁盘中存放的分区存放在内存中。</p>
</li>
<li><p>MEMORY_AND_DISK_SER:  和MEMORY_ONLY_SER差不多，只是存不下的再存储到磁盘中，而不是再重新计算。只是Java和Scala。</p>
</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:left">名字</th>
<th style="text-align:center">占用空间</th>
<th style="text-align:center">CPU时间</th>
<th style="text-align:center">在内存</th>
<th style="text-align:center">在磁盘</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">MEMORY_ONLY</td>
<td style="text-align:center">高</td>
<td style="text-align:center">低</td>
<td style="text-align:center">是</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:left">MEMORY_ONLY_SER</td>
<td style="text-align:center">低</td>
<td style="text-align:center">高</td>
<td style="text-align:center">是</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:left">MEMORY_AND_DISK</td>
<td style="text-align:center">高</td>
<td style="text-align:center">中等</td>
<td style="text-align:center">部分</td>
<td style="text-align:center">部分</td>
</tr>
<tr>
<td style="text-align:left">MEMORY_AND_DISK_SER</td>
<td style="text-align:center">低</td>
<td style="text-align:center">高</td>
<td style="text-align:center">部分</td>
<td style="text-align:center">部分</td>
</tr>
</tbody>
</table>
<p>所有的类别都通过<code>重新计算</code>丢失的数据来保证<code>容错能力</code>。完整的配置见<a href="http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence" target="_blank" rel="noopener">官方RDD持久化</a>。</p>
<p>在Python中，我们会始终序列化要存储的数据，使用的是<a href="https://docs.python.org/2/library/pickle.html" target="_blank" rel="noopener">Pickle</a>，所以不用担心选择serialized level。</p>
<p>在shuffle中，Spark会<strong>自动持久化一些中间结果</strong>，即使用户没有使用<code>persist</code>。这样是因为，如果一个节点failed，可以避免重新计算整个input。如果要<code>reuse</code>一个RDD的话，推荐使用<code>persist</code>这个RDD。</p>
<p><strong>选择</strong></p>
<p>Spark的不同storage level是为了在CPU和内存的效率之间不同的权衡，按照如下去选择：</p>
<ul>
<li>如果适合<code>MEMORY_ONLY</code>，那么就这个。CPU效率最高了。RDD的操作<strong>速度会很快</strong>！</li>
<li>如果不适合MEMORY_ONLY，则尽量使用<code>MEMORY_ONLY_SER</code>，然后<a href="http://spark.apache.org/docs/latest/tuning.html" target="_blank" rel="noopener">选个快速序列化库</a>。这样更加节省空间，理论上也能够快速访问。</li>
<li>不要溢写到磁盘。只有这两种才溢写到磁盘：计算数据集非常耗费资源；会过滤掉大量的数据。</li>
<li>如果要快速故障恢复，那么使用复制的storage level。虽然有容错能力，但是复制了，却可以直接继续执行任务，而不需要等待重新计算丢失的分区。</li>
</ul>
<p><strong>移除数据</strong></p>
<p>Spark会自动监视每个节点上的缓存使用情况，并且以<code>LRU</code>最近最少使用的策略把最老的分区从内存中移除。当然也可以使用<code>rdd.unpersist</code>手动移除。</p>
<ul>
<li>内存策略：移除分区，再次使用的时候，就需要重新计算。</li>
<li>内存和磁盘策略：移除的分区会写入磁盘。</li>
</ul>
<h3 id="共享变量"><a href="#共享变量" class="headerlink" title="共享变量"></a>共享变量</h3><p>一般，把一个函数f传给Spark的操作，f会在远程集群节点上执行。当函数f在节点上执行的时候，会对所有的变量<strong>复制一份副本到该节点</strong>，然后利用这些副本单独地工作。对这些副本变量的<strong>更新修改不会传回驱动程序</strong>，只是修改这些副本。如果要在任务之间支持一般读写共享的变量是很<strong>低效</strong>的。</p>
<p>Spark支持两种共享变量：</p>
<ul>
<li>广播变量：用来高效地分发较大的只读对象</li>
<li>累加器：用来对信息进行聚合</li>
</ul>
<h4 id="广播变量"><a href="#广播变量" class="headerlink" title="广播变量"></a>广播变量</h4><p><strong>简介</strong></p>
<p>广播变量可以让程序高效地向<strong>所有工作节点</strong>发送<strong>一个较大的只读值</strong>，供一个或多个Spark操作共同使用。</p>
<p>例如较大的只读查询表、机器学习中的一个很大的特征向量，使用广播变量就很方便。这会在每台机器上<strong>cache这个变量</strong>，而不是发送一个副本。</p>
<p>Spark的Action操作由一组stage组成，由分布式的”shuffle”操作隔离。Spark会自动广播每个stage的tasks需要的common data。这种广播的数据，是以<strong>序列化格式缓存的</strong>，并且会在每个<strong>任务运行之前反序列化</strong>。</p>
<p>创建广播变量只有下面两种情况<strong>有用</strong>：</p>
<ul>
<li>多个stage的task需要相同的数据</li>
<li>以反序列化形式缓存数据很重要</li>
</ul>
<p>存在的问题：</p>
<ul>
<li>Spark会自动把闭包中引用到的变量发送到工作节点。方便但是<strong>低效</strong>。</li>
<li>可能在并行操作中使用同一个变量，但是Spark会为每个操作都发送一次这个变量。</li>
<li>有的变量可能很大，为每个任务都发送一次代价很大。后面再用的话，则还要<strong>重新发送</strong>。</li>
</ul>
<p>广播变量来解决：</p>
<ul>
<li>其实就是一个类型为<code>spark.broadcast.BroadCast[T]</code>的变量。</li>
<li>可以<strong>在Task中进行访问</strong>。</li>
<li>广播变量只会发送到节点一次，只读。</li>
<li>一种高效地类似BitTorrent的通信机制。</li>
</ul>
<p><strong>使用方法</strong></p>
<ul>
<li>对于一个类型为T的对象，使用<code>SparkContext.broadcast</code>创建一个<code>BroadCast[T]</code>。要可以序列化</li>
<li>通过<code>value</code>属性访问值</li>
<li>变量作为<strong>只读值</strong>会发送到各个节点<strong>一次</strong>，在自己的节点上修改不会影响到其他变量。</li>
</ul>
<h4 id="累加器"><a href="#累加器" class="headerlink" title="累加器"></a>累加器</h4><p><strong>简介</strong></p>
<p>累加器可以把工作节点中的数据聚合到驱动程序中。类似于<code>reduce</code>，但是更简单。常用作对事件进行计数。累加器仅仅通过关联和交换的操作来实现<code>累加</code>。可以有效地支持并行操作。Spark本身支持数值类型的累加器，我们也可以添加新的类型。</p>
<p><strong>用法</strong></p>
<ul>
<li>在驱动器程序中，调用<code>SparkContext.accumulator(initialValue)</code>创建一个有初始值的累加器。返回值为<code>org.apache.spark.Accumulator[T]</code></li>
<li>Spark的闭包里的执行器代码可以用累加器的<code>+=</code>来累加。</li>
<li>驱动器程序中，调用累加器的<code>value</code>属性来访问累加器的值</li>
<li>工作节点上的任务不能访问累加器的值</li>
</ul>
<p><strong>例子</strong></p>
<p>累加空行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">file = sc.textFile(<span class="string">"callsign_file"</span>)</span><br><span class="line"><span class="comment"># 创建累加器Accumulator[Int]并且赋初值0</span></span><br><span class="line">blank_line_count = sc.accumulator(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_callsigns</span><span class="params">(line)</span>:</span></span><br><span class="line">    <span class="string">"""提取callsigns"""</span></span><br><span class="line">    <span class="keyword">global</span> blank_line_count		<span class="comment"># 访问全局变量</span></span><br><span class="line">    <span class="keyword">if</span> line == <span class="string">""</span>:</span><br><span class="line">        blank_line_count += <span class="number">1</span>	<span class="comment"># 累加</span></span><br><span class="line">    <span class="keyword">return</span> line.split(<span class="string">" "</span>)</span><br><span class="line"></span><br><span class="line">callsigns = file.flatMap(extract_callsigns)</span><br><span class="line">callsigns.saveAsTextFile(output_dir + <span class="string">"/callsigns"</span>)</span><br><span class="line"><span class="comment"># 读取累加器的值 由于惰性求值，只有callsigns的action发生后，才能读取到值</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">"Blank lines count: %d"</span> % blank_line_count.value</span><br></pre></td></tr></table></figure>
<p>进行错误计数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建用来验证呼号的累加器</span></span><br><span class="line">valid_signcount = sc.accumulator(<span class="number">0</span>)</span><br><span class="line">invalid_signcount = sc.accumulator(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">valid_datesign</span><span class="params">(sign)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> valid_signcount, invalid_sign_count</span><br><span class="line">    <span class="keyword">if</span> re.match(<span class="string">r"\A\d?[a-zA-Z]&#123;1,2&#125;\d&#123;1,4&#125;[a-zA-Z]&#123;1, 3&#125;\Z"</span>, sign):</span><br><span class="line">        valid_signcount += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line">   	<span class="keyword">else</span>:</span><br><span class="line">        invalid_signcount += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对每个呼号的联系次数进行计数</span></span><br><span class="line">valid_signs = callsigns.filter(valid_datesign)</span><br><span class="line">contact_count = valid_signs.map(<span class="keyword">lambda</span> sign: (sign, <span class="number">1</span>)).reduceByKey(<span class="keyword">lambda</span> (x, y): x+y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 强制求值计算计数</span></span><br><span class="line">contact_count.count()</span><br><span class="line"><span class="keyword">if</span> invalid_signcount.value &lt; <span class="number">0.1</span> * valid_signcount.value:</span><br><span class="line">    contact_count.saveAsTextFile(output_dir + <span class="string">"/contactcount"</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"Too many errors: %d in %d"</span> % (invalid_signcount.value, valid_signcount.value)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sign_prefixes = sc.broadcast(load_callsign_table())</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_sign_count</span><span class="params">(sign_count, sign_prefixes)</span>:</span></span><br><span class="line">    country = lookup_country(sign_count[<span class="number">0</span>], sign_prefixes.value)</span><br><span class="line">    count = sign_count[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> (country, count)</span><br><span class="line"></span><br><span class="line">country_contack_counts =</span><br></pre></td></tr></table></figure>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2018-11-25T08:30:10.981Z" itemprop="dateUpdated">2018-11-25 16:30:10</time>
</span><br>


        
        <br>原始链接：<a href="/2017/03/25/Spark-Programming/" target="_blank" rel="external">http://plmsmile.github.io/2017/03/25/Spark-Programming/</a>
        
    </div>
    
    <footer>
        <a href="http://plmsmile.github.io">
            <img src="/img/avatar.jpg" alt="PLM">
            PLM
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/RDD/">RDD</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/">Spark</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://plmsmile.github.io/2017/03/25/Spark-Programming/&title=《Spark-Programming》 — PLM's Notes&pic=http://plmsmile.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://plmsmile.github.io/2017/03/25/Spark-Programming/&title=《Spark-Programming》 — PLM's Notes&source=NLP, DL, MRC." data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://plmsmile.github.io/2017/03/25/Spark-Programming/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Spark-Programming》 — PLM's Notes&url=http://plmsmile.github.io/2017/03/25/Spark-Programming/&via=http://plmsmile.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://plmsmile.github.io/2017/03/25/Spark-Programming/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2017/04/04/ml-watermelon-chap1/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">机器学习-西瓜书-第一章习题</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2017/03/19/Spark-SQL/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">Spark-SQL</h4>
      </a>
    </div>
  
</nav>



    











    <!-- Valine Comments -->
    <div class="comments vcomment" id="comments"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script>
    <!-- Valine Comments script -->
    <script>
        var GUEST_INFO = ['nick','mail','link'];
        var guest_info = 'nick,mail,link'.split(',').filter(function(item){
          return GUEST_INFO.indexOf(item) > -1
        });
        new Valine({
            el: '#comments',
            notify: 'true' == 'true',
            verify: 'false' == 'true',
            appId: "kR8nND4dcsWgqDWIjpiH4YFj-gzGzoHsz",
            appKey: "il7PLkcJCfDBXMR6XirLdO2K",
            avatar: "mm",
            placeholder: "Just go go",
            guest_info: guest_info.length == 0 ? GUEST_INFO : guest_info,
            pageSize: "10"
        })
    </script>
    <!-- Valine Comments end -->







</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        谢谢大爷~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/img/wechat.png" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check" data-wechat="/img/wechat.png" data-alipay="/img/alipay.png">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <div class="bottom">
        
<p>
    <span id="busuanzi_container_site_uv" style="display:none">
        总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style="display:none">
        总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            <span>
            PLM's Notes &nbsp; &copy; &nbsp
            </span>
            2016 - 2018
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://plmsmile.github.io/2017/03/25/Spark-Programming/&title=《Spark-Programming》 — PLM's Notes&pic=http://plmsmile.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://plmsmile.github.io/2017/03/25/Spark-Programming/&title=《Spark-Programming》 — PLM's Notes&source=NLP, DL, MRC." data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://plmsmile.github.io/2017/03/25/Spark-Programming/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Spark-Programming》 — PLM's Notes&url=http://plmsmile.github.io/2017/03/25/Spark-Programming/&via=http://plmsmile.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://plmsmile.github.io/2017/03/25/Spark-Programming/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACLElEQVR42u3aQU7EMAwF0Ln/pQeJFRJq+bYDosnrqqLVNC8L49h+veLr/Xl9vb+6vr/T++XXb1wYGBiPZeTLShaR3N//cnXLMDAwzmFUQ2FvKfly87VhYGBgJO8ki0iCJgYGBsaqgJsvNE8i81COgYFxMiMvn1U/eZ8+Vr+74CyOgYHxQEavMfA397/e38DAwPj3jHfxyg+0ydNqeL1cFQYGxtaMpKyf/z0/4lYLdlE4xsDAOICRH1nnDYDq4EW00RgYGJsy8s9Xm47VtDIJ65crwcDAOIaRp3qTcFwdvIhSTAwMjGMYvRQteZq/3zv0YmBg7M2oJnNJeJ2E5ryFcHmUxcDA2JqxduQiCcG91LCc52JgYDycsapwXx2nyCe7ol/GwMA4gDEZ6sp5a8MuBgbGOYxeOhhNcLTCdz6yVgBgYGBsx+gFx2qhP2+ONgMuBgbGRozqAFbvY5ONKDQvMTAwtmZMQuekWJZvzQ8ZIAYGxtaMPLT12pzzN5OwjoGBsTcjaQbkIxd5qW5BMM0rcBgYGFsw5ilg72jaa1hGZ3EMDIyNGNWDa15ES9qc5W7q/UowMDA2ZbyL19ojaP4UAwPjZMY8Wt9/bO1/hmbtEAMDYwvGZISi2n9I3mz2NDAwMA5g5GX9tYfSXiC+DLgYGBjHM+bFtV7ZLmo2YGBgYBSHKuZJYXVTMDAwTmBUw9y8kdnbvmjYAgMDYztG7wC5CjApvY36GxgYGM9gfADsx0HPKm1vJgAAAABJRU5ErkJggg==" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


</script>

<script src="/js/main.min.js?v=1.7.2"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="/js/search.min.js?v=1.7.2" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>




<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>

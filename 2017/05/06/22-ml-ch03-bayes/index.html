<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>朴素贝叶斯算法及其代码实现 | PLM&#39;s Notes | 好好学习，天天笔记</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="机器学习,朴素贝叶斯">
    <meta name="description" content="先介绍了朴素贝叶斯思想理论，然后用朴素贝叶斯代码实现垃圾邮件分类">
<meta name="keywords" content="机器学习,朴素贝叶斯">
<meta property="og:type" content="article">
<meta property="og:title" content="朴素贝叶斯算法及其代码实现">
<meta property="og:url" content="http://plmsmile.github.io/2017/05/06/22-ml-ch03-bayes/index.html">
<meta property="og:site_name" content="PLM&#39;s Notes">
<meta property="og:description" content="先介绍了朴素贝叶斯思想理论，然后用朴素贝叶斯代码实现垃圾邮件分类">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2018-12-13T09:23:27.147Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="朴素贝叶斯算法及其代码实现">
<meta name="twitter:description" content="先介绍了朴素贝叶斯思想理论，然后用朴素贝叶斯代码实现垃圾邮件分类">
    
        <link rel="alternate" type="application/atom+xml" title="PLM&#39;s Notes" href="/atom.xml">
    
    <link rel="shortcut icon" href="/img/favicon.png">
    <link rel="stylesheet" href="/css/style.css?v=1.7.2">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide">
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">PLM</h5>
          <a href="mailto:plmsmile@126.com" title="plmsmile@126.com" class="mail">plmsmile@126.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/">
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives/">
                <i class="icon icon-lg icon-archives"></i>
                归档
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags/">
                <i class="icon icon-lg icon-tags"></i>
                标签
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories/">
                <i class="icon icon-lg icon-th-list"></i>
                类别
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/about/">
                <i class="icon icon-lg icon-user"></i>
                关于我
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/plmsmile" target="_blank">
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">朴素贝叶斯算法及其代码实现</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">朴素贝叶斯算法及其代码实现</h1>
        <h5 class="subtitle">
            
                <time datetime="2017-05-06T06:36:58.000Z" itemprop="datePublished" class="page-time">
  2017-05-06
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/机器学习/">机器学习</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#条件概率"><span class="post-toc-number">1.</span> <span class="post-toc-text">条件概率</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#基础知识"><span class="post-toc-number">1.1.</span> <span class="post-toc-text">基础知识</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#条件概率分类"><span class="post-toc-number">1.2.</span> <span class="post-toc-text">条件概率分类</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#朴素贝叶斯文档分类"><span class="post-toc-number">1.3.</span> <span class="post-toc-text">朴素贝叶斯文档分类</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#程序实现"><span class="post-toc-number">2.</span> <span class="post-toc-text">程序实现</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#加载数据"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">加载数据</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#划分数据集"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">划分数据集</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#获得训练矩阵"><span class="post-toc-number">2.3.</span> <span class="post-toc-text">获得训练矩阵</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#贝叶斯算法"><span class="post-toc-number">2.4.</span> <span class="post-toc-text">贝叶斯算法</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#测试数据"><span class="post-toc-number">2.5.</span> <span class="post-toc-text">测试数据</span></a></li></ol></li></ol>
        </nav>
    </aside>


<article id="post-22-ml-ch03-bayes" class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">朴素贝叶斯算法及其代码实现</h1>
        <div class="post-meta">
            <time class="post-time" title="2017-05-06 14:36:58" datetime="2017-05-06T06:36:58.000Z" itemprop="datePublished">2017-05-06</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/机器学习/">机器学习</a></li></ul>



            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style="display:none">
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <blockquote>
<p>先介绍了朴素贝叶斯思想理论，然后用朴素贝叶斯代码实现垃圾邮件分类</p>
</blockquote>
<a id="more"></a>
<h2 id="条件概率">条件概率</h2>
<h3 id="基础知识">基础知识</h3>
<p><strong>条件概率</strong></p>
<p>在<span class="math inline">\(B\)</span>发生的情况下<span class="math inline">\(A\)</span>的概率$ $</p>
<p>​ <span class="math inline">\(P(A|B) = \frac{P(AB)}{P(B)}\)</span></p>
<p>​ <span class="math inline">\(P(c_i|x)=\frac{P(c_ix)}{P(x)}\)</span>。<span class="math inline">\(c_i\)</span>是类别，<span class="math inline">\(x\)</span>是一个向量。<span class="math inline">\(x\)</span>属于类别<span class="math inline">\(c_i\)</span>的概率。</p>
<p><strong>贝叶斯准则</strong></p>
<p>交换条件概率中的条件与结果，得到想要的值。</p>
<p><span class="math inline">\(P(A|B) = \frac{P(AB)}{P(B)}\)</span>, <span class="math inline">\(P(B|A) = \frac{P(AB)}{P(A)}\)</span> <span class="math inline">\(\to\)</span> <span class="math inline">\(P(B|A)=\frac{P(A|B)P(B)}{P(A)}\)</span></p>
<p>所以可以得到<span class="math inline">\(\color{red}{P(c_i|x)}=\frac{P(x|c_i)P(c_i)}{P(x)}\)</span></p>
<h3 id="条件概率分类">条件概率分类</h3>
<p><strong>贝叶斯决策理论</strong></p>
<p>计算两个概率<span class="math inline">\(x\)</span>属于类别1和类别2的概率<span class="math inline">\(p_1(x)\)</span>和<span class="math inline">\(p_2(x)\)</span>。</p>
<ul>
<li>如果<span class="math inline">\(p_1(x) &gt; p_2(x)\)</span>，则<span class="math inline">\(x\)</span>属于类别1</li>
<li>如果<span class="math inline">\(p_2(x) &gt; p_1(x)\)</span>，则<span class="math inline">\(x\)</span>属于类别2</li>
</ul>
<p><strong>贝叶斯准则</strong></p>
<p><span class="math inline">\(x\)</span>属于类别<span class="math inline">\(c_i\)</span>的概率是<span class="math inline">\(\color{red}{P(c_i|x)}\)</span>。</p>
<ul>
<li>如果<span class="math inline">\(P(c_1|x) &gt; P(c_2|x)\)</span>，则<span class="math inline">\(x\)</span>属于<span class="math inline">\(c_1\)</span></li>
<li>如果<span class="math inline">\(P(c_2|x) &gt; P(c_1|x)\)</span>，则<span class="math inline">\(x\)</span>属于<span class="math inline">\(c_2\)</span></li>
</ul>
<h3 id="朴素贝叶斯文档分类">朴素贝叶斯文档分类</h3>
<p><strong>简介</strong></p>
<p>机器学习的一个重要应用就是<code>文档的自动分类</code>。我们可以观察文档中出现的词，并把<code>每个词出现与否</code>或者<code>出现次数</code>作为一个<strong>特征</strong>。<code>朴素贝叶斯</code>就是用于文档分类的常用算法，当然它可以用于任意场景的分类。</p>
<p>向量<span class="math inline">\(\color{red}{\vec{w}}={(w_1,w_2,...,w_n)}\)</span>代表一篇<strong>文章</strong>。其中<span class="math inline">\(w_i=0,1\)</span>，代表<code>词汇表</code>中第<span class="math inline">\(i\)</span>个词汇出现与否。词汇表是指一个总体的全局词汇表。文章<span class="math inline">\(\vec{w}\)</span>属于第<span class="math inline">\(i\)</span>类的概率<span class="math inline">\(\color{red}{P(c_i|\vec{w})}=\frac{P(\vec{w}|c_i)P(c_i)}{P(\vec{w})}\)</span>。</p>
<p>朴素贝叶斯分类器的两个假设：</p>
<ul>
<li>特征之间相互独立</li>
<li>每个特征同等重要</li>
</ul>
<p>尽管这有瑕疵，但是朴素贝叶斯的实际效果却很好了。</p>
<p>朴素贝叶斯分类器的两种实现：</p>
<ul>
<li>伯努利模型：只考虑出现或者不出现</li>
<li>多项式模型：考虑词在文档中的出现次数</li>
</ul>
<p>文档分类中的<code>独立</code>：每个单词出现的可能性和其他单词没有关系。独立的好处在下面概率计算中会体现出来。</p>
<p><strong>概率计算</strong></p>
<p>对每一个文章的各个分类概率计算，其实只需要计算上式的分母就行了。</p>
<p>对于<span class="math inline">\(P(c_i)=\frac{c_i数量}{总数量}\)</span>，即<span class="math inline">\(c_i\)</span>类文章的数量除以所有类别的文章的总数量。</p>
<p>对于<span class="math inline">\(P(\vec{w}|c_i)\)</span>，要稍微复杂一些。由于各个特征（单词出现否）独立，则有如下推导公式：</p>
<p><span class="math display">\[P(\vec{w}|c_i)=P(w_1,w_2,...,w_n|c_i)=P(w_1|c_i)P(w_2|c_i)\cdots P(w_n|c_i)\]</span></p>
<p>其中<span class="math inline">\(\color{red}{P(w_i|c_i)}\)</span>代表<strong>第<span class="math inline">\(i\)</span>个单词</strong>在<strong><span class="math inline">\(c_i\)</span>类别文章的总词汇</strong>里出现的<strong>概率</strong>。</p>
<p>实际操作的一个小技巧，由于概率都很小多个<strong>小值做乘法</strong>会导致<strong>下溢出</strong>，所以决定对概率<strong>取对数做加法</strong>，最后再比较对数的大小。</p>
<p><span class="math display">\[\ln(P(\vec{w}|c_i))=\ln(P(w_1|c_i))+\ln(P(w_2|c_i))+\dots+\ln(P(w_n|c_i))\]</span></p>
<p>如上，可以求得每个单词在各个类别文章里出现的概率。用<span class="math inline">\(\color{red}{\vec{wp_0}}\)</span>、<span class="math inline">\(\color{red}{\vec{wp_1}}\)</span>来分别表示所有单词在类别0、类别1中总词汇中的概率。当然，在程序中实际上这个概率是取对数了的。</p>
<p>当要求一篇新的文章<span class="math inline">\(\color{red}{\vec{w}}={(0,1,0,0,\dots)}\)</span>，此时为出现或者不出现，当然也可以统计出现次数，属于哪个类别的时候，要先求出<span class="math inline">\(\color{red}{P(w|c_0)}\)</span>和<span class="math inline">\(\color{red}{P(w|c_1)}\)</span>，然后根据贝叶斯准则选择<strong>概率大的分类为结果</strong>。</p>
<p><span class="math display">\[P(w|c_0)=\vec{w}\cdot\vec{wp_0}, P(w|c_1)=\vec{w}\cdot\vec{wp_1}\]</span></p>
<h2 id="程序实现">程序实现</h2>
<p>朴素贝叶斯的实例应有很多，这里主要是介绍<code>垃圾邮件分类</code>。数据集中的邮件有两种：垃圾邮件和正常邮件。每个类型都有25个样本，一共是50个样本。我们对数据集进行划分为训练集和测试集。训练集用来训练获得<span class="math inline">\(\vec{wp_0}\)</span>、<span class="math inline">\(\vec{wp_1}\)</span>和<span class="math inline">\(p(c_1)\)</span>。然后用测试集去进行朴素贝叶斯分类，计算错误率，查看效果。</p>
<h3 id="加载数据">加载数据</h3>
<p>数据是存放在两个文件夹中的，以txt格式的形式存储。取出来后要进行单词切割。然后得到邮件列表email_list和它对应的分类列表class_list。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_str</span><span class="params">(big_str)</span>:</span></span><br><span class="line">    <span class="string">''' 解析文本为单词列表</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        big_str: 长文本</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        单词列表</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment"># 以任何非单词字符切割</span></span><br><span class="line">    word_list = re.split(<span class="string">r'\W*'</span>, big_str)</span><br><span class="line">    <span class="comment"># 只保留长度大于3的单词，并且全部转化为小写</span></span><br><span class="line">    <span class="keyword">return</span> [word.lower() <span class="keyword">for</span> word <span class="keyword">in</span> word_list <span class="keyword">if</span> len(word) &gt; <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_dataset</span><span class="params">(spam_dir, ham_dir)</span>:</span></span><br><span class="line">    <span class="string">''' 从文件夹中加载文件</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        spam_dir: 垃圾邮件文件夹</span></span><br><span class="line"><span class="string">        ham_dir: 正常邮件文件夹</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        email_list: 邮件列表</span></span><br><span class="line"><span class="string">        class_list: 分类好的列表</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    email_list = []</span><br><span class="line">    class_list = []</span><br><span class="line">    txt_num = <span class="number">25</span>    <span class="comment"># 每个文件夹有25个文件</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, txt_num + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">            file_dir = spam_dir <span class="keyword">if</span> j == <span class="number">1</span> <span class="keyword">else</span> ham_dir</span><br><span class="line">            f = open((<span class="string">'&#123;&#125;/&#123;&#125;.txt'</span>).format(file_dir, i))</span><br><span class="line">            f_str = f.read()</span><br><span class="line">            f.close()</span><br><span class="line">            words = parse_str(f_str)</span><br><span class="line">            email_list.append(words)    <span class="comment"># 邮件列表</span></span><br><span class="line">            class_list.append(j)        <span class="comment"># 分类标签，1垃圾邮件，0非垃圾邮件</span></span><br><span class="line">    <span class="keyword">return</span> email_list, class_list</span><br></pre></td></tr></table></figure>
<h3 id="划分数据集">划分数据集</h3>
<p>由于前面email_list包含所有的邮件，下标是从0-49，所以我们划分数据集只需要获得对应的索引集合就可以了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_train_test_indices</span><span class="params">(data_num)</span>:</span></span><br><span class="line">    <span class="string">''' 划分训练集和测试集</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        data_num: 数据集的数量</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        train_indices: 训练集的索引列表</span></span><br><span class="line"><span class="string">        test_indices: 测试集的索引列表</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    train_indices = range(data_num)</span><br><span class="line">    test_ratio = <span class="number">0.3</span>        <span class="comment"># 测试数据的比例</span></span><br><span class="line">    test_num = int(data_num * test_ratio)</span><br><span class="line">    test_indices = random.sample(train_indices, test_num)	<span class="comment"># 随机抽样选择</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> test_indices:</span><br><span class="line">        train_indices.remove(i)</span><br><span class="line">    <span class="keyword">return</span> train_indices, test_indices</span><br></pre></td></tr></table></figure>
<h3 id="获得训练矩阵">获得训练矩阵</h3>
<p>获得训练数据之后，要把训练数据转化为训练矩阵。</p>
<p><strong>获得所有的词汇</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_vocab_list</span><span class="params">(post_list)</span>:</span></span><br><span class="line">    <span class="string">''' 从数据集中获取所有的不重复的词汇列表</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        post_list: 多个文章的列表，一篇文章：由单词组成的list</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        vocab_list: 单词列表</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    vocab_set = set([])</span><br><span class="line">    <span class="keyword">for</span> post <span class="keyword">in</span> post_list:</span><br><span class="line">        vocab_set = vocab_set | set(post)</span><br><span class="line">    <span class="keyword">return</span> list(vocab_set)</span><br></pre></td></tr></table></figure>
<p><strong>获得一篇文章的文档向量</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_doc_vec</span><span class="params">(doc, vocab_list, is_bag = False)</span>:</span></span><br><span class="line">    <span class="string">''' 获得一篇doc的文档向量</span></span><br><span class="line"><span class="string">    词集模型：每个词出现为1，不出现为0。每个词出现1次</span></span><br><span class="line"><span class="string">    词袋模型：每个词出现次数，可以多次出现。</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        vocab_list: 总的词汇表</span></span><br><span class="line"><span class="string">        doc: 一篇文档，由word组成的list</span></span><br><span class="line"><span class="string">        is_bag: 是否是词袋模型，默认为Fasle</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        doc_vec: 文档向量，1出现，0未出现</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    doc_vec = [<span class="number">0</span>] * len(vocab_list)</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> doc:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> vocab_list:</span><br><span class="line">            idx = vocab_list.index(word)</span><br><span class="line">            <span class="keyword">if</span> is_bag == <span class="keyword">False</span>:         <span class="comment"># 词集模型</span></span><br><span class="line">                doc_vec[idx] = <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                doc_vec[idx] += <span class="number">1</span>       <span class="comment"># 词袋模型</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">print</span> <span class="string">'词汇表中没有 %s '</span> % word</span><br><span class="line">    <span class="keyword">return</span> doc_vec</span><br></pre></td></tr></table></figure>
<p><strong>获得训练矩阵</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">go_bayes_email</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">''' 贝叶斯垃圾邮件过滤主程序</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        error_rate: 错误率</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment"># 源数据</span></span><br><span class="line">    email_list, class_list = load_dataset(<span class="string">'email/spam'</span>, <span class="string">'email/ham'</span>)</span><br><span class="line">    <span class="comment"># 总的词汇表</span></span><br><span class="line">    vocab_list = bys.get_vocab_list(email_list)</span><br><span class="line">    <span class="comment"># 训练数据，测试数据的索引列表</span></span><br><span class="line">    data_num = len(email_list)</span><br><span class="line">    train_indices, test_indices = get_train_test_indices(data_num)</span><br><span class="line">    <span class="comment"># 训练数据的矩阵和分类列表</span></span><br><span class="line">    train_mat = []</span><br><span class="line">    train_class = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> train_indices:</span><br><span class="line">        vec = bys.get_doc_vec(email_list[i], vocab_list)</span><br><span class="line">        train_mat.append(vec)</span><br><span class="line">        train_class.append(class_list[i])</span><br><span class="line">    <span class="comment"># 后续还有训练数据和测试数据，在下文给出</span></span><br></pre></td></tr></table></figure>
<h3 id="贝叶斯算法">贝叶斯算法</h3>
<p><strong>贝叶斯训练算法</strong></p>
<p>通过训练数据去计算上文提到的<span class="math inline">\(\vec{wp_0}\)</span>、<span class="math inline">\(\vec{wp_1}\)</span>和<span class="math inline">\(p(c_1)\)</span>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_nb0</span><span class="params">(train_mat, class_list)</span>:</span></span><br><span class="line">    <span class="string">''' 朴素贝叶斯训练算法，二分类问题</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        train_mat: 训练矩阵，文档向量组成的矩阵</span></span><br><span class="line"><span class="string">        class_list: 每一篇文档对应的分类结果</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        p0_vec: c0中各个word占c0总词汇的概率</span></span><br><span class="line"><span class="string">        p1_vec: c1中各个word占c1总词汇的概率</span></span><br><span class="line"><span class="string">        p1: 文章是c1的概率</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment"># 文档数目，单词数目</span></span><br><span class="line">    doc_num = len(train_mat)</span><br><span class="line">    word_num = len(train_mat[<span class="number">0</span>])</span><br><span class="line">    <span class="comment"># 两个类别的总单词数量</span></span><br><span class="line">    c0_word_count = <span class="number">2.0</span></span><br><span class="line">    c1_word_count = <span class="number">2.0</span></span><br><span class="line">    <span class="comment"># 向量累加</span></span><br><span class="line">    c0_vec_sum = np.ones(word_num)</span><br><span class="line">    c1_vec_sum = np.ones(word_num)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(doc_num):</span><br><span class="line">        <span class="keyword">if</span> class_list[i] == <span class="number">0</span>:</span><br><span class="line">            c0_word_count += sum(train_mat[i])</span><br><span class="line">            c0_vec_sum += train_mat[i]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            c1_word_count += sum(train_mat[i])</span><br><span class="line">            c1_vec_sum += train_mat[i]</span><br><span class="line">    c1_num = sum(class_list)</span><br><span class="line">    p1 = c1_num / float(doc_num)</span><br><span class="line">    p0_vec = c0_vec_sum / c0_word_count</span><br><span class="line">    p1_vec = c1_vec_sum / c1_word_count</span><br><span class="line">    <span class="comment"># 由于后面做乘法会下溢出，所以取对数做加法</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(word_num):</span><br><span class="line">        p0_vec[i] = math.log(p0_vec[i])</span><br><span class="line">        p1_vec[i] = math.log(p1_vec[i])</span><br><span class="line">    <span class="keyword">return</span> p0_vec, p1_vec, p1</span><br></pre></td></tr></table></figure>
<p><strong>贝叶斯分类</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify_nb</span><span class="params">(w_vec, p0_vec, p1_vec, p1)</span>:</span></span><br><span class="line">    <span class="string">''' 使用朴素贝叶斯分类</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        w_vec: 要测试的向量</span></span><br><span class="line"><span class="string">        p0_vec: c0中所有词汇占c0的总词汇的概率</span></span><br><span class="line"><span class="string">        p1_vec: c1中所有词汇占c1的总词汇的概率</span></span><br><span class="line"><span class="string">        p1: 文章为类型1的概率，即P(c1)</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment"># P(w|c0)*P(c0) = P(w1|c0)*...*P(wn|c0)*P(c0)</span></span><br><span class="line">    <span class="comment"># 由于下溢出，所以上文取了对数，来做加法</span></span><br><span class="line">    w_p0 = sum(w_vec * p0_vec) + math.log(<span class="number">1</span> - p1)</span><br><span class="line">    w_p1 = sum(w_vec * p1_vec) + math.log(p1)</span><br><span class="line">    <span class="keyword">if</span> w_p0 &gt; w_p1:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p><strong>训练数据</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p0_vec, p1_vec, p1 = bys.train_nb0(train_mat, train_class)</span><br></pre></td></tr></table></figure>
<h3 id="测试数据">测试数据</h3>
<p><strong>一次执行</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">go_bayes_email</span><span class="params">()</span>:</span></span><br><span class="line">	<span class="comment"># 此处省略上文的部分内容</span></span><br><span class="line">    <span class="comment"># 训练数据</span></span><br><span class="line">    p0_vec, p1_vec, p1 = bys.train_nb0(train_mat, train_class)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 测试数据</span></span><br><span class="line">    error_count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> test_indices:</span><br><span class="line">        vec = bys.get_doc_vec(email_list[i], vocab_list)</span><br><span class="line">        res = bys.classify_nb(vec, p0_vec, p1_vec, p1)</span><br><span class="line">        <span class="keyword">if</span> res != class_list[i]:</span><br><span class="line">            error_count += <span class="number">1</span></span><br><span class="line">    error_rate = error_count / float(data_num)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'error=%d, rate=%s, test=%d, all=%d'</span> % (error_count, error_rate, len(test_indices),</span><br><span class="line">                    data_num)</span><br><span class="line">    <span class="keyword">return</span> error_rate</span><br></pre></td></tr></table></figure>
<p><strong>多次执行，取平均值</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_bayes_email</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">''' 执行多次go_bayes_email，计算平均错误率 '''</span></span><br><span class="line">    times = <span class="number">100</span></span><br><span class="line">    error_rate_sum = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        error_rate_sum += go_bayes_email()</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'average_rate = %s'</span> % (error_rate_sum / <span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p><a href="https://github.com/plmsmile/study/blob/master/ml/ch04-bayes/filter_email.py" target="_blank" rel="noopener">源代码</a></p>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2018-12-13T09:23:27.147Z" itemprop="dateUpdated">2018-12-13 17:23:27</time>
</span><br>


        
        <br>原始链接：<a href="/2017/05/06/22-ml-ch03-bayes/" target="_blank" rel="external">http://plmsmile.github.io/2017/05/06/22-ml-ch03-bayes/</a>
        
    </div>
    
    <footer>
        <a href="http://plmsmile.github.io">
            <img src="/img/avatar.jpg" alt="PLM">
            PLM
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/朴素贝叶斯/">朴素贝叶斯</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://plmsmile.github.io/2017/05/06/22-ml-ch03-bayes/&title=《朴素贝叶斯算法及其代码实现》 — PLM's Notes&pic=http://plmsmile.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://plmsmile.github.io/2017/05/06/22-ml-ch03-bayes/&title=《朴素贝叶斯算法及其代码实现》 — PLM's Notes&source=
先介绍了朴素贝叶斯思想理论，然后用朴素贝叶斯代码实现垃圾邮件分类
" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://plmsmile.github.io/2017/05/06/22-ml-ch03-bayes/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《朴素贝叶斯算法及其代码实现》 — PLM's Notes&url=http://plmsmile.github.io/2017/05/06/22-ml-ch03-bayes/&via=http://plmsmile.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://plmsmile.github.io/2017/05/06/22-ml-ch03-bayes/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2017/07/14/word2vec/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">利用tensorflow实现简版word2vec</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2017/04/15/20-numpy/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">NumPy</h4>
      </a>
    </div>
  
</nav>



    











    <!-- Valine Comments -->
    <div class="comments vcomment" id="comments"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script>
    <!-- Valine Comments script -->
    <script>
        var GUEST_INFO = ['nick','mail','link'];
        var guest_info = 'nick,mail,link'.split(',').filter(function(item){
          return GUEST_INFO.indexOf(item) > -1
        });
        new Valine({
            el: '#comments',
            notify: 'true' == 'true',
            verify: 'false' == 'true',
            appId: "kR8nND4dcsWgqDWIjpiH4YFj-gzGzoHsz",
            appKey: "il7PLkcJCfDBXMR6XirLdO2K",
            avatar: "retro",
            placeholder: "快来评论吧！",
            guest_info: guest_info.length == 0 ? GUEST_INFO : guest_info,
            pageSize: "10"
        })
    </script>
    <!-- Valine Comments end -->







</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        谢谢大爷~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/img/wechat.png" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check" data-wechat="/img/wechat.png" data-alipay="/img/alipay.png">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <div class="bottom">
        
<p>
    <span id="busuanzi_container_site_uv" style="display:none">
        总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style="display:none">
        总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            <span>
            PLM's Notes &nbsp; &copy; &nbsp
            </span>
            2016 - 2018
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://plmsmile.github.io/2017/05/06/22-ml-ch03-bayes/&title=《朴素贝叶斯算法及其代码实现》 — PLM's Notes&pic=http://plmsmile.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://plmsmile.github.io/2017/05/06/22-ml-ch03-bayes/&title=《朴素贝叶斯算法及其代码实现》 — PLM's Notes&source=
先介绍了朴素贝叶斯思想理论，然后用朴素贝叶斯代码实现垃圾邮件分类
" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://plmsmile.github.io/2017/05/06/22-ml-ch03-bayes/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《朴素贝叶斯算法及其代码实现》 — PLM's Notes&url=http://plmsmile.github.io/2017/05/06/22-ml-ch03-bayes/&via=http://plmsmile.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://plmsmile.github.io/2017/05/06/22-ml-ch03-bayes/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACNElEQVR42u3aO27DMBBFUe9/007rwiLum2EMcHhVCbAU8qhg5vd64ev9cT39+vT8+q3PX9fPb7hkyJBxLOO9vGqM9Vpkdb43GTJk3MNYL/l0T95aL/+0db43GTJkyKjdp0iyrgwZMmSkDH501lJfGTJkyKglsWnKytPdn+biMmTIOJCRLv/L+3/pb8iQIeMoxju8OI+HerxV8LgrGTJkjGakZTK+iV0Hd7AfGTJkDGWQhJCnnbVUMz2yvzwpQ4aM0Yz+YbpuA6wLZ/xzoOaEDBkyRjPSkQge0qWjsbyFiYJIGTJkDGL0/wTZImlY8l9lyJBxD4NsdFugFvYieaIrQ4aM2Yw0ZuRHMz98ySeLSTJkyBjN6BymnaOZJ7rbym0yZMg4hMFbj52hCp70pq3ToKonQ4aMEQzyAgd3hi3STyZDhowbGPyIrLUw+VBFuocvjQEZMmSMY+xtD6QNyFqTQIYMGTcz+mlqCuMhJvpMMmTIGM1Ig7l0eKIzWrFOp+PMWIYMGccyeIJKvkc/Ga5V0mTIkHEDY1cbgJfYeBkOsWXIkHEBo1Ys4wNkcZSa9itlyJAxlPEOr7ToFhf3wT+AoHchQ4aMEYz0mAtGH3Aiyp/nK8qQIWMeo5NAdtJUPt4R9DRkyJAxmtEpyqdhZSfsQwMWMmTIuJ5RG7+opcHFOpwMGTJkNI7U9C0egMqQIeMGBk9EeRrMA0Ge3G4ot8mQIeNARm3EoTZ4kRbdNo9ryJAh4zzGHzV8LLp+CW/iAAAAAElFTkSuQmCC" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


</script>

<script src="/js/main.min.js?v=1.7.2"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="/js/search.min.js?v=1.7.2" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>




<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>

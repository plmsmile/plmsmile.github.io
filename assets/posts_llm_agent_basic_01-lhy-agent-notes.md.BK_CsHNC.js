import{_ as t,c as l,o as a,ah as n,j as i}from"./chunks/framework.CvbyeFFO.js";const m=JSON.parse('{"title":"Agent基础概念 (李宏毅笔记)","description":"","frontmatter":{"title":"Agent基础概念 (李宏毅笔记)","date":"2025-05-13T14:44:04.000Z","create":"2025-05-13T14:44:00.000Z","categories":["agent"],"tags":["agent","function call","tool use","memory","planning","reasonning"]},"headers":[],"relativePath":"posts/llm/agent/basic/01-lhy-agent-notes.md","filePath":"posts/llm/agent/basic/01-lhy-agent-notes.md","lastUpdated":1753200077000}'),o={name:"posts/llm/agent/basic/01-lhy-agent-notes.md"};function r(s,e,c,g,d,h){return a(),l("div",null,e[0]||(e[0]=[n('<div class="custom-block tip"><div class="custom-block-title">本文关键点</div><p>学习李宏毅老师agent课程的笔记。</p><ol><li>Agent 构建、应用</li><li>Agent Memory、调整行为</li><li>Agent 使用工具</li><li>Agent Plan 能力及强化</li></ol></div><h2 id="ai-agent-基础" tabindex="-1">AI Agent 基础 <a class="header-anchor" href="#ai-agent-基础" aria-label="Permalink to &quot;AI Agent 基础&quot;">​</a></h2><h3 id="什么是-agent" tabindex="-1">什么是 Agent <a class="header-anchor" href="#什么是-agent" aria-label="Permalink to &quot;什么是 Agent&quot;">​</a></h3><p>类似于RL，人类给定Goal，期望Agent能自主完成任务。</p><ul><li>Agent <code>观察环境</code></li><li>Agent <code>执行Action</code></li><li><code>不断循环，直到完成任务</code></li></ul><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513201053.jpg" style="display:block;margin:auto;" width="80%"><h3 id="agency-level-hf定义" tabindex="-1">Agency Level (HF定义) <a class="header-anchor" href="#agency-level-hf定义" aria-label="Permalink to &quot;Agency Level (HF定义)&quot;">​</a></h3><blockquote><p><a href="https://huggingface.co/docs/smolagents/conceptual_guides/intro_agents" target="_blank" rel="noreferrer">Introduction to Agents</a></p><p>AI Agents are <strong>programs where LLM outputs control the workflow</strong>.</p></blockquote><table tabindex="0"><thead><tr><th style="text-align:center;">Agency Level</th><th style="text-align:center;">Description</th><th style="text-align:center;">Short name</th><th style="text-align:center;">Example Code</th></tr></thead><tbody><tr><td style="text-align:center;">☆☆☆</td><td style="text-align:center;">模型输出和流程无关</td><td style="text-align:center;">Simple processor</td><td style="text-align:center;"><code>process_llm_output(llm_response)</code></td></tr><tr><td style="text-align:center;">★☆☆</td><td style="text-align:center;">输出简单的if else</td><td style="text-align:center;">Router</td><td style="text-align:center;"><code>if llm_decision(): path_a() else: path_b()</code></td></tr><tr><td style="text-align:center;">★★☆</td><td style="text-align:center;">LLM output controls <mark>函数执行</mark></td><td style="text-align:center;">Tool call</td><td style="text-align:center;"><code>run_function(llm_chosen_tool, llm_chosen_args)</code></td></tr><tr><td style="text-align:center;">★★☆</td><td style="text-align:center;">LLM output controls <mark>iteration and program continuation</mark></td><td style="text-align:center;">Multi-step Agent</td><td style="text-align:center;"><code>while llm_should_continue(): execute_next_step()</code></td></tr><tr><td style="text-align:center;">★★★</td><td style="text-align:center;">One agentic workflow can <mark>start another agentic workflow</mark></td><td style="text-align:center;">Multi-Agent</td><td style="text-align:center;"><code>if llm_trigger(): execute_agent()</code></td></tr><tr><td style="text-align:center;">★★★</td><td style="text-align:center;">LLM acts in code, <mark>can define its own tools / start other agents</mark></td><td style="text-align:center;">Code Agents</td><td style="text-align:center;"><code>def custom_tool(args): ...</code></td></tr></tbody></table><h3 id="如何构建-agent-llm-agent" tabindex="-1">如何构建 Agent (LLM Agent) <a class="header-anchor" href="#如何构建-agent-llm-agent" aria-label="Permalink to &quot;如何构建 Agent (LLM Agent)&quot;">​</a></h3><p>直接使用 <code>LLM</code>来构建Agent</p><ul><li>做接龙游戏，<span class="marker-evy">goal, obs1, action1, obs2, action2, obs3, action3...</span></li><li>相比于传统AlphaGo类似专有Agent，<span class="marker-evy">LLM近乎无限可能，能用工具、做很多事情</span></li></ul><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513201500.jpg" style="display:block;margin:auto;" width="80%"><p><strong>需要解决的问题</strong></p><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513201527.jpg" style="display:block;margin:auto;" width="80%"><p><strong>优势</strong>：<code>无限可能</code></p><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513202443.jpg" style="display:block;margin:auto;" width="70%"><h3 id="agent-应用" tabindex="-1">Agent 应用 <a class="header-anchor" href="#agent-应用" aria-label="Permalink to &quot;Agent 应用&quot;">​</a></h3><p>包括NPC、购物、训模型、做报告、上网操作电脑等等。</p><ul><li><p>NPC</p><ul><li><a href="https://youtu.be/G44Lkj7XDsA?si=cMbKG3tqPbIgnnBq" target="_blank" rel="noreferrer">(2304)村民NPC</a></li><li><a href="https://www.youtube.com/watch?v=2tbaCn0Kl90" target="_blank" rel="noreferrer">Minecraft</a></li></ul></li><li><p>操作电脑</p><ul><li>购物</li><li>(2017)Web-Based Agents</li><li><a href="https://arxiv.org/abs/2306.06070" target="_blank" rel="noreferrer">(2306)Mind2Web</a>、<a href="https://arxiv.org/abs/2307.13854" target="_blank" rel="noreferrer">(2307)WebArena</a>、<a href="https://arxiv.org/abs/2401.13649" target="_blank" rel="noreferrer">(2401)VisualWebArena</a></li></ul><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513224643.jpg" style="display:block;margin:auto;" width="80%"></li><li><p>训练模型</p><ul><li><a href="https://arxiv.org/abs/2502.13138" target="_blank" rel="noreferrer">(2502)AIDE: The Machine Learning Engineer Agent</a></li><li><a href="https://arxiv.org/abs/2410.20424" target="_blank" rel="noreferrer">(2410)AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions</a></li></ul></li><li><p>做研究</p><ul><li>谷歌：<a href="https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/" target="_blank" rel="noreferrer">Accelerating scientific breakthroughs with an AI co-scientist</a></li></ul><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513224705.jpg" style="display:block;margin:auto;" width="80%"></li><li><p>迈向更加实时交互的应用</p><ul><li>由回合制互动 -&gt; <code>及时互动</code></li></ul><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513224737.jpg" style="display:block;margin:auto;" width="80%"></li></ul><h2 id="agent-根据经验来调整行为" tabindex="-1">Agent 根据经验来调整行为 <a class="header-anchor" href="#agent-根据经验来调整行为" aria-label="Permalink to &quot;Agent 根据经验来调整行为&quot;">​</a></h2><p>按照是否微调模型，可以分为 <code>微调模型(如RL/SFT)</code>和 <code>不微调模型</code>两种，本节聚焦在后者。</p><h3 id="整体思路" tabindex="-1">整体思路 <a class="header-anchor" href="#整体思路" aria-label="Permalink to &quot;整体思路&quot;">​</a></h3><p>Agent检索历史Memory来调整当前的行为。</p><ul><li><code>经验(memory)</code>主要来自自身，外部也可以(RAG)。</li><li>Agent可以有 <code>write模块</code>，来决定当前经验是否存下来。</li><li>Agent可以有 <code>read模块</code>，检索经验来做指导。检索就是一个 <code>RAG</code>。</li><li>Agent可以有 <code>reflection模块</code>，对检索来的经验做 <code>总结汇总</code>，<code>得到更好的经验和想法</code></li></ul><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513231147.jpg" style="display:block;margin:auto;" width="80%"><h3 id="stream-bench" tabindex="-1">Stream Bench <a class="header-anchor" href="#stream-bench" aria-label="Permalink to &quot;Stream Bench&quot;">​</a></h3><ul><li>正向经验有用</li><li>负向经验无用</li></ul><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513231330.jpg" style="display:block;margin:auto;" width="80%"><h3 id="更多-memgpt-a-mem" tabindex="-1">更多(MemGPT/A-MEM) <a class="header-anchor" href="#更多-memgpt-a-mem" aria-label="Permalink to &quot;更多(MemGPT/A-MEM)&quot;">​</a></h3><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513231219.jpg" style="display:block;margin:auto;" width="80%"><h2 id="agent-使用工具" tabindex="-1">Agent 使用工具 <a class="header-anchor" href="#agent-使用工具" aria-label="Permalink to &quot;Agent 使用工具&quot;">​</a></h2><p>工具可以看作是Function，使用工具就是调用Function，又叫做 <code>Function Call</code>。常用工具包括：</p><ul><li>搜索引擎</li><li>python</li><li>其他AI</li><li>...</li></ul><h3 id="工具怎么调用的" tabindex="-1">工具怎么调用的 <a class="header-anchor" href="#工具怎么调用的" aria-label="Permalink to &quot;工具怎么调用的&quot;">​</a></h3><p>以下是一个通用的调用方法，不是唯一的。</p><p>Prompt配置</p><ul><li>System Prompt：介绍工具定义、如何使用工具等。</li><li>User Prompt：具体用户Query</li></ul><div class="custom-block tip"><div class="custom-block-title">调用流程</div><p>模型根据User Prompt来决定是否调用工具。如果需要调用，则输出工具调用指令</p><ul><li><code>&lt;tool&gt;Temperature(&#39;高雄&#39;, &#39;2025.03.10 14:00&#39;)&lt;/tool&gt;</code></li><li>系统根据指令执行工具，工具返回结果</li><li>把结果拼装到 <code>&lt;output&gt;32度&lt;/output&gt;</code>，再次调用模型</li><li>模型整理结果，返回给用户</li></ul></div><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250514102543.jpg" style="display:block;margin:auto;" width="80%"><h3 id="工具很多怎么办" tabindex="-1">工具很多怎么办 <a class="header-anchor" href="#工具很多怎么办" aria-label="Permalink to &quot;工具很多怎么办&quot;">​</a></h3><p>由于冗长问题，并不能把所有工具说明都放到System Prompt里。工具集合说明放到Agent Memory里，再接一个RAG，仅选择所需要的工具即可。</p><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250514102558.jpg" style="display:block;margin:auto;" width="60%"><h3 id="工具结果有误怎么办" tabindex="-1">工具结果有误怎么办 <a class="header-anchor" href="#工具结果有误怎么办" aria-label="Permalink to &quot;工具结果有误怎么办&quot;">​</a></h3><div class="custom-block warning"><div class="custom-block-title">过度相信</div><p>模型会因为过度相信工具而犯错。比如：</p><ul><li>RAG结果错误，用胶水粘披萨🍕，可能仅仅是一个玩笑话，模型却无法判断。</li></ul></div><p>比如</p><div class="custom-block danger"><div class="custom-block-title">工具错误</div><p>如果工具结果出现明显错误，模型会认为其错误。 比如</p><ul><li>比如高雄温度达1000度。</li><li>精神病药量每日100mg。</li></ul></div><p>LLM有一定自己判断力，取决于模型自身能力和知识。</p><p>那么什么样的外部知识信息，模型会比较容易相信呢？</p><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250514110700.jpg" style="display:block;margin:auto;" width="80%"><div class="custom-block tip"><div class="custom-block-title">模型容易相信的</div><ul><li>和模型内部知识 <code>比较相近</code>的外部知识。（可以计算模型自身知识的置信度）</li><li><code>其他AI</code>说的话。不相信人类的话</li><li>比较 <code>新的文章</code>。</li><li>美观的？</li></ul></div><h3 id="平衡工具和模型自身能力" tabindex="-1">平衡工具和模型自身能力 <a class="header-anchor" href="#平衡工具和模型自身能力" aria-label="Permalink to &quot;平衡工具和模型自身能力&quot;">​</a></h3><p>比如3*4，一下能计算出12，但通过工具，可能会更慢。</p><div class="custom-block warning"><div class="custom-block-title">工具效率</div><p>使用工具不一定总是有效率</p></div><h2 id="agent-planning" tabindex="-1">Agent Planning <a class="header-anchor" href="#agent-planning" aria-label="Permalink to &quot;Agent Planning&quot;">​</a></h2><h3 id="什么是做计划" tabindex="-1">什么是做计划 <a class="header-anchor" href="#什么是做计划" aria-label="Permalink to &quot;什么是做计划&quot;">​</a></h3><p>让模型做执行前，先做计划，列举一系列的action，再根据action来执行。</p><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250514112922.jpg" style="display:block;margin:auto;" width="80%"><div class="custom-block warning"><div class="custom-block-title">计划需改变</div><p>但原有的计划不一定适用，会发生改变。</p><p>比如，每次action时让模型重新review plan。</p></div><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250514112940.jpg" style="display:block;margin:auto;" width="80%"><h3 id="有一定-plan-能力" tabindex="-1">有一定 Plan 能力 <a class="header-anchor" href="#有一定-plan-能力" aria-label="Permalink to &quot;有一定 Plan 能力&quot;">​</a></h3><ul><li>冰箱拿牛奶（非常简单）</li><li>(2305) <a href="https://arxiv.org/abs/2305.15771" target="_blank" rel="noreferrer">PlanBench</a>：叠积木（<code>AI可能见过相关内容</code>）、神秘方块（复杂规则，推理）</li><li>(2402) <a href="https://arxiv.org/abs/2402.01622" target="_blank" rel="noreferrer">TravelPlanner</a>：旅行计划，给需求做计划。 <ul><li>分数低(4分)，是因为很多不符合限制。<a href="https://arxiv.org/abs/2402.01622" target="_blank" rel="noreferrer">https://arxiv.org/abs/2402.01622</a></li><li><code>引入限制工具辅助</code>，模型做出好效果(90分)。<a href="https://arxiv.org/abs/2404.11891" target="_blank" rel="noreferrer">https://arxiv.org/abs/2404.11891</a></li></ul></li></ul><div class="custom-block tip"><div class="custom-block-title">Plan能力介于有和无之间</div><p>模型有一定Plan能力，但效果一般，需考虑强化。</p></div><h3 id="如何优化-plan-能力" tabindex="-1">如何优化 Plan 能力 <a class="header-anchor" href="#如何优化-plan-能力" aria-label="Permalink to &quot;如何优化 Plan 能力&quot;">​</a></h3><p><code>1、暴力搜索可行吗？</code></p><ul><li>暴力搜索可达，但成本太高</li></ul><p><code>2、优化暴力搜索</code></p><ul><li>(2407) <a href="https://arxiv.org/abs/2407.01476" target="_blank" rel="noreferrer">Tree Search for LLM Agents</a>，暴搜+去除低分路径。 <ul><li>缺点：无法回溯错误，<code>覆水难收</code>。</li><li>解决：可以自行在脑内，<code>提前想象脑内小剧场</code><ul><li>但 <code>由环境来决定行为</code>的。</li></ul></li></ul></li></ul><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250514115102.jpg" style="display:block;margin:auto;" width="80%"><p><code>3、提前脑补，模拟环境交互</code></p><ul><li>(2411) <a href="https://arxiv.org/abs/2411.06559" target="_blank" rel="noreferrer">Is Your LLM Secretly a Word Model of the Internet</a><ul><li>由LLM自己做WorldModel模拟真实世界交互，利用脑内小剧场。</li></ul></li></ul><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250514115151.jpg" style="display:block;margin:auto;" width="80%"><p><code>4、推理模型</code></p><ul><li>推理模型 (DeepSeek-R1)：整体reason模型效果比非reason好</li></ul><div class="custom-block danger"><div class="custom-block-title">overthinking</div><p>但存在overthinking的问题，想太多</p></div><p><code>5、优化Overthiking</code></p><ul><li>(2502) <a href="https://arxiv.org/abs/2502.08235" target="_blank" rel="noreferrer">The Danger of Overthinking: Examining the Reasoning-Action Dilemma in Agentic Tasks</a></li></ul><h2 id="参考内容" tabindex="-1">参考内容 <a class="header-anchor" href="#参考内容" aria-label="Permalink to &quot;参考内容&quot;">​</a></h2><ul><li><a href="https://docs.google.com/presentation/d/1kTxukwlmx2Sc9H7aGPTiNiPdk4zN_NoH/edit#slide=id.p5" target="_blank" rel="noreferrer">参考PPT文件</a></li><li>视频课程地址</li></ul>',79),i("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/M2Yg1kwPpts?si=FPlgwdRaYMitxt3B",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",referrerpolicy:"strict-origin-when-cross-origin",allowfullscreen:""},null,-1)]))}const u=t(o,[["render",r]]);export{m as __pageData,u as default};

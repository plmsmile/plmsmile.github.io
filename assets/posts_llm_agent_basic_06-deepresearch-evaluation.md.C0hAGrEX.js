import{_ as a,c as l,o as i,ah as s}from"./chunks/framework.CvbyeFFO.js";const h=JSON.parse('{"title":"DeepResearch 评估","description":"","frontmatter":{"title":"DeepResearch 评估","date":"2025-06-25T10:22:40.000Z","create":"2025-06-25T10:22:40.000Z","categories":[],"tags":[]},"headers":[],"relativePath":"posts/llm/agent/basic/06-deepresearch-evaluation.md","filePath":"posts/llm/agent/basic/06-deepresearch-evaluation.md","lastUpdated":null}'),t={name:"posts/llm/agent/basic/06-deepresearch-evaluation.md"};function r(c,e,o,p,n,d){return i(),l("div",null,e[0]||(e[0]=[s('<h2 id="paper" tabindex="-1">Paper <a class="header-anchor" href="#paper" aria-label="Permalink to &quot;Paper&quot;">​</a></h2><h3 id="_2506-deepresearch-bench-a-comprehensive-benchmark-for-deep-research-agents" tabindex="-1">(2506) DeepResearch Bench: A Comprehensive Benchmark for Deep Research Agents <a class="header-anchor" href="#_2506-deepresearch-bench-a-comprehensive-benchmark-for-deep-research-agents" aria-label="Permalink to &quot;(2506) DeepResearch Bench: A Comprehensive Benchmark for Deep Research Agents&quot;">​</a></h3><div class="custom-block important"><div class="custom-block-title">摘要</div><ul><li><a href="https://www.alphaxiv.org/abs/2506.11763" target="_blank" rel="noreferrer">paper</a></li><li></li></ul></div><p><strong>❓问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">问题背景</div><ul><li>端到端复杂性能力，缺乏标准评估基准</li></ul></div><p><strong>📕核心方法</strong></p><div class="custom-block tip"><div class="custom-block-title">核心方法</div><p>整体上：提出核心评估框架，包括22个领域、100+博士级研究任务，以及2种和人类高度一致的评估方法。</p><ul><li>数据构建：50中文、50英文任务，与真实需求相同。从LLM真实聊天中9.6w筛选出4.4w需要多轮搜索的深度研究任务。</li><li>评估框架 <ul><li>RACE 报告质量评估 <ul><li>LLM-as-Judge</li><li>4个维度：全面性、洞察力、指令遵循、可读性</li></ul></li><li>FACT 事实基础评估（事实丰富度+引文可信度） <ul><li>评估事实准确性和信息检索能力，过程包括语句-url对提取、去重、支持验证。</li><li>2个关键指标：引用准确率、有效引用数</li></ul></li></ul></li><li>人类一致性验证 <ul><li>RACE框架和人类偏好度高度一致 <ul><li>成对协议率：71.33%，总体皮尔逊相关系数：99.54%，过滤后的相关系数：60.24%、59.12%</li></ul></li></ul></li></ul></div><img src="https://paper-assets.alphaxiv.org/figures/2506.11763v1/img-1.jpeg" style="display:block;margin:auto;" width="80%"><p>数据集：</p><img src="https://paper-assets.alphaxiv.org/figures/2506.11763v1/img-2.jpeg" style="display:block;margin:auto;" width="80%"><p><strong>✍️实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验配置</div><ul><li>DeepResearch：Gemini、Perplextiy、Grok、OpenAI</li><li>模型+Search：GPT-4o、Gemini、Claude等。</li></ul></div><p><strong>🍑关键结果</strong></p><div class="custom-block caution"><div class="custom-block-title">关键结果</div><ul><li>RACE：Gemini-2.5-Pro DeepResearch 去的最高分，其后是OpenAI的。</li><li>FACT：显示引用数量和准确率有个平衡。Gemini DeepResearch 有效引用最多，但准确率较低；Perplexity 准确率高，但引用数量少。</li></ul></div><img src="https://paper-assets.alphaxiv.org/figures/2506.11763v1/img-0.jpeg" style="display:block;margin:auto;" width="80%"><p><strong>⛳未来方向</strong></p><div class="custom-block note"><div class="custom-block-title">未来方向</div></div>',17)]))}const m=a(t,[["render",r]]);export{h as __pageData,m as default};

import{_ as o,c as s,o as l,ah as r}from"./chunks/framework.CvbyeFFO.js";const p=JSON.parse('{"title":"LLM 基础知识","description":"","frontmatter":{"title":"LLM 基础知识","date":"2025-07-09T14:40:15.000Z","create":"2025-07-09T14:40:15.000Z","categories":["llm-basic"],"tags":[]},"headers":[],"relativePath":"posts/llm/basic/05-llm-basic-info.md","filePath":"posts/llm/basic/05-llm-basic-info.md","lastUpdated":null}'),i={name:"posts/llm/basic/05-llm-basic-info.md"};function n(a,t,g,e,c,d){return l(),s("div",null,t[0]||(t[0]=[r('<h2 id="llm-基础知识" tabindex="-1">LLM 基础知识 <a class="header-anchor" href="#llm-基础知识" aria-label="Permalink to &quot;LLM 基础知识&quot;">​</a></h2><h3 id="训练目标" tabindex="-1">训练目标 <a class="header-anchor" href="#训练目标" aria-label="Permalink to &quot;训练目标&quot;">​</a></h3><div class="custom-block important"><div class="custom-block-title">训练目标</div><p>LLM训练目标通常是<code>最大似然估计(Max Likelihood Estimation, MLE)</code>。</p><ul><li>数据：大规模语料</li><li><strong>训练目标</strong>💗 <ul><li><strong>最大化模型生成文本序列的概率</strong>，序列来自训练数据中观察到的。</li><li>模型根据上下文生成下一个词的条件概率分布，通过<strong>最大化词序列的概率来优化模型</strong>。</li><li>通过<a href="https://plmsmile.github.io/posts/olds/dl/35-nerual-network-optim.html#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E7%9A%84%E6%94%B9%E8%BF%9B" target="_blank" rel="noreferrer">梯度下降法</a>来更新参数，使用<code>Batch Training</code>进行小批量样本参数更新。</li></ul></li></ul></div><h3 id="涌现现象" tabindex="-1">涌现现象 <a class="header-anchor" href="#涌现现象" aria-label="Permalink to &quot;涌现现象&quot;">​</a></h3><p><a href="https://zhuanlan.zhihu.com/p/621438653" target="_blank" rel="noreferrer">大模型涌现能力：现象和解释</a></p><div class="custom-block important"><div class="custom-block-title">涌现能力及其原因</div><p>🚀<strong>涌现能力</strong></p><ul><li>在训练过程中能够生成出<strong>令人惊喜</strong>、<strong>创造性</strong>和<strong>新颖的内容或行为</strong>。</li></ul><p>🤔<strong>产生原因</strong></p><ul><li><strong>任务评价指标不够平滑</strong>：某指标太严格才算对，导致结果断层。 <ul><li>比如评价需一字不错才算正确，其余都算错误。可能中间结果已经在逐步变好了，但这个指标看不出来。</li></ul></li><li><strong>复杂任务</strong> <strong>vs</strong> <strong>子任务</strong>：出现涌现现象的大都是由多个子任务组成的复杂任务，但对子任务而言，其实符合<code>scaling law</code>现象，多个子任务组合一起，表现出了复杂任务的顿悟现象。</li><li><strong>用</strong> <strong>Grokking</strong> （顿悟）<strong>来解释涌现</strong>：任务T，随着模型及训练数据的增加，其相关数据达到最小阈值，这个任务就产生顿悟现象。</li></ul></div><img src="https://picx.zhimg.com/v2-546efd6eda3d839dd0f8f4c71dc1c415_r.jpg" style="display:block;margin:auto;" width="80%"><h3 id="复读机问题" tabindex="-1">复读机问题 <a class="header-anchor" href="#复读机问题" aria-label="Permalink to &quot;复读机问题&quot;">​</a></h3><p><strong>LLMs复读机问题</strong>（<code>LLMs Parroting Problem</code>）：模型可能会简单地复制输入文本的一部分或全部内容，并将其作为生成的输出，而<strong>不提供有意义或新颖的回应，缺乏创造性和独特性</strong>。</p><div class="custom-block tip"><div class="custom-block-title">复读机问题原因</div><ul><li><strong>训练数据偏差</strong>：预训练数据中出现<strong>大量重复文本</strong>、某些句子<strong>短语出现频率较高</strong>。模型在生成时<strong>倾向于复制这些模式</strong>。</li><li><strong>缺乏多样性训练数据</strong>：如果<strong>数据缺乏多样性</strong>语言表达或语境，模型可能<strong>无法学习到足够的多样性和创造性</strong>，导致复读机。</li><li><strong>训练目标限制</strong>：自监督学习NTP任务，使得模型倾向于生成与输入相似文本。</li><li><strong>模型结构及参数设置</strong>：如注意力机制及<strong>解码策略</strong>可能有影响。</li></ul></div><div class="custom-block important"><div class="custom-block-title">解决方法</div><p>没有一种通用的方案，需要针对具体情况具体分析， 下面是一些常用手段。</p><ul><li>📚<strong>增加多样性训练数据</strong></li><li>生成文本时引入一些随机噪声，<strong>采样不同词汇增加多样性</strong>。</li><li>温度等解码参数调整：<strong>较高温度增加随机性</strong>🔥。</li><li>Beam搜索参数调整：调整搜索Beam大小和宽度。</li><li><strong>后处理和过滤重复短语句子</strong></li><li><strong>人工干预和控制</strong>：对生成文本进行审查和筛选，保证多样性。</li></ul></div><h3 id="长文本问题" tabindex="-1">长文本问题 <a class="header-anchor" href="#长文本问题" aria-label="Permalink to &quot;长文本问题&quot;">​</a></h3><div class="custom-block important"><div class="custom-block-title">处理长句的挑战</div><p>理论上，LLM可以处理任意长度的句子，但是有一些挑战：</p><ul><li>🖥️<strong>计算资源不足</strong>：长句子消耗内存和时间</li><li>😟<strong>模型训练推理存在挑战</strong>：太长可能会出现<strong>梯度消失或梯度爆炸</strong>问题🔥，<strong>影响收敛和训练效果</strong>，<strong>推理会增加错误率和生成时间</strong>。</li><li><strong>上下文建模存在挑战</strong>：LLM基于上下文建模，<strong>长句子的上下文会更长更深</strong>，模型需要捕捉长的语法结构来生成结果，有挑战。</li></ul></div><div class="custom-block important"><div class="custom-block-title">处理长文本的方法</div><p><strong>1、分块处理</strong></p><ul><li>长文本分块，逐个片段输入到模型中。相邻片段做部分重叠，保持上下文一致性。</li></ul><p><strong>2、层次建模</strong></p><ul><li>引入层次结构，把文本划分成篇章、段落、句子等层次信息，逐层输入模型进行处理。</li></ul><p><strong>3、部分生成</strong></p><ul><li>只输入部分文本作为上下文，然后让模型生成所需的部分</li></ul><p><strong>4、注意力机制</strong></p><ul><li>注意力机制帮助模型关注输入中的重要部分。</li></ul><p><strong>5、模型结构优化</strong></p><ul><li>通过优化模型结构和参数设置，可以提高模型处理长文本的能力</li></ul></div>',14)]))}const m=o(i,[["render",n]]);export{p as __pageData,m as default};

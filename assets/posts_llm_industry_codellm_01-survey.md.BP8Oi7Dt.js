import{_ as l,c as o,o as i,ah as d}from"./chunks/framework.CvbyeFFO.js";const p=JSON.parse('{"title":"Code Survey From Code Foundation Models to Agents and Applications","description":"","frontmatter":{"title":"Code Survey From Code Foundation Models to Agents and Applications","date":"2025-12-06T12:01:01.000Z","create":"2025-12-06T12:01:01.000Z","categories":["code"],"tags":["survey"]},"headers":[],"relativePath":"posts/llm/industry/codellm/01-survey.md","filePath":"posts/llm/industry/codellm/01-survey.md","lastUpdated":null}'),c={name:"posts/llm/industry/codellm/01-survey.md"};function t(a,e,r,s,n,u){return i(),o("div",null,e[0]||(e[0]=[d('<h2 id="survey-文章" tabindex="-1">Survey 文章 <a class="header-anchor" href="#survey-文章" aria-label="Permalink to &quot;Survey 文章&quot;">​</a></h2><div class="custom-block caution"><div class="custom-block-title">参考文章</div><ul><li>(2512) <a href="https://www.alphaxiv.org/abs/2511.18538" target="_blank" rel="noreferrer">From Code Foundation Models to Agents and Applications</a></li><li>(2510) <a href="https://www.alphaxiv.org/abs/2510.12399" target="_blank" rel="noreferrer">A Survey of Vibe Coding with Large Language Models</a></li><li>(2508) <a href="https://www.alphaxiv.org/abs/2508.11126" target="_blank" rel="noreferrer">AI Agentic Programming</a></li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251206172440.jpg" style="display:block;margin:auto;" width="100%"><h2 id="背景" tabindex="-1">背景 <a class="header-anchor" href="#背景" aria-label="Permalink to &quot;背景&quot;">​</a></h2><h3 id="发展历程" tabindex="-1">发展历程 <a class="header-anchor" href="#发展历程" aria-label="Permalink to &quot;发展历程&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">背景</div><p><strong>AI Coding 思想</strong></p><ul><li>利用<code>Github</code>/<code>StackOverflow</code>/<code>code</code>网站资源，把<code>多年编程经验</code>提炼成<code>指令跟随的工具</code>。</li></ul><p><strong>相关工具</strong></p><ul><li>【辅助插件】<code>GitHub Copilot</code>：VSCode 插件</li><li>【IDE】<code>Cursor</code>：对话式编程</li><li>【国产】CodeGeeX(智谱)：多语言代码</li><li>【云服务】CodeWhisperer(亚马逊)：与AWS服务无缝集成，可调用Claude或Gemini。</li><li>【命令行】<code>Claude Code/Gemini CLI</code>：命令行级别，<code>agentic-coding-workflow</code>。 <ul><li>AI 自助分析文件、运行命令、修正代码</li></ul></li></ul></div><div class="custom-block tip"><div class="custom-block-title">Code LLM 两种分歧</div><p><strong>两种分歧</strong></p><ul><li><strong>通用型LLM (广度)</strong><ul><li><code>自然语言</code>+<code>编程数据</code> <code>混合预训练</code>，在上下文/意图/领域知识等理解细致。</li><li>代表工作：GPT、Claude、LLaMA等。</li></ul></li><li><strong>专用CodeLLM (深度)</strong><ul><li><code>编程数据</code>预训练+<code>算法架构优化</code>。</li><li>代表工作：StarCoder, Code LLaMA, DeepSeek-Coder, CodeGemma, QwenCoder等。</li></ul></li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-llm-overview.jpg" style="display:block;margin:auto;" width="100%"><h3 id="尚未探索的领域" tabindex="-1">尚未探索的领域 <a class="header-anchor" href="#尚未探索的领域" aria-label="Permalink to &quot;尚未探索的领域&quot;">​</a></h3><div class="custom-block warning"><div class="custom-block-title">目前尚缺乏探索的领域</div><p><strong>1. 数据清洗策略</strong></p><ul><li>如何<code>平衡数据质量和数量</code>？ <ul><li>数据并非越多越好，顶级模型如何</li></ul></li><li>如何做<code>指令跟随</code>？ <ul><li>让模型听懂人话。</li></ul></li></ul><p><strong>2. 对齐技术</strong></p><ul><li>code需要能跑、<code>符合人类习惯</code>、是<code>安全</code>的，如何<code>根据人类反馈来做对齐</code>？</li></ul><p><strong>3. 高级提示范式</strong></p><ul><li>CoT、FewShot等。</li></ul><p><strong>4. 自主智能体</strong></p><ul><li>自动拆解任务。</li></ul><p><strong>5. RAG</strong></p><ul><li>模型会有幻觉、编写出不存在的函数。</li><li>做RAG，让模型<code>先看文档</code>，<code>再写代码</code>，保证准确性。</li></ul><p><strong>6. 评估框架</strong></p><ul><li>现在更多是<code>2元的</code>(仅看<code>正确性</code>)。</li><li>但如何评估代码<code>烂不烂</code>、<code>效率如何</code>、<code>可维护性如何</code>？</li></ul></div><h2 id="code-基模" tabindex="-1">Code 基模 <a class="header-anchor" href="#code-基模" aria-label="Permalink to &quot;Code 基模&quot;">​</a></h2><h3 id="通用大模型" tabindex="-1">通用大模型 <a class="header-anchor" href="#通用大模型" aria-label="Permalink to &quot;通用大模型&quot;">​</a></h3><h4 id="发展和涌现" tabindex="-1">发展和涌现 <a class="header-anchor" href="#发展和涌现" aria-label="Permalink to &quot;发展和涌现&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Rise of LLMs</div><p><strong>Transformer 和 Scaling Law</strong></p><ul><li><code>Transformer 一统江湖</code><ul><li>通过<code>预训练</code>和<code>知识迁移</code>，把多种统一到一个支持多种任务和模态的可扩展框架。</li><li>NTP任务</li></ul></li><li><code>Scaling Law 大力出奇迹</code><ul><li>参数、数据、计算越多，模型效果越好，可预测。</li><li>出现一些涌现能力，涌现也可能是评估指标的问题。</li></ul></li></ul><p><strong>LLM爆发出代码能力</strong></p><ul><li>OpenAI：Codex 能写代码 + HumanEval 测试集。</li><li>DeepMind：AlphaCode 能做竞技编程。</li><li><code>代码结构</code> 和<code>人类自然语</code>言在<code>底层逻辑上是相通的</code>。</li></ul><p><strong>LLM + 外部工具 变身 决策agent</strong></p><ul><li><code>外部工具</code>：计算器、搜索、代码解释器等等。</li><li><code>思考行动观察Loop</code>：思考 -&gt; 行动 -&gt; 观察 -&gt; 思考 -&gt; 行动 -&gt; 观察 ....</li><li>典型技术：ReAct，ToolFormer等。</li></ul><p><strong>突破、局限、CodeLLM动机</strong></p><ul><li>突破：SWE-Agent：修bug、通过所有测试用例。需要规划+多文件操作能力。</li><li><code>通用模型</code> 在代码领域<code>有局限性</code>： <ul><li><code>准确性</code>(复杂代码不会写)、<code>安全性</code>(有bug代码)、<code>可靠性</code>(系统级可靠性差)</li></ul></li><li>需要转<code>专有的代码大模型</code></li></ul></div><p>代码生成：HumanEval上的效果</p><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251206183411.jpg" style="display:block;margin:auto;" width="70%"><p>修bug：SWE-Bench上的效果</p><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251206183358.jpg" style="display:block;margin:auto;" width="70%"><h4 id="模型架构-多模态" tabindex="-1">模型架构&amp;多模态 <a class="header-anchor" href="#模型架构-多模态" aria-label="Permalink to &quot;模型架构&amp;多模态&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Dense Model</div><p><strong>1. Dense Model</strong></p><ul><li><a href="http://plmsmile.github.io/posts/llm/basic/04-llm-architecture.html#dense-model" target="_blank" rel="noreferrer">DenseModel</a></li></ul><p><strong>2. MoE</strong></p><ul><li><a href="http://plmsmile.github.io/posts/llm/basic/04-llm-architecture.html#moe-model" target="_blank" rel="noreferrer">MoEModel</a></li></ul><p><strong>3. Recurrent Models</strong></p><ul><li><a href="http://plmsmile.github.io/posts/llm/basic/04-llm-architecture.html#recurrent-model" target="_blank" rel="noreferrer">RecurrentModel</a></li></ul><p><strong>4. Diffusion Models</strong></p><ul><li><a href="http://plmsmile.github.io/posts/llm/basic/04-llm-architecture.html#diffusion-based-model" target="_blank" rel="noreferrer">DiffusionModel</a></li></ul><p><strong>5. Hybrid Architechures</strong></p><ul><li><a href="http://plmsmile.github.io/posts/llm/basic/04-llm-architecture.html#hybrid-architectures" target="_blank" rel="noreferrer">混合架构</a></li></ul></div><div class="custom-block note"><div class="custom-block-title">多模态</div><ul><li>主要依赖<code>视觉能力</code>，需要查看<code>图表</code>、<code>截图</code>、<code>UI元素</code>等内容。</li></ul></div><h4 id="不足" tabindex="-1">不足 <a class="header-anchor" href="#不足" aria-label="Permalink to &quot;不足&quot;">​</a></h4><div class="custom-block warning"><div class="custom-block-title">通用大模型的不足</div><p><strong>核心缺点</strong></p><ul><li><code>有广度</code>、<code>无深度</code></li><li>什么都会一点，能写简单代码、能看图等。</li></ul><p><strong>具体表现</strong></p><ul><li><code>专业和准确性不足</code><ul><li>生成表面看起来没问题的代码，但实际不能满足一些领域约束。 <ul><li><code>看起来对的代码</code>，<code>实际可能一跑就崩</code></li></ul></li></ul></li><li><code>安全和可靠性不足</code><ul><li>尽管功能正确能运行，但仍然不够安全、<code>有bug</code></li></ul></li><li><code>仓库级理解不足</code><ul><li>模型可读长上下文，但经常<code>lost-in-middle</code>。 <ul><li>关键信息藏在几万行代码中间，模型往往会忽略。</li><li><code>跨文件的变量引用</code>、<code>依赖关系</code>，模型经常搞不清楚，导致<code>无法理解整个项目</code>。</li></ul></li></ul></li><li><code>多模态障碍/看不懂界面细节</code><ul><li>能看懂是个网页，但无法看懂具体元素细节、按钮具体交互含义等</li><li>导致 AI 无法像人类一样精准地操作 GUI 界面进行编程或测试。</li></ul></li><li><code>不会用工具(Agentic限制)</code><ul><li><code>通用模型</code>容易出现<code>工具幻觉</code>：<code>假装调用了工具</code>，或者编造了工具的输出。</li><li>任务步骤变多(<code>长程推理</code>)，模型很容易这就<code>“晕”了</code>，忘记之前的步骤或偏离目标。</li></ul></li></ul><p><strong>用模型写代码不够，需要</strong></p><ul><li><code>数据清洗</code>：<code>去掉不安全</code>的代码。</li><li><code>预训练/微调</code>：让模型理解<code>代码结构</code>和<code>跨文件依赖</code></li><li><code>强化学习</code>：教模型如何<code>正确使用工具</code>和进行<code>长期规划</code></li></ul></div><h3 id="代码大模型" tabindex="-1">代码大模型 <a class="header-anchor" href="#代码大模型" aria-label="Permalink to &quot;代码大模型&quot;">​</a></h3>',24)]))}const m=l(c,[["render",t]]);export{p as __pageData,m as default};

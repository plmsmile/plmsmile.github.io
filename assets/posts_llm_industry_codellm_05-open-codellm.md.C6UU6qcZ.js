import{_ as a,c as r,o as i,ah as t,j as l,a as o}from"./chunks/framework.CvbyeFFO.js";const C=JSON.parse('{"title":"CodeLLM 索引简记","description":"","frontmatter":{"title":"CodeLLM 索引简记","date":"2025-12-17T17:31:17.000Z","create":"2025-12-17T17:31:17.000Z","categories":["code-llm"],"tags":["code-llm"]},"headers":[],"relativePath":"posts/llm/industry/codellm/05-open-codellm.md","filePath":"posts/llm/industry/codellm/05-open-codellm.md","lastUpdated":null}'),s={name:"posts/llm/industry/codellm/05-open-codellm.md"},n={class:"custom-block tip"},d={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},c={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.05ex"},xmlns:"http://www.w3.org/2000/svg",width:"3.25ex",height:"2.022ex",role:"img",focusable:"false",viewBox:"0 -871.8 1436.6 893.8","aria-hidden":"true"},p={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},g={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.05ex"},xmlns:"http://www.w3.org/2000/svg",width:"3.25ex",height:"2.005ex",role:"img",focusable:"false",viewBox:"0 -864 1436.6 886","aria-hidden":"true"};function u(h,e,m,b,k,v){return i(),r("div",null,[e[18]||(e[18]=t('<h2 id="概览内容" tabindex="-1">概览内容 <a class="header-anchor" href="#概览内容" aria-label="Permalink to &quot;概览内容&quot;">​</a></h2><h3 id="开源codellm-发展阶段" tabindex="-1">开源CodeLLM 发展阶段 <a class="header-anchor" href="#开源codellm-发展阶段" aria-label="Permalink to &quot;开源CodeLLM 发展阶段&quot;">​</a></h3><div class="custom-block info"><div class="custom-block-title">发展的几个阶段</div><p><strong>阶段1：Encoder 模型</strong></p><ul><li>聚焦在代码<code>理解任务</code>，把代码变成向量，做检索任务。</li><li>主要工作：CodeBert,ERNIE-Code等。</li></ul><p><strong>阶段2：生成式 模型</strong></p><ul><li>从读到写，聚焦在<code>理解和生成代码</code>。</li><li>主要工作：CodeT5, CodeGPT等。</li></ul><p><strong>阶段3：代码 LLM</strong></p><ul><li><p>大模型，能<code>写复杂代码</code>、<code>多轮对话</code>式编程、具有<code>指令遵循能力</code>等。</p></li><li><p>代表：StarCoder, CodeLlama, DeepSeek-Coder, CodeQwen等。</p></li></ul><p><strong>阶段4：Agentic 模型</strong></p><ul><li>通过<code>MoE来扩展参数</code> + 提升<code>agentic能力</code>(<code>工具使用</code>、<code>多步推理</code>等)。</li><li>代表：DeepSeek-Coder-V2、DeepCoder、DeepSWE等。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251209211313.jpg" style="display:block;margin:auto;" width="100%"><h2 id="rlvr-后训练相关" tabindex="-1">RLVR 后训练相关 <a class="header-anchor" href="#rlvr-后训练相关" aria-label="Permalink to &quot;RLVR 后训练相关&quot;">​</a></h2><div class="custom-block danger"><div class="custom-block-title">RLVR 开源CodeLLM</div><p>(2503) ACECoder</p><ul><li>REINCORCE++ 算法，偏好和二元两种奖励。</li></ul><p>(2503) Open-R1</p><ul><li>RoPE：300k 上下文</li></ul><p>(2503) Skywork-OR1</p><ul><li>代码和数学混合训练，多阶段RL，长度从16k -&gt; 32k</li></ul><p>(2503) Code-R1</p><ul><li>12k小数据做微调。</li></ul><p>(2503) DeepCoder</p><ul><li>去掉了KL和熵约束。</li></ul><p>(2503) Seed-Coder</p><ul><li>2阶段：DPO构建指令Instruct模型，PPO创建Reason模型</li></ul><p>(2503) AceReason</p><ul><li>2阶段课程学习：<code>先数学</code>，<code>再代码</code>。</li></ul><p>(2503) Klear-Reasoner</p><ul><li>GPPO算法，保留更多有用的梯度信息，提高梯度利用率，强制模型保持好奇心，缓解了熵坍塌。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216162559.jpg" style="display:block;margin:auto;" width="70%"><h4 id="_2508-klear-reasoner" tabindex="-1">(2508) Klear-Reasoner <a class="header-anchor" href="#_2508-klear-reasoner" aria-label="Permalink to &quot;(2508) Klear-Reasoner&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">提示</div><p><strong>参考链接</strong></p><ul><li><a href="https://arxiv.org/abs/2508.07629" target="_blank" rel="noreferrer">paper</a>, <a href="https://huggingface.co/Kwai-Klear/Klear-Reasoner-8B" target="_blank" rel="noreferrer">Klear-Reasoner-8B</a></li></ul><p><strong>基模</strong></p><p><strong>关键技术</strong></p><p><strong>训练数据</strong></p><p><strong>关键结果</strong></p></div><h4 id="_2505-code-r1" tabindex="-1">(2505) Code-R1 <a class="header-anchor" href="#_2505-code-r1" aria-label="Permalink to &quot;(2505) Code-R1&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">提示</div><p><strong>参考链接</strong></p><ul><li><a href="https://arxiv.org/abs/2505.21668" target="_blank" rel="noreferrer">paper</a>, <a href="https://github.com/ganler/code-r1" target="_blank" rel="noreferrer">coder-1</a></li></ul><p><strong>基模</strong></p><p><strong>关键技术</strong></p><p><strong>训练数据</strong></p><p><strong>关键结果</strong></p></div><h4 id="_2505-seed-coder" tabindex="-1">(2505) Seed-Coder <a class="header-anchor" href="#_2505-seed-coder" aria-label="Permalink to &quot;(2505) Seed-Coder&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">提示</div><p><strong>参考链接</strong></p><ul><li><a href="https://github.com/ByteDance-Seed/Seed-Coder" target="_blank" rel="noreferrer">Seed-Coder</a></li></ul><p><strong>基模</strong></p><p><strong>关键技术</strong></p><p><strong>训练数据</strong></p><p><strong>关键结果</strong></p></div><h4 id="_2505-acereason-nemotron" tabindex="-1">(2505) AceReason-Nemotron <a class="header-anchor" href="#_2505-acereason-nemotron" aria-label="Permalink to &quot;(2505) AceReason-Nemotron&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">提示</div><p><strong>参考链接</strong></p><ul><li><a href="https://arxiv.org/abs/2505.16400" target="_blank" rel="noreferrer">AceReason-Nemotron paper</a>, <a href="https://huggingface.co/collections/nvidia/acereason" target="_blank" rel="noreferrer">hf collection</a></li></ul><p><strong>基模</strong></p><p><strong>关键技术</strong></p><p><strong>训练数据</strong></p><p><strong>关键结果</strong></p></div><h4 id="_2505-skywork-or1" tabindex="-1">(2505) Skywork-OR1 <a class="header-anchor" href="#_2505-skywork-or1" aria-label="Permalink to &quot;(2505) Skywork-OR1&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">提示</div><p><strong>参考链接</strong></p><ul><li><a href="https://arxiv.org/abs/2505.22312" target="_blank" rel="noreferrer">tech report</a>, <a href="https://huggingface.co/collections/Skywork/skywork-or1" target="_blank" rel="noreferrer">hfmodel</a></li></ul><p><strong>基模</strong></p><p><strong>关键技术</strong></p><p><strong>训练数据</strong></p><p><strong>关键结果</strong></p></div><h4 id="_2503-deepcoder" tabindex="-1">(2503) DeepCoder <a class="header-anchor" href="#_2503-deepcoder" aria-label="Permalink to &quot;(2503) DeepCoder&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">DeepCoder (2503)</div><p><strong>参考链接</strong></p><ul><li><a href="https://pretty-radio-b75.notion.site/DeepCoder-A-Fully-Open-Source-14B-Coder-at-O3-mini-Level-1cf81902c14680b3bee5eb349a512a51" target="_blank" rel="noreferrer">DeepCoder-14B-Preview</a>, <a href="https://www.alphaxiv.org/abs/2505.05315v2" target="_blank" rel="noreferrer">Scalable CoT via Elastic Reasoning</a>, <a href="https://huggingface.co/datasets/agentica-org/DeepCoder-Preview-Dataset/tree/main" target="_blank" rel="noreferrer">agentica-org/DeepCoder-Preview-Dataset</a></li></ul><p><strong>关键技术</strong></p><ul><li>基于DS-R1-14B，继续做RLVR训练，目标repo-level代码编辑。</li><li>训练32k，测试64k。</li></ul><p><strong>训练数据</strong></p><ul><li>TACO-verified、LiveCodeBench(23-24)</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>完全开源</li></ul></div><h4 id="_2503-olympiccoder-open-r1" tabindex="-1">(2503) OlympicCoder (Open-R1) <a class="header-anchor" href="#_2503-olympiccoder-open-r1" aria-label="Permalink to &quot;(2503) OlympicCoder (Open-R1)&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">提示</div><p><strong>参考链接</strong></p><ul><li><a href="https://huggingface.co/blog/open-r1/update-3" target="_blank" rel="noreferrer">blog</a>, <a href="https://huggingface.co/open-r1/OlympicCoder-32B" target="_blank" rel="noreferrer">open-r1/OlympicCoder-32B</a></li></ul><p><strong>基模</strong></p><p><strong>关键技术</strong></p><p><strong>训练数据</strong></p><p><strong>关键结果</strong></p></div><h4 id="_2502-acecoder" tabindex="-1">(2502) AceCoder <a class="header-anchor" href="#_2502-acecoder" aria-label="Permalink to &quot;(2502) AceCoder&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">提示</div><p><strong>参考链接</strong></p><ul><li><a href="https://arxiv.org/pdf/2502.01718" target="_blank" rel="noreferrer">AceCoder</a>, <a href="https://tiger-ai-lab.github.io/AceCoder/" target="_blank" rel="noreferrer">Blog</a></li></ul><p><strong>基模</strong></p><ul><li></li></ul><p><strong>关键技术</strong></p><p><strong>训练数据</strong></p><p><strong>关键结果</strong></p></div><h2 id="闭源code-llm" tabindex="-1">闭源Code LLM <a class="header-anchor" href="#闭源code-llm" aria-label="Permalink to &quot;闭源Code LLM&quot;">​</a></h2><div class="custom-block tip"><div class="custom-block-title">闭源LLM</div><ul><li><a href="https://plmsmile.github.io/posts/llm/industry/mainllm/07-openai-series.html" target="_blank" rel="noreferrer">GPT 系列</a></li><li><a href="https://plmsmile.github.io/posts/llm/industry/mainllm/08-gemini-series.html" target="_blank" rel="noreferrer">Gemini 系列</a></li><li><a href="https://plmsmile.github.io/posts/llm/industry/mainllm/09-claude-series.html" target="_blank" rel="noreferrer">Claude 系列</a></li><li>Grok系列</li></ul></div><h2 id="开源code-llm" tabindex="-1">开源Code LLM <a class="header-anchor" href="#开源code-llm" aria-label="Permalink to &quot;开源Code LLM&quot;">​</a></h2><h3 id="阶段4-codellm-列表" tabindex="-1">阶段4-CodeLLM 列表 <a class="header-anchor" href="#阶段4-codellm-列表" aria-label="Permalink to &quot;阶段4-CodeLLM 列表&quot;">​</a></h3><h4 id="_2406-deepseek-coder-v1-v2" tabindex="-1">(2406) DeepSeek-Coder V1-V2 <a class="header-anchor" href="#_2406-deepseek-coder-v1-v2" aria-label="Permalink to &quot;(2406) DeepSeek-Coder V1-V2&quot;">​</a></h4><div class="custom-block important"><div class="custom-block-title">DeepSeek-Coder-V2 (2406)</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2406.11931" target="_blank" rel="noreferrer">DeepSeek-Coder-V2</a></li></ul><p><strong>关键技术</strong></p><ul><li>从DeepSeek-V2继续预训练，对代码和数学继续强化。</li><li>MoE 架构，两个版本：236A21B，16A2.5B。</li><li>YARN：上下文从16k扩展至128K。</li></ul><p><strong>训练数据</strong></p><ul><li>混合数据：代码、数学、文本。数学对编程逻辑重要。6T token。</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>效果和高效。</li></ul></div><div class="custom-block tip"><div class="custom-block-title">DeepSeek-Coder (2401)</div><p><strong>关键技术</strong></p><ul><li><p><code>从0开始预训练</code>，产出1.3-33B 模型</p></li><li><p><code>仓库级预训练</code>：</p><ul><li>模拟跨文件的依赖关系，提升对<code>repo-level</code>的理解和跨文件补全能力。</li></ul></li><li><p><code>中间填充目标</code>(Fill in the Midddle) + <code>长上下文</code>(16k)：</p><ul><li>增强<code>代码补全</code>和<code>长距离代码推理</code>能力。</li></ul></li></ul><p><strong>训练数据</strong></p><ul><li><code>多种编程语言</code>语料库，<code>无私有数据</code>。</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>在HumanEval和MBPP上超过 GPT-3.5</li><li>指令微调版本：<code>多轮</code>问题解决能力更好</li></ul></div><h4 id="_2510-minimax-m1-m2" tabindex="-1">(2510) MiniMax M1/M2 <a class="header-anchor" href="#_2510-minimax-m1-m2" aria-label="Permalink to &quot;(2510) MiniMax M1/M2&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">MiniMax M1/M2 (2506,2510)</div><p><strong>参考链接</strong></p><ul><li><a href="https://plmsmile.github.io/posts/llm/industry/mainllm/04-minimax-series.html#_2506-minimax-m1-scaling-test-time-compute-efficiently-with-lightning-attention" target="_blank" rel="noreferrer">M1笔记</a>， <a href="https://plmsmile.github.io/posts/llm/industry/mainllm/04-minimax-series.html#_2506-minimax-m1-scaling-test-time-compute-efficiently-with-lightning-attention" target="_blank" rel="noreferrer">M2笔记</a></li></ul><p><strong>关键技术</strong></p><ul><li>M1：线性注意力，</li><li>M2：softmax注意力。参数230B，激活10B</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p></div><h4 id="_24-25-deepseek-v3" tabindex="-1">(24,25) DeepSeek V3 <a class="header-anchor" href="#_24-25-deepseek-v3" aria-label="Permalink to &quot;(24,25) DeepSeek V3&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">DeepSeek V3 (24,25)</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2412.19437" target="_blank" rel="noreferrer">DeepSeek-V3 技术报告</a></li></ul><p><strong>关键技术</strong></p><ul><li>整体上：agent能力，混合思考模式，671B激活37B，128k上下文。</li><li>DeepSeek-V3 <ul><li>MLA+多token预测头，14.8T 预训练，无辅助loss做MoE 负载均衡</li><li>SFT + RL 微调</li></ul></li><li>DeepSeek-V3.1 <ul><li>PostTrain：840B语料，上下文由32K扩展至128k，整合DeepThink思维了模式。</li><li>增强多步工具+code-agent能力，超过v3和r1</li></ul></li><li>DeepSeek-V3.2 <ul><li>基于V3.1-Terminus，使用DSA稀疏注意力，推理成本降低50%，质量和v3.1相当</li></ul></li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p></div><h4 id="_2510-kat-dev" tabindex="-1">(2510) KAT-Dev <a class="header-anchor" href="#_2510-kat-dev" aria-label="Permalink to &quot;(2510) KAT-Dev&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">KAT-Dev (2510, 快手)</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2510.18779" target="_blank" rel="noreferrer">KAT-Coder 技术报告</a></li></ul><p><strong>关键技术</strong></p><ul><li>基于Qwen3底座。</li><li>训练pipeline <ul><li>Mid-Training：针对工具使用+指令遵循</li><li>SFT：</li><li>RL：代码任务</li><li>大规模AgentRL：</li></ul></li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>32B SWE-verified 62.4%</li></ul></div><div class="custom-block note"><div class="custom-block-title">Kimi-K2-Instruct</div><p><strong>参考链接</strong></p><ul><li><a href="https://huggingface.co/moonshotai/Kimi-K2-Instruct" target="_blank" rel="noreferrer">moonshotai/Kimi-K2-Instruct</a>, <a href="https://plmsmile.github.io/posts/llm/industry/mainllm/01-kimi-series.html#_2507-kimi-k2-open-agentic-intelligence" target="_blank" rel="noreferrer">Kimi-K2 笔记</a></li></ul><p><strong>关键技术</strong></p><ul><li>超稀疏MoE：总参数1T，激活32B</li><li>预训练：MuonClip：解决梯度爆炸不收敛的问题。</li><li>SFT：Agent数据合成技术</li><li>RL：可评估和不可评估任务。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>原生工具调用、128k上下文。权重开源。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251210230435.jpg" style="display:block;margin:auto;" width="70%"><h4 id="_2508-glm-4-5-4-6" tabindex="-1">(2508) GLM 4.5/4.6 <a class="header-anchor" href="#_2508-glm-4-5-4-6" aria-label="Permalink to &quot;(2508) GLM 4.5/4.6&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">GLM4.5/4.6 (2508)</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2508.06471" target="_blank" rel="noreferrer">GLM4.5 paper</a>,</li></ul><p><strong>关键技术</strong></p><ul><li>架构：A32B，混合推理模式，GQA+QK-Norm+MoE 多token预测头</li><li>Mid-Training <code>关键数据上采样</code>：<code>仓库级代码</code> + <code>Agent轨迹</code> 数据</li><li>上下文扩展：4k -&gt; 32k -&gt; 128k -&gt; 200k(GLM4.6)</li><li>后训练：监督学习 + 自蒸馏。 <ul><li>RL技巧：难度课程、长输出RL、代码加权loss (给代码更高权重)</li></ul></li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>在TAU-Bench、AIME、SWE-verified、BrowseComp等有较好效果。</li><li>GLM4.6 进一步提升代码、工具使用、agent能力等。</li></ul></div><h4 id="_2507-qwen3-coder" tabindex="-1">(2507) Qwen3-Coder <a class="header-anchor" href="#_2507-qwen3-coder" aria-label="Permalink to &quot;(2507) Qwen3-Coder&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Qwen3-Coder (2507)</div><p><strong>参考链接</strong></p><ul><li><a href="https://qwenlm.github.io/blog/qwen3-coder/" target="_blank" rel="noreferrer">qwen3-coder 博客</a></li></ul><p><strong>关键技术</strong></p><ul><li>MoE, <code>480A35B</code>，上下文<code>256k -&gt; 1M</code>, YaRN。</li><li><code>预训练</code> + <code>所有代码可执行</code>的Code RL训练。</li></ul><p><strong>训练数据</strong></p><ul><li>预训练 <ul><li>通用、数学 + 代码， 7.5T tokens (70%)</li><li>合成数据：利用Qwen2.5-Coder对低质数据做清洗和重写，提升质量。</li></ul></li><li>RL <ul><li>不仅是竞赛代码，对所有代码做执行驱动的RL。</li></ul></li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>Agentic Coding、Agentic Browser-Use 和 Agentic Tool-Use 开源SOTA，可与Claude Sonnet4 媲美</li></ul></div><h4 id="_2505-devstral" tabindex="-1">(2505) Devstral <a class="header-anchor" href="#_2505-devstral" aria-label="Permalink to &quot;(2505) Devstral&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">devstral (2505, mistral)</div><p><strong>参考链接</strong></p><ul><li><a href="https://mistral.ai/news/devstral" target="_blank" rel="noreferrer">devstral</a>, <a href="https://huggingface.co/mistralai/Devstral-Small-2505" target="_blank" rel="noreferrer">mistralai/Devstral-Small-2505</a></li></ul><p><strong>关键技术</strong></p><ul><li>目标<code>repo-scale SWE</code>，多文件推理、长上下文编辑、可验证。</li><li>Devstral-Small (24B, 128k上下文)，Devstral-Medium (API)</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>完全开源。</li></ul></div><h4 id="_2508-deepswe" tabindex="-1">(2508) DeepSWE <a class="header-anchor" href="#_2508-deepswe" aria-label="Permalink to &quot;(2508) DeepSWE&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">DeepSWE (2508)</div><p><strong>参考链接</strong></p><ul><li><a href="https://huggingface.co/agentica-org/DeepSWE-Preview" target="_blank" rel="noreferrer">agentica-org/DeepSWE-Preview</a>, <a href="https://pretty-radio-b75.notion.site/DeepSWE-Training-a-Fully-Open-sourced-State-of-the-Art-Coding-Agent-by-Scaling-RL-22281902c1468193aabbe9a8c59bbe33" target="_blank" rel="noreferrer">tech blog</a>, <a href="https://www.alphaxiv.org/abs/2508.03501" target="_blank" rel="noreferrer">SWE-RL-paper</a></li></ul><p><strong>关键技术</strong></p><ul><li>基模：Qwen3-32B + 思考模式</li><li><code>纯RL训练</code>，目标repo-level，<code>可执行</code>和 <code>不执行</code>两种验证器。</li><li>R2E-Gym环境，<a href="https://pretty-radio-b75.notion.site/rLLM-A-Framework-for-Post-Training-Language-Agents-21b81902c146819db63cd98a54ba5f31" target="_blank" rel="noreferrer">rLLM 训练框架</a></li></ul><p><strong>训练数据</strong></p><ul><li>R2E-Gym的子集，4.5k。</li></ul><p><strong>数据清洗</strong></p><ul><li>过滤了和bench相关的数据</li></ul><p><strong>关键结果</strong></p><ul><li>SWE-verified：59%</li></ul></div><h4 id="_2503-deepcoder-1" tabindex="-1">(2503) DeepCoder <a class="header-anchor" href="#_2503-deepcoder-1" aria-label="Permalink to &quot;(2503) DeepCoder&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">DeepCoder (2503)</div><p><strong>参考链接</strong></p><ul><li><a href="https://pretty-radio-b75.notion.site/DeepCoder-A-Fully-Open-Source-14B-Coder-at-O3-mini-Level-1cf81902c14680b3bee5eb349a512a51" target="_blank" rel="noreferrer">DeepCoder-14B-Preview</a>, <a href="https://www.alphaxiv.org/abs/2505.05315v2" target="_blank" rel="noreferrer">Scalable CoT via Elastic Reasoning</a>, <a href="https://huggingface.co/datasets/agentica-org/DeepCoder-Preview-Dataset/tree/main" target="_blank" rel="noreferrer">agentica-org/DeepCoder-Preview-Dataset</a></li></ul><p><strong>关键技术</strong></p><ul><li>基于DS-R1-14B，继续做RLVR训练，目标repo-level代码编辑。</li><li>训练32k，测试64k。</li></ul><p><strong>训练数据</strong></p><ul><li>TACO-verified、LiveCodeBench(23-24)</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>完全开源</li></ul></div><h4 id="_2506-skywork-swe" tabindex="-1">(2506) Skywork-SWE <a class="header-anchor" href="#_2506-skywork-swe" aria-label="Permalink to &quot;(2506) Skywork-SWE&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Skywork-SWE (2506)</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2506.19290" target="_blank" rel="noreferrer">Skywork-SWE-32B</a></li></ul><p><strong>关键技术</strong></p><ul><li><code>可执行的数据清洗pipeline</code><ul><li>收集<code>[PR, Isssue]</code>数据，每个issue配一个docker容器</li><li>让agent去修bug，<code>仅保留能通过</code>测试用例的轨迹数据。</li></ul></li><li>高质量可执行SWE 数据 Scale &gt; 模型尺寸 scale <ul><li>效果和数量，呈log对数增长</li></ul></li><li>在openhands框架，使用轨迹数据，做微调。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>SWE-verifed 有较好结果</li></ul></div><h4 id="_2503-ling-coder-lite" tabindex="-1">(2503) Ling-Coder-Lite <a class="header-anchor" href="#_2503-ling-coder-lite" aria-label="Permalink to &quot;(2503) Ling-Coder-Lite&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Ling-Coder-Lite (2503)</div><p><strong>参考链接</strong></p><ul><li><a href="https://huggingface.co/inclusionAI/Ling-Coder-lite" target="_blank" rel="noreferrer">inclusionAI/Ling-Coder-lite</a>, <a href="https://www.alphaxiv.org/abs/2503.17793" target="_blank" rel="noreferrer">paper</a></li></ul><p><strong>关键技术</strong></p><ul><li>MoE，top6 路由，改进的NormHead。</li><li><code>共享/常驻专家</code>：shared+routed expertes，DeepSeekV2首创设计。</li><li>训练策略：继续预训练、指令优化(<code>SFT</code> + <code>DPO</code>)</li></ul><p><strong>训练数据</strong></p><ul><li>指令优化数据：高质量、<code>可执行</code>、<code>仓库结构数据</code>。</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>HumanEval, MBPP, LiveCodeBench, BigCodeBench等</li></ul></div><h3 id="阶段3-早期工作" tabindex="-1">阶段3-早期工作 <a class="header-anchor" href="#阶段3-早期工作" aria-label="Permalink to &quot;阶段3-早期工作&quot;">​</a></h3><h4 id="_2411-opencoder" tabindex="-1">(2411) OpenCoder <a class="header-anchor" href="#_2411-opencoder" aria-label="Permalink to &quot;(2411) OpenCoder&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">OpenCoder (2411)</div><p><strong>参考链接</strong></p><ul><li><a href="https://aclanthology.org/2025.acl-long.1591/" target="_blank" rel="noreferrer">paper</a>, <a href="https://arxiv.org/pdf/2411.04905" target="_blank" rel="noreferrer">paper 2411</a>, <a href="https://opencoder-llm.github.io/" target="_blank" rel="noreferrer">OpenCoder</a></li></ul><p><strong>关键技术</strong></p><ul><li>完全开源：权重、预测、<code>RefineCode数据</code>、<code>训练流程</code></li><li>1.5B/8B，LLama-Style (RoPE, SwiGLU)</li><li>两阶段指令微调：<code>通用SFT</code>、<code>code SFT</code></li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>8B HumanEval/MBPP效果不错，debug新年超过StarCode2-15B和CodeLLama-7B</li></ul></div><h4 id="_2409-qwen1-5-2-5-coder" tabindex="-1">(2409) Qwen1.5&amp;2.5 Coder <a class="header-anchor" href="#_2409-qwen1-5-2-5-coder" aria-label="Permalink to &quot;(2409) Qwen1.5&amp;2.5 Coder&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">Qwen1.5&amp;2.5 Coder(2409)</div><p><strong>参考链接</strong></p><ul><li><a href="https://huggingface.co/Qwen/CodeQwen1.5-7B" target="_blank" rel="noreferrer">Qwen/CodeQwen1.5-7B</a>, <a href="https://arxiv.org/abs/2409.12186" target="_blank" rel="noreferrer">Qwen2.5-Coder 技术报告</a></li></ul><p><strong>CodeQwen1.5 (7B)</strong></p><ul><li><strong>关键技术</strong>：64k上下文，多种语言训练。GQA提升推理效率。</li><li><strong>训练数据</strong>：代码数据。</li><li><strong>数据清洗</strong></li><li><strong>关键结果</strong>：较好 bug, SQL, Debug能力。</li></ul><p><strong>Qwen2.5-Coder (0.5B-32B)</strong></p><ul><li><strong>关键技术</strong>： <ul><li>128k上下文(<a href="https://plmsmile.github.io/posts/llm/basic/08-llm-position-embedding.html#yarn" target="_blank" rel="noreferrer">Yarn技术</a>)</li><li>指令微调：<code>多语言合成数据</code> + <code>DPO优化 执行反馈</code>，<a href="https://plmsmile.github.io/posts/llm/rl/theory/09-policy-trpo-ppo.html#dpo" target="_blank" rel="noreferrer">DPO笔记</a></li></ul></li><li><strong>训练数据</strong>：混合代码、数学和文本。</li><li><strong>数据清洗</strong></li><li><strong>关键结果</strong><ul><li>在MultiPL-E, RepoEval, CrossCodeEval上效果不错</li><li><code>不依赖特定提示词格式</code>，泛化性不错。</li></ul></li></ul></div><h4 id="_2403-yi-coder-9b" tabindex="-1">(2403) Yi-Coder-9B <a class="header-anchor" href="#_2403-yi-coder-9b" aria-label="Permalink to &quot;(2403) Yi-Coder-9B&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">Yi-Coder (24)</div><p><strong>参考链接</strong></p><ul><li><a href="https://github.com/01-ai/Yi-Coder" target="_blank" rel="noreferrer">Yi-Coder</a>, <a href="https://huggingface.co/01-ai/Yi-Coder-9B-Chat" target="_blank" rel="noreferrer">01-ai/Yi-Coder-9B-Chat</a></li></ul><p><strong>关键技术</strong></p><ul><li>128k 上下文、52种语言。</li><li>1.5B、9B。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>HumanEval, MBPP, LiveCodeBench 和大尺寸模型相当。</li></ul></div><h4 id="_2409-codestral-22b-mistral-ai" tabindex="-1">(2409) Codestral-22B (Mistral AI) <a class="header-anchor" href="#_2409-codestral-22b-mistral-ai" aria-label="Permalink to &quot;(2409) Codestral-22B (Mistral AI)&quot;">​</a></h4><div class="custom-block important"><div class="custom-block-title">Codestral (2409, Mistral AI)</div><p><strong>参考链接</strong></p><ul><li><a href="https://huggingface.co/mistralai/Codestral-22B-v0.1" target="_blank" rel="noreferrer">mistralai/Codestral-22B-v0.1</a></li></ul><p><strong>关键技术</strong></p><ul><li>多种语言，指令跟随。</li><li>32K上下文，仓库级推理，FIM填充能力。</li><li>22B模型。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>在RepoBench和Python相关评估上，效果不错。</li></ul></div><h4 id="_2405-granite-code-ibm" tabindex="-1">(2405) Granite-Code (IBM) <a class="header-anchor" href="#_2405-granite-code-ibm" aria-label="Permalink to &quot;(2405) Granite-Code (IBM)&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">Granite-Code(2405, IBM)</div><p><strong>参考链接</strong></p><ul><li><a href="https://doi.org/10.48550/arXiv.2405.04324" target="_blank" rel="noreferrer">Granite Code Models</a></li></ul><p><strong>关键技术</strong></p><ul><li>两阶段训练：<code>code预训练</code> + <code>混合code文本增强训练</code>。</li><li>目标：FIM (PSM/SPM)</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p></div><h4 id="_2406-codegemma" tabindex="-1">(2406) CodeGemma <a class="header-anchor" href="#_2406-codegemma" aria-label="Permalink to &quot;(2406) CodeGemma&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">CodeGemma (2406)</div><p><strong>参考链接</strong></p><ul><li><a href="https://arxiv.org/abs/2406.11409" target="_blank" rel="noreferrer">CodeGemma</a> 2B, 7B</li></ul><p><strong>关键技术</strong></p><ul><li><code>代码数据</code> <code>预训练</code>和 <code>指令微调</code>。</li><li>训练目标：<code>FIM</code> 且 <code>比例更高</code>，支持2种模式 <ul><li>前缀-后缀-中间(PSM)：先给P(prefix)，再给S(suffix)，猜中间M</li><li>后缀-前缀-中间(SPM)：先给S，再给P，猜中间M。</li></ul></li><li>2种尺寸：2B IDE场景-更快；7B chat设计、推理逻辑更强。</li></ul><p><strong>训练数据</strong></p><ul><li>代码数据</li></ul><p><strong>数据清洗</strong></p><ul><li>去重、去污染(去除测试数据)</li><li><code>Multi-file packing</code>：依赖<code>图</code>和<code>单元测试</code>的多文件打包策略。</li></ul><p><strong>关键结果</strong></p></div><h4 id="_2403-codesheel" tabindex="-1">(2403) CodeSheel <a class="header-anchor" href="#_2403-codesheel" aria-label="Permalink to &quot;(2403) CodeSheel&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">CodeShell (2403)</div><p><strong>参考链接</strong></p><ul><li><a href="https://arxiv.org/abs/2403.15747" target="_blank" rel="noreferrer">tech report</a></li></ul><p><strong>关键技术</strong></p><ul><li>GPT2(7B) 扩展：8k上下文、GQA、RoPE。</li><li>数据清洗比简单scaling有效。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><ul><li>去重、困惑度筛选、结构规则过滤、模型打分。</li></ul><p><strong>关键结果</strong></p><ul><li>优于同类7B模型，在MultiPL-E和代码补全bench上不错。</li></ul></div><h4 id="_23-stable-code-3b" tabindex="-1">(23) stable-code-3B <a class="header-anchor" href="#_23-stable-code-3b" aria-label="Permalink to &quot;(23) stable-code-3B&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">StableCode (23)</div><p><strong>链接</strong></p><ul><li><a href="https://huggingface.co/stabilityai/stable-code-3b" target="_blank" rel="noreferrer">stabilityai/stable-code-3b</a></li></ul><p><strong>关键技术</strong></p><ul><li>3B，代码生成和理解，代码补全和text2code。</li><li>长上下文：16k；<code>多文件推理</code>。</li></ul><p><strong>训练数据</strong></p><ul><li>Github corpora</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>HumanEval/MBPP 效果不错</li></ul></div><h4 id="_2401-deepseek-coder见下文" tabindex="-1">(2401) DeepSeek-Coder见下文 <a class="header-anchor" href="#_2401-deepseek-coder见下文" aria-label="Permalink to &quot;(2401) DeepSeek-Coder见下文&quot;">​</a></h4><h4 id="_24-mftcoder" tabindex="-1">(24) MFTCoder <a class="header-anchor" href="#_24-mftcoder" aria-label="Permalink to &quot;(24) MFTCoder&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">MFTCoder (2024)</div><p><strong>关键技术</strong></p><ul><li>多任务微调：代码补全、text2code、代码注释、代码翻译、单元测试生成等。</li><li>多任务平衡方法：数据平衡、token-weighted loss、focal-style强调。</li><li>效率优化技术：动态padding、packed SFT、PEFT等。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>相比于单SFT和简单混合SFT，MFTCoder效果更好，具有泛化能力。</li></ul></div><h4 id="_2308-codellama" tabindex="-1">(2308) CodeLLaMA <a class="header-anchor" href="#_2308-codellama" aria-label="Permalink to &quot;(2308) CodeLLaMA&quot;">​</a></h4>',73)),l("div",n,[e[15]||(e[15]=l("div",{class:"custom-block-title"},"Code LLaMA (2308)",-1)),e[16]||(e[16]=l("p",null,[l("strong",null,"关键技术")],-1)),l("ul",null,[l("li",null,[e[8]||(e[8]=o("基于LLaMA2开发，强调")),e[9]||(e[9]=l("code",null,"长上下文",-1)),e[10]||(e[10]=o("、")),e[11]||(e[11]=l("code",null,"中间填充",-1)),e[12]||(e[12]=o("、")),e[13]||(e[13]=l("code",null,"代码指令跟随",-1)),e[14]||(e[14]=o("等。 ")),l("ul",null,[l("li",null,[e[4]||(e[4]=o("上下文：")),e[5]||(e[5]=l("a",{href:"https://plmsmile.github.io/posts/llm/basic/08-llm-position-embedding.html#%E6%97%8B%E8%BD%AC%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81",target:"_blank",rel:"noreferrer"},"RoPE",-1)),e[6]||(e[6]=o(" base由")),l("mjx-container",d,[(i(),r("svg",c,e[0]||(e[0]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1033,393.1) scale(0.707)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" style="stroke-width:3;"></path></g></g></g></g>',1)]))),e[1]||(e[1]=l("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[l("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[l("msup",null,[l("mn",null,"10"),l("mn",null,"4")])])],-1))]),e[7]||(e[7]=o("放大至")),l("mjx-container",p,[(i(),r("svg",g,e[2]||(e[2]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1033,393.1) scale(0.707)"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" style="stroke-width:3;"></path></g></g></g></g>',1)]))),e[3]||(e[3]=l("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[l("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[l("msup",null,[l("mn",null,"10"),l("mn",null,"6")])])],-1))])])])])]),e[17]||(e[17]=t("<p><strong>训练数据</strong></p><ul><li>初始化：由LLaMA2权重继续预训练。</li><li>语料库：<code>Code-heavy代码语料库</code></li><li>特定数据：Python和Instruct版本使用<code>特定数据集</code>做微调， 强调<code>特定语言</code>和<code>对齐能力</code>。</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li><code>长上下文</code>对<code>repo-level</code>任务有好处。</li><li><code>特定语言数据(python)</code>做微调对<code>语言任务有好处</code>。</li><li>经过<code>安全微调的指令模型</code>降低了毒性。</li></ul>",5))]),e[19]||(e[19]=t('<h4 id="_2305-codegen2" tabindex="-1">(2305) CodeGen2 <a class="header-anchor" href="#_2305-codegen2" aria-label="Permalink to &quot;(2305) CodeGen2&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">CodeGen2 (2305)</div><p><strong>关键技术</strong></p><ul><li>完整的训练配方：架构选择、采样模式、数据混合等。 <ul><li>架构：Casual Decoder就好了。</li></ul></li><li>混合训练目标：<code>NTP</code>(写下文，50% )；<code>Span Corruption</code>(补全中间,Infil Train, 填空题, 50%)</li><li>多轮预训练</li></ul><p><strong>训练数据</strong></p><ul><li>NL + PL (文本+代码)。</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>Infil 填空训练，会导致代码生成能力下降(从头写到尾的能力)。</li></ul></div><h4 id="_23-starcoder-1-2" tabindex="-1">(23) StarCoder 1-2 <a class="header-anchor" href="#_23-starcoder-1-2" aria-label="Permalink to &quot;(23) StarCoder 1-2&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">StarCoder 1-2 (2023)</div><p><strong>StarCoder1</strong></p><ul><li><strong>关键技术</strong>：<code>长上下文</code> + 中间填充(FIM)训练</li><li><strong>训练数据</strong><ul><li>StarCoderBase：<code>TheStack </code>(宽松许可代码)</li><li>StarCoder：<code>Python数据定向微调</code></li></ul></li><li><strong>数据清洗</strong><ul><li>近似去重、benchmark数据去除、个人隐私去除等。</li></ul></li><li><strong>关键结果</strong><ul><li>benchmark效果好，IDE demo + OpenRAIL_M 许可证。</li></ul></li></ul><p><strong>StarCoder2</strong></p><ul><li><strong>关键技术</strong><ul><li>2阶段训练：<code>先训4k</code> 学基础语法；<code>再训16k</code>，处理长代码，<code>仓库级上下文</code>。</li><li>FIM 中间填充策略。</li></ul></li><li><strong>训练数据</strong><ul><li>TheStack V2：<code>多种语言</code> <code>issue/PR</code>、docs、<code>数学和逻辑</code>数据。</li></ul></li><li><strong>数据清洗</strong></li><li><strong>关键结果</strong><ul><li>3B/7B/15B模型。</li><li>3B超过其他同尺寸模型，15B超过更大模型。</li></ul></li></ul></div><h4 id="_23-codegeex" tabindex="-1">(23) CodeGeex <a class="header-anchor" href="#_23-codegeex" aria-label="Permalink to &quot;(23) CodeGeex&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">CodeGeeX (2023)</div><p><strong>关键技术</strong></p><ul><li>专注于代码<code>生成</code>和<code>翻译</code>。</li><li>INT8量化+FastTransformer：显存大幅降低。</li><li>上线VSCode插件。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>推出HUmanEval-X，评估<code>跨语言翻译能力</code>，包括C++,Java,JavaScript,Go等。</li></ul></div><h4 id="_24-octocoder" tabindex="-1">(24) OctoCoder <a class="header-anchor" href="#_24-octocoder" aria-label="Permalink to &quot;(24) OctoCoder&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">OctoCoder (2024)</div><p><strong>关键技术</strong></p><ul><li><code>指令跟随模型</code>，基于StarCoder-16B-Base做微调而来。</li></ul><p><strong>训练数据</strong></p><ul><li>使用了<code>代码提交记录</code>，即包含<code>自然语言</code>和<code>代码</code>。</li><li><code>避免了code-only偏差</code>。</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>释放<code>HumanEvalPack</code>：把HumanEval扩展至代码<code>修复/解释/生成</code>，以及<code>6种</code>语言。</li><li>pass@1效果好，<code>commit-style</code>数据对<code>bug-fix有好处</code>。</li></ul></div><h4 id="_23-santacoder" tabindex="-1">(23) SantaCoder <a class="header-anchor" href="#_23-santacoder" aria-label="Permalink to &quot;(23) SantaCoder&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">SantaCoder (2023, BigCode)</div><p><strong>关键技术</strong></p><ul><li><a href="https://plmsmile.github.io/posts/llm/basic/06-llm-attention.html#multi-query-attention-2019" target="_blank" rel="noreferrer">MQA</a>：提高推理速度</li><li>两阶段训练方法：先验证设计，再做大规模实验</li></ul><p><strong>训练数据</strong></p><ul><li><code>Python,Java,Javascritp</code>等代码数据。</li></ul><p><strong>数据清洗</strong></p><ul><li><code>去掉个人信息</code>、<code>近似去重</code>、<code>文档质量过滤</code>等。</li></ul><p><strong>关键结果</strong></p><ul><li>在<code>多语言code benc</code>h(Multi-PL-E)上，优于一些参数更大的模型。</li></ul></div><h4 id="其他架构" tabindex="-1">其他架构 <a class="header-anchor" href="#其他架构" aria-label="Permalink to &quot;其他架构&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">提示</div><p><strong>Gemini Diffusion / Mercur Coder</strong></p><ul><li>闭源模型。质量不错，时间大幅降低。</li></ul><p><strong>DiffuCoder</strong></p><ul><li>开源模型，130B训练，与AR模型效果差不多。</li><li>Coupled-GRPO： <ul><li>专门适配扩散模型的RL算法，利用非自回归特性， 引入互补噪声，减少似然估计方差，更好利用探索空间</li><li>21k RL样本，在EvalPlus上带来4.4%的提升。</li></ul></li></ul></div>',12))])}const _=a(s,[["render",u]]);export{C as __pageData,_ as default};

import{_ as a,c as d,o as i,ah as o,j as t,a as l}from"./chunks/framework.CvbyeFFO.js";const f=JSON.parse('{"title":"Code 预训练相关","description":"","frontmatter":{"title":"Code 预训练相关","date":"2025-01-01T23:12:28.000Z","create":"2025-01-01T23:12:28.000Z","categories":["codellm"],"tags":["KAT-Dev","Seed-Coder"]},"headers":[],"relativePath":"posts/llm/industry/codellm/08-code-pretrain-summary.md","filePath":"posts/llm/industry/codellm/08-code-pretrain-summary.md","lastUpdated":null}'),s={name:"posts/llm/industry/codellm/08-code-pretrain-summary.md"},n={class:"custom-block note"},r={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},c={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.25ex"},xmlns:"http://www.w3.org/2000/svg",width:"4.192ex",height:"2.398ex",role:"img",focusable:"false",viewBox:"0 -949.5 1853 1060","aria-hidden":"true"},T={class:"custom-block note"},u={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},m={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"17.564ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 7763.1 1000","aria-hidden":"true"};function Q(g,e,p,h,b,k){return i(),d("div",null,[e[20]||(e[20]=o('<h2 id="论文阅读" tabindex="-1">论文阅读 <a class="header-anchor" href="#论文阅读" aria-label="Permalink to &quot;论文阅读&quot;">​</a></h2><h3 id="_2510-kat-dev" tabindex="-1">(2510) KAT-Dev <a class="header-anchor" href="#_2510-kat-dev" aria-label="Permalink to &quot;(2510) KAT-Dev&quot;">​</a></h3><div class="custom-block danger"><div class="custom-block-title">摘要</div><ul><li><a href="http://plmsmile.github.io/posts/llm/industry/codellm/07-code-llm-reading.html#_2510-kat-dev" target="_blank" rel="noreferrer">KAT-Dev 笔记</a></li></ul></div><h4 id="midterm-train" tabindex="-1">MidTerm-Train <a class="header-anchor" href="#midterm-train" aria-label="Permalink to &quot;MidTerm-Train&quot;">​</a></h4><p>拓展模型的推理、规划、交互等能力。</p><div class="custom-block note"><div class="custom-block-title">Train Recipe</div><p><strong>Train Recipe</strong></p><ul><li><strong>真实SWE语料库</strong>：20B token，包括<code>PR</code>、<code>Issue</code>、<code>Commit</code>、<code>Patch</code>等。</li><li><strong>推理和反思增强</strong>：利用SOTA开源模型，生成CoT轨迹，解决复杂问题。</li><li>Agent交互模拟：构建模拟环境，合成<code>Plan-Action-Observation</code>轨迹。</li><li><strong>复杂质量遵循和约束对齐</strong>：构建<code>可验证逻辑和结构</code>的<code>指令跟随数据集</code>。</li></ul></div><h3 id="_2506-seed-coder" tabindex="-1">(2506) Seed-Coder <a class="header-anchor" href="#_2506-seed-coder" aria-label="Permalink to &quot;(2506) Seed-Coder&quot;">​</a></h3><div class="custom-block danger"><div class="custom-block-title">Seed-Coder 摘要</div><ul><li><a href="http://plmsmile.github.io/posts/llm/industry/codellm/07-code-fulltrain-reading.html#_2506-seed-coder" target="_blank" rel="noreferrer">Seed-Coder 论文笔记</a></li></ul></div><p><strong>📕核心方法</strong></p><h4 id="data-pipeline-概览" tabindex="-1">Data Pipeline 概览 <a class="header-anchor" href="#data-pipeline-概览" aria-label="Permalink to &quot;Data Pipeline 概览&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">预训练数据处理 Pipeline 概览</div><p><strong>原始数据</strong></p><ul><li>Github数据、Web数据</li></ul><p><strong>处理步骤 (预处理+过滤)</strong></p><ul><li><strong>预处理</strong><ul><li><strong>去重</strong>：<code>精确去重</code>和<code>近似去重</code></li><li><strong>Mini规则过滤</strong>：去掉<code>不相关</code>或<code>非代码数据</code></li></ul></li><li><strong>LLM质量过滤</strong><ul><li>过滤后<code>数据分为4类</code><ul><li><code>文件级代码</code> + <code>仓库级代码</code> + <code>Github Commits</code> + <code>代码相关的web数据</code></li></ul></li></ul></li></ul><p><strong>处理结果</strong></p><ul><li><code>核心预训练数据</code></li><li><code>继续预训练数据</code>：<code>高质量数据</code> + <code>长上下文数据</code></li></ul></div><img src="https://paper-assets.alphaxiv.org/figures/2506.03524v2/x4.png" style="display:block;margin:auto;" width="70%"><h4 id="github-数据处理" tabindex="-1">Github 数据处理 <a class="header-anchor" href="#github-数据处理" aria-label="Permalink to &quot;Github 数据处理&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Github 数据处理</div><p><strong>数据预处理</strong></p><ul><li><code>文件级去重</code> + <code>仓库级去重</code><ul><li><code>精准去重</code>(SHA256)、<code>近似去重</code>(MinHash)</li><li>文件级：<code>短上下文学习</code>；仓库级：保留项目结构，<code>长上下文学习</code>。</li></ul></li><li><code>去掉存在语法错误的文件</code><ul><li>使用<strong>语法解析器</strong>检查文件是否存在<strong>语法错误</strong></li></ul></li><li>最终<code>减少98%</code>原始数据。</li></ul><p><strong>质量过滤</strong></p><ul><li><p><strong>规则过滤存在挑战</strong>：需要多个专家共同编辑，很难一致，而且很难去评估。</p></li><li><p><code>文件级质量评分模型</code></p><ul><li><p>四维度：<code>可读性</code>(注释合理)、<code>模块化</code>(结构好)、<code>清晰度</code>(少冗余)、<code>复用性</code>(易集成)。</p></li><li><p>输出<code>0-1分</code>，<code>过滤低质量代码文件</code>，<code>无需复杂标准</code>。过滤一些自动生成的代码。</p></li><li><p><code>微调1.3B模型</code>，<code>回归Head</code>，训练1个epoch，<code>MSEloss</code>，类别平均MAE观测指标。</p></li><li><p><strong>训练数据</strong>：<code>21种语言</code>，使用<code>GPT-4</code>/DeepSeek-Coder-33B(V2-Chat)<code>构造GT</code>。</p></li></ul></li><li><p>最终<code>去除10%数据</code></p></li></ul></div><img src="https://paper-assets.alphaxiv.org/figures/2506.03524v2/x5.png" style="display:block;margin:auto;" width="70%"><h4 id="commit-数据处理" tabindex="-1">Commit 数据处理 <a class="header-anchor" href="#commit-数据处理" aria-label="Permalink to &quot;Commit 数据处理&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Commit 数据处理</div><p><strong>Commit原始数据</strong></p><ul><li><code>14w 高质量仓库</code>、<code>7400w次提交</code>。 <ul><li>高质量仓库：100star、10个fork、100次提交、100天的维护活动</li></ul></li></ul><p><strong>Code Change 预测任务</strong></p><ul><li><code>Code change prediction</code> 任务数据格式： <ul><li>给定<code>提交信息</code>、<code>上下文</code>，模型预测<code>被修改的文件</code>、<code>代码变化</code>。</li><li>上下文：<code>README</code>、<code>目录结构</code>、BM25算法检索的<code>top5相关文件</code></li></ul></li><li>经过去重和预处理后，获得100b tokens。</li><li>提供 <code>真实Code变化</code> <code>强监督信号</code></li></ul></div><h4 id="code-web-数据处理" tabindex="-1">Code-Web 数据处理 <a class="header-anchor" href="#code-web-数据处理" aria-label="Permalink to &quot;Code-Web 数据处理&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Code-Related Web Data</div><p><strong>核心</strong></p><ul><li>从<code>web数据</code>(common crawl等)中，提取出<code>高质量</code>、<code>代码相关</code>的数据。</li></ul><p><strong>预处理</strong></p><ul><li><code>代码提取</code>：带有显示<code>&lt;code&gt;&lt;/code&gt;</code>&gt;标签的数据，非显示代码标签的数据。</li><li><code>去重</code>：使用<code>精确去重</code>和<code>近似去重</code>，同github数据一样。</li><li><code>启发式过滤方法</code>：<code>去掉低质量文档</code>(如低于10个单词)。</li></ul><p><strong>质量过滤</strong></p><ul><li>核心：<code>识别代码相关内容</code> + <code>评估内容质量</code>。</li><li><code>FastText 召回代码内容</code><ul><li>从<code>没有代码标签</code>的数据中<code>召回代码内容</code></li><li>提取并评分1000w个候选网页，标注数据，70%作为种子语料库、30%用于验证</li><li><code>训练fastText模型</code>，<code>识别</code>和<code>检索代码内容</code>。99%召回率、45%精确率。</li><li><code>约3%识别为代码内容</code> (common crawl)</li></ul></li><li><code>LLM 过滤低质数据：打0-10分</code><ul><li>不同类别的网站质量分数存在差异。 <ul><li>电商平台/文档站点/等：结构清晰，分数较高</li><li>社区论坛：得分较低，因为结构化低、混杂多</li></ul></li></ul></li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/seed-coder/20251228193405.jpg" style="display:block;margin:auto;" width="70%"><h4 id="continue-pretrain-数据处理" tabindex="-1">Continue Pretrain 数据处理 <a class="header-anchor" href="#continue-pretrain-数据处理" aria-label="Permalink to &quot;Continue Pretrain 数据处理&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">CPT-高质量数据</div><ul><li>数据来源：主流编程语言、算法、应用开发、jupyter、通用代码数据。</li><li><code>高质量fastText</code> <code>检索高质量数据</code><ul><li>针对每种特征的数据：划分<code>小且多样</code>的<code>高质量种子数据</code>，10w样本，作为正样本，</li><li><code>训练fastText模型</code><ul><li>使用<code>10w正样本</code>，<code>负样本</code>由<code>随机选择</code>和<code>精心构建</code>2部分组成。</li><li><code>迭代训练</code>：训练-&gt;召回新数据-&gt;把最好的加入种子库-&gt;重新训练</li></ul></li><li>经过<code>2-3轮fastText模型训练</code><ul><li><code>逐渐扩充正样本</code>，最终得到<code>130b高质量数据</code>，用作CPT</li></ul></li></ul></li></ul></div><div class="custom-block note"><div class="custom-block-title">CPT-长上下文数据</div><ul><li><strong>长上下文数据</strong><ul><li><code>文件级</code>：结合<code>LLM过滤</code>，从中筛选出<code>长上下文数据</code>。</li><li><code>仓库级</code>：根据<code>文件的平均质量分数</code>选择<code>高质量仓库</code>。 <ul><li><code>主流语言</code>(python/java/c)：基于<code>文件依赖关系</code>做<code>拼接</code></li><li><code>其他语言</code>(HTML/SQL/Shell)：<code>随机拼接</code>。</li><li>每个仓库，作为一个单一的字符串</li></ul></li></ul></li><li>32k长上下文，两个阶段：<code>原始</code> -&gt; <code>8k</code> -&gt; <code>32k</code></li></ul></div><h4 id="预训练策略" tabindex="-1">预训练策略 <a class="header-anchor" href="#预训练策略" aria-label="Permalink to &quot;预训练策略&quot;">​</a></h4>',24)),t("div",n,[e[12]||(e[12]=o('<div class="custom-block-title">预训练策略</div><p><strong>模型架构</strong></p><ul><li>LLama3，8.2B参数，36层，隐藏层大小为4096，中间层大小为14336，</li><li>采用GQA，32个query头，8个key-value头。</li></ul><p><strong>上下文长度</strong></p><ul><li>初期：8k</li><li>CPT：32k</li></ul><p><strong>Token和学习率参数</strong></p>',6)),t("ul",null,[e[10]||(e[10]=t("li",null,[t("code",null,"初期(基础)"),l("：3e-4，"),t("code",null,"1万亿token"),l("，代码web+数学web数据")],-1)),e[11]||(e[11]=t("li",null,[t("code",null,"中期(专业数据)"),l("："),t("code",null,"4万亿token"),l("，"),t("code",null,"精选代码数据")],-1)),t("li",null,[e[5]||(e[5]=t("code",null,"CPT(冲刺)",-1)),e[6]||(e[6]=l("：")),e[7]||(e[7]=t("code",null,"高质量",-1)),e[8]||(e[8]=l("和")),e[9]||(e[9]=t("code",null,"长上下文数据",-1)),t("ul",null,[t("li",null,[e[2]||(e[2]=l("学习率降低")),t("mjx-container",r,[(i(),d("svg",c,e[0]||(e[0]=[o('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msqrt"><g transform="translate(853,0)"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(0,89.5)"><path data-c="221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z" style="stroke-width:3;"></path></g><rect width="1000" height="60" x="853" y="829.5"></rect></g></g></g>',1)]))),e[1]||(e[1]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("msqrt",null,[t("mn",null,"10")])])],-1))]),e[3]||(e[3]=l("倍，训400b token"))]),e[4]||(e[4]=t("li",null,"学习率降低到3e-5，继续训练600b token",-1))])])])]),e[21]||(e[21]=o('<div class="custom-block note"><div class="custom-block-title">FIM任务</div><ul><li><p>Prefix Suffix Middle vs <code>Suffix Prefix Middle</code></p><ul><li>实验<code>SPM</code>效果更好，可能和<code>Attention机制</code>有关系，Prefix后面紧接Middle。</li></ul></li><li><p><strong>FIM训练比例</strong></p><ul><li>初期：<code>50%时间</code>在训练FIM，非常重视<code>代码补全能力</code></li><li>后期：<code>降到10%</code>，需要探索长文本和整体生成能力</li></ul></li></ul></div><h4 id="策略" tabindex="-1">策略 <a class="header-anchor" href="#策略" aria-label="Permalink to &quot;策略&quot;">​</a></h4><h2 id="预训练基础知识" tabindex="-1">预训练基础知识 <a class="header-anchor" href="#预训练基础知识" aria-label="Permalink to &quot;预训练基础知识&quot;">​</a></h2><h3 id="模型训练阶段" tabindex="-1">模型训练阶段 <a class="header-anchor" href="#模型训练阶段" aria-label="Permalink to &quot;模型训练阶段&quot;">​</a></h3><div class="custom-block warning"><div class="custom-block-title">预训练</div><p><strong>数据收集和处理</strong></p><ul><li>爬取海量数据：web 网页、书籍、学术文献、专有材料等。</li><li>数据处理：去重、过滤、tokenize、格式标准化、统一编码、增加特殊标记等。 <ul><li>清洗过滤：去掉低质量、敏感数据等。具体可看主要工作怎么清洗的。</li></ul></li></ul><p><strong>预训练</strong></p><ul><li>随机初始化参数进行训练，消耗最大的部分。</li><li>目标：NTP/MTP/FIM等任务，自监督学习，预测mask的部分。</li></ul><p><strong>CPT</strong></p><ul><li><code>在预训练模型基础上</code>，喂<code>大量代码数据</code> 做<code>继续预训练</code>，做领域适配等等。</li></ul><p><strong>退火策略</strong></p><ul><li>在训练后期，动态调整参数，重点是学习率。</li><li>训练初期学习率较大，加速收敛，后期需要逐渐降低学习率，帮助收敛至最优解。</li></ul></div><div class="custom-block warning"><div class="custom-block-title">后训练</div><p><strong>SFT</strong></p><ul><li>给定输入-输出，教模型回答，</li><li>如Repo SFT，角膜型理解多文件直接的依赖关系。</li></ul><p><strong>RL</strong></p><ul><li>通过人类反馈、奖励机制，进一步提升模型性能。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251210214716.jpg" style="display:block;margin:auto;" width="70%"><h3 id="预训练任务" tabindex="-1">预训练任务 <a class="header-anchor" href="#预训练任务" aria-label="Permalink to &quot;预训练任务&quot;">​</a></h3>',8)),t("div",T,[e[17]||(e[17]=t("div",{class:"custom-block-title"},"基模预训练任务",-1)),e[18]||(e[18]=t("p",null,[t("strong",null,"NTP")],-1)),t("ul",null,[e[16]||(e[16]=t("li",null,"猜下一词",-1)),t("li",null,[e[15]||(e[15]=l("最大化条件概率 ")),t("mjx-container",u,[(i(),d("svg",m,e[13]||(e[13]=[o('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(751,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(1140,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(605,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(2953.9,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(3231.9,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(605,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(4240.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(4685.2,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(5129.8,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(5574.5,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(6019.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(6463.8,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(7374.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)]))),e[14]||(e[14]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"P"),t("mo",{stretchy:"false"},"("),t("msub",null,[t("mi",null,"x"),t("mrow",{"data-mjx-texclass":"ORD"},[t("mi",null,"t"),t("mo",null,"+"),t("mn",null,"1")])]),t("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),t("msub",null,[t("mi",null,"x"),t("mn",null,"1")]),t("mo",null,","),t("mo",null,"."),t("mo",null,"."),t("mo",null,"."),t("mo",null,","),t("msub",null,[t("mi",null,"x"),t("mi",null,"t")]),t("mo",{stretchy:"false"},")")])],-1))])])]),e[19]||(e[19]=o("<p><strong>MTP</strong></p><ul><li>一次猜多个词，预判了你的预判。</li></ul><p><strong>Fill-in-the-Middle (FIM)</strong></p><ul><li>背景：在文件中间插入代码， 需要看<code>前面的代码prefix</code>，也要看<code>后面的代码suffix</code>。</li><li><code>代码模型的特有能力</code>之一，增强代码补全能力。</li></ul><p><strong>Diffusion Coder Training Task</strong></p><ul><li>加噪：把一段<code>好代码</code>随机替换成<code>乱码/噪声</code>。</li><li>去噪：让模型<code>把乱码</code>逐步还原成<code>清晰的代码</code>。</li></ul>",6))]),e[22]||(e[22]=o('<table tabindex="0"><thead><tr><th style="text-align:left;">任务名称</th><th style="text-align:left;">核心逻辑</th><th style="text-align:left;">典型应用场景</th><th style="text-align:left;">优势</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>NTP</strong> (Next Token Prediction)</td><td style="text-align:left;">猜下一个词</td><td style="text-align:left;">所有的 GPT 类模型</td><td style="text-align:left;">基础能力，学会语法和逻辑</td></tr><tr><td style="text-align:left;"><strong>MTP</strong> (Multi-Token Prediction)</td><td style="text-align:left;">猜下面 N 个词</td><td style="text-align:left;">高级模型训练</td><td style="text-align:left;">提高推理速度，增强逻辑连贯性</td></tr><tr><td style="text-align:left;"><strong>FIM</strong> (Fill-in-the-Middle)</td><td style="text-align:left;">完形填空</td><td style="text-align:left;">IDE 里的光标补全</td><td style="text-align:left;">能同时看上下文，补全更准</td></tr><tr><td style="text-align:left;"><strong>Diffusion</strong> (扩散任务)</td><td style="text-align:left;">降噪去模糊</td><td style="text-align:left;">探索性架构</td><td style="text-align:left;">生成多样性高，可并行生成</td></tr></tbody></table><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251210212946.jpg" style="display:block;margin:auto;" width="70%"><h3 id="预训练数据" tabindex="-1">预训练数据 <a class="header-anchor" href="#预训练数据" aria-label="Permalink to &quot;预训练数据&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">预训练数据</div><p><strong>整体趋势</strong></p><ul><li>从追求庞大数量 -&gt; 追求数据质量/许可等。即粗放收集 -&gt; 精细化清洗 -&gt; 合规与大规模。</li></ul><p><strong>Github 数据</strong></p><ul><li>The Stack v1 <ul><li>358种编程语言，3.1TB数据，宽松许可源代码。</li><li>两阶段去重策略：精准匹配hash和近似去重hash。</li></ul></li><li>The Stack v2(当前行业标准) <ul><li>数据扩大四倍，900B token，600种语言，32TB</li><li>来源引入<code>Software Heritage</code>，加入<code>PR&amp;Issues</code>，包含人类如何<code>讨论</code>和<code>修改</code>代码的<code>逻辑过程</code>。</li></ul></li><li>Open Coder <ul><li>3.3TB，13种语言</li></ul></li></ul><p><strong>StarCoder 数据</strong></p><ul><li>从The Stack里精选出来的一部分数据，783GB，86种语言。</li><li>策略：去掉bench数据更干净，增加github issue和commit。</li></ul><p><strong>其他数据</strong></p><ul><li>The Pile：825GB，有代码、论文、网页等混合数据，早期数据。</li><li>RedPajama：1T，包括59B的代码数据，宽松许可证。最初用来复现LLaMA模型的。</li><li>CodeParrot：专注于python的高质量数据集，去重过滤了70%的原始数据。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251210221622.jpg" style="display:block;margin:auto;" width="70%">',5))])}const v=a(s,[["render",Q]]);export{f as __pageData,v as default};

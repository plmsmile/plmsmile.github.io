import{_ as e,c as l,o as c,ah as i}from"./chunks/framework.CvbyeFFO.js";const p=JSON.parse('{"title":"SWE 合成数据 系列","description":"","frontmatter":{"title":"SWE 合成数据 系列","date":"2026-01-05T16:00:16.000Z","create":"2026-01-05T16:00:16.000Z","categories":["swe-data"],"tags":["SWE-Mirror","Issue迁移","生成测试用例","生成Bug源码，Issue描述生成","AgentSFT 数据蒸馏","SWE-Mirror-LM-32B","Skywork-SWE","SWE-smith","SWE-Agent-LM-32B","Agent安装环境","4策略合成Bug","PR Mirror","执行验证","逆向合成Issue","R2E-Gym","Hybrid TTS","挖掘Commit数据","SWE-Gym","SWE-Agent","ACI","Agent-Computer-Interface"]},"headers":[],"relativePath":"posts/llm/industry/codellm/11-swe-data-series.md","filePath":"posts/llm/industry/codellm/11-swe-data-series.md","lastUpdated":null}'),d={name:"posts/llm/industry/codellm/11-swe-data-series.md"};function t(s,o,r,a,n,u){return c(),l("div",null,o[0]||(o[0]=[i('<h2 id="_2509-swe-mirror-seed" tabindex="-1">(2509) SWE-Mirror (Seed) <a class="header-anchor" href="#_2509-swe-mirror-seed" aria-label="Permalink to &quot;(2509) SWE-Mirror (Seed)&quot;">​</a></h2><p>🌺 <strong>论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">论文摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2509.08724" target="_blank" rel="noreferrer">paper</a></li></ul><p><strong>核心方法</strong></p><ul><li><p>1套<code>SWE任务合成移植方法</code>：<code>任务选择</code> + <code>任务移植</code> + <code>任务验证</code></p><ul><li>移植：<code>生成测试用例</code> + <code>生成Bug源代码</code> + <code>生成Issue描述</code></li><li>SWE-mirror-60k：<code>4语言</code>，<code>40 仓库</code>，<code>60k任务</code>，Python大头</li><li>蒸馏了<code>6.3k轨迹</code></li></ul></li><li><p>SFT：<code>Mask错误动作</code></p></li></ul><p><strong>模型效果(Qwen2.5-Coder-Instruct-32B)</strong></p><ul><li>SWE-verified 达<code>52分</code>。Multi-SWE-Bench-Flash 达21分。</li></ul><p><strong>重要结论</strong></p><ul><li><code>Mask错误动作</code> SFT 效果比不Mask或片段剪辑掉的好。</li><li>SFT <code>Data Scaling有效</code>：<code>4k</code>轨迹训练，6-&gt;<code>35分</code>；<code>12k</code>训练，达<code>52分</code>。</li></ul><p><strong>关键贡献</strong></p><ul><li>SWE-Mirror-60k 任务。</li></ul></div><h3 id="问题背景" tabindex="-1">问题背景 <a class="header-anchor" href="#问题背景" aria-label="Permalink to &quot;问题背景&quot;">​</a></h3><p>❓<strong>​问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">SWE组件和两种任务构建方法优缺点</div><p><strong>SWE 两大组件</strong></p><ul><li><strong>Task Context</strong><ul><li><code>Issue</code> + <code>PR</code> + <code>仓库代码</code></li><li><code>测试用例</code>、<code>标准答案</code></li></ul></li><li><strong>Gym</strong><ul><li>可执行环境：测试命令、日志解析、验证正确性、提供奖励。</li></ul></li></ul><p><strong>SWE 两种任务构建方法</strong></p><ul><li><code>合成问题</code>-扩展任务 <ul><li>工作：SWE-smith，SWE-Synth，<code>程序化</code>+<code>重写</code>等方法<code>构建Bug</code>，合成数据。</li><li>优点：规模化。</li><li>缺点：未利用真实软件工程中丰富的历史数据，<code>人工制造的Bug</code></li></ul></li><li><code>搭建Gym</code>-扩展任务 <ul><li>工作：自动搭建环境、收集PR扩展数据。SWE-rebench。</li><li>优点：利用真实数据。</li><li>缺点：<code>环境成本高</code>，<code>成功率低</code>，<code>1实例-1GB</code>，10w实例 -100TB存储。</li></ul></li></ul><p><strong>PR-Mirror</strong></p><ul><li>核心：利用<code>现有代码</code>+<code>现有环境</code>，移植复现<code>之前的Bug</code>，避免为每个bug都重装环境。</li><li>扩展：把<code>原Repo</code>的<code>PR</code>，移植到<code>相似</code>的<code>目标Repo</code>，去<code>构建新任务</code>。</li><li>移植可行的3个理论 <ul><li>组件相似性：很多组件底层架构逻辑和API，有相似之处。(如Pytorch/Tensorflow)</li><li>逻辑可移植性：Bug本质往往是逻辑错误。</li><li>验证可迁移性：源仓库测试用例经过修改后，可验证目标仓库Bug。</li></ul></li></ul></div><div class="custom-block warning"><div class="custom-block-title">SWE 挑战</div><p><strong>Gym 环境构建困难</strong></p><ul><li>收集Context容易，但构建Gym很困难，需要<code>大量人工</code> <code>单独搭环境</code>。</li><li>大部分：<code>Task-Gym</code> 是<code>一对一</code>依赖关系。</li></ul></div><h3 id="swe-mirror-swe任务合成移植方法" tabindex="-1">SWE-Mirror SWE任务合成移植方法 <a class="header-anchor" href="#swe-mirror-swe任务合成移植方法" aria-label="Permalink to &quot;SWE-Mirror SWE任务合成移植方法&quot;">​</a></h3><div class="custom-block info"><div class="custom-block-title">数据源</div><p><strong>数据源(Gym环境)</strong></p><ul><li>SWE-Gym, SWE-rebench, Multi-SWE-RL</li><li>筛选条件：<code>5分钟 完成所有测试</code> + <code>1GB内存</code></li></ul><p><strong>最终数据集</strong></p><ul><li>SWE-mirror-60k：<code>4语言</code>，<code>40 仓库</code>，<code>60k任务</code>，Python大头</li></ul></div><h4 id="任务选择" tabindex="-1">任务选择 <a class="header-anchor" href="#任务选择" aria-label="Permalink to &quot;任务选择&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">1. 任务选择</div><ul><li>目标：为<code>每个Repo+Gym</code> (目标Repo)，寻找可移植的Issue。</li><li><strong>搜索相关相似Repo</strong>： <ul><li><code>Qwen-32B 生成5个关键词</code> + <code>关键词搜索相关Top20 Repo</code></li></ul></li><li>从相关Repo<strong>收集过滤Issue-PR</strong>： <ul><li><code>手工规则</code>+<code>LLM筛选</code>，筛选<code>高质量</code> <code>可移植</code>的<code>Issue</code></li><li>100测试集，LLM准召：84%、86%</li></ul></li></ul></div><h4 id="issue-迁移" tabindex="-1">Issue 迁移 <a class="header-anchor" href="#issue-迁移" aria-label="Permalink to &quot;Issue 迁移&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">2. 任务移植</div><p><strong>原Issue提炼</strong></p><ul><li><code>原Issue-PR 简洁抽象描述提炼</code>：包括功能、核心逻辑、当前行为、预期行为、观察症状等。</li></ul><p><strong>移植过程</strong></p><ul><li><strong>生成 测试用例</strong><ul><li><code>TestAgent</code>：<code>抽象描述</code> + 目标Repo-Gym的<code>测试套件 </code> --&gt; <code>新的测试用例</code></li><li><code>test.patch</code>：当前代码能通过，应用Bug后的代码不能通过。</li></ul></li><li><strong>生成 Bug源代码</strong><ul><li><code>Mirror Agent</code>：<code>抽象描述</code> + test.patch 包含的<code>文件路径</code> + <code>函数名称</code> --&gt; <code>修改源代码</code></li><li><code>mirror.patch</code>：有Bug的版本，任务起点。</li><li><code>fix.patch</code>：正确答案，无bug，即未应用Bug的版本。</li></ul></li><li><strong>生成 Issue描述</strong><ul><li>Prompt指令：原Issue描述 + <code>test.patch</code> + <code>fix.patch</code> + <code>few-shot 示例</code></li><li>描述：<code>连贯</code> <code>自包含</code>的任务描述。</li></ul></li></ul><p><strong>最终产出任务</strong></p><ul><li><code>mirror.patch</code>：引入目标bug的补丁</li><li><code>test.patch</code>：测试用例</li><li><code>fix.patch</code>：无bug，标准答案</li><li><code>Issue描述/problem_statement</code>：问题描述</li></ul><p><strong>效果评估</strong></p><ul><li>成功率：46% 很高了。88%任务具和原始Issue相比具有中高一致性。</li></ul></div><h4 id="任务验证" tabindex="-1">任务验证 <a class="header-anchor" href="#任务验证" aria-label="Permalink to &quot;任务验证&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">3. 任务验证 (质量控制)</div><p><strong>应用实际测试</strong></p><ul><li>run.log：<code>mirror</code>，执行原始测试</li><li>test.log：<code>mirror</code> + <code>test</code>，执行生成的测试</li><li>fix.log：<code>mirror</code> + <code>test</code> + <code>fix</code>，应用3个补丁，执行测试</li></ul><p><strong>日志检查及过滤标准</strong></p><ul><li><code>不能导致原测试挂掉</code>：检查run.log+test.log，只能有pass2pass, fail2fail, skip2skip, none2fail。</li><li>必须<code>真的修复Bug</code>：必须有 Fail2Pass</li><li><code>不能产生新Bug</code>：不能有 Fail2Pass</li><li>测试不能不稳定：有时fail、有时pass，必须过滤</li></ul></div><h4 id="agentsft-数据蒸馏" tabindex="-1">AgentSFT 数据蒸馏 <a class="header-anchor" href="#agentsft-数据蒸馏" aria-label="Permalink to &quot;AgentSFT 数据蒸馏&quot;">​</a></h4><div class="custom-block info"><div class="custom-block-title">SWE-Mirror AgentSFT 轨迹数据蒸馏</div><p><strong>概览</strong></p><ul><li>模型：Claude3.7-Sonnet, Claude4-Sonnet</li><li>任务：SWE-Mirror-60k，选择 <code>15k任务</code></li><li>Agent：<code>OpenHands</code></li><li>超参：100轮，每任务3轨迹，温度=1</li><li>成功蒸馏：<code>6.3k 轨迹</code></li><li>和 <a href="https://huggingface.co/datasets/nebius/SWE-rebench" target="_blank" rel="noreferrer">SWE-rebench</a>轨迹合并，组成<code>12k轨迹</code>。</li></ul></div><h3 id="实验设置" tabindex="-1">实验设置 <a class="header-anchor" href="#实验设置" aria-label="Permalink to &quot;实验设置&quot;">​</a></h3><p>✍️<strong>实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li>Qwen2.5-Coder-Instruct-7B/32B</li></ul><p><strong>训练任务/数据</strong></p><ul><li>SWE-Mirror 蒸馏轨迹 + SWE-rebench轨迹，合计<code>12k轨迹</code></li></ul><p><strong>评测任务/数据</strong></p><ul><li><code>SWE-verified</code>, <code>Multi-SWE-Bench-Flash</code></li></ul><p><strong>算法/策略</strong></p><ul><li>SFT：<code>Mask错误动作</code>，只学习有效轮次。同 <a href="http://plmsmile.github.io/posts/llm/industry/codellm/09-swe-series.html#_2508-nebius-%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E5%A4%9A%E8%BD%AEswe-%E7%AD%9B%E9%80%89swe-rebench%E6%95%B0%E6%8D%AE" target="_blank" rel="noreferrer">NEBIUS RFT冷启动 </a>一致。</li><li>Scaffold：OpenHands，MopenHands(多语言) <ul><li>OpenHands：编辑文件、shell命令、浏览网页等。</li></ul></li></ul><p><strong>超参</strong></p><ul><li>3epoch，AdamW cosine decay, decay weight=0.01, warmpup=0.1, 峰值lr=5e-5</li><li>如果数据小于4k，则：5epoch，lr=1e-4</li></ul></div><h3 id="关键结果-qwen2-5-coder-instruct-32b" tabindex="-1">关键结果(Qwen2.5-Coder-Instruct-32B) <a class="header-anchor" href="#关键结果-qwen2-5-coder-instruct-32b" aria-label="Permalink to &quot;关键结果(Qwen2.5-Coder-Instruct-32B)&quot;">​</a></h3><p>🍑<strong>关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><p><strong>模型效果(Qwen2.5-Coder-Instruct-32B)</strong></p><ul><li>SWE-Mirror-LM-32B <code>swe达52分</code>，7B达 22分。MSB-Flash 32B达21分。</li><li>32B 超过DeepSeekR1-0528(45分)，低于Qwen3-Coder-480B-A35B(69.6)</li></ul><p><strong>重要结论</strong></p><ul><li><code>Mask错误动作</code> SFT 效果比不Mask或片段剪辑掉的好。</li><li>SFT <code>Data Scaling有效</code>：<code>4k</code>轨迹训练，6-&gt;<code>35分</code>；<code>12k</code>训练，达<code>52分</code>。</li></ul><p><strong>关键贡献</strong></p><ul><li>SWE-Mirror-60k 任务。</li></ul></div><h3 id="未来方向" tabindex="-1">未来方向 <a class="header-anchor" href="#未来方向" aria-label="Permalink to &quot;未来方向&quot;">​</a></h3><p>⛳ <strong>未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div><ul><li>数据扩展：</li><li>多语言扩展：</li></ul></div><h2 id="_2506-skywork-swe" tabindex="-1">(2506) Skywork-SWE <a class="header-anchor" href="#_2506-skywork-swe" aria-label="Permalink to &quot;(2506) Skywork-SWE&quot;">​</a></h2><p>🌺 <strong>论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">Skywork-SWE 摘要</div><p><strong>参考链接</strong></p><ul><li><a href="http://plmsmile.github.io/posts/llm/industry/mainllm/15-skywork-series.html#_2506-skywork-swe" target="_blank" rel="noreferrer">论文笔记</a>, <a href="https://www.alphaxiv.org/abs/2506.19290" target="_blank" rel="noreferrer">paper</a>, <a href="https://huggingface.co/Skywork/Skywork-SWE-32B" target="_blank" rel="noreferrer">Skywork-SWE-32B</a>, <a href="https://quixotic-sting-239.notion.site/Skywork-SWE-Unveiling-Data-Scaling-Laws-for-Software-Engineering-in-LLMs-eb17f379610040ceb54da5d5d24065bd" target="_blank" rel="noreferrer">blog</a></li></ul><p><strong>核心方法</strong></p><ul><li>1套<code>SWE任务收集构建方法</code>：<code>Repo+PR 收集</code> + <code>统一环境安装</code> + <code>执行验证</code>等。 <ul><li>基于<code>真实环境执行</code>来做<code>数据验证</code>，<code>3层增量式镜像</code> (基础+环境+实例镜像)。</li><li><code>Skywork-SWE数据</code>：<code>10k任务</code> + <code>2.5k仓库</code>。</li><li>AgentSFT蒸馏：<code>8k轨迹数据</code>。</li></ul></li></ul><p><strong>模型效果 (Qwen-2.5-Coder-32B)</strong></p><ul><li><code>闭源LLM蒸馏</code> <code>轨迹数据SFT</code> ，<code>SWE-verified 达36分</code>，<code>TTS, Best-of-3</code> 达<code>47分</code>。</li></ul><p><strong>重要结论</strong></p><ul><li>SWE <code>Data-Scaling</code>, <code>Test-Time-Scaling</code>, <code>轮数Scaling</code> Law 得到验证。</li><li>经过<code>单元测试验证的数据</code>比<code>SWE-smith合成数据</code> 靠谱，提升6.8%</li></ul><p><strong>关键贡献</strong></p><ul><li>开源数据和模型SkyWork-SWE-32B。</li></ul></div><h2 id="_2505-swe-rebench" tabindex="-1">(2505) SWE-rebench <a class="header-anchor" href="#_2505-swe-rebench" aria-label="Permalink to &quot;(2505) SWE-rebench&quot;">​</a></h2><p>🌺 <strong>论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">论文摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2505.20411" target="_blank" rel="noreferrer">paper</a></li></ul><p><strong>模型效果</strong></p><ul><li></li></ul><p><strong>核心方法</strong></p><ul><li>自动实时构建Github Issue。</li></ul><p><strong>重要结论</strong></p><ul><li></li></ul><p><strong>关键贡献</strong></p><ul><li></li></ul></div><h2 id="_2504-swe-smith-swe-agent-lm" tabindex="-1">(2504) SWE-smith (SWE-Agent-LM) <a class="header-anchor" href="#_2504-swe-smith-swe-agent-lm" aria-label="Permalink to &quot;(2504) SWE-smith (SWE-Agent-LM)&quot;">​</a></h2><p><strong>🌺 论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">SWE-smith 摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2504.21798" target="_blank" rel="noreferrer">paper</a>, <a href="https://github.com/SWE-bench/SWE-smith" target="_blank" rel="noreferrer">SWE-smith</a></li></ul><p><strong>核心方法</strong></p><ul><li>1套<code>SWE任务合成方法</code>：<code>Agent安装环境</code> + <code>4策略合成候选任务</code> + <code>执行验证</code> + <code>逆向合成Issue</code><ul><li>SWE-smith： <code>50k任务</code> + <code>128仓库</code>。</li></ul></li><li>1套<code>轨迹蒸馏方法</code>：<code>5k 轨迹</code>。</li></ul><p><strong>模型效果 (Qwen2.5-Coder-32B)</strong></p><ul><li>使用<code>轨迹数据SFT</code>，<code>SWE-verified 达40</code>，<code>提升33pt</code>。</li></ul><p><strong>重要结论</strong></p><ul><li><code>任务Scaling有效</code>，<code>多样性很重要</code>，<code>PR-Mirror</code>, <code>LM-Rewrite</code>的任务比较好。</li></ul><p><strong>关键贡献</strong></p><ul><li>开源：SWE-Smith 工具包，<code>任务实例+环境+轨迹数据</code></li></ul></div><h3 id="问题背景-缺乏数据-现2种数据方法有缺点" tabindex="-1">问题背景(缺乏数据+现2种数据方法有缺点) <a class="header-anchor" href="#问题背景-缺乏数据-现2种数据方法有缺点" aria-label="Permalink to &quot;问题背景(缺乏数据+现2种数据方法有缺点)&quot;">​</a></h3><p><strong>❓问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">问题背景</div><p><strong>SWE 任务缺数据</strong></p><ul><li>SWE-LLM 依赖闭源模型，开源<code>缺乏大规模</code>、<code>高质量训练数据</code>。需要infra去促进训练数据scale</li></ul><p><strong>两种数据模式各有弊端</strong></p><ul><li><code>直接爬取 Github PR/Issue</code><ul><li>优点：简单，<code>量大管饱</code></li><li>缺点：<code>缺乏执行环境</code>、<code>缺乏测试用例</code>，<code>缺乏可靠验证信号</code>，数据质量不可靠</li><li>学习：模型只能学习<code>表面代码相似度形式</code></li></ul></li><li><code>SWE-bench 扩展模式</code><ul><li>优点：<code>执行单元测试</code> 可靠，可以用来<code>蒸馏轨迹数据</code>，<code>数据质量高</code></li><li>学习：学习<code>逻辑功能</code>。</li><li>PR 要求：<code>解决了Issue</code> + <code>需修改新增真实单元测试</code></li><li>缺点：成本高，<code>数据要求严格</code>导致扩展受限，<code>人工调试环境</code>。</li></ul></li></ul></div><h3 id="swe-smith-任务合成方法" tabindex="-1">SWE-Smith 任务合成方法 <a class="header-anchor" href="#swe-smith-任务合成方法" aria-label="Permalink to &quot;SWE-Smith 任务合成方法&quot;">​</a></h3><p><strong>📕核心方法</strong></p><h4 id="数据方法概览" tabindex="-1">数据方法概览 <a class="header-anchor" href="#数据方法概览" aria-label="Permalink to &quot;数据方法概览&quot;">​</a></h4><div class="custom-block info"><div class="custom-block-title">SWE-Smith 整体流程</div><ul><li>先定义环境，再合成任务实例。 <ul><li>给定代码库，<code>使用SWE-Agent来构建环境</code>，<code>仓库级环境</code>。</li><li>通过4种策略，<code>生成多个候选任务</code></li><li>通过执行验证，<code>过滤不合格任务</code>。</li><li>使用<code>LLM生成Issue描述</code>。</li></ul></li><li>最终： <code>128个Python仓库</code> + <code>50k任务实例</code></li><li>轨迹蒸馏：最终 <code>5k 轨迹数据</code></li></ul></div><img src="https://paper-assets.alphaxiv.org/figures/2504.21798v2/x10.png" style="display:block;margin:auto;" width="70%"><img src="https://paper-assets.alphaxiv.org/figures/2504.21798v2/x1.png" style="display:block;margin:auto;" width="70%"><h4 id="合成细节-agent搭环境-4策略合成bug-执行验证-合成issue" tabindex="-1">合成细节(Agent搭环境+4策略合成Bug+执行验证+合成Issue) <a class="header-anchor" href="#合成细节-agent搭环境-4策略合成bug-执行验证-合成issue" aria-label="Permalink to &quot;合成细节(Agent搭环境+4策略合成Bug+执行验证+合成Issue)&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">SWE-Smith 任务构建方法</div><p><strong>环境构建</strong></p><ul><li>仓库筛选：24年11月 <code>PyPI下载量前5000</code>的包，去掉<code>stars&lt;1000</code>+<code>SWE重复</code>的仓库。</li><li><code>给定仓库</code>(最新commit)，<code>让SWE-Agent</code> 在100内 <code>安装环境</code>和<code>执行测试</code>。</li><li>人工验证安装和测试情况：<code>测试用例通过&gt;80%</code>，则算成功，为其构建<code>仓库级docker镜像</code>。</li></ul><p><strong>候选任务构建</strong></p><ul><li>核心：为每个仓库，通过4种策略<code>生成不同的候选任务</code>。</li><li><strong>大模型生成</strong>： <ul><li><code>给函数文档重新实现</code>：LLM-Rewrite，<code>效果很好</code></li><li><code>让LLM故意改错代码</code> ：LLM-Modify，效果最差</li></ul></li><li><strong>程序化制造Bug</strong>：<code>效果好</code>。 <ul><li>先<code>解析代码结构</code>再<code>故意破坏</code>。错误微小，难以觉察。</li></ul></li><li><strong>组合Bug</strong>：在同1文件里组合前面的多个bug</li><li><strong>PR Mirror(PR 反转)</strong>：<code>效果最好</code><ul><li>从<code>正确代码</code>-&gt;<code>错误代码</code>，在<code>现有版本</code>上模拟<code>之前的bug</code>，<code>避免重装环境</code></li><li>找到之前<code>修复bug的PR</code>，给LLM输入 <code>最新代码</code> + <code>diff文件</code>，让其<code>复原之前的Bug代码</code>。</li><li>优点：始终在<code>最新版本</code>和<code>环境</code>上工作，环境配置简单。</li></ul></li></ul><p><strong>执行验证</strong></p><ul><li>为每个候选patch，<code>执行测试</code>，仅保留能制造<code>Fail2Pass</code>的任务。</li><li><code>做2分钟耗时限制</code>：bug测试卡死或很慢，依然丢弃。</li></ul><p><strong>Issue 生成</strong></p><ul><li>难度控制住：描述很重要，不能太简单了。</li><li>LLM逆向生成： <ul><li>LLM输入：<code>diff patch</code>、<code>F2P test的源代码</code>、<code>测试失败的报错日志</code></li><li>LLM生成：Github <code>issue风格</code>的<code>Issue描述</code>。</li></ul></li></ul></div><p>LLM 生成Bug</p><img src="https://paper-assets.alphaxiv.org/figures/2504.21798v2/x11.png" style="display:block;margin:auto;" width="70%"><p>程序化制造Bug</p><img src="https://paper-assets.alphaxiv.org/figures/2504.21798v2/x12.png" style="display:block;margin:auto;" width="70%"><p>组合Bug</p><img src="https://paper-assets.alphaxiv.org/figures/2504.21798v2/x13.png" style="display:block;margin:auto;" width="70%"><p>PR Mirroring，从正确代码-&gt;错误代码，复现之前的bug</p><img src="https://paper-assets.alphaxiv.org/figures/2504.21798v2/x14.png" style="display:block;margin:auto;" width="70%"><h4 id="agentsft-数据蒸馏-1" tabindex="-1">AgentSFT 数据蒸馏 <a class="header-anchor" href="#agentsft-数据蒸馏-1" aria-label="Permalink to &quot;AgentSFT 数据蒸馏&quot;">​</a></h4><div class="custom-block info"><div class="custom-block-title">SFT 轨迹数据蒸馏</div><p><strong>概览</strong></p><ul><li>模型：GPT4o, Claude 3.7 SOnet</li><li>Agent：<code>SWE-Agent</code>，<code>ReAct</code></li><li>轮数：<code>75轮</code></li><li>任务：SWE-Smith <code>50k 任务</code></li><li>最终数据：<code>5k 轨迹</code></li></ul><p><strong>关键策略</strong></p><ul><li>任务：<code>共8k任务做蒸馏</code>，占比Smith任务 17.3% <ul><li>包含：<code>PR-Mirror</code> + <code>LLM Rewrite</code> 这两种策略产生的<code>轨迹最有效</code>。</li></ul></li><li><strong>轨迹</strong>：每任务执行3次，17k尝试，解决率36%，共6.4k轨迹。</li><li><strong>过滤</strong>：<code>去掉简单任务</code>，最终5k轨迹</li></ul></div><h3 id="实验设置-1" tabindex="-1">实验设置 <a class="header-anchor" href="#实验设置-1" aria-label="Permalink to &quot;实验设置&quot;">​</a></h3><p><strong>✍️实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li>Qwen2.5-Coder-Instruct-7B/32B</li></ul><p><strong>训练任务/数据</strong></p><ul><li>在<code>SWE-smith任务</code>上，<code>合成的5k轨迹</code> (Claude/GPT4o)</li></ul><p><strong>评测任务/数据</strong></p><ul><li>SWE-verified(500)， SWE-light(300)，SWE-Multilingual(300)</li></ul><p><strong>算法/策略</strong></p><ul><li>SFT</li><li>SWE-Agent：ReAct 风格， <ul><li>编辑文件、执行命令等。</li></ul></li></ul><p><strong>超参</strong></p></div><h3 id="关键结果-swe-agent-lm-32b" tabindex="-1">关键结果(SWE-Agent-LM-32B) <a class="header-anchor" href="#关键结果-swe-agent-lm-32b" aria-label="Permalink to &quot;关键结果(SWE-Agent-LM-32B)&quot;">​</a></h3><p><strong>🍑关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><p><strong>模型效果</strong></p><ul><li>SFT后的SWE-Agent-LM-32B，<code>SWE-Verified 40.2pt</code>，<code>提升33pt</code></li><li>SWE-Agent-LM-32B 仅需24.9步，但Claude 3.7 Sonnet 需要29.1步。 <ul><li>但<code>32B容易陷入重复动作</code>。</li></ul></li></ul><p><strong>重要结论</strong></p><ul><li><code>任务实例</code>/<code>bug类型</code>/<code>仓库覆盖</code> 越多越好，任务<code>Scaling有效果</code>。<code>多样性&gt;难度</code>。</li><li><code>PR-Mirror</code>、<code>LM-Rewrite</code>、程序化制造Bug 效果都好，依次排序，LM Modify 效果最差。</li><li><code>合成Issue</code>已非常<code>接近人类真实水平</code></li><li>可针<code>对特定仓库优化</code>模型表现(Pandas,Sckikit-learn等)，对通用能力损害小</li></ul><p><strong>关键贡献</strong></p><ul><li>开源SWE-smith工具包：<code>生成任务实例</code> + <code>执行环境</code> + <code>专家轨迹数据</code></li></ul></div><h3 id="未来方向-1" tabindex="-1">未来方向 <a class="header-anchor" href="#未来方向-1" aria-label="Permalink to &quot;未来方向&quot;">​</a></h3><p><strong>⛳ 未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div></div><h2 id="_2504-r2e-gym" tabindex="-1">(2504) R2E-Gym <a class="header-anchor" href="#_2504-r2e-gym" aria-label="Permalink to &quot;(2504) R2E-Gym&quot;">​</a></h2><h3 id="摘要背景" tabindex="-1">摘要背景 <a class="header-anchor" href="#摘要背景" aria-label="Permalink to &quot;摘要背景&quot;">​</a></h3><p><strong>🌺 论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">R2E-Gym 摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2504.07164?chatId=019b8c06-0a6c-7d41-b722-443e9539be96" target="_blank" rel="noreferrer">paper</a>, <a href="https://r2e-gym.github.io/" target="_blank" rel="noreferrer">r2e-gym</a></li></ul><p><strong>核心方法</strong></p><ul><li>1套<code>自动合成SWE任务</code>方法：<code>Commit挖掘</code>+<code>测试用例生成</code>+<code>反向Issue生成</code></li><li>R2E-Gym： <code>8k任务</code> + <code>10仓库</code>，其中sub 4k任务</li></ul><p><strong>模型效果</strong></p><ul><li><code>蒸馏Claude轨迹</code>做SFT，Qwen-Coder-32B<code>SWE达34.4分</code></li></ul><p><strong>重要结论</strong></p><ul><li><code>合成数据不输人工数据</code></li><li><code>Hybrid TTS</code> 有效果，从34.4<code>提升至51分</code>。</li></ul></div><p><strong>❓问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">问题背景</div><p><strong>问题</strong></p><ul><li><strong>开源模型有差距</strong>：真实<code>GitHub-SWE问题</code>，<code>开源</code>显著<code>落后于闭源模型</code>（如 GPT-4, Claude 3.5）.</li><li><strong>数据有瓶颈</strong>：缺乏<code>大规模</code>、<code>高质量</code>的<code>可执行训练环境</code>。 <ul><li>现有数据：许多<code>无可执行环境</code>，或依赖<code>人类编写的Issue</code>和<code>测试用例</code>，<code>难以自动化扩充</code>。</li></ul></li><li><strong>推理扩展难题</strong>：现有验证方法 <code>基于测试执行</code> + <code>基于模型打分</code>，都<code>存在局限性</code>。 <ul><li>缺乏对测试时计算（test-time compute）的最佳扩展策略的研究。</li></ul></li></ul></div><h3 id="r2e-gym-任务合成方法" tabindex="-1">R2E-Gym 任务合成方法 <a class="header-anchor" href="#r2e-gym-任务合成方法" aria-label="Permalink to &quot;R2E-Gym 任务合成方法&quot;">​</a></h3><p><strong>📕核心方法</strong></p><div class="custom-block note"><div class="custom-block-title">R2E-Gym SWE任务合成方法</div><p><strong>合成流程</strong></p><ul><li><p><code>挖掘Commit变更数据</code></p><ul><li>SEART 搜索 Python 仓库，</li><li>提取<code>Commit历史记录</code>，使<code>用LLM挖掘</code>出<code>有价值的变更</code>。<code>不依赖 Pull Requests</code>。</li></ul></li><li><p><code>提取或生成测试用例</code></p><ul><li>如Commit带测试用例，<code>直接提取Fail2Pass测试用例</code>。</li><li>若无测试用例，则<code>自动生成测试用例</code>。</li></ul></li><li><p><code>反向翻译生成 Issue</code></p><ul><li>利用<code>TestCases</code>+ <code>Commit</code> 来反向 <code>合成Issue</code>。</li></ul></li></ul><p><strong>最终数据集</strong></p><ul><li><code>R2E-Gym</code> <code>8.1k</code>任务，<code>subset</code> <code>4.5k</code> 任务，仅<code>10 python仓库</code>。</li></ul></div><div class="custom-block caution"><div class="custom-block-title">AgentSFT 数据蒸馏</div><ul><li>基于<code>Subset任务</code> + <code>Claude-3.5-Sonnet 做蒸馏</code> + <code>Openhands</code> + <code>R2E 环境</code></li><li>共<code>3.3k 轨迹</code>，<code>2k任务</code></li></ul></div><h3 id="hybrid-tts" tabindex="-1">Hybrid TTS <a class="header-anchor" href="#hybrid-tts" aria-label="Permalink to &quot;Hybrid TTS&quot;">​</a></h3><div class="custom-block note"><div class="custom-block-title">Hybrid TTS (执行验证+免执行验证)</div><ul><li>先基于<code>免执行验证</code>选出<code>top-n</code>，再基于<code>执行验证</code>做<code>最终排序</code>。</li></ul></div><h3 id="sft-实验设置" tabindex="-1">SFT 实验设置 <a class="header-anchor" href="#sft-实验设置" aria-label="Permalink to &quot;SFT 实验设置&quot;">​</a></h3><p><strong>✍️实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li>Qwen2.5-Coder-7B, 14B, 32B</li></ul><p><strong>训练任务/数据</strong></p><ul><li>SWE任务：R2E-Gym-Subset 4.5k</li><li>SFT 数据：蒸馏<code>3.3k轨迹</code> + <code>2k任务</code>。</li></ul><p><strong>评测任务/数据</strong></p><ul><li>SWE-Verified</li></ul><p><strong>算法/策略</strong></p><ul><li>SFT 训练，LLaMA-Factory</li><li>验证器训练： <ul><li>Testing Agent：Qwen-Coder-32B</li><li><code>免执行验证器</code>：Qwen-Coder-14B，对轨迹做<code>二分类打分</code>。</li></ul></li></ul><p><strong>脚手架</strong></p><ul><li>OpenHands的ReAct框架 <ul><li><code>file_editor</code>、<code>search_tool</code>、<code>execute_bash</code>、<code>submit</code></li></ul></li></ul><p><strong>超参</strong></p><ul><li>2epochs, lr=1e-5, bs=78 <code>seqlen=20k</code></li></ul></div><h3 id="关键结果" tabindex="-1">关键结果 <a class="header-anchor" href="#关键结果" aria-label="Permalink to &quot;关键结果&quot;">​</a></h3><p><strong>🍑关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><ul><li><strong>数据扩展有效</strong><ul><li><code>SFT-32B</code> SWE-Verified达 <code>34.4% Pass@1</code>，比之前SOTA SWE-Gym提高13.8%。</li><li>证明了<code>合成数据的有效性</code>。</li><li><strong>合成数据不输人工数据</strong>： <ul><li>纯<code>合成数据</code>训练：<code>27分</code>；纯<code>人工数据</code>训练：<code>28分</code>。差不多。</li></ul></li><li>训练带思考比不带思考，提升4pt，思考34分，不带思考仅30分。</li></ul></li><li><strong>验证器性能互补</strong><ul><li>单独使用<code>基于执行</code>或<code>免执行</code>的方法，性能均在 <code>42-43%</code> 左右饱和。</li><li><code>混合验证器</code>，将性能提升至 <strong>51.0%</strong>。</li></ul></li><li><strong>计算效率</strong>： <ul><li>增加“测试 Agent”的采样次数比单纯增加“编辑 Agent”的采样次数更具计算性价比。</li></ul></li><li><strong>SOTA 表现</strong>：51分成绩使<code>开源模型</code>首次在SWE任务与专有模型(o1, Sonnet + Tools)竞争。</li></ul></div><img src="https://r2e-gym.github.io/assets/r2egym/data_size_ablation.png" style="display:block;margin:auto;" width="70%"><p><strong>⛳ 未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div><ul><li><strong>环境构建自动化</strong>：目前的<code>依赖安装</code>和<code>环境构建</code>仍含手动步骤，未来<code>利用LLM实现全自动化</code>。</li><li><strong>更长上下文</strong>：训练仅20k/32k上下文，未来利用上下文并行训练处理更复杂的Agent。</li><li><strong>测试生成质量</strong>：进一步<code>减少</code>生成测试中的<code>毒性Toxic Tests</code>和<code>无效测试</code>，提高验证器的鲁棒性。</li></ul></div><h2 id="_2412-swe-gym" tabindex="-1">(2412) SWE-Gym <a class="header-anchor" href="#_2412-swe-gym" aria-label="Permalink to &quot;(2412) SWE-Gym&quot;">​</a></h2><p><strong>🌺 论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">SWE-Gym 摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2412.21139" target="_blank" rel="noreferrer">paper</a></li></ul><p><strong>核心方法</strong></p><ul><li>1套<code>SWE任务构建方法</code>：<code>通过脚本直接提取PR</code>，并半手动<code>构建好环境</code>(仅覆盖11仓库)</li><li>SWE-Gym：<code>2.4k任务</code> + <code>11仓库</code>，SWE-Gym-Lite：230任务 + 11仓库</li></ul><p><strong>模型效果</strong></p><ul><li><code>SFT合成数据微调</code>：蒸馏<code>491条成功轨迹</code>，<code>RFT微调</code>，<code>32B</code> SWE分数从<code>7分</code>-&gt;<code>20分</code>。</li></ul><p><strong>重要结论</strong></p><ul><li><code>Best-of-16策略</code>：20.6 -&gt; <code>32分</code>，开源模型新标杆。</li></ul></div><img src="https://arxiv.org/html/2412.21139v2/x1.png" style="display:block;margin:auto;" width="70%"><h3 id="swe-gym-任务收集构建方法" tabindex="-1">SWE-Gym 任务收集构建方法 <a class="header-anchor" href="#swe-gym-任务收集构建方法" aria-label="Permalink to &quot;SWE-Gym 任务收集构建方法&quot;">​</a></h3><div class="custom-block info"><div class="custom-block-title">SWE-Gym 任务构建方法</div><p><strong>仓库识别</strong></p><ul><li><code>用SEART搜索</code> + <code>选择python仓库</code></li><li>过滤条件：<code>PyPI 下载top-5k</code> + <code>500star</code> + <code>300行代码</code> + <code>500个pr</code> + <code>100个contributor</code></li><li>最终数据：<code>358 仓库</code>。时间：2022.07.01之前的</li></ul><p><strong>任务构建</strong></p><ul><li><p>SWE-bench的<code>提取脚本</code>：把<code>仓库PR</code> 转换成具体<code>任务实例</code></p></li><li><p>最终数据：<code>64k实例</code>，作为<code>SWE-Gym-Raw</code></p></li><li><p>每个任务：Issue、代码、解决方案，但是缺乏可执行环境。</p></li></ul><p><strong>环境构建</strong></p><ul><li>为<code>11个仓库</code> + <code>大量任务实例</code>，<code>半手动的创建环境</code></li><li>设置版本编号，按版本来构建实例环境，按版本分组。</li><li>手动查阅CI脚本，一个一个配置环境。</li></ul><p><strong>验证机制</strong></p><ul><li>Fail2Pass：<code>原始代码必须失败</code>，<code>打上patch后 必须通过</code>。</li></ul><p><strong>结果</strong></p><ul><li>200小时人工配置，6TB Docker镜像。</li></ul></div><div class="custom-block info"><div class="custom-block-title">SFT 数据蒸馏</div><ul><li>模型：GPT4o, Claude3.5-Sonnet</li><li>轮数：平均19轮</li><li>最终：491轨迹</li></ul></div><img src="https://arxiv.org/html/2412.21139v2/x2.png" style="display:block;margin:auto;" width="70%"><h2 id="_2405-swe-agent" tabindex="-1">(2405) SWE-agent <a class="header-anchor" href="#_2405-swe-agent" aria-label="Permalink to &quot;(2405) SWE-agent&quot;">​</a></h2><p><strong>🌺 论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">SWE-agent 摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2405.15793" target="_blank" rel="noreferrer">paper</a></li></ul><p><strong>核心方法</strong></p><ul><li>设计<code>Agent-Computer-Interface 范式</code></li></ul><p><strong>模型效果</strong></p><ul><li>基于<code>SWE-Agent框架</code>，GPT4-Turbo，<code>SWE-Full-12分</code>，<code>Light-18分</code></li><li><code>SWE-Agent</code>比<code>标准Shell提高7pt</code>，<code>比RAG提高16pt</code>。</li></ul></div><p><strong>📕核心方法</strong></p><h3 id="aci-接口" tabindex="-1">ACI 接口 <a class="header-anchor" href="#aci-接口" aria-label="Permalink to &quot;ACI 接口&quot;">​</a></h3><div class="custom-block note"><div class="custom-block-title">Agent-Computer-Interface 范式</div><p><strong>搜索和导航工具</strong></p><ul><li><code>find_file</code>, <code>search_file</code>, <code>search_dir</code> ..</li></ul><p><strong>文件查看器</strong></p><ul><li><code>open</code>, <code>scroll_down</code>, <code>scroll_up</code>, <code>goto</code>等</li></ul><p><strong>智能文件编辑器</strong></p><ul><li><code>edit</code>：在单次操作中进行范围替换，启动自动静态代码检查等(flake8工具)</li></ul><p><strong>上下文管理</strong></p><ul><li>采用ReAct框架，每个步骤模型给出思考和行动，</li><li>仅<code>保留最近5轮交互</code>，历史观察折叠显示，降低上下文窗口压力。</li></ul></div><img src="https://paper-assets.alphaxiv.org/figures/2405.15793v3/img-0.jpeg" style="display:block;margin:auto;" width="70%"><h3 id="实验设置-2" tabindex="-1">实验设置 <a class="header-anchor" href="#实验设置-2" aria-label="Permalink to &quot;实验设置&quot;">​</a></h3><p><strong>✍️实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li><strong>GPT-4 Turbo</strong> (gpt-4-1106-preview)</li><li><strong>Claude 3 Opus</strong> (claude-3-opus-20240229)</li></ul><p><strong>训练任务/数据</strong></p><ul><li>无训练</li></ul><p><strong>评测任务/数据</strong></p><ul><li><code>SWE-bench (Full &amp; Lite)</code>：真实Python问题，2.2k-Full, 300-Lite</li><li><code>HumanEvalFix</code>：代码调试/修复任务。</li></ul><p><strong>算法/策略</strong></p><ul><li><code>SWE-agent</code>：基于 <code>ACI 的交互式 Agent</code>。</li><li><code>Shell-only</code>：<code>基线 Agent</code>，仅使用标准 Linux Shell。</li><li><strong>RAG</strong>：基线方法，检索相关文件后直接生成补丁（非交互）。</li></ul><p><strong>超参</strong></p><ul><li>上下文窗口限制：<code>128k (GPT-4)</code> / <code>200k (Claude 3)</code>。</li><li>预算限制：每个任务最多 $4.00 推理成本。</li></ul></div><h3 id="关键结果-1" tabindex="-1">关键结果 <a class="header-anchor" href="#关键结果-1" aria-label="Permalink to &quot;关键结果&quot;">​</a></h3><p><strong>🍑关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><ul><li>SWE-Agent 通过ACI显著提升SWE分数，GPT4-Turbo分数如下： <ul><li><code>SWE-Agent</code>：<code>Full-12分</code>，<code>Lite-18分</code>。</li><li>标准Shell：FUll-, <code>Lite-11分</code>。</li><li>RAG：Full-1.3分，<code>Lite-2.67分</code>。</li></ul></li><li>SWE-Agent：<code>HumanEvalFix 87.7% pass@1</code></li><li>消融实验 <ul><li>Linter：移除<code>编辑时语法检查</code>，会下降3pt</li><li>搜索工具：<code>总结性工具</code>比没有搜索工具或繁杂迭代搜索工具效果好。</li><li>文件查看：<code>显示100行</code> 比 全部显示 或 仅显示30行 好。</li></ul></li></ul></div><h3 id="未来方向-2" tabindex="-1">未来方向 <a class="header-anchor" href="#未来方向-2" aria-label="Permalink to &quot;未来方向&quot;">​</a></h3><p><strong>⛳ 未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div><ul><li><strong>工具扩展</strong>：引入<code>更多开发工具</code>，如<code>网页浏览</code>（用于查阅文档）或<code>静态分析工具</code>。</li><li><strong>自动化 ACI 设计</strong>：目前 ACI 是手动设计的，未来可探索自动化生成针对特定模型或领域最优的接口。</li><li><strong>跨领域应用</strong>：将 ACI 的设计原则（简化命令、压缩反馈、错误护栏）应用到数据分析、网页导航等其他 Agent 领域。</li><li><strong>安全性</strong>：研究在沙盒环境中限制 Agent 的行为，防止生成恶意代码或误删文件。</li></ul></div>',110)]))}const h=e(d,[["render",t]]);export{p as __pageData,h as default};

import{_ as o,c as l,o as t,ah as i}from"./chunks/framework.CvbyeFFO.js";const g=JSON.parse('{"title":"SkyWork 系列","description":"","frontmatter":{"title":"SkyWork 系列","date":"2025-01-02T12:15:26.000Z","create":"2025-01-02T12:15:26.000Z","categories":["skywork"],"tags":["SkyRL-v0","Skywork-SWE","SWE任务收集","执行测试"]},"headers":[],"relativePath":"posts/llm/industry/mainllm/15-skywork-series.md","filePath":"posts/llm/industry/mainllm/15-skywork-series.md","lastUpdated":null}'),d={name:"posts/llm/industry/mainllm/15-skywork-series.md"};function c(a,e,r,s,n,p){return t(),l("div",null,e[0]||(e[0]=[i('<h2 id="_2512-skywork-r1v4-多模态" tabindex="-1">(2512) Skywork-R1V4 (多模态) <a class="header-anchor" href="#_2512-skywork-r1v4-多模态" aria-label="Permalink to &quot;(2512) Skywork-R1V4 (多模态)&quot;">​</a></h2><p><strong>🌺 论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">论文摘要</div><p><strong>相关链接</strong></p><ul><li></li></ul><p><strong>效果</strong></p><ul><li></li></ul><p><strong>核心方法</strong></p><ul><li></li></ul><p><strong>重要结论</strong></p><ul><li></li></ul><p><strong>关键贡献</strong></p></div><h2 id="_2511-skyrl-agent" tabindex="-1">(2511) SkyRL-Agent <a class="header-anchor" href="#_2511-skyrl-agent" aria-label="Permalink to &quot;(2511) SkyRL-Agent&quot;">​</a></h2><p><strong>🌺 论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">论文摘要</div><ul><li><a href="https://www.alphaxiv.org/abs/2511.16108" target="_blank" rel="noreferrer">paper</a></li><li></li></ul></div><h3 id="问题背景" tabindex="-1">问题背景 <a class="header-anchor" href="#问题背景" aria-label="Permalink to &quot;问题背景&quot;">​</a></h3><p><strong>❓问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">问题背景</div></div><h3 id="核心方法" tabindex="-1">核心方法 <a class="header-anchor" href="#核心方法" aria-label="Permalink to &quot;核心方法&quot;">​</a></h3><p><strong>📕核心方法</strong></p><div class="custom-block note"><div class="custom-block-title">核心方法</div></div><h3 id="算法实验" tabindex="-1">算法实验 <a class="header-anchor" href="#算法实验" aria-label="Permalink to &quot;算法实验&quot;">​</a></h3><h4 id="实验设置" tabindex="-1">实验设置 <a class="header-anchor" href="#实验设置" aria-label="Permalink to &quot;实验设置&quot;">​</a></h4><p><strong>✍️实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li></li></ul><p><strong>训练任务/数据</strong></p><ul><li></li></ul><p><strong>评测任务/数据</strong></p><ul><li></li></ul><p><strong>算法/策略</strong></p><ul><li></li></ul><p><strong>超参</strong></p><ul><li></li><li></li></ul></div><h4 id="关键结果" tabindex="-1">关键结果 <a class="header-anchor" href="#关键结果" aria-label="Permalink to &quot;关键结果&quot;">​</a></h4><p><strong>🍑关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div></div><h3 id="未来方向" tabindex="-1">未来方向 <a class="header-anchor" href="#未来方向" aria-label="Permalink to &quot;未来方向&quot;">​</a></h3><p><strong>⛳ 未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div></div><h2 id="_2506-skywork-swe" tabindex="-1">(2506) Skywork-SWE <a class="header-anchor" href="#_2506-skywork-swe" aria-label="Permalink to &quot;(2506) Skywork-SWE&quot;">​</a></h2><p><strong>🌺 论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">Skywork-SWE 摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2506.19290" target="_blank" rel="noreferrer">paper</a>, <a href="https://huggingface.co/Skywork/Skywork-SWE-32B" target="_blank" rel="noreferrer">Skywork-SWE-32B</a>, <a href="https://quixotic-sting-239.notion.site/Skywork-SWE-Unveiling-Data-Scaling-Laws-for-Software-Engineering-in-LLMs-eb17f379610040ceb54da5d5d24065bd" target="_blank" rel="noreferrer">blog</a></li></ul><p><strong>核心方法</strong></p><ul><li>1套<code>SWE任务收集构建方法</code>：<code>Repo+PR 收集</code> + <code>统一环境安装</code> + <code>执行验证</code>等。 <ul><li>基于<code>真实环境执行</code>来做<code>数据验证</code>，<code>3层增量式镜像</code> (基础+环境+实例镜像)。</li><li><code>Skywork-SWE数据</code>：<code>10k任务</code> + <code>2.5k仓库</code>。</li><li>AgentSFT蒸馏：<code>8k轨迹数据</code>。</li></ul></li></ul><p><strong>模型效果 (Qwen-2.5-Coder-32B)</strong></p><ul><li><code>闭源LLM蒸馏</code> <code>轨迹数据SFT</code> ，<code>SWE-verified 达36分</code>，<code>TTS, Best-of-3</code> 达<code>47分</code>。</li></ul><p><strong>重要结论</strong></p><ul><li>SWE <code>Data-Scaling</code>, <code>Test-Time-Scaling</code>, <code>轮数Scaling</code> Law 得到验证。</li><li>经过<code>单元测试验证的数据</code>比<code>SWE-smith合成数据</code> 靠谱，提升6.8%</li></ul><p><strong>关键贡献</strong></p><ul><li>开源数据和模型SkyWork-SWE-32B。</li></ul></div><h3 id="问题背景-swe任务挑战-sweagent" tabindex="-1">问题背景(SWE任务挑战+SWEAgent) <a class="header-anchor" href="#问题背景-swe任务挑战-sweagent" aria-label="Permalink to &quot;问题背景(SWE任务挑战+SWEAgent)&quot;">​</a></h3><p><strong>❓问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">代码任务</div><p><strong>代码生成</strong></p><ul><li>竞赛代码、一次性生成，<code>self-contained</code>。</li><li>简答代码(HumanEval/MBPP) -&gt; 竞赛代码(LiveCodeBench) -&gt; 推理LLM.</li></ul><p><strong>SWE</strong></p><ul><li><p><code>bug定位</code>、<code>修改源代码</code>、<code>执行测试</code>，多轮<code>迭代式解决</code>问题。<code>使用工具</code>，<code>长上下文依赖</code>。</p></li><li><p>一些工作：</p><ul><li><p>SWE-Bench-extra：扩展了6k python数据，无环境。</p></li><li><p><a href="https://ubecwang.notion.site/1bc32cf963e080b2a01df2895f66021f?v=1bc32cf963e0810ca07e000c86c4c1e1" target="_blank" rel="noreferrer">SWe-Dev</a>：测试用例合成pipeline。</p></li><li><p>SWE-Gym：有环境，仅2k数据；</p></li><li><p>SWE-Fixer/SWE-Smith：注入验证合理的bug，合成F2P实例，产生几k SWE任务实例。</p></li></ul></li></ul></div><div class="custom-block warning"><div class="custom-block-title">SWE 挑战</div><p><strong>挑战</strong></p><ul><li>环境验证不足：<code>可执行环境</code> + <code>验证过的单元测试</code> + <code>代码执行套件</code>(统一执行脚本)</li><li><strong>高质量数据不足</strong>：<code>量大质低</code> + <code>质高量小</code><ul><li>SWE-Dev：数据多，但缺环境和单元测试</li><li>SWE-Gym：有环境，但仅11仓库</li></ul></li><li><strong>SWE-Scaling Law 尚不清晰</strong>：SWE数据量小，Scaling Law尚未得到验证，增加数据是否带来效果提升？</li></ul></div><div class="custom-block caution"><div class="custom-block-title">SWE CodeAgent</div><p><strong>全能派 Rich ACI</strong></p><ul><li>OpenHands <ul><li>提供<code>编辑器</code> + <code>命令行终端</code> + <code>网页搜索</code>，agent在<code>沙箱环境</code> <code>自主迭代式完成任务</code>。</li><li>优点：上限高，能处理复杂问题，更像人。</li><li>缺点：成本高，容易陷入死循环</li></ul></li><li>SWE-Agent <ul><li>使用Agent-Computer-Interface，提供<code>编辑器</code>+<code>shell</code>+<code>测试运行器</code>给LLM。</li></ul></li></ul><p><strong>专有精细派</strong></p><ul><li><code>专有Pipeline</code><ul><li>Agentless：固定的<code>定位-修复-验证</code> pipeline</li><li>Moatless：主张<code>有效上下文检索</code>才是关键。</li></ul></li><li>检索微调 <ul><li>SWE-fixer：由粗到细，文件检索和编辑解耦。</li></ul></li></ul></div><p><strong>📕核心方法</strong></p><h3 id="swe任务收集构建方法和轨迹蒸馏" tabindex="-1">SWE任务收集构建方法和轨迹蒸馏 <a class="header-anchor" href="#swe任务收集构建方法和轨迹蒸馏" aria-label="Permalink to &quot;SWE任务收集构建方法和轨迹蒸馏&quot;">​</a></h3><p>SWE任务收集构建和轨迹蒸馏流程：</p><img src="https://arxiv.org/html/2506.19290v1/x3.png" style="display:block;margin:auto;" width="70%"><img src="https://arxiv.org/html/2506.19290v1/x4.png" style="display:block;margin:auto;" width="70%"><h4 id="repo-pr数据收集和环境预过滤" tabindex="-1">Repo+PR数据收集和环境预过滤 <a class="header-anchor" href="#repo-pr数据收集和环境预过滤" aria-label="Permalink to &quot;Repo+PR数据收集和环境预过滤&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">RepoPR数据收集&amp;环境安装预过滤</div><p><strong>Repo 收集</strong></p><ul><li>通过<code>Github DeveloperAPI</code> 收集<code>Metadata</code>信息 (name/star/pull数量等)。</li><li><code>过滤缺字段repo</code>，数量：<code>15k -&gt; 8k</code></li></ul><p><strong>PR 收集</strong></p><ul><li>拉取Repo的PR，只选<code>这3类PR</code><ul><li><code>Merged</code>：关键字<code>closes/fixes/resolves#</code></li><li><code>Linked to Issue</code>：必须解决了某个Issue <ul><li>要<code>base_commit</code>+<code>gold_patch</code> + <code>test_patch</code></li></ul></li><li><code>修改了测试文件</code>：只保留<code>修改了测试相关文件</code>的PR</li></ul></li><li>共<code>146w 任务</code></li></ul><p><strong>环境安装预过滤</strong></p><ul><li>尝试<code>去安装环境</code>，<code>过滤123w</code>，最终<code>共23k 任务</code></li></ul></div><h4 id="环境准备和执行验证" tabindex="-1">环境准备和执行验证 <a class="header-anchor" href="#环境准备和执行验证" aria-label="Permalink to &quot;环境准备和执行验证&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">基于执行的验证</div><p><strong>统一命令配置</strong></p><ul><li><p><code>环境初始化</code>、<code>依赖安装</code>、<code>测试命令</code>。</p></li><li><p>默认<code>python3.9</code>，系统包gcc/g++/make/pkg-config,</p></li><li><p>依赖：<code>requrements.txt</code> ,</p></li><li><p>测试包：pytests/hypothesis/mock/setuptools</p></li><li><p>测试命令：<code>pytest</code></p></li></ul><p><strong>环境安装：三层增量镜像</strong></p><ul><li><p>每个实例一个docker实例镜像</p></li><li><p><code>基础镜像</code>：ubuntu22.04，apt安装系统包，安装miniconda</p></li><li><p><code>环境镜像</code>：<code>Repo复用</code>，<code>setup_env.sh</code>，安装requirements.txt和额外开发测试包</p></li><li><p><code>实例镜像</code>：<code>增量构建</code></p><ul><li>执行<code>setup_repo.sh</code>，克隆仓库，checkout<code>特定commit_id</code></li><li>安装pre_sintall列出的<code>系统依赖</code></li></ul></li></ul><p><strong>执行验证</strong></p><ul><li>实例进行过，执行测试： <ul><li><code>Empty测试</code>：复现bug，应用empt-patch，得到：empty-FAIL, empty-PASS</li><li><code>Gold测试</code>：验证修复，应用gold-patch，得到：gold-FAIL, gold-PASS</li></ul></li><li>指标计算 <ul><li><code>FAILE_TO_PASS</code>：empty-FAIL &amp; gold-PASS</li><li>PASS_TO_PASS：empty-PASS &amp; gold-PASS</li><li><code>PASS_TO_FAIL</code>：empt-PASS &amp; gold-FAIL</li></ul></li></ul></div><h4 id="skywork-swe-数据集分析" tabindex="-1">SkyWork-SWE 数据集分析 <a class="header-anchor" href="#skywork-swe-数据集分析" aria-label="Permalink to &quot;SkyWork-SWE 数据集分析&quot;">​</a></h4><div class="custom-block caution"><div class="custom-block-title">SkyWork-SWE 数据分析</div><p><strong>最终数据</strong></p><ul><li><code>2.5k 仓库</code>，<code>10k python任务实例</code></li><li>每实例：<code>NL描述</code> + <code>可执行环境</code> + <code>单元测试</code></li></ul><p><strong>特点</strong></p><ul><li>数量大：2.5k仓库，10k实例</li><li>难度高：<code>平均编辑2.5个文件</code>、<code>74.2行代码</code>，<code>10.2个 FAIL2PASS </code>。</li><li>编辑复杂度：难度适中，<code>60%多文件编辑</code>，50%实例编辑1-3个代码库，<code>70%少于50行代码编辑</code>。</li><li>时间分布：2013-2025，但89%都是2018-2024这6年。</li><li>分布长尾：</li></ul></div><img src="https://arxiv.org/html/2506.19290v1/x5.png" style="display:block;margin:auto;" width="70%"><img src="https://arxiv.org/html/2506.19290v1/x6.png" style="display:block;margin:auto;" width="70%"><h4 id="agentsft-轨迹数据蒸馏" tabindex="-1">AgentSFT 轨迹数据蒸馏 <a class="header-anchor" href="#agentsft-轨迹数据蒸馏" aria-label="Permalink to &quot;AgentSFT 轨迹数据蒸馏&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">AgentSFT 轨迹数据蒸馏</div><ul><li><p><strong>轨迹rollout/模型蒸馏</strong></p><ul><li><code>多个私有代码LLM</code> + <code>OpenHands v0.32.0</code>，最多<code>100轮</code></li><li>一系列模型，模型-解决率依次Gemini2.5-Pro (20)，GPT-4.1(18)，o3-mini(15)...</li></ul></li><li><p><strong>轨迹验证/过滤</strong>：</p><ul><li><code>应用patch做测试</code>，<code>通过所有测试</code>才算成功。仅保留正确数据。</li></ul></li><li><p>最终：<code>8k 轨迹数据</code>。</p></li></ul></div><h3 id="实验设置-1" tabindex="-1">实验设置 <a class="header-anchor" href="#实验设置-1" aria-label="Permalink to &quot;实验设置&quot;">​</a></h3><p><strong>✍️实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li>Qwen-2.5-Coder-32B-Instruct</li></ul><p><strong>训练任务/数据</strong></p><ul><li><code>8k SFT轨迹蒸馏数据</code>，来自 <code>2.5k仓库</code> + <code>10k python实例</code></li></ul><p><strong>评测任务/数据</strong></p><ul><li>SWE-Verified</li><li>Skywork-SWE-32B：rollout=1，直接去评测，<code>38分</code></li><li>Skywork-SWE-32B (+TTS)：<code>rollout=8</code>，使用<code>Critic 打分</code>，<code>选最优轨迹</code>评测，<code>47分</code><ul><li>Critic模型：<a href="https://openhands.dev/blog/sota-on-swe-bench-verified-with-inference-time-scaling-and-critic-model" target="_blank" rel="noreferrer">OpenHands critic model</a></li></ul></li></ul><p><strong>算法/策略</strong></p><ul><li><code>SFT</code>，OpenHands agent</li></ul><p><strong>超参</strong></p><ul><li><code>8 H100</code> - 训练12h, <code>3epoch</code>，总计8000轮</li><li>Adam, <code>cosine decay</code>, weight decay=0.01</li></ul></div><h3 id="关键结果-qwen2-5-coder-32b" tabindex="-1">关键结果 (Qwen2.5-Coder-32B) <a class="header-anchor" href="#关键结果-qwen2-5-coder-32b" aria-label="Permalink to &quot;关键结果 (Qwen2.5-Coder-32B)&quot;">​</a></h3><p><strong>🍑关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">SkyWork-SWE-32B 关键结果</div><p><strong>效果</strong></p><ul><li><code>Qwen2.5-Coder-32B</code> <code>SFT</code>后，<code>SWE达38分</code>，使用<code>TTS(best-of-8)</code>达<code>47分</code>。</li></ul><p><strong>重要结论</strong></p><ul><li><p>SWE Scaling Law 验证</p><ul><li>Data Scaling：<code>数据增加</code>，效果增加，<code>6.4 -&gt; 38</code></li><li>Test-Time Scaling：<code>Best-of-8</code>，<code>38 -&gt; 47</code></li><li>轮数 Scaling：<code>10步：28</code>，<code>75步：37</code>，100步：38。75步以后收益小。</li></ul></li><li><p>经过<code>单元测试验证</code>的数据比<code>SWE-smith合成</code>数据靠谱，<code>提升6.8%</code></p></li></ul><p><strong>关键贡献</strong></p><ul><li>1套<code>SWE Data Pipeline</code>：自动构建<code>大规模</code>、<code>高质量</code>、<code>SWE任务数据</code>。</li><li>SkyWork-SWE-32B：开源。</li></ul></div><h3 id="未来方向-1" tabindex="-1">未来方向 <a class="header-anchor" href="#未来方向-1" aria-label="Permalink to &quot;未来方向&quot;">​</a></h3><p><strong>⛳ 未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div><ul><li><code>自动为测试配置环境的agent</code><ul><li><a href="https://plmsmile.github.io/posts/llm/industry/mainllm/02-deepseek-series.html#%E5%A4%A7%E8%A7%84%E6%A8%A1agentic%E4%BB%BB%E5%8A%A1%E6%9E%84%E5%BB%BA" target="_blank" rel="noreferrer">DeepSeekV3.2 已有环境构建Agent</a>，负责<code>包安装</code>、<code>依赖解析</code>、<code>测试执行</code></li></ul></li><li>上下文限制：<code>目前仅32k</code>，<code>需扩展至128k</code>，<code>序列并行</code>。 <ul><li>但交互超过50轮时，会超过32k。</li></ul></li><li>不同OpenHands版本Prompt不同，建议使用最新版本。</li></ul></div><h2 id="_2506-skyrl-v0-1-rl框架" tabindex="-1">(2506) SkyRL-V0.1 (RL框架) <a class="header-anchor" href="#_2506-skyrl-v0-1-rl框架" aria-label="Permalink to &quot;(2506) SkyRL-V0.1 (RL框架)&quot;">​</a></h2><div class="custom-block danger"><div class="custom-block-title">摘要</div><ul><li><a href="https://novasky-ai.notion.site/skyrl-v01" target="_blank" rel="noreferrer">blog</a>, <a href="https://novasky-ai.github.io/" target="_blank" rel="noreferrer">skywork blog</a></li><li>SkyRL一个模块化的RL框架</li></ul></div><h2 id="_2505-skyrl-v0" tabindex="-1">(2505) SkyRL-v0 <a class="header-anchor" href="#_2505-skyrl-v0" aria-label="Permalink to &quot;(2505) SkyRL-v0&quot;">​</a></h2><h3 id="摘要背景" tabindex="-1">摘要背景 <a class="header-anchor" href="#摘要背景" aria-label="Permalink to &quot;摘要背景&quot;">​</a></h3><div class="custom-block important"><div class="custom-block-title">SkyRL 摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://novasky-ai.notion.site/skyrl-v0" target="_blank" rel="noreferrer">skyrl-v0</a></li></ul><p><strong>模型效果</strong></p><ul><li>基于Qwen3-14B，从<code>SWE-Gym</code>中选择<code>少量数据</code>，做RL训练，<code>SWE达21分</code>。</li></ul><p><strong>核心方法</strong></p><ul><li>环境：<code>远程sandbox server</code> + <code>异步Rollout</code>；<code>OpenHands scaffold</code> + <code>CodeAct Agent</code>。</li></ul></div><p><strong>❓问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">问题背景</div><p><strong>背景</strong></p><ul><li>现有RL任务大多<strong>单轮、短期、无状态交互</strong>(简单搜索/代码等)。</li><li>但<code>复杂真实任务</code>需要<code>高级agent能力</code><ul><li>复杂任务：<strong>SWE-Bench</strong>、<strong>WebDev</strong>、<strong>Web浏览</strong>等</li><li>能力：<code>多工具调用</code>、<code>code</code>、<strong>测试</strong>、<strong>长期规划</strong>等</li></ul></li></ul><p><strong>挑战</strong></p><ul><li><code>Agentic RL</code> 训练具有挑战 <ul><li>训练需要：<code>高速环境执行</code>、<code>高效rollout</code></li><li><code>稳定训练Long Horizon</code>的RL算法</li></ul></li></ul></div><p><strong>📕核心方法</strong></p><h3 id="sandbox环境和rollout优化" tabindex="-1">Sandbox环境和Rollout优化 <a class="header-anchor" href="#sandbox环境和rollout优化" aria-label="Permalink to &quot;Sandbox环境和Rollout优化&quot;">​</a></h3><div class="custom-block info"><div class="custom-block-title">SandboxServer + Rollout加速优化</div><p><strong>环境扩展：远程sandbox server</strong></p><ul><li>使用<code>远程sandbox server</code>，环境和训练分开，确保<code>gpu高效利用</code>。</li><li>Kubernets部署Sever：16CPU节点，运行80-100个容器，且没有稳定性问题。</li><li>开源。</li></ul><p><strong>Rollout加速优化</strong></p><ul><li>背景：agent和环境<code>多次交互</code>，<code>很耗时</code>。 <ul><li>如OpenHands+SWE 需要20-50轮，python测试很耗时。</li></ul></li><li>方法1：<code>异步rollout</code><ul><li>每个轨迹独立进行，避免全局同步。</li></ul></li><li>方法2：<code>三阶段Producer-Consumer Pipeline</code><ul><li>三个队列：初始化(准备环境) -&gt; 运行 -&gt; 评估(计算奖励)</li><li>Asyncio：动态创建任务s，异步推送，提高系统吞吐量</li></ul></li></ul></div><img src="https://novasky-ai.notion.site/image/attachment%3A81b6c6c3-a2ed-409a-ab89-3250a61b0c75%3Aimage.png?table=block&amp;id=1ea8f001-6b9d-80a1-b848-d7ce098670e3&amp;spaceId=9c6d4028-07f7-4e0f-8a1c-5f45ee53d6cd&amp;width=1420&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><img src="https://novasky-ai.notion.site/image/attachment%3A7e020b6f-fbd8-4076-a6da-459bfab53dda%3Askygym-pipeline.jpg?table=block&amp;id=1e78f001-6b9d-80b9-bc38-d39d28e3e7f7&amp;spaceId=9c6d4028-07f7-4e0f-8a1c-5f45ee53d6cd&amp;width=1420&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><h3 id="rl设计" tabindex="-1">RL设计 <a class="header-anchor" href="#rl设计" aria-label="Permalink to &quot;RL设计&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">RL设计</div><p><strong>任务设计(Rollout/AgentLoop)</strong></p><ul><li><code>CodeAct</code> + <code>OpenHands scaffold</code></li><li>三个Action：<code>execute_bash</code> + <code>finish</code> + <code>str_replace_editor</code></li><li>AgentLoop循环，直到任务完成。</li></ul><p><strong>奖励设计</strong></p><ul><li>Rule：应用Patch，<code>测试全部通过</code>：<code>1分</code>；<code>其他</code>：<code>0分</code>。</li></ul><p><strong>数据集</strong></p><ul><li><code>SWE-Gym 2.4k</code> python任务，但很难，GPT-4o仅9%。</li><li>仅<code>选择能成功的部分数据</code><ul><li><a href="https://huggingface.co/datasets/NovaSky-AI/SkyRL-v0-80-data" target="_blank" rel="noreferrer">SkyRL-v0-80-data</a>：7b pass@16，<a href="https://huggingface.co/datasets/NovaSky-AI/SkyRL-v0-220-data" target="_blank" rel="noreferrer">SkyRL-v0-220-data</a>：32b pass@16，<a href="https://huggingface.co/datasets/NovaSky-AI/SkyRL-v0-293-data" target="_blank" rel="noreferrer">SkyRL-v0-293-data</a>：gpt-4o或claude-sonnet</li><li>担心太难，没有学习信号。</li></ul></li></ul><p><strong>2种常见失败模式</strong></p><ul><li>陷入死循环：模型连续3轮执行相同动作</li><li>没有结束动作：</li></ul></div><h3 id="实验结果-qwen3-14b" tabindex="-1">实验结果 (Qwen3-14B) <a class="header-anchor" href="#实验结果-qwen3-14b" aria-label="Permalink to &quot;实验结果 (Qwen3-14B)&quot;">​</a></h3><p><strong>✍️实验配置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验配置</div><p><strong>模型</strong></p><ul><li>OpenHands-7B-Agent -&gt; SkyRL-Agent-7B-v</li><li><strong>Qwen3-8B(非推理)</strong> -&gt; <code>SkyRL-Agent-8B-v0</code></li><li><strong>Qwen3-14B(推理)</strong> -&gt; <code>SkyRL-Agent-14B-v0</code></li></ul><p><strong>训练数据</strong></p><ul><li>SkyRL-v0-80/220/293-data，从SWE-Gym 选的。</li></ul><p><strong>框架</strong></p><ul><li><code>OpenHands scaffold</code> + <code>CodeAct Agent</code>。</li></ul><p><strong>超参</strong></p><ul><li>32k，50轮。</li></ul><p><strong>🍑关键结果</strong></p><ul><li>14B 达21.6%</li></ul></div><p>三个尺寸模型：7B、8B、14B，四种实验方法：Zero-Shot, Zero-Shot(推理)、SFT、RL。具体如下表所示：</p><table tabindex="0"><thead><tr><th></th><th>Resolved Rate</th><th>Technique</th></tr></thead><tbody><tr><td>Qwen3-14B</td><td>18%</td><td>Zero-Shot (Thinking)</td></tr><tr><td>SkyRL-Agent-14B-v0 (Best👍)</td><td><code>21.6%</code></td><td>Outcome based Reinforcement Learning</td></tr><tr><td>Qwen3-8B</td><td>3.6%</td><td>Zero-Shot (Non thinking)</td></tr><tr><td>SkyRL-Agent-8B-v0</td><td>9.4%</td><td>Outcome based Reinforcement Learning</td></tr><tr><td>Qwen2.5-Coder-Instruct</td><td>1.8%</td><td>Zero-Shot</td></tr><tr><td>OpenHands-7B-Agent</td><td>11.0%</td><td>Supervised Fine-tuning</td></tr><tr><td>SkyRL-Agent-7B-v0</td><td>14.6%</td><td>Outcome based Reinforcement Learning</td></tr></tbody></table>',73)]))}const k=o(d,[["render",c]]);export{g as __pageData,k as default};

import{_ as a,c as r,o as i,a2 as t,j as l,a as o}from"./chunks/framework.CJy6NSJ1.js";const T=JSON.parse('{"title":"分布式训练框架","description":"","frontmatter":{"title":"分布式训练框架","date":"2025-07-17T19:30:29.000Z","create":"2025-07-17T19:30:29.000Z","categories":[],"tags":[]},"headers":[],"relativePath":"posts/llm/infra/02-speed-framework.md","filePath":"posts/llm/infra/02-speed-framework.md","lastUpdated":null}'),s={name:"posts/llm/infra/02-speed-framework.md"},n={class:"custom-block tip"},d={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},m={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.781ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.416ex",height:"2.737ex",role:"img",focusable:"false",viewBox:"0 -864.9 1067.9 1209.9","aria-hidden":"true"};function c(u,e,p,g,h,k){return i(),r("div",null,[e[10]||(e[10]=t('<h2 id="背景知识" tabindex="-1">背景知识 <a class="header-anchor" href="#背景知识" aria-label="Permalink to &quot;背景知识&quot;">​</a></h2><h3 id="分布式基础概念" tabindex="-1">分布式基础概念 <a class="header-anchor" href="#分布式基础概念" aria-label="Permalink to &quot;分布式基础概念&quot;">​</a></h3><div class="custom-block note"><div class="custom-block-title">基础概念</div><p><a href="https://plmsmile.github.io/posts/llm/basic/04-llm-architecture.html#moe" target="_blank" rel="noreferrer">moe</a></p><p><strong>1. 机器概念</strong></p><ul><li><code>主节点 master ip/port</code>：协调其他节点、分配任务、结果汇总等。</li><li><code>节点编号 node_rank</code>：每个<strong>节点的唯一标识</strong>，不同计算机通信</li><li><code>局部进程编号 local_rank</code>：<strong>节点内部</strong>的进程编号</li><li><code>全局进程编号 rank</code>：整个系统<strong>全局进程编号</strong>，唯一标识</li><li><code>全局进程总数 word_size</code>：整个系统所有<strong>进程总数</strong></li></ul><p><strong>2. 通信策略</strong></p><ul><li><code>mpi</code>：跨节点通信库，常用于CPU集群</li><li><code>gloo</code>： 高性能分布式训练框架，支持CPU和GPU集群</li><li>⭐<code>nccl</code>：<mark>NVIDIA的GPU专有通信库，适用于GPU</mark></li></ul><p><strong>3. 训练概念</strong></p><ul><li><code>混合精度训练</code>：同时使用<strong>FP16</strong>(<strong>半精度</strong>浮点数，<strong>降低内存占用</strong>) 和 FP32(单精度浮点数)技术，训练<strong>更大模型</strong>。</li><li><code>ZeRO</code>：Zero Redundancy Optimizer，减少内存占用；<code>Optimizer States</code>、<code>Gradient</code>、<code>Model Parameter</code>。</li></ul></div><h2 id="deepseed" tabindex="-1">DeepSeed <a class="header-anchor" href="#deepseed" aria-label="Permalink to &quot;DeepSeed&quot;">​</a></h2><h3 id="背景知识-1" tabindex="-1">背景知识 <a class="header-anchor" href="#背景知识-1" aria-label="Permalink to &quot;背景知识&quot;">​</a></h3>',5)),l("div",n,[e[9]||(e[9]=l("div",{class:"custom-block-title"},"背景",-1)),l("ul",null,[e[8]||(e[8]=t("<li>GPU存储太多数据 <ul><li><code>模型参数</code>、<code>优化器状态</code>、<code>激活函数输出值</code>、<code>梯度</code>、<code>临时buffer</code>等。</li><li>使用混合精度时，<mark>状态参数(优化器/梯度/模型参数)占大半以上，考虑去除冗余数据</mark>。</li></ul></li>",1)),l("li",null,[e[7]||(e[7]=o("DeepSeed ZeRO分片 ")),l("ul",null,[l("li",null,[e[2]||(e[2]=l("strong",null,"每张卡只存",-1)),l("mjx-container",d,[(i(),r("svg",m,e[0]||(e[0]=[t('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mstyle" fill="blue" stroke="blue"><g data-mml-node="mfrac"><g data-mml-node="mn" transform="translate(357.2,394) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(220,-345) scale(0.707)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z" style="stroke-width:3;"></path></g><rect width="827.9" height="60" x="120" y="220"></rect></g></g></g></g>',1)]))),e[1]||(e[1]=l("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[l("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[l("mstyle",{mathcolor:"blue"},[l("mfrac",null,[l("mn",null,"1"),l("mi",null,"N")])])])],-1))]),e[3]||(e[3]=l("strong",null,"的模型状态量",-1)),e[4]||(e[4]=o("，系统只维护")),e[5]||(e[5]=l("code",null,"1份模型状态参数",-1)),e[6]||(e[6]=o("。"))])])])])]),e[11]||(e[11]=t('<img src="https://wdndev.github.io/llm_interview_note/04.%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/2.%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C/image/image_eNJ6FyULtl.png" style="display:block;margin:auto;" width="80%"><h3 id="zero-1" tabindex="-1">ZeRO-1 <a class="header-anchor" href="#zero-1" aria-label="Permalink to &quot;ZeRO-1&quot;">​</a></h3><div class="custom-block important"><div class="custom-block-title">ZeRO-1</div><ul><li><p>核心思想</p><ul><li><p>🌟<strong>只对优化器进行分片</strong>，不对模型和梯度分片，训练过程类似DDP：</p><ul><li>各GPU单独做前向、反向、参数更新。反向在各GPU间梯度AllReduce之后。</li></ul></li><li><p>OptimizerState<strong>基于参数量进行分片(贪心算法)，确保每个rank拥有相同大小的优化器内存</strong>。</p></li><li><p>每个rank只优化当前分片部分，更新后通过广播保证所有rank收到更新后的参数。</p></li></ul></li><li><p>适用场景</p><ul><li>适合<a href="https://plmsmile.github.io/posts/olds/dl/35-nerual-network-optim.html#adam" target="_blank" rel="noreferrer">Adam</a>，因为有额外参数m和v。</li><li>不适合<a href="https://plmsmile.github.io/posts/olds/dl/35-nerual-network-optim.html#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95" target="_blank" rel="noreferrer">SGD</a>，因为其只有较少参数内存。</li></ul></li></ul></div><h3 id="zero-2" tabindex="-1">ZeRO-2 <a class="header-anchor" href="#zero-2" aria-label="Permalink to &quot;ZeRO-2&quot;">​</a></h3><div class="custom-block important"><div class="custom-block-title">ZeRO-2</div><ul><li>核心思想 <ul><li>🔑分片：<strong>优化器、梯度</strong>。</li><li><strong>梯度reduce到对应rank，无需AllReduce</strong>，降低通讯开销</li><li>每个rank更新各自参数，再广播保证所有rank收到更新后的参数。</li></ul></li></ul></div><h3 id="zero-3" tabindex="-1">ZeRO-3 <a class="header-anchor" href="#zero-3" aria-label="Permalink to &quot;ZeRO-3&quot;">​</a></h3><div class="custom-block important"><div class="custom-block-title">ZeRO-3</div><ul><li>核心思想： <ul><li>分片：<strong>优化器、梯度、模型</strong>，<code>模型参数的分片</code></li><li>模型每层拥有该层完整参数，能被单个GPU装下。前向除了当前rank层以外，其他参数都可以不要。类似数据并行+模型并行。</li></ul></li></ul></div>',7))])}const b=a(s,[["render",c]]);export{T as __pageData,b as default};

import{_ as s,c as a,o,ah as T,j as t,a as Q}from"./chunks/framework.CvbyeFFO.js";const D=JSON.parse('{"title":"强化学习基本概念","description":"","frontmatter":{"title":"强化学习基本概念","date":"2025-08-18T22:05:22.000Z","create":"2025-08-18T22:05:22.000Z","categories":["rl"],"tags":["试错学习","智能体","环境","动作空间","策略","随机性策略","确定性策略","模型","状态转移","奖励","回报","价值","序列决策","规划","学习","Value-based RL","Policy-based RL","Model-based RL","Model-free RL","探索","利用"]},"headers":[],"relativePath":"posts/llm/rl/theory/01-rl-introduction.md","filePath":"posts/llm/rl/theory/01-rl-introduction.md","lastUpdated":null}'),e={name:"posts/llm/rl/theory/01-rl-introduction.md"},i={class:"custom-block note"},r={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},n={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"19.127ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 8454.1 1000","aria-hidden":"true"},d={class:"custom-block info"},m={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},g={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.439ex"},xmlns:"http://www.w3.org/2000/svg",width:"26.615ex",height:"1.984ex",role:"img",focusable:"false",viewBox:"0 -683 11763.9 877","aria-hidden":"true"},p={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},u={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.621ex"},xmlns:"http://www.w3.org/2000/svg",width:"11.916ex",height:"2.318ex",role:"img",focusable:"false",viewBox:"0 -750 5266.9 1024.5","aria-hidden":"true"},h={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},c={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.623ex"},xmlns:"http://www.w3.org/2000/svg",width:"11.715ex",height:"2.319ex",role:"img",focusable:"false",viewBox:"0 -750 5177.8 1025.2","aria-hidden":"true"},H={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},w={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.623ex"},xmlns:"http://www.w3.org/2000/svg",width:"11.986ex",height:"2.151ex",role:"img",focusable:"false",viewBox:"0 -675.5 5297.9 950.7","aria-hidden":"true"},b={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},k={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"13.45ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 5944.7 1000","aria-hidden":"true"},x={class:"custom-block important"},f={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},y={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.025ex"},xmlns:"http://www.w3.org/2000/svg",width:"0.919ex",height:"1ex",role:"img",focusable:"false",viewBox:"0 -431 406 442","aria-hidden":"true"};function L(M,l,v,V,Z,_){return o(),a("div",null,[l[55]||(l[55]=T("",13)),t("div",i,[l[14]||(l[14]=t("div",{class:"custom-block-title"},"关键定义",-1)),l[15]||(l[15]=t("p",null,[t("strong",null,"智能体")],-1)),t("ul",null,[l[11]||(l[11]=t("li",null,"和环境交互，感知环境状态和奖励，输出动作",-1)),l[12]||(l[12]=t("li",null,"目标：选取一系列动作来最大化奖励，即学到最大化奖励的策略",-1)),l[13]||(l[13]=t("li",null,[t("strong",null,"动作空间"),Q("："),t("code",null,"离散、连续"),Q("动作空间")],-1)),t("li",null,[l[8]||(l[8]=t("strong",null,"策略",-1)),l[9]||(l[9]=Q("：在当前状态s下，agent根据策略来")),l[10]||(l[10]=t("code",null,"选下一步动作",-1)),t("ul",null,[l[6]||(l[6]=t("li",null,[t("strong",null,"随机性策略"),Q("：输出"),t("code",null,"动作概率分布"),Q("，"),t("code",null,"根据概率选动作"),Q("，0.7概率往左，0.3概率往右")],-1)),t("li",null,[l[2]||(l[2]=t("strong",null,"确定性策略",-1)),l[3]||(l[3]=Q("：")),l[4]||(l[4]=t("code",null,"直接选最有可能的动作",-1)),l[5]||(l[5]=Q("，输出不变： ")),t("mjx-container",r,[(o(),a("svg",n,l[0]||(l[0]=[T("",1)]))),l[1]||(l[1]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("msup",null,[t("mi",null,"a"),t("mrow",{"data-mjx-texclass":"ORD"},[t("mo",null,"∗")])]),t("mo",null,"="),t("mrow",{"data-mjx-texclass":"ORD"},[t("mi",{"data-mjx-auto-op":"false"},"arg"),t("mi",{"data-mjx-auto-op":"false"},"max")]),t("mstyle",{scriptlevel:"0"},[t("mspace",{width:"0.278em"})]),t("mi",null,"π"),t("mo",{stretchy:"false"},"("),t("mi",null,"a"),t("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),t("mi",null,"s"),t("mo",{stretchy:"false"},")")])],-1))])]),l[7]||(l[7]=t("li",null,[Q("一般选择"),t("code",null,"随机性策略"),Q("👍，"),t("code",null,"更好探索环境"),Q("、"),t("code",null,"动作具有多样性")],-1))])])]),l[16]||(l[16]=T("",4))]),l[56]||(l[56]=T("",9)),t("div",d,[l[37]||(l[37]=t("div",{class:"custom-block-title"},"状态观测序列决策",-1)),l[38]||(l[38]=t("p",null,[t("strong",null,"状态、观测、历史")],-1)),t("ul",null,[l[21]||(l[21]=t("li",null,[t("strong",null,"状态"),Q("：对世界的完整描述。离散或连续")],-1)),l[22]||(l[22]=t("li",null,[t("strong",null,"观测"),Q("：对状态的部分描述，智能体会有很多观测。")],-1)),t("li",null,[l[19]||(l[19]=t("strong",null,"历史",-1)),l[20]||(l[20]=Q("：观测、动作、奖励的序列。 ")),t("mjx-container",m,[(o(),a("svg",g,l[17]||(l[17]=[T("",1)]))),l[18]||(l[18]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("msub",null,[t("mi",null,"H"),t("mi",null,"t")]),t("mo",null,"="),t("msub",null,[t("mi",null,"o"),t("mn",null,"1")]),t("mo",null,","),t("msub",null,[t("mi",null,"a"),t("mn",null,"1")]),t("mo",null,","),t("msub",null,[t("mi",null,"r"),t("mn",null,"1")]),t("mo",null,","),t("mo",null,"⋯"),t("mo",null,","),t("msub",null,[t("mi",null,"o"),t("mi",null,"t")]),t("mo",null,","),t("msub",null,[t("mi",null,"a"),t("mi",null,"t")]),t("mo",null,","),t("msub",null,[t("mi",null,"r"),t("mi",null,"t")])])],-1))])])]),l[39]||(l[39]=t("p",null,[t("strong",null,"序列决策")],-1)),t("ul",null,[l[35]||(l[35]=t("li",null,[t("strong",null,"智能体和环境交互"),Q("，选取一系列动作来最大化奖励。")],-1)),t("li",null,[l[27]||(l[27]=Q("agent内部状态：")),t("mjx-container",p,[(o(),a("svg",u,l[23]||(l[23]=[T("",1)]))),l[24]||(l[24]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("msubsup",null,[t("mi",null,"s"),t("mi",null,"t"),t("mi",null,"a")]),t("mo",null,"="),t("msup",null,[t("mi",null,"f"),t("mi",null,"a")]),t("mo",{stretchy:"false"},"("),t("msub",null,[t("mi",null,"H"),t("mi",null,"t")]),t("mo",{stretchy:"false"},")")])],-1))]),l[28]||(l[28]=Q("，环境内部状态：")),t("mjx-container",h,[(o(),a("svg",c,l[25]||(l[25]=[T("",1)]))),l[26]||(l[26]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("msubsup",null,[t("mi",null,"s"),t("mi",null,"t"),t("mi",null,"e")]),t("mo",null,"="),t("msup",null,[t("mi",null,"f"),t("mi",null,"e")]),t("mo",{stretchy:"false"},"("),t("msub",null,[t("mi",null,"H"),t("mi",null,"t")]),t("mo",{stretchy:"false"},")")])],-1))])]),t("li",null,[l[31]||(l[31]=t("strong",null,"马尔可夫决策过程",-1)),l[32]||(l[32]=Q("：")),l[33]||(l[33]=t("code",null,"完全可观测",-1)),l[34]||(l[34]=Q("，智能体能看到环境所有状态，")),t("mjx-container",H,[(o(),a("svg",w,l[29]||(l[29]=[T("",1)]))),l[30]||(l[30]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("msub",null,[t("mi",null,"o"),t("mi",null,"t")]),t("mo",null,"="),t("msubsup",null,[t("mi",null,"s"),t("mi",null,"t"),t("mi",null,"a")]),t("mo",null,"="),t("msubsup",null,[t("mi",null,"s"),t("mi",null,"t"),t("mi",null,"e")])])],-1))])]),l[36]||(l[36]=t("li",null,[t("strong",null,"部分可观测马尔科夫决策过程"),Q("："),t("code",null,"部分可观测"),Q("，智能体只能看到部分状态")],-1))])]),l[57]||(l[57]=T("",24)),t("ul",null,[t("li",null,[l[42]||(l[42]=t("code",null,"状态转移概率",-1)),l[43]||(l[43]=Q()),t("mjx-container",b,[(o(),a("svg",k,l[40]||(l[40]=[T("",1)]))),l[41]||(l[41]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"p"),t("mo",{stretchy:"false"},"("),t("msub",null,[t("mi",null,"s"),t("mrow",{"data-mjx-texclass":"ORD"},[t("mi",null,"t"),t("mo",null,"+"),t("mn",null,"1")])]),t("mo",null,"∣"),t("msub",null,[t("mi",null,"s"),t("mi",null,"t")]),t("mo",null,","),t("msub",null,[t("mi",null,"a"),t("mi",null,"t")]),t("mo",{stretchy:"false"},")")])],-1))]),l[44]||(l[44]=Q("，")),l[45]||(l[45]=t("code",null,"奖励函数",-1))]),l[46]||(l[46]=t("li",null,[t("strong",null,"通常很难获得环境信息")],-1))]),l[58]||(l[58]=T("",12)),t("div",x,[l[54]||(l[54]=t("div",{class:"custom-block-title"},"探索策略",-1)),t("ul",null,[t("li",null,[l[50]||(l[50]=Q("如何")),l[51]||(l[51]=t("strong",null,"在探索和利用之间进行平衡",-1)),l[52]||(l[52]=Q("。 ")),t("ul",null,[t("li",null,[t("mjx-container",f,[(o(),a("svg",y,l[47]||(l[47]=[t("g",{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"scale(1,-1)"},[t("g",{"data-mml-node":"math"},[t("g",{"data-mml-node":"mi"},[t("path",{"data-c":"1D716",d:"M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z",style:{"stroke-width":"3"}})])])],-1)]))),l[48]||(l[48]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"ϵ")])],-1))]),l[49]||(l[49]=Q("贪心法、上置信界法。"))])])]),l[53]||(l[53]=t("li",null,"如何提高探索效率避免局部最优解。",-1))])]),l[59]||(l[59]=T("",4))])}const A=s(e,[["render",L]]);export{D as __pageData,A as default};

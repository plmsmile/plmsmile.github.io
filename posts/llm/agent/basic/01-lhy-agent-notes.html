<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Agent基础概念 (李宏毅笔记) | 📚 plmblog</title>
    <meta name="description" content="记录一些学习笔记。">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/assets/style.DcBljOKC.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.DH1DF09d.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.Bc4HM4R7.js">
    <link rel="modulepreload" href="/assets/chunks/framework.CvbyeFFO.js">
    <link rel="modulepreload" href="/assets/posts_llm_agent_basic_01-lhy-agent-notes.md.BK_CsHNC.lean.js">
    <link rel="icon" href="/plm.png">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-cecb633e><!--[--><!--]--><!--[--><span tabindex="-1" data-v-c979f278></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-c979f278>Skip to content</a><!--]--><!----><header class="VPNav" data-v-cecb633e data-v-0ad68676><div class="VPNavBar" data-v-0ad68676 data-v-ce71e4ef><div class="wrapper" data-v-ce71e4ef><div class="container" data-v-ce71e4ef><div class="title" data-v-ce71e4ef><div class="VPNavBarTitle has-sidebar" data-v-ce71e4ef data-v-7e906684><a class="title" href="/" data-v-7e906684><!--[--><!--]--><!----><span data-v-7e906684>📚 plmblog</span><!--[--><!--]--></a></div></div><div class="content" data-v-ce71e4ef><div class="content-body" data-v-ce71e4ef><!--[--><!--]--><div class="VPNavBarSearch search" data-v-ce71e4ef><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-ce71e4ef data-v-e0cd9371><span id="main-nav-aria-label" class="visually-hidden" data-v-e0cd9371> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>首页</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>🐲LLM</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Basic</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/basic/01-lm-define-information-theory.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🦋基础知识</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/infra/01-parrallel.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🛠基建框架</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>强化学习</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/rl/theory/01-reinforce-learning.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🎓RL理论基础</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/rl/rlhf.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚘RLHF</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/rl/o1llm.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚢推理模型</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/rl/02-agent-tool.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚄Agent-RL</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Agent</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/basic.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🤖概念及应用</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>行业方向</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/industry/mainllm/01-kimi-series.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚀主流模型</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>📙旧文章</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍓NLP</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/nlp.html" data-v-dc987abe><!--[--><span data-v-dc987abe>自然语言处理</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍑基础知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/dl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>深度学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/rl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>强化学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/ml.html" data-v-dc987abe><!--[--><span data-v-dc987abe>机器学习</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍎算法</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/algo/" data-v-dc987abe><!--[--><span data-v-dc987abe>算法题</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/bigdata/" data-v-dc987abe><!--[--><span data-v-dc987abe>大数据</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍒其他</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/env/" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/other/" data-v-dc987abe><!--[--><span data-v-dc987abe>其他</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>经验</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>环境</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/env/01-blog-env.html" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>心得</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/mind.html" data-v-dc987abe><!--[--><span data-v-dc987abe>心得体会</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/archive.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>归档</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/me.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>关于我</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-ce71e4ef data-v-b59ebfac><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-b59ebfac data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-ce71e4ef data-v-e0f2db57 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-ce71e4ef data-v-8897e953 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-ffaaba87><span class="vpi-more-horizontal icon" data-v-ffaaba87></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><!----><!--[--><!--[--><!----><div class="group" data-v-8897e953><div class="item appearance" data-v-8897e953><p class="label" data-v-8897e953>Appearance</p><div class="appearance-action" data-v-8897e953><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-8897e953 data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div></div></div><div class="group" data-v-8897e953><div class="item social-links" data-v-8897e953><div class="VPSocialLinks social-links-list" data-v-8897e953 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-ce71e4ef data-v-37e0f734><span class="container" data-v-37e0f734><span class="top" data-v-37e0f734></span><span class="middle" data-v-37e0f734></span><span class="bottom" data-v-37e0f734></span></span></button></div></div></div></div><div class="divider" data-v-ce71e4ef><div class="divider-line" data-v-ce71e4ef></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-cecb633e data-v-1b409c8b><div class="container" data-v-1b409c8b><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-1b409c8b><span class="vpi-align-left menu-icon" data-v-1b409c8b></span><span class="menu-text" data-v-1b409c8b>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-1b409c8b data-v-a203161a><button data-v-a203161a>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-cecb633e data-v-18f7b5ca><div class="curtain" data-v-18f7b5ca></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-18f7b5ca><span class="visually-hidden" id="sidebar-aria-label" data-v-18f7b5ca> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-7f5b9a39><section class="VPSidebarItem level-0 has-active" data-v-7f5b9a39 data-v-a4affe07><div class="item" role="button" tabindex="0" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><h2 class="text" data-v-a4affe07>Agent-基础</h2><!----></div><div class="items" data-v-a4affe07><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/agent/basic/06-deepresearch-evaluation.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>DeepResearch 评估</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/agent/basic/05-comuter-agent.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Computer-Agent</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/agent/basic/04-agent-blogs.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Agent 思考性文章</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/agent/basic/03-current-agents.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>一些流行的Agents</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/agent/basic/02-evaluation-agent.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Agent 评估 Benchmarks</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/agent/basic/01-lhy-agent-notes.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Agent基础概念 (李宏毅笔记)</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-cecb633e data-v-53a9cb18><div class="VPDoc has-sidebar has-aside" data-v-53a9cb18 data-v-5a64a79a><!--[--><!--]--><div class="container" data-v-5a64a79a><div class="aside" data-v-5a64a79a><div class="aside-curtain" data-v-5a64a79a></div><div class="aside-container" data-v-5a64a79a><div class="aside-content" data-v-5a64a79a><div class="VPDocAside" data-v-5a64a79a data-v-f8ea3c28><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-f8ea3c28 data-v-b94d89ac><div class="content" data-v-b94d89ac><div class="outline-marker" data-v-b94d89ac></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-b94d89ac>当前页大纲</div><ul class="VPDocOutlineItem root" data-v-b94d89ac data-v-80b46526><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-f8ea3c28></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-5a64a79a><div class="content-container" data-v-5a64a79a><!--[--><!--[--><!--[--><article class="post-header" data-v-a99fd7c9><h1 class="title" data-v-a99fd7c9>Agent基础概念 (李宏毅笔记)</h1><div class="stats-container" data-v-a99fd7c9><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 📅 发表于 <span class="stat-text" data-v-a99fd7c9>2025/05/13</span></div><div class="stat-item" data-v-a99fd7c9> 🔄 更新于 <span class="stat-text" data-v-a99fd7c9>2025/05/13</span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 👁️ <span class="stat-text" data-v-a99fd7c9>-- 次访问</span><span id="busuanzi_value_page_pv" style="display:none;" data-page="/posts/llm/agent/basic/01-lhy-agent-notes.html" data-v-a99fd7c9></span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 📝 <span class="stat-text" data-v-a99fd7c9>0 字</span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> ⏳ <span class="stat-text" data-v-a99fd7c9>0 分钟</span></div><div class="stat-divider" data-v-a99fd7c9></div></div><div class="tag-group" data-v-a99fd7c9><!--[--><div class="category-item" data-v-a99fd7c9>agent</div><!--]--><!--[--><div class="tag-item" data-v-a99fd7c9> #agent</div><div class="tag-item" data-v-a99fd7c9> #function call</div><div class="tag-item" data-v-a99fd7c9> #tool use</div><div class="tag-item" data-v-a99fd7c9> #memory</div><div class="tag-item" data-v-a99fd7c9> #planning</div><div class="tag-item" data-v-a99fd7c9> #reasonning</div><!--]--></div></article><!--]--><!--]--><!--]--><main class="main" data-v-5a64a79a><div style="position:relative;" class="vp-doc _posts_llm_agent_basic_01-lhy-agent-notes" data-v-5a64a79a><div><div class="custom-block tip"><div class="custom-block-title">本文关键点</div><p>学习李宏毅老师agent课程的笔记。</p><ol><li>Agent 构建、应用</li><li>Agent Memory、调整行为</li><li>Agent 使用工具</li><li>Agent Plan 能力及强化</li></ol></div><h2 id="ai-agent-基础" tabindex="-1">AI Agent 基础 <a class="header-anchor" href="#ai-agent-基础" aria-label="Permalink to &quot;AI Agent 基础&quot;">​</a></h2><h3 id="什么是-agent" tabindex="-1">什么是 Agent <a class="header-anchor" href="#什么是-agent" aria-label="Permalink to &quot;什么是 Agent&quot;">​</a></h3><p>类似于RL，人类给定Goal，期望Agent能自主完成任务。</p><ul><li>Agent <code>观察环境</code></li><li>Agent <code>执行Action</code></li><li><code>不断循环，直到完成任务</code></li></ul><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513201053.jpg" style="display:block;margin:auto;" width="80%"><h3 id="agency-level-hf定义" tabindex="-1">Agency Level (HF定义) <a class="header-anchor" href="#agency-level-hf定义" aria-label="Permalink to &quot;Agency Level (HF定义)&quot;">​</a></h3><blockquote><p><a href="https://huggingface.co/docs/smolagents/conceptual_guides/intro_agents" target="_blank" rel="noreferrer">Introduction to Agents</a></p><p>AI Agents are <strong>programs where LLM outputs control the workflow</strong>.</p></blockquote><table tabindex="0"><thead><tr><th style="text-align:center;">Agency Level</th><th style="text-align:center;">Description</th><th style="text-align:center;">Short name</th><th style="text-align:center;">Example Code</th></tr></thead><tbody><tr><td style="text-align:center;">☆☆☆</td><td style="text-align:center;">模型输出和流程无关</td><td style="text-align:center;">Simple processor</td><td style="text-align:center;"><code>process_llm_output(llm_response)</code></td></tr><tr><td style="text-align:center;">★☆☆</td><td style="text-align:center;">输出简单的if else</td><td style="text-align:center;">Router</td><td style="text-align:center;"><code>if llm_decision(): path_a() else: path_b()</code></td></tr><tr><td style="text-align:center;">★★☆</td><td style="text-align:center;">LLM output controls <mark>函数执行</mark></td><td style="text-align:center;">Tool call</td><td style="text-align:center;"><code>run_function(llm_chosen_tool, llm_chosen_args)</code></td></tr><tr><td style="text-align:center;">★★☆</td><td style="text-align:center;">LLM output controls <mark>iteration and program continuation</mark></td><td style="text-align:center;">Multi-step Agent</td><td style="text-align:center;"><code>while llm_should_continue(): execute_next_step()</code></td></tr><tr><td style="text-align:center;">★★★</td><td style="text-align:center;">One agentic workflow can <mark>start another agentic workflow</mark></td><td style="text-align:center;">Multi-Agent</td><td style="text-align:center;"><code>if llm_trigger(): execute_agent()</code></td></tr><tr><td style="text-align:center;">★★★</td><td style="text-align:center;">LLM acts in code, <mark>can define its own tools / start other agents</mark></td><td style="text-align:center;">Code Agents</td><td style="text-align:center;"><code>def custom_tool(args): ...</code></td></tr></tbody></table><h3 id="如何构建-agent-llm-agent" tabindex="-1">如何构建 Agent (LLM Agent) <a class="header-anchor" href="#如何构建-agent-llm-agent" aria-label="Permalink to &quot;如何构建 Agent (LLM Agent)&quot;">​</a></h3><p>直接使用 <code>LLM</code>来构建Agent</p><ul><li>做接龙游戏，<span class="marker-evy">goal, obs1, action1, obs2, action2, obs3, action3...</span></li><li>相比于传统AlphaGo类似专有Agent，<span class="marker-evy">LLM近乎无限可能，能用工具、做很多事情</span></li></ul><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513201500.jpg" style="display:block;margin:auto;" width="80%"><p><strong>需要解决的问题</strong></p><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513201527.jpg" style="display:block;margin:auto;" width="80%"><p><strong>优势</strong>：<code>无限可能</code></p><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513202443.jpg" style="display:block;margin:auto;" width="70%"><h3 id="agent-应用" tabindex="-1">Agent 应用 <a class="header-anchor" href="#agent-应用" aria-label="Permalink to &quot;Agent 应用&quot;">​</a></h3><p>包括NPC、购物、训模型、做报告、上网操作电脑等等。</p><ul><li><p>NPC</p><ul><li><a href="https://youtu.be/G44Lkj7XDsA?si=cMbKG3tqPbIgnnBq" target="_blank" rel="noreferrer">(2304)村民NPC</a></li><li><a href="https://www.youtube.com/watch?v=2tbaCn0Kl90" target="_blank" rel="noreferrer">Minecraft</a></li></ul></li><li><p>操作电脑</p><ul><li>购物</li><li>(2017)Web-Based Agents</li><li><a href="https://arxiv.org/abs/2306.06070" target="_blank" rel="noreferrer">(2306)Mind2Web</a>、<a href="https://arxiv.org/abs/2307.13854" target="_blank" rel="noreferrer">(2307)WebArena</a>、<a href="https://arxiv.org/abs/2401.13649" target="_blank" rel="noreferrer">(2401)VisualWebArena</a></li></ul><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513224643.jpg" style="display:block;margin:auto;" width="80%"></li><li><p>训练模型</p><ul><li><a href="https://arxiv.org/abs/2502.13138" target="_blank" rel="noreferrer">(2502)AIDE: The Machine Learning Engineer Agent</a></li><li><a href="https://arxiv.org/abs/2410.20424" target="_blank" rel="noreferrer">(2410)AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions</a></li></ul></li><li><p>做研究</p><ul><li>谷歌：<a href="https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/" target="_blank" rel="noreferrer">Accelerating scientific breakthroughs with an AI co-scientist</a></li></ul><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513224705.jpg" style="display:block;margin:auto;" width="80%"></li><li><p>迈向更加实时交互的应用</p><ul><li>由回合制互动 -&gt; <code>及时互动</code></li></ul><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513224737.jpg" style="display:block;margin:auto;" width="80%"></li></ul><h2 id="agent-根据经验来调整行为" tabindex="-1">Agent 根据经验来调整行为 <a class="header-anchor" href="#agent-根据经验来调整行为" aria-label="Permalink to &quot;Agent 根据经验来调整行为&quot;">​</a></h2><p>按照是否微调模型，可以分为 <code>微调模型(如RL/SFT)</code>和 <code>不微调模型</code>两种，本节聚焦在后者。</p><h3 id="整体思路" tabindex="-1">整体思路 <a class="header-anchor" href="#整体思路" aria-label="Permalink to &quot;整体思路&quot;">​</a></h3><p>Agent检索历史Memory来调整当前的行为。</p><ul><li><code>经验(memory)</code>主要来自自身，外部也可以(RAG)。</li><li>Agent可以有 <code>write模块</code>，来决定当前经验是否存下来。</li><li>Agent可以有 <code>read模块</code>，检索经验来做指导。检索就是一个 <code>RAG</code>。</li><li>Agent可以有 <code>reflection模块</code>，对检索来的经验做 <code>总结汇总</code>，<code>得到更好的经验和想法</code></li></ul><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513231147.jpg" style="display:block;margin:auto;" width="80%"><h3 id="stream-bench" tabindex="-1">Stream Bench <a class="header-anchor" href="#stream-bench" aria-label="Permalink to &quot;Stream Bench&quot;">​</a></h3><ul><li>正向经验有用</li><li>负向经验无用</li></ul><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513231330.jpg" style="display:block;margin:auto;" width="80%"><h3 id="更多-memgpt-a-mem" tabindex="-1">更多(MemGPT/A-MEM) <a class="header-anchor" href="#更多-memgpt-a-mem" aria-label="Permalink to &quot;更多(MemGPT/A-MEM)&quot;">​</a></h3><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250513231219.jpg" style="display:block;margin:auto;" width="80%"><h2 id="agent-使用工具" tabindex="-1">Agent 使用工具 <a class="header-anchor" href="#agent-使用工具" aria-label="Permalink to &quot;Agent 使用工具&quot;">​</a></h2><p>工具可以看作是Function，使用工具就是调用Function，又叫做 <code>Function Call</code>。常用工具包括：</p><ul><li>搜索引擎</li><li>python</li><li>其他AI</li><li>...</li></ul><h3 id="工具怎么调用的" tabindex="-1">工具怎么调用的 <a class="header-anchor" href="#工具怎么调用的" aria-label="Permalink to &quot;工具怎么调用的&quot;">​</a></h3><p>以下是一个通用的调用方法，不是唯一的。</p><p>Prompt配置</p><ul><li>System Prompt：介绍工具定义、如何使用工具等。</li><li>User Prompt：具体用户Query</li></ul><div class="custom-block tip"><div class="custom-block-title">调用流程</div><p>模型根据User Prompt来决定是否调用工具。如果需要调用，则输出工具调用指令</p><ul><li><code>&lt;tool&gt;Temperature(&#39;高雄&#39;, &#39;2025.03.10 14:00&#39;)&lt;/tool&gt;</code></li><li>系统根据指令执行工具，工具返回结果</li><li>把结果拼装到 <code>&lt;output&gt;32度&lt;/output&gt;</code>，再次调用模型</li><li>模型整理结果，返回给用户</li></ul></div><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250514102543.jpg" style="display:block;margin:auto;" width="80%"><h3 id="工具很多怎么办" tabindex="-1">工具很多怎么办 <a class="header-anchor" href="#工具很多怎么办" aria-label="Permalink to &quot;工具很多怎么办&quot;">​</a></h3><p>由于冗长问题，并不能把所有工具说明都放到System Prompt里。工具集合说明放到Agent Memory里，再接一个RAG，仅选择所需要的工具即可。</p><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250514102558.jpg" style="display:block;margin:auto;" width="60%"><h3 id="工具结果有误怎么办" tabindex="-1">工具结果有误怎么办 <a class="header-anchor" href="#工具结果有误怎么办" aria-label="Permalink to &quot;工具结果有误怎么办&quot;">​</a></h3><div class="custom-block warning"><div class="custom-block-title">过度相信</div><p>模型会因为过度相信工具而犯错。比如：</p><ul><li>RAG结果错误，用胶水粘披萨🍕，可能仅仅是一个玩笑话，模型却无法判断。</li></ul></div><p>比如</p><div class="custom-block danger"><div class="custom-block-title">工具错误</div><p>如果工具结果出现明显错误，模型会认为其错误。 比如</p><ul><li>比如高雄温度达1000度。</li><li>精神病药量每日100mg。</li></ul></div><p>LLM有一定自己判断力，取决于模型自身能力和知识。</p><p>那么什么样的外部知识信息，模型会比较容易相信呢？</p><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250514110700.jpg" style="display:block;margin:auto;" width="80%"><div class="custom-block tip"><div class="custom-block-title">模型容易相信的</div><ul><li>和模型内部知识 <code>比较相近</code>的外部知识。（可以计算模型自身知识的置信度）</li><li><code>其他AI</code>说的话。不相信人类的话</li><li>比较 <code>新的文章</code>。</li><li>美观的？</li></ul></div><h3 id="平衡工具和模型自身能力" tabindex="-1">平衡工具和模型自身能力 <a class="header-anchor" href="#平衡工具和模型自身能力" aria-label="Permalink to &quot;平衡工具和模型自身能力&quot;">​</a></h3><p>比如3*4，一下能计算出12，但通过工具，可能会更慢。</p><div class="custom-block warning"><div class="custom-block-title">工具效率</div><p>使用工具不一定总是有效率</p></div><h2 id="agent-planning" tabindex="-1">Agent Planning <a class="header-anchor" href="#agent-planning" aria-label="Permalink to &quot;Agent Planning&quot;">​</a></h2><h3 id="什么是做计划" tabindex="-1">什么是做计划 <a class="header-anchor" href="#什么是做计划" aria-label="Permalink to &quot;什么是做计划&quot;">​</a></h3><p>让模型做执行前，先做计划，列举一系列的action，再根据action来执行。</p><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250514112922.jpg" style="display:block;margin:auto;" width="80%"><div class="custom-block warning"><div class="custom-block-title">计划需改变</div><p>但原有的计划不一定适用，会发生改变。</p><p>比如，每次action时让模型重新review plan。</p></div><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250514112940.jpg" style="display:block;margin:auto;" width="80%"><h3 id="有一定-plan-能力" tabindex="-1">有一定 Plan 能力 <a class="header-anchor" href="#有一定-plan-能力" aria-label="Permalink to &quot;有一定 Plan 能力&quot;">​</a></h3><ul><li>冰箱拿牛奶（非常简单）</li><li>(2305) <a href="https://arxiv.org/abs/2305.15771" target="_blank" rel="noreferrer">PlanBench</a>：叠积木（<code>AI可能见过相关内容</code>）、神秘方块（复杂规则，推理）</li><li>(2402) <a href="https://arxiv.org/abs/2402.01622" target="_blank" rel="noreferrer">TravelPlanner</a>：旅行计划，给需求做计划。 <ul><li>分数低(4分)，是因为很多不符合限制。<a href="https://arxiv.org/abs/2402.01622" target="_blank" rel="noreferrer">https://arxiv.org/abs/2402.01622</a></li><li><code>引入限制工具辅助</code>，模型做出好效果(90分)。<a href="https://arxiv.org/abs/2404.11891" target="_blank" rel="noreferrer">https://arxiv.org/abs/2404.11891</a></li></ul></li></ul><div class="custom-block tip"><div class="custom-block-title">Plan能力介于有和无之间</div><p>模型有一定Plan能力，但效果一般，需考虑强化。</p></div><h3 id="如何优化-plan-能力" tabindex="-1">如何优化 Plan 能力 <a class="header-anchor" href="#如何优化-plan-能力" aria-label="Permalink to &quot;如何优化 Plan 能力&quot;">​</a></h3><p><code>1、暴力搜索可行吗？</code></p><ul><li>暴力搜索可达，但成本太高</li></ul><p><code>2、优化暴力搜索</code></p><ul><li>(2407) <a href="https://arxiv.org/abs/2407.01476" target="_blank" rel="noreferrer">Tree Search for LLM Agents</a>，暴搜+去除低分路径。 <ul><li>缺点：无法回溯错误，<code>覆水难收</code>。</li><li>解决：可以自行在脑内，<code>提前想象脑内小剧场</code><ul><li>但 <code>由环境来决定行为</code>的。</li></ul></li></ul></li></ul><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250514115102.jpg" style="display:block;margin:auto;" width="80%"><p><code>3、提前脑补，模拟环境交互</code></p><ul><li>(2411) <a href="https://arxiv.org/abs/2411.06559" target="_blank" rel="noreferrer">Is Your LLM Secretly a Word Model of the Internet</a><ul><li>由LLM自己做WorldModel模拟真实世界交互，利用脑内小剧场。</li></ul></li></ul><img src="https://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/01-lhy-agent-notes/20250514115151.jpg" style="display:block;margin:auto;" width="80%"><p><code>4、推理模型</code></p><ul><li>推理模型 (DeepSeek-R1)：整体reason模型效果比非reason好</li></ul><div class="custom-block danger"><div class="custom-block-title">overthinking</div><p>但存在overthinking的问题，想太多</p></div><p><code>5、优化Overthiking</code></p><ul><li>(2502) <a href="https://arxiv.org/abs/2502.08235" target="_blank" rel="noreferrer">The Danger of Overthinking: Examining the Reasoning-Action Dilemma in Agentic Tasks</a></li></ul><h2 id="参考内容" tabindex="-1">参考内容 <a class="header-anchor" href="#参考内容" aria-label="Permalink to &quot;参考内容&quot;">​</a></h2><ul><li><a href="https://docs.google.com/presentation/d/1kTxukwlmx2Sc9H7aGPTiNiPdk4zN_NoH/edit#slide=id.p5" target="_blank" rel="noreferrer">参考PPT文件</a></li><li>视频课程地址</li></ul><iframe width="560" height="315" src="https://www.youtube.com/embed/M2Yg1kwPpts?si=FPlgwdRaYMitxt3B" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></div></div></main><footer class="VPDocFooter" data-v-5a64a79a data-v-54a90a4a><!--[--><!--]--><div class="edit-info" data-v-54a90a4a><!----><div class="last-updated" data-v-54a90a4a><p class="VPLastUpdated" data-v-54a90a4a data-v-08208c09>Last updated: <time datetime="2025-07-22T16:01:17.000Z" data-v-08208c09></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-54a90a4a><span class="visually-hidden" id="doc-footer-aria-label" data-v-54a90a4a>Pager</span><div class="pager" data-v-54a90a4a><a class="VPLink link pager-link prev" href="/posts/llm/agent/basic/02-evaluation-agent.html" data-v-54a90a4a><!--[--><span class="desc" data-v-54a90a4a>上一页</span><span class="title" data-v-54a90a4a>Agent 评估 Benchmarks</span><!--]--></a></div><div class="pager" data-v-54a90a4a><!----></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--[--><div class="busuanzi"> 总访客数： <span id="busuanzi_value_site_uv"></span>   ·   总访问量： <span id="busuanzi_value_site_pv"></span></div><div class="busuanzi"> PLM&#39;s Blog @ 2016 - 2025</div><!--]--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api-examples.md\":\"Drgk6GHl\",\"index.md\":\"BheGDo0s\",\"markdown-examples.md\":\"BJDtqj8S\",\"posts_archive.md\":\"pZWQT7dp\",\"posts_exps_env_01-blog-env.md\":\"DsD2OukA\",\"posts_exps_env_index.md\":\"BJEZeoT-\",\"posts_exps_mind_index.md\":\"naOB3-Mb\",\"posts_llm_agent_basic_01-lhy-agent-notes.md\":\"BK_CsHNC\",\"posts_llm_agent_basic_02-evaluation-agent.md\":\"Dn02cVtP\",\"posts_llm_agent_basic_03-current-agents.md\":\"C25gmbg8\",\"posts_llm_agent_basic_04-agent-blogs.md\":\"_QbL2Plv\",\"posts_llm_agent_basic_05-comuter-agent.md\":\"D0gJpId6\",\"posts_llm_agent_basic_06-deepresearch-evaluation.md\":\"DdRDcxUJ\",\"posts_llm_agent_basic_index.md\":\"ClGtwUqg\",\"posts_llm_agent_rl_01-agent-rl.md\":\"wOF9bz66\",\"posts_llm_agent_rl_02-agent-tool.md\":\"IB_AqkSe\",\"posts_llm_agent_rl_03-agent-search.md\":\"CoYozBSV\",\"posts_llm_agent_rl_04-agent-env.md\":\"C_O9BVi3\",\"posts_llm_agent_rl_index.md\":\"BudtoDK9\",\"posts_llm_basic_01-lm-define-information-theory.md\":\"D_NiDMJf\",\"posts_llm_basic_02-llm-components.md\":\"CK5rj3vH\",\"posts_llm_basic_03-transformer-detail.md\":\"BgLyAVDZ\",\"posts_llm_basic_04-llm-architecture.md\":\"CJ4m4grf\",\"posts_llm_basic_05-llm-basic-info.md\":\"bdnM02bn\",\"posts_llm_basic_index.md\":\"DjX2HRXy\",\"posts_llm_industry_mainllm_01-kimi-series.md\":\"BpSW4UZD\",\"posts_llm_industry_mainllm_02-deepseek-series.md\":\"BSYWoiac\",\"posts_llm_infra_01-parrallel.md\":\"4SPd423i\",\"posts_llm_infra_02-speed-framework.md\":\"DR7mq5S5\",\"posts_llm_infra_03-inference-tech.md\":\"BMBxLcEu\",\"posts_llm_rl_index.md\":\"iUgEsMU1\",\"posts_llm_rl_theory_01-reinforce-learning.md\":\"BSYrbQOo\",\"posts_llm_rl_theory_02-value-learning.md\":\"B1_9D1Y9\",\"posts_llm_rl_theory_03-strategy-learning.md\":\"BFNPugMk\",\"posts_llm_rl_theory_04-reinforce-conclusion-simple.md\":\"CuLb6Pxe\",\"posts_me.md\":\"B9W6CMag\",\"posts_olds_algo_aim2offer.md\":\"Dg9B7Z3I\",\"posts_olds_algo_aim2offer2.md\":\"CnDd98IS\",\"posts_olds_algo_aim2offer3.md\":\"YnkHg59Q\",\"posts_olds_algo_aim2offer4.md\":\"BXurWO8W\",\"posts_olds_algo_algorithm-dfs.md\":\"VxYdFkrt\",\"posts_olds_algo_index.md\":\"CmdF0Gg2\",\"posts_olds_algo_leetcode-01.md\":\"DaoLL5QB\",\"posts_olds_algo_sort-algorithms.md\":\"CGSaXABt\",\"posts_olds_bigdata_16-spark-baserdd.md\":\"nnsc9x1_\",\"posts_olds_bigdata_17-spark-pairrdd.md\":\"DTYLfi_i\",\"posts_olds_bigdata_18-spark-sql.md\":\"BZ3MwzEC\",\"posts_olds_bigdata_19-spark-programming.md\":\"DrAdYxjj\",\"posts_olds_bigdata_20-numpy.md\":\"CN3CN-Cf\",\"posts_olds_bigdata_index.md\":\"CWrZwWPb\",\"posts_olds_dl_23-pytorch-start.md\":\"BHevLby6\",\"posts_olds_dl_35-nerual-network-optim.md\":\"Cp2SpLoE\",\"posts_olds_dl_38-convolution.md\":\"CC_SQ57z\",\"posts_olds_dl_cs224n-assignment-1.md\":\"D0dK0rzN\",\"posts_olds_dl_cs224n-notes3-neural-networks-2.md\":\"TG3qYWqo\",\"posts_olds_dl_cs224n-notes3-neural-networks.md\":\"CDZWc4X6\",\"posts_olds_dl_cs231n-linear-notes.md\":\"DLRyzcwJ\",\"posts_olds_dl_index.md\":\"C1dyLGNS\",\"posts_olds_dl_rnn.md\":\"CwYYWZ7N\",\"posts_olds_env_09-linux-notes.md\":\"DERcUyYf\",\"posts_olds_env_12-ide-envs.md\":\"Bx6h4IWK\",\"posts_olds_env_13-old-blog-problems.md\":\"DsYjJL2J\",\"posts_olds_env_24-hexo-problems.md\":\"BWPoXjZh\",\"posts_olds_env_index.md\":\"DQpgTXVj\",\"posts_olds_ml_10-trees.md\":\"BkNaj6fL\",\"posts_olds_ml_14-em.md\":\"DIufCP0H\",\"posts_olds_ml_21-lr.md\":\"C-1ms511\",\"posts_olds_ml_22-ml-ch03-bayes.md\":\"Dqb846RT\",\"posts_olds_ml_27-svm-notes.md\":\"C96WS6CL\",\"posts_olds_ml_28-ml-interview-notes.md\":\"D-r631Oz\",\"posts_olds_ml_29-desicion-tree.md\":\"CtwmlbWl\",\"posts_olds_ml_crf.md\":\"CEE5oTqd\",\"posts_olds_ml_index.md\":\"BLMEziB1\",\"posts_olds_ml_maxentmodel.md\":\"CSbOumJx\",\"posts_olds_ml_pgm-01.md\":\"BTwybTMD\",\"posts_olds_nlp_11-nlp-labels.md\":\"Cl0Lb8OT\",\"posts_olds_nlp_25-google-nmt.md\":\"BOM-hoYN\",\"posts_olds_nlp_26-wordpieacemodel.md\":\"Q8-L5j15\",\"posts_olds_nlp_30-dynamic-memory-network.md\":\"AB-oqmxo\",\"posts_olds_nlp_31-co-attention-vqa.md\":\"lzwuVKG5\",\"posts_olds_nlp_32-dynamic-coattention-network.md\":\"Bxl4ABWd\",\"posts_olds_nlp_33-attention-summary.md\":\"DT6np0xG\",\"posts_olds_nlp_36-alime-chat.md\":\"Cu2xkcdT\",\"posts_olds_nlp_39-squard-models.md\":\"B1L3iDEv\",\"posts_olds_nlp_45-match-lstm.md\":\"DkpQKM5B\",\"posts_olds_nlp_46-rnet-selfmatch.md\":\"CzGHQ-PZ\",\"posts_olds_nlp_47-bidaf.md\":\"DFJaLh2v\",\"posts_olds_nlp_48-attention-is-all-you-need.md\":\"BY6XvFQ5\",\"posts_olds_nlp_49-qanet.md\":\"BPKWHzTf\",\"posts_olds_nlp_50-elmo.md\":\"WuOt1elN\",\"posts_olds_nlp_51-opengpt.md\":\"B9pQ3h5W\",\"posts_olds_nlp_52-bert.md\":\"5q3t5Qqh\",\"posts_olds_nlp_53-mrc-brief.md\":\"D9CkYrea\",\"posts_olds_nlp_54-mrc-models.md\":\"Ak4bDf1J\",\"posts_olds_nlp_attention-based-nmt.md\":\"DzovOxdG\",\"posts_olds_nlp_attention-model.md\":\"BVcXcWt7\",\"posts_olds_nlp_cs224n-lecture2-word2vec.md\":\"_MmBTADr\",\"posts_olds_nlp_cs224n-notes1-word2vec.md\":\"DXSi5KGh\",\"posts_olds_nlp_index.md\":\"Bfo4Lwn3\",\"posts_olds_nlp_nlp-notes.md\":\"D0Rkl4SF\",\"posts_olds_nlp_nmt.md\":\"DUgy6vHF\",\"posts_olds_nlp_subword-units.md\":\"BUzbRrkD\",\"posts_olds_nlp_word2vec-math.md\":\"agvHiE1x\",\"posts_olds_nlp_word2vec.md\":\"D0EJh12M\",\"posts_olds_other_15-cpp-pointer-object-reference.md\":\"uCLsDJe3\",\"posts_olds_other_index.md\":\"C1T-ubsz\",\"posts_olds_rl_37-reinforce-learning.md\":\"Cf2nny8k\",\"posts_olds_rl_40-value-learning.md\":\"DcnHvvpH\",\"posts_olds_rl_41-strategy-learning.md\":\"CStMrB-q\",\"posts_olds_rl_42-reinforce-conclusion-simple.md\":\"flRZUmJZ\",\"posts_olds_rl_43-intent-detection-slot-filling.md\":\"DcAUbaZU\",\"posts_olds_rl_44-reinforce-nlp.md\":\"Br2ShITL\",\"posts_olds_rl_index.md\":\"CUsxM3zO\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"📚 plmblog\",\"description\":\"记录一些学习笔记。\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"首页\",\"link\":\"/\"},{\"text\":\"🐲LLM\",\"items\":[{\"text\":\"Basic\",\"items\":[{\"text\":\"🦋基础知识\",\"link\":\"/posts/llm/basic/01-lm-define-information-theory\"},{\"text\":\"🛠基建框架\",\"link\":\"/posts/llm/infra/01-parrallel\"}]},{\"text\":\"强化学习\",\"items\":[{\"text\":\"🎓RL理论基础\",\"link\":\"/posts/llm/rl/theory/01-reinforce-learning\"},{\"text\":\"🚘RLHF\",\"link\":\"/posts/llm/rl/rlhf\"},{\"text\":\"🚢推理模型\",\"link\":\"/posts/llm/rl/o1llm\"},{\"text\":\"🚄Agent-RL\",\"link\":\"/posts/llm/agent/rl/02-agent-tool\"}]},{\"text\":\"Agent\",\"items\":[{\"text\":\"🤖概念及应用\",\"link\":\"/posts/llm/agent/basic\"}]},{\"text\":\"行业方向\",\"items\":[{\"text\":\"🚀主流模型\",\"link\":\"/posts/llm/industry/mainllm/01-kimi-series\"}]}]},{\"text\":\"📙旧文章\",\"items\":[{\"text\":\"🍓NLP\",\"items\":[{\"text\":\"自然语言处理\",\"link\":\"/posts/olds/nlp\"}]},{\"text\":\"🍑基础知识\",\"items\":[{\"text\":\"深度学习\",\"link\":\"/posts/olds/dl\"},{\"text\":\"强化学习\",\"link\":\"/posts/olds/rl\"},{\"text\":\"机器学习\",\"link\":\"/posts/olds/ml\"}]},{\"text\":\"🍎算法\",\"items\":[{\"text\":\"算法题\",\"link\":\"/posts/olds/algo/\"},{\"text\":\"大数据\",\"link\":\"/posts/olds/bigdata/\"}]},{\"text\":\"🍒其他\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/olds/env/\"},{\"text\":\"其他\",\"link\":\"/posts/olds/other/\"}]}]},{\"text\":\"经验\",\"items\":[{\"text\":\"环境\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/exps/env/01-blog-env\"}]},{\"text\":\"心得\",\"items\":[{\"text\":\"心得体会\",\"link\":\"/posts/exps/mind\"}]}]},{\"text\":\"归档\",\"link\":\"/posts/archive.md\"},{\"text\":\"关于我\",\"link\":\"/posts/me\"}],\"outline\":{\"level\":[1,4],\"label\":\"当前页大纲\"},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/plmsmile\"}],\"search\":{\"provider\":\"local\"},\"docFooter\":{\"prev\":\"上一页\",\"next\":\"下一页\"},\"sidebar\":{\"/posts/olds/nlp/\":{\"base\":\"/posts/olds/nlp/\",\"items\":[{\"text\":\"NLP\",\"items\":[{\"text\":\"机器阅读(二)--模型(未完成)\",\"link\":\"54-mrc-models\"},{\"text\":\"机器阅读(一)--整体概述\",\"link\":\"53-mrc-brief\"},{\"text\":\"BERT 详解\",\"link\":\"52-bert\"},{\"text\":\"OpenAI GPT：Improving Language Understanding by Generative Pre-Training\",\"link\":\"51-opengpt\"},{\"text\":\"ELMo：Deep Contextualized Word Representations\",\"link\":\"50-elmo\"},{\"text\":\"QANet\",\"link\":\"49-qanet\"},{\"text\":\"Transformer\",\"link\":\"48-attention-is-all-you-need\"},{\"text\":\"Bidirectional Attention Flow\",\"link\":\"47-bidaf\"},{\"text\":\"R-Net (Gated Self-Matching Networks)\",\"link\":\"46-rnet-selfmatch\"},{\"text\":\"Match-LSTM and Answer Pointer\",\"link\":\"45-match-lstm\"},{\"text\":\"阅读理解模型总结\",\"link\":\"39-squard-models\"},{\"text\":\"阿里小蜜论文\",\"link\":\"36-alime-chat\"},{\"text\":\"各种注意力总结\",\"link\":\"33-attention-summary\"},{\"text\":\"Dynamic Coattention Network (Plus)\",\"link\":\"32-dynamic-coattention-network\"},{\"text\":\"协同注意力简介\",\"link\":\"31-co-attention-vqa\"},{\"text\":\"使用Dynamic Memory Network实现一个简单QA\",\"link\":\"30-dynamic-memory-network\"},{\"text\":\"词性标注和句法依存的表示符号\",\"link\":\"11-nlp-labels\"},{\"text\":\"Word2vec之总体介绍\",\"link\":\"cs224n-notes1-word2vec\"},{\"text\":\"Word2vec之数学模型\",\"link\":\"word2vec-math\"},{\"text\":\"Word2vec之公式推导笔记\",\"link\":\"cs224n-lecture2-word2vec\"},{\"text\":\"subword-units\",\"link\":\"subword-units\"},{\"text\":\"Wordpiece模型\",\"link\":\"26-wordpieacemodel\"},{\"text\":\"谷歌RNN翻译模型\",\"link\":\"25-google-nmt\"},{\"text\":\"机器翻译注意力机制及其PyTorch实现\",\"link\":\"Attention-based-NMT\"},{\"text\":\"图文介绍RNN注意力机制\",\"link\":\"attention-model\"},{\"text\":\"最初RNN神经翻译简略笔记\",\"link\":\"NMT\"},{\"text\":\"语言模型和平滑方法\",\"link\":\"nlp-notes\"},{\"text\":\"利用tensorflow实现简版word2vec\",\"link\":\"word2vec\"}]}]},\"/posts/olds/dl/\":{\"base\":\"/posts/olds/dl/\",\"items\":[{\"text\":\"DL\",\"items\":[{\"text\":\"卷积神经网络总结\",\"link\":\"38-convolution\"},{\"text\":\"网络优化\",\"link\":\"35-nerual-network-optim\"},{\"text\":\"cs224n作业一\",\"link\":\"cs224n-assignment-1\"},{\"text\":\"cs231n线性分类器和损失函数\",\"link\":\"cs231n-linear-notes\"},{\"text\":\"神经网络-过拟合-预处理-BN\",\"link\":\"cs224n-notes3-neural-networks-2\"},{\"text\":\"神经网络基础-反向传播-激活函数\",\"link\":\"cs224n-notes3-neural-networks\"},{\"text\":\"循环神经网络\",\"link\":\"rnn\"},{\"text\":\"PyTorch快速上手\",\"link\":\"23-pytorch-start\"}]}]},\"/posts/olds/rl/\":{\"base\":\"/posts/olds/rl/\",\"items\":[{\"text\":\"RL\",\"items\":[{\"text\":\"强化学习在NLP中的应用\",\"link\":\"44-reinforce-nlp\"},{\"text\":\"意图识别和槽填充\",\"link\":\"43-intent-detection-slot-filling\"},{\"text\":\"强化学习算法小结\",\"link\":\"42-reinforce-conclusion-simple\"},{\"text\":\"基于策略函数的学习方法\",\"link\":\"41-strategy-learning\"},{\"text\":\"基于值函数的学习\",\"link\":\"40-value-learning\"},{\"text\":\"强化学习\",\"link\":\"37-reinforce-learning\"}]}]},\"/posts/olds/ml/\":{\"base\":\"/posts/olds/ml/\",\"items\":[{\"text\":\"ML\",\"items\":[{\"text\":\"决策树笔记\",\"link\":\"29-desicion-tree\"},{\"text\":\"机器学习知识点汇总整理\",\"link\":\"28-ml-interview-notes\"},{\"text\":\"SVM笔记\",\"link\":\"27-svm-notes\"},{\"text\":\"树的总结\",\"link\":\"10-trees\"},{\"text\":\"条件随机场\",\"link\":\"crf\"},{\"text\":\"最大熵模型\",\"link\":\"maxentmodel\"},{\"text\":\"线性回归和逻辑回归\",\"link\":\"21-lr\"},{\"text\":\"最大期望算法\",\"link\":\"14-em\"},{\"text\":\"马尔可夫模型\",\"link\":\"pgm-01\"},{\"text\":\"朴素贝叶斯算法及其代码实现\",\"link\":\"22-ml-ch03-bayes\"}]}]},\"/posts/olds/algo/\":{\"base\":\"/posts/olds/algo/\",\"items\":[{\"text\":\"ALGO\",\"items\":[{\"text\":\"剑指offer4(51-64)\",\"link\":\"aim2offer4\"},{\"text\":\"剑指offer3(21-40)\",\"link\":\"aim2offer3\"},{\"text\":\"数据结构之搜索算法\",\"link\":\"algorithm-dfs\"},{\"text\":\"leetcode-01\",\"link\":\"leetcode-01\"},{\"text\":\"剑指offer(11-20)\",\"link\":\"aim2offer2\"},{\"text\":\"排序算法总结\",\"link\":\"sort-algorithms\"},{\"text\":\"剑指Offer(1-10)\",\"link\":\"aim2offer\"}]}]},\"/posts/olds/bigdata/\":{\"base\":\"/posts/olds/bigdata/\",\"items\":[{\"text\":\"BIG Data\",\"items\":[{\"text\":\"NumPy\",\"link\":\"20-numpy\"},{\"text\":\"Spark基础编程核心思想介绍\",\"link\":\"19-spark-programming\"},{\"text\":\"Spark-SQL的简略笔记\",\"link\":\"18-spark-sql\"},{\"text\":\"Spark键值对RDD的常用API\",\"link\":\"17-spark-pairrdd\"},{\"text\":\"Spark基础RDD的常用API\",\"link\":\"16-Spark-BaseRDD\"}]}]},\"/posts/olds/env/\":{\"base\":\"/posts/olds/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"IDE配置\",\"link\":\"12-ide-envs\"},{\"text\":\"Linux使用笔记\",\"link\":\"09-linux-notes\"},{\"text\":\"博客搭建及相关问题\",\"link\":\"24-hexo-problems\"},{\"text\":\"旧版博客搭建过程及其问题\",\"link\":\"13-old-blog-problems\"}]}]},\"/posts/olds/other/\":{\"base\":\"/posts/olds/other/\",\"items\":[{\"text\":\"其他\",\"items\":[{\"text\":\"C++类对象和指针的区别\",\"link\":\"15-cpp-pointer-object-reference\"}]}]},\"/posts/llm/agent/rl/\":{\"base\":\"/posts/llm/agent/rl/\",\"items\":[{\"text\":\"Agent-RL\",\"items\":[{\"text\":\"Agent-Interaction-RL 笔记\",\"link\":\"04-agent-env\"},{\"text\":\"Agent-Search-RL 笔记\",\"link\":\"03-agent-search\"},{\"text\":\"Agent-Tool-RL 笔记\",\"link\":\"02-agent-tool\"},{\"text\":\"Agent-RL 综述型笔记\",\"link\":\"01-agent-rl\"}]}]},\"/posts/llm/agent/basic/\":{\"base\":\"/posts/llm/agent/basic/\",\"items\":[{\"text\":\"Agent-基础\",\"items\":[{\"text\":\"DeepResearch 评估\",\"link\":\"06-deepresearch-evaluation\"},{\"text\":\"Computer-Agent\",\"link\":\"05-comuter-agent\"},{\"text\":\"Agent 思考性文章\",\"link\":\"04-agent-blogs\"},{\"text\":\"一些流行的Agents\",\"link\":\"03-current-agents\"},{\"text\":\"Agent 评估 Benchmarks\",\"link\":\"02-evaluation-agent\"},{\"text\":\"Agent基础概念 (李宏毅笔记)\",\"link\":\"01-lhy-agent-notes\"}]}]},\"/posts/llm/rl/theory/\":{\"base\":\"/posts/llm/rl/theory/\",\"items\":[{\"text\":\"RL-Theory\",\"items\":[{\"text\":\"强化学习算法小结\",\"link\":\"04-reinforce-conclusion-simple\"},{\"text\":\"基于策略函数的学习方法\",\"link\":\"03-strategy-learning\"},{\"text\":\"基于值函数的学习\",\"link\":\"02-value-learning\"},{\"text\":\"强化学习基础\",\"link\":\"01-reinforce-learning\"}]}]},\"/posts/llm/rl/rlhf/\":{\"base\":\"/posts/llm/rl/rlhf/\",\"items\":[{\"text\":\"RLHF\",\"items\":[]}]},\"/posts/llm/rl/o1llm/\":{\"base\":\"/posts/llm/rl/o1llm/\",\"items\":[{\"text\":\"推理模型\",\"items\":[]}]},\"/posts/llm/industry/mainllm/\":{\"base\":\"/posts/llm/industry/mainllm/\",\"items\":[{\"text\":\"🚀主流模型\",\"items\":[{\"text\":\"DeepSeek 系列\",\"link\":\"02-deepseek-series\"},{\"text\":\"Kimi 系列\",\"link\":\"01-kimi-series\"}]}]},\"/posts/llm/basic/\":{\"base\":\"/posts/llm/basic/\",\"items\":[{\"text\":\"LLM-basic\",\"items\":[{\"text\":\"LLM 基础知识\",\"link\":\"05-llm-basic-info\"},{\"text\":\"大语言模型架构\",\"link\":\"04-llm-architecture\"},{\"text\":\"Transformer细节\",\"link\":\"03-transformer-detail\"},{\"text\":\"语言模型重要组件\",\"link\":\"02-llm-components\"},{\"text\":\"语言模型定义及信息理论\",\"link\":\"01-lm-define-information-theory\"}]}]},\"/posts/llm/infra/\":{\"base\":\"/posts/llm/infra/\",\"items\":[{\"text\":\"🛠LLM-基建框架\",\"items\":[{\"text\":\"推理优化技术\",\"link\":\"03-inference-tech\"},{\"text\":\"分布式训练框架\",\"link\":\"02-speed-framework\"},{\"text\":\"分布式并行策略\",\"link\":\"01-parrallel\"}]}]},\"/posts/exps/env/\":{\"base\":\"/posts/exps/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"环境搭建的一些坑\",\"link\":\"01-blog-env\"}]}]},\"/posts/exps/mind/\":{\"base\":\"/posts/exps/mind/\",\"items\":[{\"text\":\"心得体会\",\"items\":[]}]}}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>
<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Agent 评估 Benchmarks | 📚 plmblog</title>
    <meta name="description" content="记录一些学习笔记。">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/assets/style.DcBljOKC.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.BwIPoEGV.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.CcrKC_eu.js">
    <link rel="modulepreload" href="/assets/chunks/framework.CvbyeFFO.js">
    <link rel="modulepreload" href="/assets/posts_llm_agent_basic_02-evaluation-agent.md.Dn02cVtP.lean.js">
    <link rel="icon" href="/plm.png">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-cecb633e><!--[--><!--]--><!--[--><span tabindex="-1" data-v-c979f278></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-c979f278>Skip to content</a><!--]--><!----><header class="VPNav" data-v-cecb633e data-v-0ad68676><div class="VPNavBar" data-v-0ad68676 data-v-ce71e4ef><div class="wrapper" data-v-ce71e4ef><div class="container" data-v-ce71e4ef><div class="title" data-v-ce71e4ef><div class="VPNavBarTitle has-sidebar" data-v-ce71e4ef data-v-7e906684><a class="title" href="/" data-v-7e906684><!--[--><!--]--><!----><span data-v-7e906684>📚 plmblog</span><!--[--><!--]--></a></div></div><div class="content" data-v-ce71e4ef><div class="content-body" data-v-ce71e4ef><!--[--><!--]--><div class="VPNavBarSearch search" data-v-ce71e4ef><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-ce71e4ef data-v-e0cd9371><span id="main-nav-aria-label" class="visually-hidden" data-v-e0cd9371> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>首页</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>🐲LLM</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Basic</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/basic/01-lm-define-information-theory.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🦋基础知识</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/infra/01-parrallel.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🛠基建框架</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>强化学习</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/rl/theory/01-reinforce-learning.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🎓RL理论基础</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/rl/rlhf.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚘RLHF</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/rl/o1llm.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚢推理模型</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/rl/02-agent-tool.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚄Agent-RL</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Agent</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/basic.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🤖概念及应用</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>行业方向</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/industry/mainllm/01-kimi-series.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚀主流模型</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>📙旧文章</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍓NLP</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/nlp.html" data-v-dc987abe><!--[--><span data-v-dc987abe>自然语言处理</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍑基础知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/dl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>深度学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/rl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>强化学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/ml.html" data-v-dc987abe><!--[--><span data-v-dc987abe>机器学习</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍎算法</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/algo/" data-v-dc987abe><!--[--><span data-v-dc987abe>算法题</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/bigdata/" data-v-dc987abe><!--[--><span data-v-dc987abe>大数据</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍒其他</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/env/" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/other/" data-v-dc987abe><!--[--><span data-v-dc987abe>其他</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>经验</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>环境</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/env/01-blog-env.html" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>心得</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/mind.html" data-v-dc987abe><!--[--><span data-v-dc987abe>心得体会</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/archive.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>归档</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/me.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>关于我</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-ce71e4ef data-v-b59ebfac><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-b59ebfac data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-ce71e4ef data-v-e0f2db57 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-ce71e4ef data-v-8897e953 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-ffaaba87><span class="vpi-more-horizontal icon" data-v-ffaaba87></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><!----><!--[--><!--[--><!----><div class="group" data-v-8897e953><div class="item appearance" data-v-8897e953><p class="label" data-v-8897e953>Appearance</p><div class="appearance-action" data-v-8897e953><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-8897e953 data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div></div></div><div class="group" data-v-8897e953><div class="item social-links" data-v-8897e953><div class="VPSocialLinks social-links-list" data-v-8897e953 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-ce71e4ef data-v-37e0f734><span class="container" data-v-37e0f734><span class="top" data-v-37e0f734></span><span class="middle" data-v-37e0f734></span><span class="bottom" data-v-37e0f734></span></span></button></div></div></div></div><div class="divider" data-v-ce71e4ef><div class="divider-line" data-v-ce71e4ef></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-cecb633e data-v-1b409c8b><div class="container" data-v-1b409c8b><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-1b409c8b><span class="vpi-align-left menu-icon" data-v-1b409c8b></span><span class="menu-text" data-v-1b409c8b>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-1b409c8b data-v-a203161a><button data-v-a203161a>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-cecb633e data-v-18f7b5ca><div class="curtain" data-v-18f7b5ca></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-18f7b5ca><span class="visually-hidden" id="sidebar-aria-label" data-v-18f7b5ca> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-7f5b9a39><section class="VPSidebarItem level-0 has-active" data-v-7f5b9a39 data-v-a4affe07><div class="item" role="button" tabindex="0" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><h2 class="text" data-v-a4affe07>Agent-基础</h2><!----></div><div class="items" data-v-a4affe07><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/agent/basic/06-deepresearch-evaluation.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>DeepResearch 评估</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/agent/basic/05-comuter-agent.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Computer-Agent</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/agent/basic/04-agent-blogs.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Agent 思考性文章</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/agent/basic/03-current-agents.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>一些流行的Agents</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/agent/basic/02-evaluation-agent.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Agent 评估 Benchmarks</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/agent/basic/01-lhy-agent-notes.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Agent基础概念 (李宏毅笔记)</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-cecb633e data-v-53a9cb18><div class="VPDoc has-sidebar has-aside" data-v-53a9cb18 data-v-5a64a79a><!--[--><!--]--><div class="container" data-v-5a64a79a><div class="aside" data-v-5a64a79a><div class="aside-curtain" data-v-5a64a79a></div><div class="aside-container" data-v-5a64a79a><div class="aside-content" data-v-5a64a79a><div class="VPDocAside" data-v-5a64a79a data-v-f8ea3c28><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-f8ea3c28 data-v-b94d89ac><div class="content" data-v-b94d89ac><div class="outline-marker" data-v-b94d89ac></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-b94d89ac>当前页大纲</div><ul class="VPDocOutlineItem root" data-v-b94d89ac data-v-80b46526><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-f8ea3c28></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-5a64a79a><div class="content-container" data-v-5a64a79a><!--[--><!--[--><!--[--><article class="post-header" data-v-a99fd7c9><h1 class="title" data-v-a99fd7c9>Agent 评估 Benchmarks</h1><div class="stats-container" data-v-a99fd7c9><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 📅 发表于 <span class="stat-text" data-v-a99fd7c9>2025/05/14</span></div><div class="stat-item" data-v-a99fd7c9> 🔄 更新于 <span class="stat-text" data-v-a99fd7c9>2025/05/14</span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 👁️ <span class="stat-text" data-v-a99fd7c9>-- 次访问</span><span id="busuanzi_value_page_pv" style="display:none;" data-page="/posts/llm/agent/basic/02-evaluation-agent.html" data-v-a99fd7c9></span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 📝 <span class="stat-text" data-v-a99fd7c9>0 字</span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> ⏳ <span class="stat-text" data-v-a99fd7c9>0 分钟</span></div><div class="stat-divider" data-v-a99fd7c9></div></div><div class="tag-group" data-v-a99fd7c9><!--[--><div class="category-item" data-v-a99fd7c9>agent</div><!--]--><!--[--><div class="tag-item" data-v-a99fd7c9> #agent evalution</div><!--]--></div></article><!--]--><!--]--><!--]--><main class="main" data-v-5a64a79a><div style="position:relative;" class="vp-doc _posts_llm_agent_basic_02-evaluation-agent" data-v-5a64a79a><div><div class="custom-block tip"><div class="custom-block-title">本文概览</div><p>Agent Evaluation 相关内容</p></div><h2 id="一图概览-来自论文" tabindex="-1">一图概览(来自论文) <a class="header-anchor" href="#一图概览-来自论文" aria-label="Permalink to &quot;一图概览(来自论文)&quot;">​</a></h2><img src="https://paper-assets.alphaxiv.org/figures/2503.16416/img-0.jpeg" style="display:block;margin:auto;" width="70%"><h2 id="智能体能力评估" tabindex="-1">智能体能力评估 <a class="header-anchor" href="#智能体能力评估" aria-label="Permalink to &quot;智能体能力评估&quot;">​</a></h2><h3 id="plan-multi-step-reasoning" tabindex="-1">Plan &amp; Multi-step Reasoning <a class="header-anchor" href="#plan-multi-step-reasoning" aria-label="Permalink to &quot;Plan &amp; Multi-step Reasoning&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">Plan and Multi-step Reasoning / Multi-step Planning</div><p>这是LLM-Agent的基本能力，要求他们能<code>把复杂任务分解成更小更容易管理的子任务</code>，并<code>执行一系列action</code>来完成任务。</p></div><p>以下是一些基准，这些基准都突出了Agent Plan所需要的关键能力：</p><ul><li>任务分解能力(<code>task decomposition</code>)：分解复杂问题</li><li>状态跟踪和信念维护能力(<code>state tracking and belief maintenance</code>)：用于准确的多步推理</li><li>自我修正能力(<code>self-correction</code>)：用于检测错误和还原回溯</li><li>因果理解(<code>casual understanding</code>)：预测action结果</li><li>元规划(<code>meta-planing</code>)：改进规划策略</li></ul><table tabindex="0"><thead><tr><th>类型<img width="100/"></th><th>名称<img width="250/"></th><th>备注</th></tr></thead><tbody><tr><td>数学推理</td><td>(2021)GMS8k、(2021)MATH、(2017)QAUA-RAT</td><td></td></tr><tr><td>多跳问答</td><td>(2017)<code>HotpotQA</code>、(2021)StrategyQA、(2018)MultiRC</td><td></td></tr><tr><td>科学推理</td><td>(2018)ARC</td><td></td></tr><tr><td>逻辑推理</td><td>(2024)FOLIO、(2022)P-FOLIO</td><td></td></tr><tr><td>常识推理</td><td>(2023)MUSR</td><td></td></tr><tr><td>挑战型推理</td><td>(2022)BBH</td><td></td></tr><tr><td>综合型推理</td><td>(2023)PlanBench</td><td>评估不同领域LLM的规划能力，表明短期规划ok，长期规划不ok</td></tr><tr><td>日常场景推理</td><td>(2023)AutoPlanBench</td><td>评估日常场景中的规划能力</td></tr><tr><td>工作流</td><td>(2024)FlowBench</td><td>评估工作流程规划能力，重点关注知识密集型任务</td></tr><tr><td>核心推理</td><td>(2024)ACPBench</td><td>评估LLM核心推理技能</td></tr><tr><td>现实世界</td><td>(2024)<mark>Natural Plan Benchmark</mark></td><td>评估现实世界的规划任务</td></tr><tr><td>工具规划推理</td><td>(2023)ToolEmu</td><td></td></tr></tbody></table><h3 id="function-calling-tool-use" tabindex="-1">Function Calling &amp; Tool Use <a class="header-anchor" href="#function-calling-tool-use" aria-label="Permalink to &quot;Function Calling &amp; Tool Use&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">函数调用</div><p>调用外部工具，是构建实时且准确回复Agent的重要能力。函数调用设计多个子任务协作，包括以下几个流程</p><ul><li>意图识别：根据query识别何时需要某个函数，确定使用哪个工具</li><li>参数提取：从对话中提取函数参数</li><li>函数调用：调用外部函数获取结果</li><li>LLM回复： 把结果整合到输入中，给到LLM做回复</li></ul></div><p>整体有如下Bench：</p><ul><li>早期：侧重简单、提供明确参数的但不交互 <ul><li>(2023)ToolAlpaca、(2025)APIBench、(2023)ToolBench</li><li>(2024)<code>BFCL</code> v1(实时性)、v2(组织工具)、<code>v3</code>(多轮、多步)，(<mark>Berkeley Function Calling Leaderboard</mark> )</li></ul></li><li>演变：拓展评估领域 <ul><li>(2024) ToolSandbox：结合状态、隐式依赖关系等。</li><li>(2024) Seal-Tools：采用self-instruct来生成嵌套的工具调用。</li><li>(2023) API-Bank：对话、真实API评估。</li><li>(2024) API-Blend：真实场景。</li><li>(2023) RestBench、(2024) APIGen、(2024) StableToolBench。</li></ul></li><li>多步骤交互： <ul><li>(2025) ComplexFUncBench：需要隐式参数推断、用户约束、长上下文处理的场景。</li></ul></li></ul><h3 id="self-reflection-反思" tabindex="-1">Self-Reflection 反思 <a class="header-anchor" href="#self-reflection-反思" aria-label="Permalink to &quot;Self-Reflection 反思&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">self-refelection</div><p>agent能够自我反思、通过交互式反馈来提升推理能力，从而减少错误。</p></div><ul><li>早期：间接评估，将已有的推理/规划任务重新用于多轮反馈，查看模型能否根据外部反馈纠正自身错误 <ul><li>(2023) AGIEval、(2022)MedMCQA、(2021) ALFWorld</li></ul></li><li>中期：交互式自我反思 基准 <ul><li>(2023) LLF-Bench：扩展各种决策任务</li><li>(2024) LLM-Evolve：</li><li>(2024) LiveCodeBench：交互式设置</li></ul></li><li>认知科学角度： <ul><li>(2024) Reflection-Bench：评估LLM的认知反思能力。将其分解为： <ul><li>新信息感知：new information perception</li><li>记忆使用：memory usage</li><li>信念更新：belief updating following surprise</li><li>决策调整：decesion-making adjustments</li><li>反事实推理：counterfactual reasoning</li><li>Meta-reflection：</li></ul></li></ul></li></ul><h3 id="memory" tabindex="-1">Memory <a class="header-anchor" href="#memory" aria-label="Permalink to &quot;Memory&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">Memory</div><p>记忆力机制可以在交互机制中保持一定的上下文。</p><ul><li><mark>短期记忆</mark> ：助于<mark>实时响应</mark></li><li><mark>长期记忆</mark> ：助于更<mark>深入的理解</mark>和<mark>长期应用知识</mark></li></ul></div><ul><li><p>长上下文评估：通过memory来增强长上下文或检索相关的推理。</p><ul><li>工作：(2024)ReadAgent、(2024)MemGPT、(2025)A-Mem</li><li>Bench：(2021)Quality、(2018) NarrativeQA、(2021) QMSum、(2024) LoCoMo、(2024) NaturalQuestions-Open</li></ul></li><li><p>情景记忆评估</p><ul><li>(2025) Episode Memories：评估LLM如何生成和管理memories</li></ul></li><li><p>外部记忆结合评估</p><ul><li>(2024) <code>StreamBench</code>：评估利用外部memory(反馈)来持续提高效果，在HotpotQA/ToolBench/Spider等多数据集上测。</li></ul></li><li><p>实时决策和学习评估：<code>优化action</code></p><ul><li>(2024)<code>LTMBench</code>：通过扩展的多任务交互、频繁上下文切换，来评估对话agent的长期记忆和信息整合能力。</li></ul></li></ul><h2 id="特定智能体评估" tabindex="-1">特定智能体评估 <a class="header-anchor" href="#特定智能体评估" aria-label="Permalink to &quot;特定智能体评估&quot;">​</a></h2><h3 id="web-agents" tabindex="-1">Web Agents <a class="header-anchor" href="#web-agents" aria-label="Permalink to &quot;Web Agents&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">Web Agents</div><p>通过网络交互来完成任务的AI 系统，例如订机票、购物等。</p></div><ul><li>早期：静态。 <ul><li>(2022) WebShop、(2023) Mind2Web、(2024) WebVoyoger</li></ul></li><li>近期：动态、更真实的场景 <ul><li>适应网页动态变化：(2024) WebLInx</li><li>解释包含视觉信息：(2023) WebArea、(2024)Visual-WebArea</li><li>办公室复杂任务：(2024) WorkArea、(2025) WorkArea++</li><li>多模态/多站点：(2024) MMInA、(2024) AssistantBench、(2024) WebCanvas</li><li>动静态结合：(2024) ST-WebAgentBench</li></ul></li></ul><h3 id="software-engineering-agents" tabindex="-1">Software Engineering Agents <a class="header-anchor" href="#software-engineering-agents" aria-label="Permalink to &quot;Software Engineering Agents&quot;">​</a></h3><ul><li>最主要 <ul><li>SWEBench系列：(2023) SWEBench、(2024) SWEBench-Lite、(2024) SWEBench Multimodal</li><li>AgentBench：评估SWE Agent的交互能力</li><li>(2025) SWELancer：代表最新趋势，把性能和货币价值结合起来，凸显诸多挑战。</li></ul></li></ul><h3 id="scientfic-agents" tabindex="-1">Scientfic Agents <a class="header-anchor" href="#scientfic-agents" aria-label="Permalink to &quot;Scientfic Agents&quot;">​</a></h3><ul><li>早期：强调科学知识回忆和推理 <ul><li>(2017) ACR Clark、(2022) Science QA、(2022) Science World等等。</li></ul></li><li>近期：强调加速科学研究，单一任务为主 <ul><li><code>科学构思</code>：<mark>产生新颖、专家级的想法</mark>。</li><li><code>实验设计</code>：</li><li><code>实验代码生成</code>： (2024) SciCode、(2025) ScienceAgentBench、(2024) <code>CORE-Bench</code>等。</li><li><code>同行评审生成</code>：</li></ul></li><li>近期/未来：由单一向统一集成转变 <ul><li>(2025) <code>AAAR-1.0</code>：同时评估方程推理、实验设计、论文缺陷识别和评审4项任务。</li><li>(2025) <code>MLGym</code>：健身房环境，13个挑战</li><li>(2024)<mark>DiscoverWorld</mark>：模拟120个不同任务完整科学发现周期</li><li>(2024) LabBench：生物学研究领域评估</li></ul></li></ul><h3 id="对话-agents" tabindex="-1">对话 Agents <a class="header-anchor" href="#对话-agents" aria-label="Permalink to &quot;对话 Agents&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">提示</div><p>Conversational agents 处理用户请求，完成多轮对话，涉及调用工具等。</p></div><p>主要有：</p><ul><li>(2021) Action-Based Conversations Datasets(ABCD)：10k对话，55种意图</li><li>(2024) ALMITA Bench：客服领域，14个意图，192个对话，1420个测试</li><li>(2024) <mark>τ -Bench</mark>：航空和零售领域</li><li>(2025) <mark>IntellAgent</mark>：一个自动评估对话agent的框架，以数据库/公司政策为输入，基于事件和用户测试</li></ul><h3 id="data-agents" tabindex="-1">Data Agents <a class="header-anchor" href="#data-agents" aria-label="Permalink to &quot;Data Agents&quot;">​</a></h3><p>(2502)DABStep</p><div class="custom-block tip"><div class="custom-block-title">DABStep</div><ul><li>(2025)<a href="https://huggingface.co/blog/dabstep" target="_blank" rel="noreferrer">DABStep</a>，Data Agent Benchmark for Multi-Step Reasoning</li><li><a href="https://huggingface.co/spaces/adyen/DABstep/tree/main/baseline" target="_blank" rel="noreferrer">Baseline</a>、<a href="https://huggingface.co/spaces/adyen/DABstep" target="_blank" rel="noreferrer">DABStep Leaderboard</a>、<a href="https://colab.research.google.com/drive/1pXi5ffBFNJQ5nn1111SnIfjfKCOlunxu" target="_blank" rel="noreferrer">QuickStart</a></li></ul><p>DABStep是一个多步推理的数据Benchmark，包括450个数据分析任务。它要求模型</p><ul><li>深入数据细节、保持严谨无幻觉</li><li>对结构化和非结构化数据进行推理。</li><li>连接到真实实际应用场景中。是分析师日常面料的真实挑战0</li></ul></div><p><strong>数据示例</strong></p><p>数据由多种金融文件组成。</p><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/02-evaluation-agent/20250519102532.jpg" style="display:block;margin:auto;" width="80%"><p>问题示例：</p><p>包括：<mark>问题、难度、Guidelines</mark>(说明如何去解析答案结构来评估正确性)</p><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/llm/agent/02-evaluation-agent/20250519102645.jpg" style="display:block;margin:auto;" width="80%"><p>对于难度1，很多acc达到90%，但<mark>对于难度2，o3 mini、DSR1也只有10+的准确率。</mark></p><h2 id="通用智能体评估" tabindex="-1">通用智能体评估 <a class="header-anchor" href="#通用智能体评估" aria-label="Permalink to &quot;通用智能体评估&quot;">​</a></h2><div class="custom-block tip"><div class="custom-block-title">Generalist Agent</div><p>由单一能力向综合转变，整合LLM、网络导航、信息检索、代码执行等能力，处理复杂任务。</p></div><p>主要有：</p><ul><li>一般能力评估：<mark>多步推理、交互式解决问题、工具使用等</mark>。 <ul><li>(2023) <mark>GAIA</mark>：466个真实问题，测试推理、多模理解、网页导航、工具使用等。</li><li>(2025) Galileo’s Agent Leaderboard：强调实际应用中函数调用的能力。</li><li>(2023) AgentBench：交互式环境，操作系统、SQL、数字游戏、家务任务等。</li></ul></li><li>超越一般评估：<mark>强调在完整计算机系统中的表现</mark><ul><li>(2024) OSWorld、(2024) OminiAct、(2024) AppWorld。需编写调试代码， 保证系统稳定运行</li></ul></li><li>数字工作环境评估：像人类工作一样评估 <ul><li>(2024) <mark>TheAgentCompany</mark>：浏览内部网站、编写代码、与同事沟通。</li><li>(2025) CRMArena：客户关系管理</li></ul></li><li>标准化评估平台 <ul><li>(2025) Holistic Agent Leaderboard：一个标准化汇评估平台，汇总多个bench</li></ul></li></ul><h2 id="agent评估框架" tabindex="-1">Agent评估框架 <a class="header-anchor" href="#agent评估框架" aria-label="Permalink to &quot;Agent评估框架&quot;">​</a></h2><table tabindex="0"><thead><tr><th>时期</th><th>特点</th></tr></thead><tbody><tr><td>早期</td><td>单轮交互、<mark>评估任务完成度</mark></td></tr><tr><td>最近</td><td><mark>多步推理、轨迹分析、特定agent评估</mark>(如tool use)等。</td></tr></tbody></table><h3 id="主要框架" tabindex="-1">主要框架 <a class="header-anchor" href="#主要框架" aria-label="Permalink to &quot;主要框架&quot;">​</a></h3><p>主要包括：</p><table tabindex="0"><thead><tr><th>名称</th><th>内容</th></tr></thead><tbody><tr><td>(2023) LangSmith</td><td>Langchain的</td></tr><tr><td>(2023) LangFuse</td><td></td></tr><tr><td>(2025) LangChain AgentsEvals</td><td>Langchain的</td></tr><tr><td>(2025) Google Vertex AI Evaluation</td><td></td></tr><tr><td>(2025) Arize AI&#39;s Evaluation Framework</td><td></td></tr><tr><td>(2025) Galileo Agentic Evaluation</td><td></td></tr><tr><td>(2023) Databricsks Mosaic AI Agent Evaluation</td><td>主要forRAG任务</td></tr><tr><td>(2025) Botpress Multi-Agent Evaluation System</td><td>Mulit-Agent</td></tr><tr><td>(2024) AutoGen</td><td>Multi-Agent</td></tr></tbody></table><h3 id="评估维度" tabindex="-1">评估维度 <a class="header-anchor" href="#评估维度" aria-label="Permalink to &quot;评估维度&quot;">​</a></h3><table tabindex="0"><thead><tr><th><strong>名称</strong></th><th><strong>内容</strong></th></tr></thead><tbody><tr><td><mark>Final Response 评估</mark></td><td>事先定义好<code>评估标准</code>，再使用<code>LLM-based judeges</code>来评估。</td></tr><tr><td><mark>Stepwise 评估</mark></td><td><code>细粒度评估每个action</code>，分析错误原因。比如<code>工具选择</code>、执行等。<br>如Galieo Agentic Evaluation提供 <code>action advancement metric</code>，来评估action是否有贡献等。<br>但问题是，缺乏泛化通用judge，很多都是task-specific的。</td></tr><tr><td>Traj-Based 评估</td><td>评估决策过程相对预期最佳路径所采取的步骤顺序。</td></tr></tbody></table><h2 id="benchmarks" tabindex="-1">Benchmarks <a class="header-anchor" href="#benchmarks" aria-label="Permalink to &quot;Benchmarks&quot;">​</a></h2><ul><li><a href="https://huggingface.co/spaces/smolagents/smolagents-leaderboard" target="_blank" rel="noreferrer">Smolagents Ledearboard</a></li><li><a href="https://huggingface.co/blog/dabstep" target="_blank" rel="noreferrer">DABStep Data Agent Benchmark for Multi-step Reasoning</a></li></ul></div></div></main><footer class="VPDocFooter" data-v-5a64a79a data-v-54a90a4a><!--[--><!--]--><div class="edit-info" data-v-54a90a4a><!----><div class="last-updated" data-v-54a90a4a><p class="VPLastUpdated" data-v-54a90a4a data-v-08208c09>Last updated: <time datetime="2025-07-22T16:01:17.000Z" data-v-08208c09></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-54a90a4a><span class="visually-hidden" id="doc-footer-aria-label" data-v-54a90a4a>Pager</span><div class="pager" data-v-54a90a4a><a class="VPLink link pager-link prev" href="/posts/llm/agent/basic/03-current-agents.html" data-v-54a90a4a><!--[--><span class="desc" data-v-54a90a4a>上一页</span><span class="title" data-v-54a90a4a>一些流行的Agents</span><!--]--></a></div><div class="pager" data-v-54a90a4a><a class="VPLink link pager-link next" href="/posts/llm/agent/basic/01-lhy-agent-notes.html" data-v-54a90a4a><!--[--><span class="desc" data-v-54a90a4a>下一页</span><span class="title" data-v-54a90a4a>Agent基础概念 (李宏毅笔记)</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--[--><div class="busuanzi"> 总访客数： <span id="busuanzi_value_site_uv"></span>   ·   总访问量： <span id="busuanzi_value_site_pv"></span></div><div class="busuanzi"> PLM&#39;s Blog @ 2016 - 2025</div><!--]--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api-examples.md\":\"Drgk6GHl\",\"index.md\":\"BheGDo0s\",\"markdown-examples.md\":\"CEw-8KIO\",\"posts_archive.md\":\"pZWQT7dp\",\"posts_exps_env_01-blog-env.md\":\"DsD2OukA\",\"posts_exps_env_index.md\":\"BJEZeoT-\",\"posts_exps_mind_index.md\":\"naOB3-Mb\",\"posts_llm_agent_basic_01-lhy-agent-notes.md\":\"BK_CsHNC\",\"posts_llm_agent_basic_02-evaluation-agent.md\":\"Dn02cVtP\",\"posts_llm_agent_basic_03-current-agents.md\":\"C25gmbg8\",\"posts_llm_agent_basic_04-agent-blogs.md\":\"_QbL2Plv\",\"posts_llm_agent_basic_05-comuter-agent.md\":\"D0gJpId6\",\"posts_llm_agent_basic_06-deepresearch-evaluation.md\":\"DdRDcxUJ\",\"posts_llm_agent_basic_index.md\":\"ClGtwUqg\",\"posts_llm_agent_rl_01-agent-rl.md\":\"wOF9bz66\",\"posts_llm_agent_rl_02-agent-tool.md\":\"IB_AqkSe\",\"posts_llm_agent_rl_03-agent-search.md\":\"CoYozBSV\",\"posts_llm_agent_rl_04-agent-env.md\":\"C_O9BVi3\",\"posts_llm_agent_rl_index.md\":\"BudtoDK9\",\"posts_llm_basic_01-lm-define-information-theory.md\":\"D_NiDMJf\",\"posts_llm_basic_02-llm-components.md\":\"CK5rj3vH\",\"posts_llm_basic_03-transformer-detail.md\":\"BgLyAVDZ\",\"posts_llm_basic_04-llm-architecture.md\":\"CJ4m4grf\",\"posts_llm_basic_05-llm-basic-info.md\":\"bdnM02bn\",\"posts_llm_basic_index.md\":\"DjX2HRXy\",\"posts_llm_industry_mainllm_01-kimi-series.md\":\"BpSW4UZD\",\"posts_llm_industry_mainllm_02-deepseek-series.md\":\"BSYWoiac\",\"posts_llm_infra_01-parrallel.md\":\"4SPd423i\",\"posts_llm_infra_02-speed-framework.md\":\"DR7mq5S5\",\"posts_llm_infra_03-inference-tech.md\":\"BMBxLcEu\",\"posts_llm_infra_04-verl.md\":\"Bq6mdbhL\",\"posts_llm_rl_index.md\":\"iUgEsMU1\",\"posts_llm_rl_theory_01-reinforce-learning.md\":\"BeNW7nu0\",\"posts_llm_rl_theory_01-rl-introduction.md\":\"Cu_GDTkQ\",\"posts_llm_rl_theory_02-markove-process.md\":\"BzAP1hx-\",\"posts_llm_rl_theory_02-value-learning.md\":\"Dhs-VEnc\",\"posts_llm_rl_theory_03-model-based-prediction-control.md\":\"MAiIWHzx\",\"posts_llm_rl_theory_03-strategy-learning.md\":\"KKz0IU0B\",\"posts_llm_rl_theory_04-model-free-prediction-control.md\":\"Bruy0RJ_\",\"posts_llm_rl_theory_04-reinforce-conclusion-simple.md\":\"4ZBuW05y\",\"posts_llm_rl_theory_05-dqn.md\":\"DTAJYnu0\",\"posts_llm_rl_theory_06-policy-gradient.md\":\"B8hEHpfY\",\"posts_llm_rl_theory_07-actor-critic.md\":\"DTVRwCE3\",\"posts_llm_rl_theory_08-deterministic-policy-gradient.md\":\"BZdKzGR2\",\"posts_llm_rl_theory_09-policy-trpo-ppo.md\":\"bYFPVUzg\",\"posts_me.md\":\"B9W6CMag\",\"posts_olds_algo_aim2offer.md\":\"Dg9B7Z3I\",\"posts_olds_algo_aim2offer2.md\":\"CnDd98IS\",\"posts_olds_algo_aim2offer3.md\":\"YnkHg59Q\",\"posts_olds_algo_aim2offer4.md\":\"BXurWO8W\",\"posts_olds_algo_algorithm-dfs.md\":\"VxYdFkrt\",\"posts_olds_algo_index.md\":\"CmdF0Gg2\",\"posts_olds_algo_leetcode-01.md\":\"DaoLL5QB\",\"posts_olds_algo_sort-algorithms.md\":\"CGSaXABt\",\"posts_olds_bigdata_16-spark-baserdd.md\":\"nnsc9x1_\",\"posts_olds_bigdata_17-spark-pairrdd.md\":\"DTYLfi_i\",\"posts_olds_bigdata_18-spark-sql.md\":\"BZ3MwzEC\",\"posts_olds_bigdata_19-spark-programming.md\":\"DrAdYxjj\",\"posts_olds_bigdata_20-numpy.md\":\"CN3CN-Cf\",\"posts_olds_bigdata_index.md\":\"CWrZwWPb\",\"posts_olds_dl_23-pytorch-start.md\":\"BHevLby6\",\"posts_olds_dl_35-nerual-network-optim.md\":\"Cp2SpLoE\",\"posts_olds_dl_38-convolution.md\":\"CC_SQ57z\",\"posts_olds_dl_cs224n-assignment-1.md\":\"D0dK0rzN\",\"posts_olds_dl_cs224n-notes3-neural-networks-2.md\":\"TG3qYWqo\",\"posts_olds_dl_cs224n-notes3-neural-networks.md\":\"CDZWc4X6\",\"posts_olds_dl_cs231n-linear-notes.md\":\"DLRyzcwJ\",\"posts_olds_dl_index.md\":\"C1dyLGNS\",\"posts_olds_dl_rnn.md\":\"CwYYWZ7N\",\"posts_olds_env_09-linux-notes.md\":\"DERcUyYf\",\"posts_olds_env_12-ide-envs.md\":\"Bx6h4IWK\",\"posts_olds_env_13-old-blog-problems.md\":\"DsYjJL2J\",\"posts_olds_env_24-hexo-problems.md\":\"BWPoXjZh\",\"posts_olds_env_index.md\":\"DQpgTXVj\",\"posts_olds_ml_10-trees.md\":\"BkNaj6fL\",\"posts_olds_ml_14-em.md\":\"DIufCP0H\",\"posts_olds_ml_21-lr.md\":\"C-1ms511\",\"posts_olds_ml_22-ml-ch03-bayes.md\":\"Dqb846RT\",\"posts_olds_ml_27-svm-notes.md\":\"C96WS6CL\",\"posts_olds_ml_28-ml-interview-notes.md\":\"D-r631Oz\",\"posts_olds_ml_29-desicion-tree.md\":\"CtwmlbWl\",\"posts_olds_ml_crf.md\":\"CEE5oTqd\",\"posts_olds_ml_index.md\":\"BLMEziB1\",\"posts_olds_ml_maxentmodel.md\":\"CSbOumJx\",\"posts_olds_ml_pgm-01.md\":\"BTwybTMD\",\"posts_olds_nlp_11-nlp-labels.md\":\"Cl0Lb8OT\",\"posts_olds_nlp_25-google-nmt.md\":\"BOM-hoYN\",\"posts_olds_nlp_26-wordpieacemodel.md\":\"Q8-L5j15\",\"posts_olds_nlp_30-dynamic-memory-network.md\":\"AB-oqmxo\",\"posts_olds_nlp_31-co-attention-vqa.md\":\"lzwuVKG5\",\"posts_olds_nlp_32-dynamic-coattention-network.md\":\"Bxl4ABWd\",\"posts_olds_nlp_33-attention-summary.md\":\"DT6np0xG\",\"posts_olds_nlp_36-alime-chat.md\":\"Cu2xkcdT\",\"posts_olds_nlp_39-squard-models.md\":\"B1L3iDEv\",\"posts_olds_nlp_45-match-lstm.md\":\"DkpQKM5B\",\"posts_olds_nlp_46-rnet-selfmatch.md\":\"CzGHQ-PZ\",\"posts_olds_nlp_47-bidaf.md\":\"DFJaLh2v\",\"posts_olds_nlp_48-attention-is-all-you-need.md\":\"BY6XvFQ5\",\"posts_olds_nlp_49-qanet.md\":\"BPKWHzTf\",\"posts_olds_nlp_50-elmo.md\":\"WuOt1elN\",\"posts_olds_nlp_51-opengpt.md\":\"B9pQ3h5W\",\"posts_olds_nlp_52-bert.md\":\"5q3t5Qqh\",\"posts_olds_nlp_53-mrc-brief.md\":\"D9CkYrea\",\"posts_olds_nlp_54-mrc-models.md\":\"Ak4bDf1J\",\"posts_olds_nlp_attention-based-nmt.md\":\"DzovOxdG\",\"posts_olds_nlp_attention-model.md\":\"BVcXcWt7\",\"posts_olds_nlp_cs224n-lecture2-word2vec.md\":\"_MmBTADr\",\"posts_olds_nlp_cs224n-notes1-word2vec.md\":\"DXSi5KGh\",\"posts_olds_nlp_index.md\":\"Bfo4Lwn3\",\"posts_olds_nlp_nlp-notes.md\":\"D0Rkl4SF\",\"posts_olds_nlp_nmt.md\":\"DUgy6vHF\",\"posts_olds_nlp_subword-units.md\":\"BUzbRrkD\",\"posts_olds_nlp_word2vec-math.md\":\"agvHiE1x\",\"posts_olds_nlp_word2vec.md\":\"D0EJh12M\",\"posts_olds_other_15-cpp-pointer-object-reference.md\":\"uCLsDJe3\",\"posts_olds_other_index.md\":\"C1T-ubsz\",\"posts_olds_rl_37-reinforce-learning.md\":\"Cf2nny8k\",\"posts_olds_rl_40-value-learning.md\":\"DcnHvvpH\",\"posts_olds_rl_41-strategy-learning.md\":\"CStMrB-q\",\"posts_olds_rl_42-reinforce-conclusion-simple.md\":\"flRZUmJZ\",\"posts_olds_rl_43-intent-detection-slot-filling.md\":\"DcAUbaZU\",\"posts_olds_rl_44-reinforce-nlp.md\":\"Br2ShITL\",\"posts_olds_rl_index.md\":\"CUsxM3zO\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"📚 plmblog\",\"description\":\"记录一些学习笔记。\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"首页\",\"link\":\"/\"},{\"text\":\"🐲LLM\",\"items\":[{\"text\":\"Basic\",\"items\":[{\"text\":\"🦋基础知识\",\"link\":\"/posts/llm/basic/01-lm-define-information-theory\"},{\"text\":\"🛠基建框架\",\"link\":\"/posts/llm/infra/01-parrallel\"}]},{\"text\":\"强化学习\",\"items\":[{\"text\":\"🎓RL理论基础\",\"link\":\"/posts/llm/rl/theory/01-reinforce-learning\"},{\"text\":\"🚘RLHF\",\"link\":\"/posts/llm/rl/rlhf\"},{\"text\":\"🚢推理模型\",\"link\":\"/posts/llm/rl/o1llm\"},{\"text\":\"🚄Agent-RL\",\"link\":\"/posts/llm/agent/rl/02-agent-tool\"}]},{\"text\":\"Agent\",\"items\":[{\"text\":\"🤖概念及应用\",\"link\":\"/posts/llm/agent/basic\"}]},{\"text\":\"行业方向\",\"items\":[{\"text\":\"🚀主流模型\",\"link\":\"/posts/llm/industry/mainllm/01-kimi-series\"}]}]},{\"text\":\"📙旧文章\",\"items\":[{\"text\":\"🍓NLP\",\"items\":[{\"text\":\"自然语言处理\",\"link\":\"/posts/olds/nlp\"}]},{\"text\":\"🍑基础知识\",\"items\":[{\"text\":\"深度学习\",\"link\":\"/posts/olds/dl\"},{\"text\":\"强化学习\",\"link\":\"/posts/olds/rl\"},{\"text\":\"机器学习\",\"link\":\"/posts/olds/ml\"}]},{\"text\":\"🍎算法\",\"items\":[{\"text\":\"算法题\",\"link\":\"/posts/olds/algo/\"},{\"text\":\"大数据\",\"link\":\"/posts/olds/bigdata/\"}]},{\"text\":\"🍒其他\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/olds/env/\"},{\"text\":\"其他\",\"link\":\"/posts/olds/other/\"}]}]},{\"text\":\"经验\",\"items\":[{\"text\":\"环境\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/exps/env/01-blog-env\"}]},{\"text\":\"心得\",\"items\":[{\"text\":\"心得体会\",\"link\":\"/posts/exps/mind\"}]}]},{\"text\":\"归档\",\"link\":\"/posts/archive.md\"},{\"text\":\"关于我\",\"link\":\"/posts/me\"}],\"outline\":{\"level\":[1,4],\"label\":\"当前页大纲\"},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/plmsmile\"}],\"search\":{\"provider\":\"local\"},\"docFooter\":{\"prev\":\"上一页\",\"next\":\"下一页\"},\"sidebar\":{\"/posts/olds/nlp/\":{\"base\":\"/posts/olds/nlp/\",\"items\":[{\"text\":\"NLP\",\"items\":[{\"text\":\"机器阅读(二)--模型(未完成)\",\"link\":\"54-mrc-models\"},{\"text\":\"机器阅读(一)--整体概述\",\"link\":\"53-mrc-brief\"},{\"text\":\"BERT 详解\",\"link\":\"52-bert\"},{\"text\":\"OpenAI GPT：Improving Language Understanding by Generative Pre-Training\",\"link\":\"51-opengpt\"},{\"text\":\"ELMo：Deep Contextualized Word Representations\",\"link\":\"50-elmo\"},{\"text\":\"QANet\",\"link\":\"49-qanet\"},{\"text\":\"Transformer\",\"link\":\"48-attention-is-all-you-need\"},{\"text\":\"Bidirectional Attention Flow\",\"link\":\"47-bidaf\"},{\"text\":\"R-Net (Gated Self-Matching Networks)\",\"link\":\"46-rnet-selfmatch\"},{\"text\":\"Match-LSTM and Answer Pointer\",\"link\":\"45-match-lstm\"},{\"text\":\"阅读理解模型总结\",\"link\":\"39-squard-models\"},{\"text\":\"阿里小蜜论文\",\"link\":\"36-alime-chat\"},{\"text\":\"各种注意力总结\",\"link\":\"33-attention-summary\"},{\"text\":\"Dynamic Coattention Network (Plus)\",\"link\":\"32-dynamic-coattention-network\"},{\"text\":\"协同注意力简介\",\"link\":\"31-co-attention-vqa\"},{\"text\":\"使用Dynamic Memory Network实现一个简单QA\",\"link\":\"30-dynamic-memory-network\"},{\"text\":\"词性标注和句法依存的表示符号\",\"link\":\"11-nlp-labels\"},{\"text\":\"Word2vec之总体介绍\",\"link\":\"cs224n-notes1-word2vec\"},{\"text\":\"Word2vec之数学模型\",\"link\":\"word2vec-math\"},{\"text\":\"Word2vec之公式推导笔记\",\"link\":\"cs224n-lecture2-word2vec\"},{\"text\":\"subword-units\",\"link\":\"subword-units\"},{\"text\":\"Wordpiece模型\",\"link\":\"26-wordpieacemodel\"},{\"text\":\"谷歌RNN翻译模型\",\"link\":\"25-google-nmt\"},{\"text\":\"机器翻译注意力机制及其PyTorch实现\",\"link\":\"Attention-based-NMT\"},{\"text\":\"图文介绍RNN注意力机制\",\"link\":\"attention-model\"},{\"text\":\"最初RNN神经翻译简略笔记\",\"link\":\"NMT\"},{\"text\":\"语言模型和平滑方法\",\"link\":\"nlp-notes\"},{\"text\":\"利用tensorflow实现简版word2vec\",\"link\":\"word2vec\"}]}]},\"/posts/olds/dl/\":{\"base\":\"/posts/olds/dl/\",\"items\":[{\"text\":\"DL\",\"items\":[{\"text\":\"卷积神经网络总结\",\"link\":\"38-convolution\"},{\"text\":\"网络优化\",\"link\":\"35-nerual-network-optim\"},{\"text\":\"cs224n作业一\",\"link\":\"cs224n-assignment-1\"},{\"text\":\"cs231n线性分类器和损失函数\",\"link\":\"cs231n-linear-notes\"},{\"text\":\"神经网络-过拟合-预处理-BN\",\"link\":\"cs224n-notes3-neural-networks-2\"},{\"text\":\"神经网络基础-反向传播-激活函数\",\"link\":\"cs224n-notes3-neural-networks\"},{\"text\":\"循环神经网络\",\"link\":\"rnn\"},{\"text\":\"PyTorch快速上手\",\"link\":\"23-pytorch-start\"}]}]},\"/posts/olds/rl/\":{\"base\":\"/posts/olds/rl/\",\"items\":[{\"text\":\"RL\",\"items\":[{\"text\":\"强化学习在NLP中的应用\",\"link\":\"44-reinforce-nlp\"},{\"text\":\"意图识别和槽填充\",\"link\":\"43-intent-detection-slot-filling\"},{\"text\":\"强化学习算法小结\",\"link\":\"42-reinforce-conclusion-simple\"},{\"text\":\"基于策略函数的学习方法\",\"link\":\"41-strategy-learning\"},{\"text\":\"基于值函数的学习\",\"link\":\"40-value-learning\"},{\"text\":\"强化学习\",\"link\":\"37-reinforce-learning\"}]}]},\"/posts/olds/ml/\":{\"base\":\"/posts/olds/ml/\",\"items\":[{\"text\":\"ML\",\"items\":[{\"text\":\"决策树笔记\",\"link\":\"29-desicion-tree\"},{\"text\":\"机器学习知识点汇总整理\",\"link\":\"28-ml-interview-notes\"},{\"text\":\"SVM笔记\",\"link\":\"27-svm-notes\"},{\"text\":\"树的总结\",\"link\":\"10-trees\"},{\"text\":\"条件随机场\",\"link\":\"crf\"},{\"text\":\"最大熵模型\",\"link\":\"maxentmodel\"},{\"text\":\"线性回归和逻辑回归\",\"link\":\"21-lr\"},{\"text\":\"最大期望算法\",\"link\":\"14-em\"},{\"text\":\"马尔可夫模型\",\"link\":\"pgm-01\"},{\"text\":\"朴素贝叶斯算法及其代码实现\",\"link\":\"22-ml-ch03-bayes\"}]}]},\"/posts/olds/algo/\":{\"base\":\"/posts/olds/algo/\",\"items\":[{\"text\":\"ALGO\",\"items\":[{\"text\":\"剑指offer4(51-64)\",\"link\":\"aim2offer4\"},{\"text\":\"剑指offer3(21-40)\",\"link\":\"aim2offer3\"},{\"text\":\"数据结构之搜索算法\",\"link\":\"algorithm-dfs\"},{\"text\":\"leetcode-01\",\"link\":\"leetcode-01\"},{\"text\":\"剑指offer(11-20)\",\"link\":\"aim2offer2\"},{\"text\":\"排序算法总结\",\"link\":\"sort-algorithms\"},{\"text\":\"剑指Offer(1-10)\",\"link\":\"aim2offer\"}]}]},\"/posts/olds/bigdata/\":{\"base\":\"/posts/olds/bigdata/\",\"items\":[{\"text\":\"BIG Data\",\"items\":[{\"text\":\"NumPy\",\"link\":\"20-numpy\"},{\"text\":\"Spark基础编程核心思想介绍\",\"link\":\"19-spark-programming\"},{\"text\":\"Spark-SQL的简略笔记\",\"link\":\"18-spark-sql\"},{\"text\":\"Spark键值对RDD的常用API\",\"link\":\"17-spark-pairrdd\"},{\"text\":\"Spark基础RDD的常用API\",\"link\":\"16-Spark-BaseRDD\"}]}]},\"/posts/olds/env/\":{\"base\":\"/posts/olds/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"IDE配置\",\"link\":\"12-ide-envs\"},{\"text\":\"Linux使用笔记\",\"link\":\"09-linux-notes\"},{\"text\":\"博客搭建及相关问题\",\"link\":\"24-hexo-problems\"},{\"text\":\"旧版博客搭建过程及其问题\",\"link\":\"13-old-blog-problems\"}]}]},\"/posts/olds/other/\":{\"base\":\"/posts/olds/other/\",\"items\":[{\"text\":\"其他\",\"items\":[{\"text\":\"C++类对象和指针的区别\",\"link\":\"15-cpp-pointer-object-reference\"}]}]},\"/posts/llm/agent/rl/\":{\"base\":\"/posts/llm/agent/rl/\",\"items\":[{\"text\":\"Agent-RL\",\"items\":[{\"text\":\"Agent-Interaction-RL 笔记\",\"link\":\"04-agent-env\"},{\"text\":\"Agent-Search-RL 笔记\",\"link\":\"03-agent-search\"},{\"text\":\"Agent-Tool-RL 笔记\",\"link\":\"02-agent-tool\"},{\"text\":\"Agent-RL 综述型笔记\",\"link\":\"01-agent-rl\"}]}]},\"/posts/llm/agent/basic/\":{\"base\":\"/posts/llm/agent/basic/\",\"items\":[{\"text\":\"Agent-基础\",\"items\":[{\"text\":\"DeepResearch 评估\",\"link\":\"06-deepresearch-evaluation\"},{\"text\":\"Computer-Agent\",\"link\":\"05-comuter-agent\"},{\"text\":\"Agent 思考性文章\",\"link\":\"04-agent-blogs\"},{\"text\":\"一些流行的Agents\",\"link\":\"03-current-agents\"},{\"text\":\"Agent 评估 Benchmarks\",\"link\":\"02-evaluation-agent\"},{\"text\":\"Agent基础概念 (李宏毅笔记)\",\"link\":\"01-lhy-agent-notes\"}]}]},\"/posts/llm/rl/theory/\":{\"base\":\"/posts/llm/rl/theory/\",\"items\":[{\"text\":\"RL-Theory\",\"items\":[{\"text\":\"策略改进方法：TRPO+PPO\",\"link\":\"09-policy-trpo-ppo\"},{\"text\":\"确定性策略梯度\",\"link\":\"08-deterministic-policy-gradient\"},{\"text\":\"Actor-Critic 算法\",\"link\":\"07-actor-critic\"},{\"text\":\"策略梯度算法\",\"link\":\"06-policy-gradient\"},{\"text\":\"DQN算法及进阶\",\"link\":\"05-dqn\"},{\"text\":\"免模型预测和控制\",\"link\":\"04-model-free-prediction-control\"},{\"text\":\"有模型预测和控制\",\"link\":\"03-model-based-prediction-control\"},{\"text\":\"马尔可夫决策过程\",\"link\":\"02-markove-process\"},{\"text\":\"强化学习基本概念\",\"link\":\"01-rl-introduction\"},{\"text\":\"(18年笔记)强化学习算法小结\",\"link\":\"04-reinforce-conclusion-simple\"},{\"text\":\"(18年笔记)基于策略函数的学习方法\",\"link\":\"03-strategy-learning\"},{\"text\":\"(18年笔记)基于值函数的学习\",\"link\":\"02-value-learning\"},{\"text\":\"(18年笔记)强化学习基础\",\"link\":\"01-reinforce-learning\"}]}]},\"/posts/llm/rl/rlhf/\":{\"base\":\"/posts/llm/rl/rlhf/\",\"items\":[{\"text\":\"RLHF\",\"items\":[]}]},\"/posts/llm/rl/o1llm/\":{\"base\":\"/posts/llm/rl/o1llm/\",\"items\":[{\"text\":\"推理模型\",\"items\":[]}]},\"/posts/llm/industry/mainllm/\":{\"base\":\"/posts/llm/industry/mainllm/\",\"items\":[{\"text\":\"🚀主流模型\",\"items\":[{\"text\":\"DeepSeek 系列\",\"link\":\"02-deepseek-series\"},{\"text\":\"Kimi 系列\",\"link\":\"01-kimi-series\"}]}]},\"/posts/llm/basic/\":{\"base\":\"/posts/llm/basic/\",\"items\":[{\"text\":\"LLM-basic\",\"items\":[{\"text\":\"LLM 基础知识\",\"link\":\"05-llm-basic-info\"},{\"text\":\"大语言模型架构\",\"link\":\"04-llm-architecture\"},{\"text\":\"Transformer细节\",\"link\":\"03-transformer-detail\"},{\"text\":\"语言模型重要组件\",\"link\":\"02-llm-components\"},{\"text\":\"语言模型定义及信息理论\",\"link\":\"01-lm-define-information-theory\"}]}]},\"/posts/llm/infra/\":{\"base\":\"/posts/llm/infra/\",\"items\":[{\"text\":\"🛠LLM-基建框架\",\"items\":[{\"text\":\"Verl\",\"link\":\"04-verl\"},{\"text\":\"推理优化技术\",\"link\":\"03-inference-tech\"},{\"text\":\"分布式训练框架\",\"link\":\"02-speed-framework\"},{\"text\":\"分布式并行策略\",\"link\":\"01-parrallel\"}]}]},\"/posts/exps/env/\":{\"base\":\"/posts/exps/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"环境搭建的一些坑\",\"link\":\"01-blog-env\"}]}]},\"/posts/exps/mind/\":{\"base\":\"/posts/exps/mind/\",\"items\":[{\"text\":\"心得体会\",\"items\":[]}]}}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>
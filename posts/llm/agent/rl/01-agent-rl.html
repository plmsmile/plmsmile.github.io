<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Agent-RL 综述型笔记 | 📚 plmblog</title>
    <meta name="description" content="记录一些学习笔记。">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/assets/style.GGHgvGoj.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.B_JmdCGY.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.hsQ8Wx2B.js">
    <link rel="modulepreload" href="/assets/chunks/framework.CJy6NSJ1.js">
    <link rel="modulepreload" href="/assets/posts_llm_agent_rl_01-agent-rl.md.jyOjNDzR.lean.js">
    <link rel="icon" href="/plm.png">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-cecb633e><!--[--><!--]--><!--[--><span tabindex="-1" data-v-c979f278></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-c979f278>Skip to content</a><!--]--><!----><header class="VPNav" data-v-cecb633e data-v-0ad68676><div class="VPNavBar" data-v-0ad68676 data-v-ce71e4ef><div class="wrapper" data-v-ce71e4ef><div class="container" data-v-ce71e4ef><div class="title" data-v-ce71e4ef><div class="VPNavBarTitle has-sidebar" data-v-ce71e4ef data-v-7e906684><a class="title" href="/" data-v-7e906684><!--[--><!--]--><!----><span data-v-7e906684>📚 plmblog</span><!--[--><!--]--></a></div></div><div class="content" data-v-ce71e4ef><div class="content-body" data-v-ce71e4ef><!--[--><!--]--><div class="VPNavBarSearch search" data-v-ce71e4ef><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-ce71e4ef data-v-e0cd9371><span id="main-nav-aria-label" class="visually-hidden" data-v-e0cd9371> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>首页</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>🐲LLM</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Basic</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/basic/01-lm-define-information-theory.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🦋基础知识</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/infra/01-parrallel.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🛠基建框架</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Agent</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/basic.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🤖概念及应用</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/rl/02-agent-tool.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚄Agent-RL</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>行业方向</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/industry/mainllm/01-kimi-series.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚀主流模型</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>rl</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/rl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🐼r1相关</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>📙旧文章</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍓NLP</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/nlp.html" data-v-dc987abe><!--[--><span data-v-dc987abe>自然语言处理</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍑基础知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/dl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>深度学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/rl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>强化学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/ml.html" data-v-dc987abe><!--[--><span data-v-dc987abe>机器学习</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍎算法</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/algo/" data-v-dc987abe><!--[--><span data-v-dc987abe>算法题</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/bigdata/" data-v-dc987abe><!--[--><span data-v-dc987abe>大数据</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍒其他</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/env/" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/other/" data-v-dc987abe><!--[--><span data-v-dc987abe>其他</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>经验</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>环境</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/env/01-blog-env.html" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>心得</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/mind.html" data-v-dc987abe><!--[--><span data-v-dc987abe>心得体会</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/archive.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>归档</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/me.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>关于我</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-ce71e4ef data-v-b59ebfac><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-b59ebfac data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-ce71e4ef data-v-e0f2db57 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-ce71e4ef data-v-8897e953 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-ffaaba87><span class="vpi-more-horizontal icon" data-v-ffaaba87></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><!----><!--[--><!--[--><!----><div class="group" data-v-8897e953><div class="item appearance" data-v-8897e953><p class="label" data-v-8897e953>Appearance</p><div class="appearance-action" data-v-8897e953><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-8897e953 data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div></div></div><div class="group" data-v-8897e953><div class="item social-links" data-v-8897e953><div class="VPSocialLinks social-links-list" data-v-8897e953 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-ce71e4ef data-v-37e0f734><span class="container" data-v-37e0f734><span class="top" data-v-37e0f734></span><span class="middle" data-v-37e0f734></span><span class="bottom" data-v-37e0f734></span></span></button></div></div></div></div><div class="divider" data-v-ce71e4ef><div class="divider-line" data-v-ce71e4ef></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-cecb633e data-v-1b409c8b><div class="container" data-v-1b409c8b><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-1b409c8b><span class="vpi-align-left menu-icon" data-v-1b409c8b></span><span class="menu-text" data-v-1b409c8b>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-1b409c8b data-v-a203161a><button data-v-a203161a>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-cecb633e data-v-18f7b5ca><div class="curtain" data-v-18f7b5ca></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-18f7b5ca><span class="visually-hidden" id="sidebar-aria-label" data-v-18f7b5ca> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-7f5b9a39><section class="VPSidebarItem level-0 has-active" data-v-7f5b9a39 data-v-a4affe07><div class="item" role="button" tabindex="0" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><h2 class="text" data-v-a4affe07>Agent-RL</h2><!----></div><div class="items" data-v-a4affe07><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/agent/rl/04-agent-env.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Agent-Interaction-RL 笔记</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/agent/rl/03-agent-search.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Agent-Search-RL 笔记</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/agent/rl/02-agent-tool.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Agent-Tool-RL 笔记</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/agent/rl/01-agent-rl.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Agent-RL 综述型笔记</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-cecb633e data-v-53a9cb18><div class="VPDoc has-sidebar has-aside" data-v-53a9cb18 data-v-5a64a79a><!--[--><!--]--><div class="container" data-v-5a64a79a><div class="aside" data-v-5a64a79a><div class="aside-curtain" data-v-5a64a79a></div><div class="aside-container" data-v-5a64a79a><div class="aside-content" data-v-5a64a79a><div class="VPDocAside" data-v-5a64a79a data-v-f8ea3c28><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-f8ea3c28 data-v-b94d89ac><div class="content" data-v-b94d89ac><div class="outline-marker" data-v-b94d89ac></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-b94d89ac>当前页大纲</div><ul class="VPDocOutlineItem root" data-v-b94d89ac data-v-80b46526><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-f8ea3c28></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-5a64a79a><div class="content-container" data-v-5a64a79a><!--[--><!--[--><!--[--><article class="post-header" data-v-7b55fc8b><h1 class="title" data-v-7b55fc8b>Agent-RL 综述型笔记</h1><div class="stats-container" data-v-7b55fc8b><div class="stat-divider" data-v-7b55fc8b></div><div class="stat-item" data-v-7b55fc8b> 📅 发表于 <span class="stat-text" data-v-7b55fc8b>2025/05/21</span></div><div class="stat-item" data-v-7b55fc8b> 🔄 更新于 <span class="stat-text" data-v-7b55fc8b>2025/05/21</span></div><div class="stat-divider" data-v-7b55fc8b></div><div class="stat-item" data-v-7b55fc8b> 👁️ <span class="stat-text" data-v-7b55fc8b><span id="busuanzi_value_page_pv" data-v-7b55fc8b>--</span> 次访问</span></div><div class="stat-divider" data-v-7b55fc8b></div><div class="stat-item" data-v-7b55fc8b> 📝 <span class="stat-text" data-v-7b55fc8b>0 字</span></div><div class="stat-divider" data-v-7b55fc8b></div><div class="stat-item" data-v-7b55fc8b> ⏳ <span class="stat-text" data-v-7b55fc8b>0 分钟</span></div><div class="stat-divider" data-v-7b55fc8b></div></div><div class="tag-group" data-v-7b55fc8b><!--[--><div class="category-item" data-v-7b55fc8b>agent-rl</div><!--]--><!--[--><div class="tag-item" data-v-7b55fc8b> #agent-rl</div><!--]--></div></article><!--]--><!--]--><!--]--><main class="main" data-v-5a64a79a><div style="position:relative;" class="vp-doc _posts_llm_agent_rl_01-agent-rl" data-v-5a64a79a><div><div class="custom-block important"><div class="custom-block-title">文章概要</div><ul><li>记录整理学习他人的<mark>Agent-RL综述/方向型</mark>的内容笔记。</li></ul></div><h2 id="前言-✨" tabindex="-1">前言 ✨ <a class="header-anchor" href="#前言-✨" aria-label="Permalink to &quot;前言 ✨&quot;">​</a></h2><p>在学习<code>Agent-RL</code>过程中，发现很多有意思的文章，本想放到一篇博客整理，但发现太多，于是对其进行拆开，整体目前分为4个部分：</p><ul><li>《Agent-Search-RL 笔记》：记录<mark>搜索浏览</mark>相关内容。</li><li>《Agent-Tool-RL 笔记》：记录<mark>工具调用</mark>相关内容，目前代码数学问题居多。</li><li>《Agent-Interaction-RL 笔记》：侧重于<mark>环境多轮交互</mark>，目前游戏居多。</li><li>《Agent-RL 综合性笔记》(本文)：不属于上述类型的内容，偏综述型的内容。</li></ul><h2 id="技术文章-📚" tabindex="-1">技术文章 📚 <a class="header-anchor" href="#技术文章-📚" aria-label="Permalink to &quot;技术文章 📚&quot;">​</a></h2><p>技术达人写的文章，笔记。</p><h3 id="_2505-是念-2025年大模型agent-rl训练多轮planning技术torl-toolrl-otc-skyrl-v0-gigpo-tool-n1-artist-zerotir-grpo" tabindex="-1">(2505) 是念：2025年大模型agent rl训练多轮planning技术TORL,ToolRL,OTC,SkyRL-v0, GiGPO,Tool-N1 ,ARTIST, ZeroTIR, GRPO <a class="header-anchor" href="#_2505-是念-2025年大模型agent-rl训练多轮planning技术torl-toolrl-otc-skyrl-v0-gigpo-tool-n1-artist-zerotir-grpo" aria-label="Permalink to &quot;(2505) 是念：2025年大模型agent rl训练多轮planning技术TORL,ToolRL,OTC,SkyRL-v0, GiGPO,Tool-N1 ,ARTIST, ZeroTIR, GRPO&quot;">​</a></h3><div class="custom-block important"><div class="custom-block-title">概要</div><ul><li><strong>AgentRL优点</strong>： 通过工具交互能获取外部知识。</li><li><strong>AgentRL缺点</strong>： 目前<mark>交互次数少</mark>、<mark>多工具混合研究少</mark>，解决复杂问题仍有挑战。</li><li>DeepSeek R1 带火了 RL技术。</li><li>列举了相关流行工作，见拆解文章。</li><li>原文链接：<a href="https://zhuanlan.zhihu.com/p/1902381952998281700" target="_blank" rel="noreferrer">是念:2025大模型agentrl...</a></li></ul></div><p><strong>Agent RL 优缺点分析</strong> 🧐</p><div class="custom-block tip"><div class="custom-block-title">Agent RL 优缺点 🛠️</div><p>🏴 <strong>背景</strong></p><ul><li><code>Agentic tool use learning</code> 也开始用上了 GRPO 等 RL 算法，让 LLM 学会使用 <code>code-intepreter</code>、<code>web-search</code> 等工具，增强模型数学及推理能力，包括单轮/多轮 tool-use。</li></ul><p>🌟 <strong>Agent RL 优点</strong></p><ul><li><mark>通过 tool 交互获取外部知识</mark>，进一步提升模型准确率。</li><li>PPO 系列是一个 <code>online-rl</code> 方法，<mark>需要的数据量小很多</mark>，而传统 DPO 需要大量数据进行训练。 <ul><li><mark>每次通过 sampling 生成样本，然后进行训练提升</mark>。</li></ul></li></ul><p>⚠️ <strong>Agent RL 缺点</strong></p><ul><li>真正复杂任务可能需要 30-100 个 step 才能完成，目前 RL 框架集中解决 10 个 step 左右就能完成的任务，<mark>距离真正解决复杂问题仍有一段距离</mark>。 <ul><li>受限于 LLM 处理长序列效果下降、计算效率低等原因。</li></ul></li><li>GRPO rule-based 方法虽已简化流程，<mark>仍需要标注数据、精心设计 reward、调参及数据，才能得到好效果</mark>。</li><li>RL 依赖环境训练，一般速度较慢（仿真环境），如何跟上 GPU 计算 RL 训练，仍是一个问题。</li><li>Agent-RL <mark>研究单一工具居多</mark>（code, web-search），而<mark>多工具混合、多轮调用研究较少</mark>。</li></ul></div><img src="https://pic3.zhimg.com/v2-abc23ce6d62f9fceba4931742e2240da_1440w.jpg" style="display:block;margin:auto;" width="80%"><p><strong>DeepSeek 技术分析</strong> 🔍</p><ul><li><code>MoE</code>：降低了训练成本、提高了推理效率</li><li><code>Multi-Head Latent Attention</code>：减少了注意力部分的KV缓存、Low Rank</li><li><code>Multi-Token Prediction</code>：提高模型性能(准确性)</li><li><code>DualPipe</code>：提高了大规模GPU集群的计算与通信比率和效率</li><li><code>FP8 Training</code>：采样低精度训练进一步降低训练成本</li><li><code>DeepSeek-R1</code>：采样GRPO和多阶段训练。</li></ul><div class="custom-block caution"><div class="custom-block-title">GRPO vs PPO ⚠️</div><p>DeepSeek R1 GRPO 带火了RL技术路线，其中GRPO和PPO相差较小。主要区别是advantage是sampling过程产生样本的reward 求均值求方差得到的。</p></div><img src="https://pica.zhimg.com/v2-e696727d297071de37dbe8e6fb13eaf4_1440w.jpg" style="display:block;margin:auto;" width="80%"><p>其他具体内容见拆分后的笔记。</p><h3 id="_2505-亚里随笔-toolrl探路者——万字长文总结llm-toolrl系列近期工作-✍️" tabindex="-1">(2505) 亚里随笔：ToolRL探路者——万字长文总结LLM ToolRL系列近期工作 ✍️ <a class="header-anchor" href="#_2505-亚里随笔-toolrl探路者——万字长文总结llm-toolrl系列近期工作-✍️" aria-label="Permalink to &quot;(2505) 亚里随笔：ToolRL探路者——万字长文总结LLM ToolRL系列近期工作 ✍️&quot;">​</a></h3><div class="custom-block important"><div class="custom-block-title">概要</div><ul><li>原文：<a href="https://zhuanlan.zhihu.com/p/1904999390919259656" target="_blank" rel="noreferrer">亚里随笔：TooRL...</a></li><li>有搜索，具体看拆解文章。</li></ul></div><div class="custom-block warning"><div class="custom-block-title">问题背景 🚧</div><ul><li>纯文本推理具有局限性：面对复杂计算等场景，有<strong>工具调用需求</strong>。</li><li>工具集成推理的<strong>现有问题</strong>：<mark>SFT/Prompt方法不具备泛化能力</mark>，难以发现最优策略，限制了模型探索。</li><li>RL的挑战 (<strong>偏搜索</strong>) <ul><li>如何<mark>将搜索引擎集成到RL并保持优化稳定</mark></li><li>LLM难以实现迭代推理和搜索引擎调用，无法<mark>根据问题复杂性动态调整检索策略</mark></li><li>有效的<mark>搜索/推理奖励设计困难</mark>，简单基于结果的奖励可能不足以引导LLM学习有意义的搜索行为</li></ul></li><li>工具使用<strong>效率问题</strong>：当前方法通常鼓励无节制工具使用，训练/推理存在问题。</li><li>现有<strong>训练数据和方法不足</strong>：为增强工具调用能力，现研究大都合成工具使用数据来简单微调，但缺乏推理步骤，训练难以对过程指导，容易导致伪推理</li></ul></div><img src="https://pic1.zhimg.com/70/v2-52ec96b8baaf23c8890c2c658779c867_1440w.avis?source=172ae18b&amp;biz_tag=Post" style="display:block;margin:auto;" width="80%"><p>其他具体内容见拆分后的笔记。</p></div></div></main><footer class="VPDocFooter" data-v-5a64a79a data-v-54a90a4a><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-54a90a4a><span class="visually-hidden" id="doc-footer-aria-label" data-v-54a90a4a>Pager</span><div class="pager" data-v-54a90a4a><a class="VPLink link pager-link prev" href="/posts/llm/agent/rl/02-agent-tool.html" data-v-54a90a4a><!--[--><span class="desc" data-v-54a90a4a>上一页</span><span class="title" data-v-54a90a4a>Agent-Tool-RL 笔记</span><!--]--></a></div><div class="pager" data-v-54a90a4a><!----></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--[--><div class="busuanzi"> 总访客数： <span id="busuanzi_value_site_uv"></span>   ·   总访问量： <span id="busuanzi_value_site_pv"></span></div><div class="busuanzi"> PLM&#39;s Blog @ 2016 - 2025</div><!--]--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api-examples.md\":\"Y9eynrdR\",\"index.md\":\"DVvGCOlY\",\"markdown-examples.md\":\"CkWUfLYE\",\"posts_archive.md\":\"8vYcf8wj\",\"posts_exps_env_01-blog-env.md\":\"DVI_e15O\",\"posts_exps_env_index.md\":\"DAyCQNlK\",\"posts_exps_mind_index.md\":\"C8diJi8A\",\"posts_llm_agent_basic_01-lhy-agent-notes.md\":\"f9RVoHs8\",\"posts_llm_agent_basic_02-evaluation-agent.md\":\"Br3xO7-g\",\"posts_llm_agent_basic_03-current-agents.md\":\"DNR-gWzY\",\"posts_llm_agent_basic_04-agent-blogs.md\":\"D_-ZRp-r\",\"posts_llm_agent_basic_05-comuter-agent.md\":\"B-iNFXMz\",\"posts_llm_agent_basic_06-deepresearch-evaluation.md\":\"CXGMzGBA\",\"posts_llm_agent_basic_index.md\":\"BFDMBTpF\",\"posts_llm_agent_rl_01-agent-rl.md\":\"jyOjNDzR\",\"posts_llm_agent_rl_02-agent-tool.md\":\"DaoGeo3v\",\"posts_llm_agent_rl_03-agent-search.md\":\"BiQTLCnC\",\"posts_llm_agent_rl_04-agent-env.md\":\"BXeXid9k\",\"posts_llm_agent_rl_index.md\":\"B8y8HKKS\",\"posts_llm_basic_01-lm-define-information-theory.md\":\"DCG7BTwu\",\"posts_llm_basic_02-llm-components.md\":\"BQobf_6q\",\"posts_llm_basic_03-transformer-detail.md\":\"BzIUBVNh\",\"posts_llm_basic_04-llm-architecture.md\":\"DPg1Hfz0\",\"posts_llm_basic_05-llm-basic-info.md\":\"CV9kFidy\",\"posts_llm_basic_index.md\":\"Mu70B5rY\",\"posts_llm_industry_mainllm_01-kimi-series.md\":\"BoVWiEmK\",\"posts_llm_industry_mainllm_02-deepseek-series.md\":\"Ci_tITmB\",\"posts_llm_infra_01-parrallel.md\":\"CEjmsmA6\",\"posts_llm_infra_02-speed-framework.md\":\"CDaRPQyN\",\"posts_llm_rl_index.md\":\"DLeCp16H\",\"posts_me.md\":\"iI6_ItsV\",\"posts_olds_algo_aim2offer.md\":\"qvviemol\",\"posts_olds_algo_aim2offer2.md\":\"CEAJxhWb\",\"posts_olds_algo_aim2offer3.md\":\"PZtgeJ9F\",\"posts_olds_algo_aim2offer4.md\":\"BnYAkmHt\",\"posts_olds_algo_algorithm-dfs.md\":\"CHPZRKsA\",\"posts_olds_algo_index.md\":\"BhbTDX55\",\"posts_olds_algo_leetcode-01.md\":\"Bg217zcj\",\"posts_olds_algo_sort-algorithms.md\":\"Cr5uahbz\",\"posts_olds_bigdata_16-spark-baserdd.md\":\"C1K3uUYA\",\"posts_olds_bigdata_17-spark-pairrdd.md\":\"Dr5nG99R\",\"posts_olds_bigdata_18-spark-sql.md\":\"-GLJplmi\",\"posts_olds_bigdata_19-spark-programming.md\":\"DCcBBWs-\",\"posts_olds_bigdata_20-numpy.md\":\"CRBlvUQ_\",\"posts_olds_bigdata_index.md\":\"CtavPZWa\",\"posts_olds_dl_23-pytorch-start.md\":\"DT2H6iVn\",\"posts_olds_dl_35-nerual-network-optim.md\":\"DrTCHHUE\",\"posts_olds_dl_38-convolution.md\":\"DfFiwTE7\",\"posts_olds_dl_cs224n-assignment-1.md\":\"Ddjtd5UG\",\"posts_olds_dl_cs224n-notes3-neural-networks-2.md\":\"1zcpx99O\",\"posts_olds_dl_cs224n-notes3-neural-networks.md\":\"DEyO4jGf\",\"posts_olds_dl_cs231n-linear-notes.md\":\"D1oRys3x\",\"posts_olds_dl_index.md\":\"CS6rHhIV\",\"posts_olds_dl_rnn.md\":\"LzReSQyh\",\"posts_olds_env_09-linux-notes.md\":\"DbkCXZ83\",\"posts_olds_env_12-ide-envs.md\":\"sX0Qg_h1\",\"posts_olds_env_13-old-blog-problems.md\":\"ClA1Iijp\",\"posts_olds_env_24-hexo-problems.md\":\"DFA9jrEE\",\"posts_olds_env_index.md\":\"DQaZkHqo\",\"posts_olds_ml_10-trees.md\":\"BYvJdbgN\",\"posts_olds_ml_14-em.md\":\"BJzWid8Q\",\"posts_olds_ml_21-lr.md\":\"ayDyHZ10\",\"posts_olds_ml_22-ml-ch03-bayes.md\":\"ayG6FnyX\",\"posts_olds_ml_27-svm-notes.md\":\"BTwtHsAd\",\"posts_olds_ml_28-ml-interview-notes.md\":\"Dyyv6C46\",\"posts_olds_ml_29-desicion-tree.md\":\"B6YMTRUn\",\"posts_olds_ml_crf.md\":\"nEUdU_CD\",\"posts_olds_ml_index.md\":\"tPD0NnOn\",\"posts_olds_ml_maxentmodel.md\":\"DyZoZ30W\",\"posts_olds_ml_pgm-01.md\":\"Bv-bQVCl\",\"posts_olds_nlp_11-nlp-labels.md\":\"CVS7vg71\",\"posts_olds_nlp_25-google-nmt.md\":\"CAxoaPzE\",\"posts_olds_nlp_26-wordpieacemodel.md\":\"DCO-85Bv\",\"posts_olds_nlp_30-dynamic-memory-network.md\":\"CsxZZTGD\",\"posts_olds_nlp_31-co-attention-vqa.md\":\"IPofOCAW\",\"posts_olds_nlp_32-dynamic-coattention-network.md\":\"CWbcBdfE\",\"posts_olds_nlp_33-attention-summary.md\":\"CVdO21fy\",\"posts_olds_nlp_36-alime-chat.md\":\"BSS9es6R\",\"posts_olds_nlp_39-squard-models.md\":\"yGiaNORJ\",\"posts_olds_nlp_45-match-lstm.md\":\"NjDMgW9n\",\"posts_olds_nlp_46-rnet-selfmatch.md\":\"CzgVGH67\",\"posts_olds_nlp_47-bidaf.md\":\"P2y3gNyV\",\"posts_olds_nlp_48-attention-is-all-you-need.md\":\"BzXMPF8E\",\"posts_olds_nlp_49-qanet.md\":\"DsM30dCk\",\"posts_olds_nlp_50-elmo.md\":\"CZtZH25R\",\"posts_olds_nlp_51-opengpt.md\":\"w62tuNik\",\"posts_olds_nlp_52-bert.md\":\"DpZJYNtu\",\"posts_olds_nlp_53-mrc-brief.md\":\"C5V5gwBS\",\"posts_olds_nlp_54-mrc-models.md\":\"DxmKV3KH\",\"posts_olds_nlp_attention-based-nmt.md\":\"Bn_bTi2k\",\"posts_olds_nlp_attention-model.md\":\"DW7ZJtBd\",\"posts_olds_nlp_cs224n-lecture2-word2vec.md\":\"D67GtNFT\",\"posts_olds_nlp_cs224n-notes1-word2vec.md\":\"CV3b2YYi\",\"posts_olds_nlp_index.md\":\"7e_c5Dgg\",\"posts_olds_nlp_nlp-notes.md\":\"DjIaRbBf\",\"posts_olds_nlp_nmt.md\":\"DrElp_ti\",\"posts_olds_nlp_subword-units.md\":\"DoDitJn6\",\"posts_olds_nlp_word2vec-math.md\":\"DvNmm_r6\",\"posts_olds_nlp_word2vec.md\":\"DOnjpiX9\",\"posts_olds_other_15-cpp-pointer-object-reference.md\":\"7ALrpXGq\",\"posts_olds_other_index.md\":\"wnulexTE\",\"posts_olds_rl_37-reinforce-learning.md\":\"Dj7FHsXy\",\"posts_olds_rl_40-value-learning.md\":\"D-ZRmFUX\",\"posts_olds_rl_41-strategy-learning.md\":\"XVe1WkNc\",\"posts_olds_rl_42-reinforce-conclusion-simple.md\":\"DH4WjF9f\",\"posts_olds_rl_43-intent-detection-slot-filling.md\":\"B9jTErSS\",\"posts_olds_rl_44-reinforce-nlp.md\":\"DzDKesvU\",\"posts_olds_rl_index.md\":\"zVkT01gw\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"📚 plmblog\",\"description\":\"记录一些学习笔记。\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"首页\",\"link\":\"/\"},{\"text\":\"🐲LLM\",\"items\":[{\"text\":\"Basic\",\"items\":[{\"text\":\"🦋基础知识\",\"link\":\"/posts/llm/basic/01-lm-define-information-theory\"},{\"text\":\"🛠基建框架\",\"link\":\"/posts/llm/infra/01-parrallel\"}]},{\"text\":\"Agent\",\"items\":[{\"text\":\"🤖概念及应用\",\"link\":\"/posts/llm/agent/basic\"},{\"text\":\"🚄Agent-RL\",\"link\":\"/posts/llm/agent/rl/02-agent-tool\"}]},{\"text\":\"行业方向\",\"items\":[{\"text\":\"🚀主流模型\",\"link\":\"/posts/llm/industry/mainllm/01-kimi-series\"}]},{\"text\":\"rl\",\"items\":[{\"text\":\"🐼r1相关\",\"link\":\"/posts/llm/rl\"}]}]},{\"text\":\"📙旧文章\",\"items\":[{\"text\":\"🍓NLP\",\"items\":[{\"text\":\"自然语言处理\",\"link\":\"/posts/olds/nlp\"}]},{\"text\":\"🍑基础知识\",\"items\":[{\"text\":\"深度学习\",\"link\":\"/posts/olds/dl\"},{\"text\":\"强化学习\",\"link\":\"/posts/olds/rl\"},{\"text\":\"机器学习\",\"link\":\"/posts/olds/ml\"}]},{\"text\":\"🍎算法\",\"items\":[{\"text\":\"算法题\",\"link\":\"/posts/olds/algo/\"},{\"text\":\"大数据\",\"link\":\"/posts/olds/bigdata/\"}]},{\"text\":\"🍒其他\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/olds/env/\"},{\"text\":\"其他\",\"link\":\"/posts/olds/other/\"}]}]},{\"text\":\"经验\",\"items\":[{\"text\":\"环境\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/exps/env/01-blog-env\"}]},{\"text\":\"心得\",\"items\":[{\"text\":\"心得体会\",\"link\":\"/posts/exps/mind\"}]}]},{\"text\":\"归档\",\"link\":\"/posts/archive.md\"},{\"text\":\"关于我\",\"link\":\"/posts/me\"}],\"outline\":{\"level\":[1,4],\"label\":\"当前页大纲\"},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/plmsmile\"}],\"search\":{\"provider\":\"local\"},\"docFooter\":{\"prev\":\"上一页\",\"next\":\"下一页\"},\"sidebar\":{\"/posts/olds/nlp/\":{\"base\":\"/posts/olds/nlp/\",\"items\":[{\"text\":\"NLP\",\"items\":[{\"text\":\"机器阅读(二)--模型(未完成)\",\"link\":\"54-mrc-models\"},{\"text\":\"机器阅读(一)--整体概述\",\"link\":\"53-mrc-brief\"},{\"text\":\"BERT 详解\",\"link\":\"52-bert\"},{\"text\":\"OpenAI GPT：Improving Language Understanding by Generative Pre-Training\",\"link\":\"51-opengpt\"},{\"text\":\"ELMo：Deep Contextualized Word Representations\",\"link\":\"50-elmo\"},{\"text\":\"QANet\",\"link\":\"49-qanet\"},{\"text\":\"Transformer\",\"link\":\"48-attention-is-all-you-need\"},{\"text\":\"Bidirectional Attention Flow\",\"link\":\"47-bidaf\"},{\"text\":\"R-Net (Gated Self-Matching Networks)\",\"link\":\"46-rnet-selfmatch\"},{\"text\":\"Match-LSTM and Answer Pointer\",\"link\":\"45-match-lstm\"},{\"text\":\"阅读理解模型总结\",\"link\":\"39-squard-models\"},{\"text\":\"阿里小蜜论文\",\"link\":\"36-alime-chat\"},{\"text\":\"各种注意力总结\",\"link\":\"33-attention-summary\"},{\"text\":\"Dynamic Coattention Network (Plus)\",\"link\":\"32-dynamic-coattention-network\"},{\"text\":\"协同注意力简介\",\"link\":\"31-co-attention-vqa\"},{\"text\":\"使用Dynamic Memory Network实现一个简单QA\",\"link\":\"30-dynamic-memory-network\"},{\"text\":\"词性标注和句法依存的表示符号\",\"link\":\"11-nlp-labels\"},{\"text\":\"Word2vec之总体介绍\",\"link\":\"cs224n-notes1-word2vec\"},{\"text\":\"Word2vec之数学模型\",\"link\":\"word2vec-math\"},{\"text\":\"Word2vec之公式推导笔记\",\"link\":\"cs224n-lecture2-word2vec\"},{\"text\":\"subword-units\",\"link\":\"subword-units\"},{\"text\":\"Wordpiece模型\",\"link\":\"26-wordpieacemodel\"},{\"text\":\"谷歌RNN翻译模型\",\"link\":\"25-google-nmt\"},{\"text\":\"机器翻译注意力机制及其PyTorch实现\",\"link\":\"Attention-based-NMT\"},{\"text\":\"图文介绍RNN注意力机制\",\"link\":\"attention-model\"},{\"text\":\"最初RNN神经翻译简略笔记\",\"link\":\"NMT\"},{\"text\":\"语言模型和平滑方法\",\"link\":\"nlp-notes\"},{\"text\":\"利用tensorflow实现简版word2vec\",\"link\":\"word2vec\"}]}]},\"/posts/olds/dl/\":{\"base\":\"/posts/olds/dl/\",\"items\":[{\"text\":\"DL\",\"items\":[{\"text\":\"卷积神经网络总结\",\"link\":\"38-convolution\"},{\"text\":\"网络优化\",\"link\":\"35-nerual-network-optim\"},{\"text\":\"cs224n作业一\",\"link\":\"cs224n-assignment-1\"},{\"text\":\"cs231n线性分类器和损失函数\",\"link\":\"cs231n-linear-notes\"},{\"text\":\"神经网络-过拟合-预处理-BN\",\"link\":\"cs224n-notes3-neural-networks-2\"},{\"text\":\"神经网络基础-反向传播-激活函数\",\"link\":\"cs224n-notes3-neural-networks\"},{\"text\":\"循环神经网络\",\"link\":\"rnn\"},{\"text\":\"PyTorch快速上手\",\"link\":\"23-pytorch-start\"}]}]},\"/posts/olds/rl/\":{\"base\":\"/posts/olds/rl/\",\"items\":[{\"text\":\"RL\",\"items\":[{\"text\":\"强化学习在NLP中的应用\",\"link\":\"44-reinforce-nlp\"},{\"text\":\"意图识别和槽填充\",\"link\":\"43-intent-detection-slot-filling\"},{\"text\":\"强化学习算法小结\",\"link\":\"42-reinforce-conclusion-simple\"},{\"text\":\"基于策略函数的学习方法\",\"link\":\"41-strategy-learning\"},{\"text\":\"基于值函数的学习\",\"link\":\"40-value-learning\"},{\"text\":\"强化学习\",\"link\":\"37-reinforce-learning\"}]}]},\"/posts/olds/ml/\":{\"base\":\"/posts/olds/ml/\",\"items\":[{\"text\":\"ML\",\"items\":[{\"text\":\"决策树笔记\",\"link\":\"29-desicion-tree\"},{\"text\":\"机器学习知识点汇总整理\",\"link\":\"28-ml-interview-notes\"},{\"text\":\"SVM笔记\",\"link\":\"27-svm-notes\"},{\"text\":\"树的总结\",\"link\":\"10-trees\"},{\"text\":\"条件随机场\",\"link\":\"crf\"},{\"text\":\"最大熵模型\",\"link\":\"maxentmodel\"},{\"text\":\"线性回归和逻辑回归\",\"link\":\"21-lr\"},{\"text\":\"最大期望算法\",\"link\":\"14-em\"},{\"text\":\"马尔可夫模型\",\"link\":\"pgm-01\"},{\"text\":\"朴素贝叶斯算法及其代码实现\",\"link\":\"22-ml-ch03-bayes\"}]}]},\"/posts/olds/algo/\":{\"base\":\"/posts/olds/algo/\",\"items\":[{\"text\":\"ALGO\",\"items\":[{\"text\":\"剑指offer4(51-64)\",\"link\":\"aim2offer4\"},{\"text\":\"剑指offer3(21-40)\",\"link\":\"aim2offer3\"},{\"text\":\"数据结构之搜索算法\",\"link\":\"algorithm-dfs\"},{\"text\":\"leetcode-01\",\"link\":\"leetcode-01\"},{\"text\":\"剑指offer(11-20)\",\"link\":\"aim2offer2\"},{\"text\":\"排序算法总结\",\"link\":\"sort-algorithms\"},{\"text\":\"剑指Offer(1-10)\",\"link\":\"aim2offer\"}]}]},\"/posts/olds/bigdata/\":{\"base\":\"/posts/olds/bigdata/\",\"items\":[{\"text\":\"BIG Data\",\"items\":[{\"text\":\"NumPy\",\"link\":\"20-numpy\"},{\"text\":\"Spark基础编程核心思想介绍\",\"link\":\"19-spark-programming\"},{\"text\":\"Spark-SQL的简略笔记\",\"link\":\"18-spark-sql\"},{\"text\":\"Spark键值对RDD的常用API\",\"link\":\"17-spark-pairrdd\"},{\"text\":\"Spark基础RDD的常用API\",\"link\":\"16-Spark-BaseRDD\"}]}]},\"/posts/olds/env/\":{\"base\":\"/posts/olds/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"IDE配置\",\"link\":\"12-ide-envs\"},{\"text\":\"Linux使用笔记\",\"link\":\"09-linux-notes\"},{\"text\":\"博客搭建及相关问题\",\"link\":\"24-hexo-problems\"},{\"text\":\"旧版博客搭建过程及其问题\",\"link\":\"13-old-blog-problems\"}]}]},\"/posts/olds/other/\":{\"base\":\"/posts/olds/other/\",\"items\":[{\"text\":\"其他\",\"items\":[{\"text\":\"C++类对象和指针的区别\",\"link\":\"15-cpp-pointer-object-reference\"}]}]},\"/posts/llm/agent/rl/\":{\"base\":\"/posts/llm/agent/rl/\",\"items\":[{\"text\":\"Agent-RL\",\"items\":[{\"text\":\"Agent-Interaction-RL 笔记\",\"link\":\"04-agent-env\"},{\"text\":\"Agent-Search-RL 笔记\",\"link\":\"03-agent-search\"},{\"text\":\"Agent-Tool-RL 笔记\",\"link\":\"02-agent-tool\"},{\"text\":\"Agent-RL 综述型笔记\",\"link\":\"01-agent-rl\"}]}]},\"/posts/llm/agent/basic/\":{\"base\":\"/posts/llm/agent/basic/\",\"items\":[{\"text\":\"Agent-基础\",\"items\":[{\"text\":\"DeepResearch 评估\",\"link\":\"06-deepresearch-evaluation\"},{\"text\":\"Computer-Agent\",\"link\":\"05-comuter-agent\"},{\"text\":\"Agent 思考性文章\",\"link\":\"04-agent-blogs\"},{\"text\":\"一些流行的Agents\",\"link\":\"03-current-agents\"},{\"text\":\"Agent 评估 Benchmarks\",\"link\":\"02-evaluation-agent\"},{\"text\":\"Agent基础概念 (李宏毅笔记)\",\"link\":\"01-lhy-agent-notes\"}]}]},\"/posts/llm/rl/\":{\"base\":\"/posts/llm/rl/\",\"items\":[{\"text\":\"LLM-RL\",\"items\":[]}]},\"/posts/llm/industry/mainllm/\":{\"base\":\"/posts/llm/industry/mainllm/\",\"items\":[{\"text\":\"🚀主流模型\",\"items\":[{\"text\":\"DeepSeek 系列\",\"link\":\"02-deepseek-series\"},{\"text\":\"Kimi 系列\",\"link\":\"01-kimi-series\"}]}]},\"/posts/llm/basic/\":{\"base\":\"/posts/llm/basic/\",\"items\":[{\"text\":\"LLM-basic\",\"items\":[{\"text\":\"LLM 基础知识\",\"link\":\"05-llm-basic-info\"},{\"text\":\"大语言模型架构\",\"link\":\"04-llm-architecture\"},{\"text\":\"Transformer细节\",\"link\":\"03-transformer-detail\"},{\"text\":\"语言模型重要组件\",\"link\":\"02-llm-components\"},{\"text\":\"语言模型定义及信息理论\",\"link\":\"01-lm-define-information-theory\"}]}]},\"/posts/llm/infra/\":{\"base\":\"/posts/llm/infra/\",\"items\":[{\"text\":\"🛠LLM-基建框架\",\"items\":[{\"text\":\"分布式训练框架\",\"link\":\"02-speed-framework\"},{\"text\":\"分布式并行策略\",\"link\":\"01-parrallel\"}]}]},\"/posts/exps/env/\":{\"base\":\"/posts/exps/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"环境搭建的一些坑\",\"link\":\"01-blog-env\"}]}]},\"/posts/exps/mind/\":{\"base\":\"/posts/exps/mind/\",\"items\":[{\"text\":\"心得体会\",\"items\":[]}]}}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>
<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>LLM 基础知识 | 📚 plmblog</title>
    <meta name="description" content="记录一些学习笔记。">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/assets/style.bRo886SX.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.CA7QrZtr.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.C4Nv35MZ.js">
    <link rel="modulepreload" href="/assets/chunks/framework.CvbyeFFO.js">
    <link rel="modulepreload" href="/assets/posts_llm_basic_05-llm-basic-info.md.DQpSFOl_.lean.js">
    <link rel="icon" href="/plm.png">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-cecb633e><!--[--><!--]--><!--[--><span tabindex="-1" data-v-c979f278></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-c979f278>Skip to content</a><!--]--><!----><header class="VPNav" data-v-cecb633e data-v-0ad68676><div class="VPNavBar" data-v-0ad68676 data-v-ce71e4ef><div class="wrapper" data-v-ce71e4ef><div class="container" data-v-ce71e4ef><div class="title" data-v-ce71e4ef><div class="VPNavBarTitle has-sidebar" data-v-ce71e4ef data-v-7e906684><a class="title" href="/" data-v-7e906684><!--[--><!--]--><!----><span data-v-7e906684>📚 plmblog</span><!--[--><!--]--></a></div></div><div class="content" data-v-ce71e4ef><div class="content-body" data-v-ce71e4ef><!--[--><!--]--><div class="VPNavBarSearch search" data-v-ce71e4ef><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-ce71e4ef data-v-e0cd9371><span id="main-nav-aria-label" class="visually-hidden" data-v-e0cd9371> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>首页</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>🐲LLM</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Basic</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/basic/01-lm-define-information-theory.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🦋基础</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Agent</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/basic.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🤖概念及应用</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/rl/02-agent-tool.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚄Agent-RL</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>rl</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/rl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🐼r1相关</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>📙旧文章</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍓NLP</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/nlp.html" data-v-dc987abe><!--[--><span data-v-dc987abe>自然语言处理</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍑基础知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/dl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>深度学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/rl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>强化学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/ml.html" data-v-dc987abe><!--[--><span data-v-dc987abe>机器学习</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍎算法</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/algo/" data-v-dc987abe><!--[--><span data-v-dc987abe>算法题</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/bigdata/" data-v-dc987abe><!--[--><span data-v-dc987abe>大数据</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍒其他</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/env/" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/other/" data-v-dc987abe><!--[--><span data-v-dc987abe>其他</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>经验</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>环境</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/env/01-blog-env.html" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>心得</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/mind.html" data-v-dc987abe><!--[--><span data-v-dc987abe>心得体会</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/archive.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>归档</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/me.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>关于我</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-ce71e4ef data-v-b59ebfac><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-b59ebfac data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-ce71e4ef data-v-e0f2db57 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-ce71e4ef data-v-8897e953 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-ffaaba87><span class="vpi-more-horizontal icon" data-v-ffaaba87></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><!----><!--[--><!--[--><!----><div class="group" data-v-8897e953><div class="item appearance" data-v-8897e953><p class="label" data-v-8897e953>Appearance</p><div class="appearance-action" data-v-8897e953><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-8897e953 data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div></div></div><div class="group" data-v-8897e953><div class="item social-links" data-v-8897e953><div class="VPSocialLinks social-links-list" data-v-8897e953 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-ce71e4ef data-v-37e0f734><span class="container" data-v-37e0f734><span class="top" data-v-37e0f734></span><span class="middle" data-v-37e0f734></span><span class="bottom" data-v-37e0f734></span></span></button></div></div></div></div><div class="divider" data-v-ce71e4ef><div class="divider-line" data-v-ce71e4ef></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-cecb633e data-v-1b409c8b><div class="container" data-v-1b409c8b><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-1b409c8b><span class="vpi-align-left menu-icon" data-v-1b409c8b></span><span class="menu-text" data-v-1b409c8b>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-1b409c8b data-v-a203161a><button data-v-a203161a>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-cecb633e data-v-18f7b5ca><div class="curtain" data-v-18f7b5ca></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-18f7b5ca><span class="visually-hidden" id="sidebar-aria-label" data-v-18f7b5ca> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-7f5b9a39><section class="VPSidebarItem level-0 has-active" data-v-7f5b9a39 data-v-a4affe07><div class="item" role="button" tabindex="0" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><h2 class="text" data-v-a4affe07>LLM-basic</h2><!----></div><div class="items" data-v-a4affe07><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/basic/05-llm-basic-info.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>LLM 基础知识</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/basic/04-llm-architecture.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>大语言模型架构</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/basic/03-transformer-detail.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Transformer细节</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/basic/02-llm-components.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>语言模型重要组件</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/basic/01-lm-define-information-theory.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>语言模型定义及信息理论</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-cecb633e data-v-53a9cb18><div class="VPDoc has-sidebar has-aside" data-v-53a9cb18 data-v-5a64a79a><!--[--><!--]--><div class="container" data-v-5a64a79a><div class="aside" data-v-5a64a79a><div class="aside-curtain" data-v-5a64a79a></div><div class="aside-container" data-v-5a64a79a><div class="aside-content" data-v-5a64a79a><div class="VPDocAside" data-v-5a64a79a data-v-f8ea3c28><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-f8ea3c28 data-v-b94d89ac><div class="content" data-v-b94d89ac><div class="outline-marker" data-v-b94d89ac></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-b94d89ac>当前页大纲</div><ul class="VPDocOutlineItem root" data-v-b94d89ac data-v-80b46526><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-f8ea3c28></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-5a64a79a><div class="content-container" data-v-5a64a79a><!--[--><!--[--><!--[--><article class="post-header" data-v-d3ef8077><h1 class="title" data-v-d3ef8077>LLM 基础知识</h1><div class="stats-container" data-v-d3ef8077><div class="stat-divider" data-v-d3ef8077></div><div class="stat-item" data-v-d3ef8077> 📅 发表于 <span class="stat-text" data-v-d3ef8077>2025/07/09</span></div><div class="stat-item" data-v-d3ef8077> 🔄 更新于 <span class="stat-text" data-v-d3ef8077>2025/07/09</span></div><div class="stat-divider" data-v-d3ef8077></div><div class="stat-item" data-v-d3ef8077> 👁️ <span id="busuanzi_value_page_pv" style="display:none;" data-v-d3ef8077></span><span class="stat-text" data-v-d3ef8077> 次访问</span></div><div class="stat-divider" data-v-d3ef8077></div><div class="stat-item" data-v-d3ef8077> 📝 <span class="stat-text" data-v-d3ef8077>0 字</span></div><div class="stat-divider" data-v-d3ef8077></div><div class="stat-item" data-v-d3ef8077> ⏳ <span class="stat-text" data-v-d3ef8077>0 分钟</span></div><div class="stat-divider" data-v-d3ef8077></div></div><!----></article><!--]--><!--]--><!--]--><main class="main" data-v-5a64a79a><div style="position:relative;" class="vp-doc _posts_llm_basic_05-llm-basic-info" data-v-5a64a79a><div><h2 id="llm-基础知识" tabindex="-1">LLM 基础知识 <a class="header-anchor" href="#llm-基础知识" aria-label="Permalink to &quot;LLM 基础知识&quot;">​</a></h2><h3 id="训练目标" tabindex="-1">训练目标 <a class="header-anchor" href="#训练目标" aria-label="Permalink to &quot;训练目标&quot;">​</a></h3><div class="custom-block important"><div class="custom-block-title">训练目标</div><p>LLM训练目标通常是<code>最大似然估计(Max Likelihood Estimation, MLE)</code>。</p><ul><li>数据：大规模语料</li><li><strong>训练目标</strong>💗 <ul><li><strong>最大化模型生成文本序列的概率</strong>，序列来自训练数据中观察到的。</li><li>模型根据上下文生成下一个词的条件概率分布，通过<strong>最大化词序列的概率来优化模型</strong>。</li><li>通过<a href="https://plmsmile.github.io/posts/olds/dl/35-nerual-network-optim.html#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E7%9A%84%E6%94%B9%E8%BF%9B" target="_blank" rel="noreferrer">梯度下降法</a>来更新参数，使用<code>Batch Training</code>进行小批量样本参数更新。</li></ul></li></ul></div><h3 id="涌现现象" tabindex="-1">涌现现象 <a class="header-anchor" href="#涌现现象" aria-label="Permalink to &quot;涌现现象&quot;">​</a></h3><p><a href="https://zhuanlan.zhihu.com/p/621438653" target="_blank" rel="noreferrer">大模型涌现能力：现象和解释</a></p><div class="custom-block important"><div class="custom-block-title">涌现能力及其原因</div><p>🚀<strong>涌现能力</strong></p><ul><li>在训练过程中能够生成出<strong>令人惊喜</strong>、<strong>创造性</strong>和<strong>新颖的内容或行为</strong>。</li></ul><p>🤔<strong>产生原因</strong></p><ul><li><strong>任务评价指标不够平滑</strong>：某指标太严格才算对，导致结果断层。 <ul><li>比如评价需一字不错才算正确，其余都算错误。可能中间结果已经在逐步变好了，但这个指标看不出来。</li></ul></li><li><strong>复杂任务</strong> <strong>vs</strong> <strong>子任务</strong>：出现涌现现象的大都是由多个子任务组成的复杂任务，但对子任务而言，其实符合<code>scaling law</code>现象，多个子任务组合一起，表现出了复杂任务的顿悟现象。</li><li><strong>用</strong> <strong>Grokking</strong> （顿悟）<strong>来解释涌现</strong>：任务T，随着模型及训练数据的增加，其相关数据达到最小阈值，这个任务就产生顿悟现象。</li></ul></div><img src="https://picx.zhimg.com/v2-546efd6eda3d839dd0f8f4c71dc1c415_r.jpg" style="display:block;margin:auto;" width="80%"><h3 id="复读机问题" tabindex="-1">复读机问题 <a class="header-anchor" href="#复读机问题" aria-label="Permalink to &quot;复读机问题&quot;">​</a></h3><p><strong>LLMs复读机问题</strong>（<code>LLMs Parroting Problem</code>）：模型可能会简单地复制输入文本的一部分或全部内容，并将其作为生成的输出，而<strong>不提供有意义或新颖的回应，缺乏创造性和独特性</strong>。</p><div class="custom-block tip"><div class="custom-block-title">复读机问题原因</div><ul><li><strong>训练数据偏差</strong>：预训练数据中出现<strong>大量重复文本</strong>、某些句子<strong>短语出现频率较高</strong>。模型在生成时<strong>倾向于复制这些模式</strong>。</li><li><strong>缺乏多样性训练数据</strong>：如果<strong>数据缺乏多样性</strong>语言表达或语境，模型可能<strong>无法学习到足够的多样性和创造性</strong>，导致复读机。</li><li><strong>训练目标限制</strong>：自监督学习NTP任务，使得模型倾向于生成与输入相似文本。</li><li><strong>模型结构及参数设置</strong>：如注意力机制及<strong>解码策略</strong>可能有影响。</li></ul></div><div class="custom-block important"><div class="custom-block-title">解决方法</div><p>没有一种通用的方案，需要针对具体情况具体分析， 下面是一些常用手段。</p><ul><li>📚<strong>增加多样性训练数据</strong></li><li>生成文本时引入一些随机噪声，<strong>采样不同词汇增加多样性</strong>。</li><li>温度等解码参数调整：<strong>较高温度增加随机性</strong>🔥。</li><li>Beam搜索参数调整：调整搜索Beam大小和宽度。</li><li><strong>后处理和过滤重复短语句子</strong></li><li><strong>人工干预和控制</strong>：对生成文本进行审查和筛选，保证多样性。</li></ul></div><h3 id="长文本问题" tabindex="-1">长文本问题 <a class="header-anchor" href="#长文本问题" aria-label="Permalink to &quot;长文本问题&quot;">​</a></h3><div class="custom-block important"><div class="custom-block-title">处理长句的挑战</div><p>理论上，LLM可以处理任意长度的句子，但是有一些挑战：</p><ul><li>🖥️<strong>计算资源不足</strong>：长句子消耗内存和时间</li><li>😟<strong>模型训练推理存在挑战</strong>：太长可能会出现<strong>梯度消失或梯度爆炸</strong>问题🔥，<strong>影响收敛和训练效果</strong>，<strong>推理会增加错误率和生成时间</strong>。</li><li><strong>上下文建模存在挑战</strong>：LLM基于上下文建模，<strong>长句子的上下文会更长更深</strong>，模型需要捕捉长的语法结构来生成结果，有挑战。</li></ul></div><div class="custom-block important"><div class="custom-block-title">处理长文本的方法</div><p><strong>1、分块处理</strong></p><ul><li>长文本分块，逐个片段输入到模型中。相邻片段做部分重叠，保持上下文一致性。</li></ul><p><strong>2、层次建模</strong></p><ul><li>引入层次结构，把文本划分成篇章、段落、句子等层次信息，逐层输入模型进行处理。</li></ul><p><strong>3、部分生成</strong></p><ul><li>只输入部分文本作为上下文，然后让模型生成所需的部分</li></ul><p><strong>4、注意力机制</strong></p><ul><li>注意力机制帮助模型关注输入中的重要部分。</li></ul><p><strong>5、模型结构优化</strong></p><ul><li>通过优化模型结构和参数设置，可以提高模型处理长文本的能力</li></ul></div></div></div></main><footer class="VPDocFooter" data-v-5a64a79a data-v-54a90a4a><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-54a90a4a><span class="visually-hidden" id="doc-footer-aria-label" data-v-54a90a4a>Pager</span><div class="pager" data-v-54a90a4a><!----></div><div class="pager" data-v-54a90a4a><a class="VPLink link pager-link next" href="/posts/llm/basic/04-llm-architecture.html" data-v-54a90a4a><!--[--><span class="desc" data-v-54a90a4a>下一页</span><span class="title" data-v-54a90a4a>大语言模型架构</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--[--><div class="busuanzi"> 总访客数： <span id="busuanzi_value_site_uv"></span>   ·   总访问量： <span id="busuanzi_value_site_pv"></span></div><div class="busuanzi"> PLM&#39;s Blog @ 2016 - 2025</div><!--]--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api-examples.md\":\"Xkffl130\",\"index.md\":\"BheGDo0s\",\"markdown-examples.md\":\"BRkVNFxB\",\"posts_archive.md\":\"CQTyVdEr\",\"posts_exps_env_01-blog-env.md\":\"Bus1IKDN\",\"posts_exps_env_index.md\":\"ViDjWzoZ\",\"posts_exps_mind_index.md\":\"CyLVrSwW\",\"posts_llm_agent_basic_01-lhy-agent-notes.md\":\"DpDHY26Z\",\"posts_llm_agent_basic_02-evaluation-agent.md\":\"BXkS4Ri2\",\"posts_llm_agent_basic_03-current-agents.md\":\"CaKTH2fO\",\"posts_llm_agent_basic_04-agent-blogs.md\":\"BqKvEFhZ\",\"posts_llm_agent_basic_05-comuter-agent.md\":\"B_rhpefo\",\"posts_llm_agent_basic_06-deepresearch-evaluation.md\":\"C0hAGrEX\",\"posts_llm_agent_basic_index.md\":\"DXkNFY8D\",\"posts_llm_agent_rl_01-agent-rl.md\":\"BOySVqgY\",\"posts_llm_agent_rl_02-agent-tool.md\":\"mhnQFP9r\",\"posts_llm_agent_rl_03-agent-search.md\":\"B5KoNKft\",\"posts_llm_agent_rl_04-agent-env.md\":\"jEKUUE26\",\"posts_llm_agent_rl_index.md\":\"BD7Q337w\",\"posts_llm_basic_01-lm-define-information-theory.md\":\"DYvRUr3Y\",\"posts_llm_basic_02-llm-components.md\":\"nwKtRHC5\",\"posts_llm_basic_03-transformer-detail.md\":\"kwnrr7vO\",\"posts_llm_basic_04-llm-architecture.md\":\"OoMrsPyt\",\"posts_llm_basic_05-llm-basic-info.md\":\"DQpSFOl_\",\"posts_llm_basic_index.md\":\"Dz5x496q\",\"posts_llm_rl_index.md\":\"C5bZT_bz\",\"posts_me.md\":\"BAbIfwmW\",\"posts_olds_algo_aim2offer.md\":\"Cz6K5T_f\",\"posts_olds_algo_aim2offer2.md\":\"CsDg2hmi\",\"posts_olds_algo_aim2offer3.md\":\"Bqx47LqA\",\"posts_olds_algo_aim2offer4.md\":\"oYzKNAUb\",\"posts_olds_algo_algorithm-dfs.md\":\"C65SjM61\",\"posts_olds_algo_index.md\":\"BLDaJaAX\",\"posts_olds_algo_leetcode-01.md\":\"CuTe0X9_\",\"posts_olds_algo_sort-algorithms.md\":\"BRXzDVU8\",\"posts_olds_bigdata_16-spark-baserdd.md\":\"OqXRKfbL\",\"posts_olds_bigdata_17-spark-pairrdd.md\":\"feRVt5rb\",\"posts_olds_bigdata_18-spark-sql.md\":\"D7SRDFvb\",\"posts_olds_bigdata_19-spark-programming.md\":\"CfbNRd0q\",\"posts_olds_bigdata_20-numpy.md\":\"BFNVBsp_\",\"posts_olds_bigdata_index.md\":\"C4Y8Qm6R\",\"posts_olds_dl_23-pytorch-start.md\":\"zJr7Di2v\",\"posts_olds_dl_35-nerual-network-optim.md\":\"BR7Pojf3\",\"posts_olds_dl_38-convolution.md\":\"BAE2Eqmr\",\"posts_olds_dl_attention-model.md\":\"u_f5k2ZA\",\"posts_olds_dl_cs224n-assignment-1.md\":\"2iJxHFWC\",\"posts_olds_dl_cs224n-lecture2-word2vec.md\":\"ClthZPeA\",\"posts_olds_dl_cs224n-notes1-word2vec.md\":\"DrgwSD0P\",\"posts_olds_dl_cs224n-notes3-neural-networks-2.md\":\"DEOKMjM4\",\"posts_olds_dl_cs224n-notes3-neural-networks.md\":\"uHRveaKW\",\"posts_olds_dl_cs231n-linear-notes.md\":\"NDaJ9Gz1\",\"posts_olds_dl_index.md\":\"14-y5uZG\",\"posts_olds_dl_rnn.md\":\"jefV1kO8\",\"posts_olds_env_09-linux-notes.md\":\"hexIjQEN\",\"posts_olds_env_12-ide-envs.md\":\"6Cp0-Out\",\"posts_olds_env_13-old-blog-problems.md\":\"D2qn7U-U\",\"posts_olds_env_24-hexo-problems.md\":\"YvaoXoMV\",\"posts_olds_env_index.md\":\"DHT-S0xK\",\"posts_olds_ml_10-trees.md\":\"BvaIT7ZX\",\"posts_olds_ml_14-em.md\":\"Br7akr6s\",\"posts_olds_ml_21-lr.md\":\"DWpXnFoO\",\"posts_olds_ml_22-ml-ch03-bayes.md\":\"C3MWhhR1\",\"posts_olds_ml_27-svm-notes.md\":\"CiaAcANg\",\"posts_olds_ml_28-ml-interview-notes.md\":\"DbX9BXZo\",\"posts_olds_ml_29-desicion-tree.md\":\"B0D7-yOJ\",\"posts_olds_ml_crf.md\":\"Cq6uRF2F\",\"posts_olds_ml_index.md\":\"CMAVKRwK\",\"posts_olds_ml_maxentmodel.md\":\"BhI-D-St\",\"posts_olds_ml_pgm-01.md\":\"B98vMEDt\",\"posts_olds_nlp_11-nlp-labels.md\":\"D_2zV9zh\",\"posts_olds_nlp_25-google-nmt.md\":\"BDd-XjAk\",\"posts_olds_nlp_26-wordpieacemodel.md\":\"B5QvDwRt\",\"posts_olds_nlp_30-dynamic-memory-network.md\":\"CJduMr_x\",\"posts_olds_nlp_31-co-attention-vqa.md\":\"YqUwFeuX\",\"posts_olds_nlp_32-dynamic-coattention-network.md\":\"DzJVI_o7\",\"posts_olds_nlp_33-attention-summary.md\":\"CXBYEWYo\",\"posts_olds_nlp_36-alime-chat.md\":\"BLDf7EoM\",\"posts_olds_nlp_39-squard-models.md\":\"BLS_8SRG\",\"posts_olds_nlp_45-match-lstm.md\":\"B6IkL5cR\",\"posts_olds_nlp_46-rnet-selfmatch.md\":\"BEm_VY9n\",\"posts_olds_nlp_47-bidaf.md\":\"_vw-uiAU\",\"posts_olds_nlp_48-attention-is-all-you-need.md\":\"CWi6xOzR\",\"posts_olds_nlp_49-qanet.md\":\"GE4Cd3RX\",\"posts_olds_nlp_50-elmo.md\":\"DOa6jfpi\",\"posts_olds_nlp_51-opengpt.md\":\"DI_-PibW\",\"posts_olds_nlp_52-bert.md\":\"BZCUgFMu\",\"posts_olds_nlp_53-mrc-brief.md\":\"DguP_qcH\",\"posts_olds_nlp_54-mrc-models.md\":\"Bh_-c6qs\",\"posts_olds_nlp_attention-based-nmt.md\":\"DX7shIIn\",\"posts_olds_nlp_index.md\":\"fbJN1i8j\",\"posts_olds_nlp_nlp-notes.md\":\"BJpNHEg_\",\"posts_olds_nlp_nmt.md\":\"BcCiPtrz\",\"posts_olds_nlp_subword-units.md\":\"M6KRaDoT\",\"posts_olds_nlp_word2vec-math.md\":\"ptv0LLxb\",\"posts_olds_nlp_word2vec.md\":\"C3mQIIHl\",\"posts_olds_other_15-cpp-pointer-object-reference.md\":\"CpWjxBD8\",\"posts_olds_other_index.md\":\"_S-bEwIt\",\"posts_olds_rl_37-reinforce-learning.md\":\"BU1rDhhw\",\"posts_olds_rl_40-value-learning.md\":\"8DiVSefv\",\"posts_olds_rl_41-strategy-learning.md\":\"Cl0FdxtC\",\"posts_olds_rl_42-reinforce-conclusion-simple.md\":\"DIw2tPlF\",\"posts_olds_rl_43-intent-detection-slot-filling.md\":\"CbEf3hcQ\",\"posts_olds_rl_44-reinforce-nlp.md\":\"Cn2wpki_\",\"posts_olds_rl_index.md\":\"DrdmSwsd\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"📚 plmblog\",\"description\":\"记录一些学习笔记。\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"首页\",\"link\":\"/\"},{\"text\":\"🐲LLM\",\"items\":[{\"text\":\"Basic\",\"items\":[{\"text\":\"🦋基础\",\"link\":\"/posts/llm/basic/01-lm-define-information-theory\"}]},{\"text\":\"Agent\",\"items\":[{\"text\":\"🤖概念及应用\",\"link\":\"/posts/llm/agent/basic\"},{\"text\":\"🚄Agent-RL\",\"link\":\"/posts/llm/agent/rl/02-agent-tool\"}]},{\"text\":\"rl\",\"items\":[{\"text\":\"🐼r1相关\",\"link\":\"/posts/llm/rl\"}]}]},{\"text\":\"📙旧文章\",\"items\":[{\"text\":\"🍓NLP\",\"items\":[{\"text\":\"自然语言处理\",\"link\":\"/posts/olds/nlp\"}]},{\"text\":\"🍑基础知识\",\"items\":[{\"text\":\"深度学习\",\"link\":\"/posts/olds/dl\"},{\"text\":\"强化学习\",\"link\":\"/posts/olds/rl\"},{\"text\":\"机器学习\",\"link\":\"/posts/olds/ml\"}]},{\"text\":\"🍎算法\",\"items\":[{\"text\":\"算法题\",\"link\":\"/posts/olds/algo/\"},{\"text\":\"大数据\",\"link\":\"/posts/olds/bigdata/\"}]},{\"text\":\"🍒其他\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/olds/env/\"},{\"text\":\"其他\",\"link\":\"/posts/olds/other/\"}]}]},{\"text\":\"经验\",\"items\":[{\"text\":\"环境\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/exps/env/01-blog-env\"}]},{\"text\":\"心得\",\"items\":[{\"text\":\"心得体会\",\"link\":\"/posts/exps/mind\"}]}]},{\"text\":\"归档\",\"link\":\"/posts/archive.md\"},{\"text\":\"关于我\",\"link\":\"/posts/me\"}],\"outline\":{\"level\":[1,4],\"label\":\"当前页大纲\"},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/plmsmile\"}],\"search\":{\"provider\":\"local\"},\"docFooter\":{\"prev\":\"上一页\",\"next\":\"下一页\"},\"sidebar\":{\"/posts/olds/nlp/\":{\"base\":\"/posts/olds/nlp/\",\"items\":[{\"text\":\"NLP\",\"items\":[{\"text\":\"机器阅读(二)--模型(未完成)\",\"link\":\"54-mrc-models\"},{\"text\":\"机器阅读(一)--整体概述\",\"link\":\"53-mrc-brief\"},{\"text\":\"BERT 详解\",\"link\":\"52-bert\"},{\"text\":\"OpenAI GPT：Improving Language Understanding by Generative Pre-Training\",\"link\":\"51-opengpt\"},{\"text\":\"ELMo：Deep Contextualized Word Representations\",\"link\":\"50-elmo\"},{\"text\":\"QANet\",\"link\":\"49-qanet\"},{\"text\":\"Transformer\",\"link\":\"48-attention-is-all-you-need\"},{\"text\":\"Bidirectional Attention Flow\",\"link\":\"47-bidaf\"},{\"text\":\"R-Net (Gated Self-Matching Networks)\",\"link\":\"46-rnet-selfmatch\"},{\"text\":\"Match-LSTM and Answer Pointer\",\"link\":\"45-match-lstm\"},{\"text\":\"阅读理解模型总结\",\"link\":\"39-squard-models\"},{\"text\":\"阿里小蜜论文\",\"link\":\"36-alime-chat\"},{\"text\":\"各种注意力总结\",\"link\":\"33-attention-summary\"},{\"text\":\"Dynamic Coattention Network (Plus)\",\"link\":\"32-dynamic-coattention-network\"},{\"text\":\"协同注意力简介\",\"link\":\"31-co-attention-vqa\"},{\"text\":\"使用Dynamic Memory Network实现一个简单QA\",\"link\":\"30-dynamic-memory-network\"},{\"text\":\"词性标注和句法依存的表示符号\",\"link\":\"11-nlp-labels\"},{\"text\":\"Word2vec之数学模型\",\"link\":\"word2vec-math\"},{\"text\":\"subword-units\",\"link\":\"subword-units\"},{\"text\":\"Wordpiece模型\",\"link\":\"26-wordpieacemodel\"},{\"text\":\"谷歌RNN翻译模型\",\"link\":\"25-google-nmt\"},{\"text\":\"机器翻译注意力机制及其PyTorch实现\",\"link\":\"Attention-based-NMT\"},{\"text\":\"最初RNN神经翻译简略笔记\",\"link\":\"NMT\"},{\"text\":\"语言模型和平滑方法\",\"link\":\"nlp-notes\"},{\"text\":\"利用tensorflow实现简版word2vec\",\"link\":\"word2vec\"}]}]},\"/posts/olds/dl/\":{\"base\":\"/posts/olds/dl/\",\"items\":[{\"text\":\"DL\",\"items\":[{\"text\":\"卷积神经网络总结\",\"link\":\"38-convolution\"},{\"text\":\"网络优化\",\"link\":\"35-nerual-network-optim\"},{\"text\":\"cs224n作业一\",\"link\":\"cs224n-assignment-1\"},{\"text\":\"cs231n线性分类器和损失函数\",\"link\":\"cs231n-linear-notes\"},{\"text\":\"神经网络-过拟合-预处理-BN\",\"link\":\"cs224n-notes3-neural-networks-2\"},{\"text\":\"神经网络基础-反向传播-激活函数\",\"link\":\"cs224n-notes3-neural-networks\"},{\"text\":\"Word2vec之总体介绍\",\"link\":\"cs224n-notes1-word2vec\"},{\"text\":\"Word2vec之公式推导笔记\",\"link\":\"cs224n-lecture2-word2vec\"},{\"text\":\"循环神经网络\",\"link\":\"rnn\"},{\"text\":\"图文介绍RNN注意力机制\",\"link\":\"attention-model\"},{\"text\":\"PyTorch快速上手\",\"link\":\"23-pytorch-start\"}]}]},\"/posts/olds/rl/\":{\"base\":\"/posts/olds/rl/\",\"items\":[{\"text\":\"RL\",\"items\":[{\"text\":\"强化学习在NLP中的应用\",\"link\":\"44-reinforce-nlp\"},{\"text\":\"意图识别和槽填充\",\"link\":\"43-intent-detection-slot-filling\"},{\"text\":\"强化学习算法小结\",\"link\":\"42-reinforce-conclusion-simple\"},{\"text\":\"基于策略函数的学习方法\",\"link\":\"41-strategy-learning\"},{\"text\":\"基于值函数的学习\",\"link\":\"40-value-learning\"},{\"text\":\"强化学习\",\"link\":\"37-reinforce-learning\"}]}]},\"/posts/olds/ml/\":{\"base\":\"/posts/olds/ml/\",\"items\":[{\"text\":\"ML\",\"items\":[{\"text\":\"决策树笔记\",\"link\":\"29-desicion-tree\"},{\"text\":\"机器学习知识点汇总整理\",\"link\":\"28-ml-interview-notes\"},{\"text\":\"SVM笔记\",\"link\":\"27-svm-notes\"},{\"text\":\"树的总结\",\"link\":\"10-trees\"},{\"text\":\"条件随机场\",\"link\":\"crf\"},{\"text\":\"最大熵模型\",\"link\":\"maxentmodel\"},{\"text\":\"线性回归和逻辑回归\",\"link\":\"21-lr\"},{\"text\":\"最大期望算法\",\"link\":\"14-em\"},{\"text\":\"马尔可夫模型\",\"link\":\"pgm-01\"},{\"text\":\"朴素贝叶斯算法及其代码实现\",\"link\":\"22-ml-ch03-bayes\"}]}]},\"/posts/olds/algo/\":{\"base\":\"/posts/olds/algo/\",\"items\":[{\"text\":\"ALGO\",\"items\":[{\"text\":\"剑指offer4(51-64)\",\"link\":\"aim2offer4\"},{\"text\":\"剑指offer3(21-40)\",\"link\":\"aim2offer3\"},{\"text\":\"数据结构之搜索算法\",\"link\":\"algorithm-dfs\"},{\"text\":\"leetcode-01\",\"link\":\"leetcode-01\"},{\"text\":\"剑指offer(11-20)\",\"link\":\"aim2offer2\"},{\"text\":\"排序算法总结\",\"link\":\"sort-algorithms\"},{\"text\":\"剑指Offer(1-10)\",\"link\":\"aim2offer\"}]}]},\"/posts/olds/bigdata/\":{\"base\":\"/posts/olds/bigdata/\",\"items\":[{\"text\":\"BIG Data\",\"items\":[{\"text\":\"NumPy\",\"link\":\"20-numpy\"},{\"text\":\"Spark基础编程核心思想介绍\",\"link\":\"19-spark-programming\"},{\"text\":\"Spark-SQL的简略笔记\",\"link\":\"18-spark-sql\"},{\"text\":\"Spark键值对RDD的常用API\",\"link\":\"17-spark-pairrdd\"},{\"text\":\"Spark基础RDD的常用API\",\"link\":\"16-Spark-BaseRDD\"}]}]},\"/posts/olds/env/\":{\"base\":\"/posts/olds/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"IDE配置\",\"link\":\"12-ide-envs\"},{\"text\":\"Linux使用笔记\",\"link\":\"09-linux-notes\"},{\"text\":\"博客搭建及相关问题\",\"link\":\"24-hexo-problems\"},{\"text\":\"旧版博客搭建过程及其问题\",\"link\":\"13-old-blog-problems\"}]}]},\"/posts/olds/other/\":{\"base\":\"/posts/olds/other/\",\"items\":[{\"text\":\"其他\",\"items\":[{\"text\":\"C++类对象和指针的区别\",\"link\":\"15-cpp-pointer-object-reference\"}]}]},\"/posts/llm/agent/rl/\":{\"base\":\"/posts/llm/agent/rl/\",\"items\":[{\"text\":\"Agent-RL\",\"items\":[{\"text\":\"Agent-Interaction-RL 笔记\",\"link\":\"04-agent-env\"},{\"text\":\"Agent-Search-RL 笔记\",\"link\":\"03-agent-search\"},{\"text\":\"Agent-Tool-RL 笔记\",\"link\":\"02-agent-tool\"},{\"text\":\"Agent-RL 综述型笔记\",\"link\":\"01-agent-rl\"}]}]},\"/posts/llm/agent/basic/\":{\"base\":\"/posts/llm/agent/basic/\",\"items\":[{\"text\":\"Agent-基础\",\"items\":[{\"text\":\"DeepResearch 评估\",\"link\":\"06-deepresearch-evaluation\"},{\"text\":\"Computer-Agent\",\"link\":\"05-comuter-agent\"},{\"text\":\"Agent 思考性文章\",\"link\":\"04-agent-blogs\"},{\"text\":\"一些流行的Agents\",\"link\":\"03-current-agents\"},{\"text\":\"Agent 评估 Benchmarks\",\"link\":\"02-evaluation-agent\"},{\"text\":\"Agent基础概念 (李宏毅笔记)\",\"link\":\"01-lhy-agent-notes\"}]}]},\"/posts/llm/rl/\":{\"base\":\"/posts/llm/rl/\",\"items\":[{\"text\":\"LLM-RL\",\"items\":[]}]},\"/posts/llm/basic/\":{\"base\":\"/posts/llm/basic/\",\"items\":[{\"text\":\"LLM-basic\",\"items\":[{\"text\":\"LLM 基础知识\",\"link\":\"05-llm-basic-info\"},{\"text\":\"大语言模型架构\",\"link\":\"04-llm-architecture\"},{\"text\":\"Transformer细节\",\"link\":\"03-transformer-detail\"},{\"text\":\"语言模型重要组件\",\"link\":\"02-llm-components\"},{\"text\":\"语言模型定义及信息理论\",\"link\":\"01-lm-define-information-theory\"}]}]},\"/posts/exps/env/\":{\"base\":\"/posts/exps/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"环境搭建的一些坑\",\"link\":\"01-blog-env\"}]}]},\"/posts/exps/mind/\":{\"base\":\"/posts/exps/mind/\",\"items\":[{\"text\":\"心得体会\",\"items\":[]}]}}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>
<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Code Survey | 📚 plmblog</title>
    <meta name="description" content="记录一些学习笔记。">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/assets/style.CuIOXX7t.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.DpGDoEiv.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.DUEAmsFX.js">
    <link rel="modulepreload" href="/assets/chunks/framework.CvbyeFFO.js">
    <link rel="modulepreload" href="/assets/posts_llm_industry_codellm_01-survey.md.DIZQiOWr.lean.js">
    <link rel="icon" href="/plm.png">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-cecb633e><!--[--><!--]--><!--[--><span tabindex="-1" data-v-c979f278></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-c979f278>Skip to content</a><!--]--><!----><header class="VPNav" data-v-cecb633e data-v-0ad68676><div class="VPNavBar" data-v-0ad68676 data-v-ce71e4ef><div class="wrapper" data-v-ce71e4ef><div class="container" data-v-ce71e4ef><div class="title" data-v-ce71e4ef><div class="VPNavBarTitle has-sidebar" data-v-ce71e4ef data-v-7e906684><a class="title" href="/" data-v-7e906684><!--[--><!--]--><!----><span data-v-7e906684>📚 plmblog</span><!--[--><!--]--></a></div></div><div class="content" data-v-ce71e4ef><div class="content-body" data-v-ce71e4ef><!--[--><!--]--><div class="VPNavBarSearch search" data-v-ce71e4ef><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-ce71e4ef data-v-e0cd9371><span id="main-nav-aria-label" class="visually-hidden" data-v-e0cd9371> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>首页</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup active" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>🐲LLM</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Basic</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/basic/01-lm-define-information-theory.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🦋基础知识</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/infra/01-parrallel.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🛠基建框架</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>强化学习</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/rl/theory/01-reinforce-learning.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🎓RL理论基础</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/rl/02-agent-tool.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚄Agent-RL</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>行业方向</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/industry/mainllm/01-kimi-series.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚀主流模型</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link active" href="/posts/llm/industry/codellm/01-survey.html" data-v-dc987abe><!--[--><span data-v-dc987abe>💻代码模型</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Agent</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/basic.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🤖概念及应用</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>📙旧文章</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍓NLP</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/nlp.html" data-v-dc987abe><!--[--><span data-v-dc987abe>自然语言处理</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍑基础知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/dl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>深度学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/rl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>强化学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/ml.html" data-v-dc987abe><!--[--><span data-v-dc987abe>机器学习</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍎算法</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/algo/" data-v-dc987abe><!--[--><span data-v-dc987abe>算法题</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/bigdata/" data-v-dc987abe><!--[--><span data-v-dc987abe>大数据</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍒其他</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/env/" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/other/" data-v-dc987abe><!--[--><span data-v-dc987abe>其他</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>经验</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>环境</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/env/01-blog-env.html" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>心得</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/mind.html" data-v-dc987abe><!--[--><span data-v-dc987abe>心得体会</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/archive.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>归档</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/me.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>关于我</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-ce71e4ef data-v-b59ebfac><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-b59ebfac data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-ce71e4ef data-v-e0f2db57 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-ce71e4ef data-v-8897e953 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-ffaaba87><span class="vpi-more-horizontal icon" data-v-ffaaba87></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><!----><!--[--><!--[--><!----><div class="group" data-v-8897e953><div class="item appearance" data-v-8897e953><p class="label" data-v-8897e953>Appearance</p><div class="appearance-action" data-v-8897e953><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-8897e953 data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div></div></div><div class="group" data-v-8897e953><div class="item social-links" data-v-8897e953><div class="VPSocialLinks social-links-list" data-v-8897e953 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-ce71e4ef data-v-37e0f734><span class="container" data-v-37e0f734><span class="top" data-v-37e0f734></span><span class="middle" data-v-37e0f734></span><span class="bottom" data-v-37e0f734></span></span></button></div></div></div></div><div class="divider" data-v-ce71e4ef><div class="divider-line" data-v-ce71e4ef></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-cecb633e data-v-1b409c8b><div class="container" data-v-1b409c8b><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-1b409c8b><span class="vpi-align-left menu-icon" data-v-1b409c8b></span><span class="menu-text" data-v-1b409c8b>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-1b409c8b data-v-a203161a><button data-v-a203161a>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-cecb633e data-v-18f7b5ca><div class="curtain" data-v-18f7b5ca></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-18f7b5ca><span class="visually-hidden" id="sidebar-aria-label" data-v-18f7b5ca> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-7f5b9a39><section class="VPSidebarItem level-0 has-active" data-v-7f5b9a39 data-v-a4affe07><div class="item" role="button" tabindex="0" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><h2 class="text" data-v-a4affe07>💻代码模型</h2><!----></div><div class="items" data-v-a4affe07><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/07-code-fulltrain-reading.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 全训练 论文阅读</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/06-code-taskrl-reading.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code TaskRL 论文阅读</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/05-open-codellm.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>CodeLLM 索引简记</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/04-safety-code.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 安全相关</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/03-rl-task.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code RL 任务</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/02-eval-task-benchmark.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 任务Bench相关</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/01-survey.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code Survey</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/08-code-pretrain-summary.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 预训练相关</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-cecb633e data-v-53a9cb18><div class="VPDoc has-sidebar has-aside" data-v-53a9cb18 data-v-5a64a79a><!--[--><!--]--><div class="container" data-v-5a64a79a><div class="aside" data-v-5a64a79a><div class="aside-curtain" data-v-5a64a79a></div><div class="aside-container" data-v-5a64a79a><div class="aside-content" data-v-5a64a79a><div class="VPDocAside" data-v-5a64a79a data-v-f8ea3c28><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-f8ea3c28 data-v-b94d89ac><div class="content" data-v-b94d89ac><div class="outline-marker" data-v-b94d89ac></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-b94d89ac>当前页大纲</div><ul class="VPDocOutlineItem root" data-v-b94d89ac data-v-80b46526><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-f8ea3c28></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-5a64a79a><div class="content-container" data-v-5a64a79a><!--[--><!--[--><!--[--><article class="post-header" data-v-a99fd7c9><h1 class="title" data-v-a99fd7c9>Code Survey</h1><div class="stats-container" data-v-a99fd7c9><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 📅 发表于 <span class="stat-text" data-v-a99fd7c9>2025/12/06</span></div><div class="stat-item" data-v-a99fd7c9> 🔄 更新于 <span class="stat-text" data-v-a99fd7c9>2025/12/06</span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 👁️ <span class="stat-text" data-v-a99fd7c9>-- 次访问</span><span id="busuanzi_value_page_pv" style="display:none;" data-page="/posts/llm/industry/codellm/01-survey.html" data-v-a99fd7c9></span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 📝 <span class="stat-text" data-v-a99fd7c9>0 字</span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> ⏳ <span class="stat-text" data-v-a99fd7c9>0 分钟</span></div><div class="stat-divider" data-v-a99fd7c9></div></div><div class="tag-group" data-v-a99fd7c9><!--[--><div class="category-item" data-v-a99fd7c9>code</div><!--]--><!--[--><div class="tag-item" data-v-a99fd7c9> #survey</div><!--]--></div></article><!--]--><!--]--><!--]--><main class="main" data-v-5a64a79a><div style="position:relative;" class="vp-doc _posts_llm_industry_codellm_01-survey" data-v-5a64a79a><div><h2 id="survey-文章" tabindex="-1">Survey 文章 <a class="header-anchor" href="#survey-文章" aria-label="Permalink to &quot;Survey 文章&quot;">​</a></h2><div class="custom-block caution"><div class="custom-block-title">参考文章</div><ul><li>(2512) <a href="https://www.alphaxiv.org/abs/2511.18538" target="_blank" rel="noreferrer">From Code Foundation Models to Agents and Applications</a></li><li>(2510) <a href="https://www.alphaxiv.org/abs/2510.12399" target="_blank" rel="noreferrer">A Survey of Vibe Coding with Large Language Models</a></li><li>(2508) <a href="https://www.alphaxiv.org/abs/2508.11126" target="_blank" rel="noreferrer">AI Agentic Programming</a></li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251206172440.jpg" style="display:block;margin:auto;" width="100%"><h2 id="背景" tabindex="-1">背景 <a class="header-anchor" href="#背景" aria-label="Permalink to &quot;背景&quot;">​</a></h2><h3 id="发展历程" tabindex="-1">发展历程 <a class="header-anchor" href="#发展历程" aria-label="Permalink to &quot;发展历程&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">背景</div><p><strong>AI Coding 思想</strong></p><ul><li>利用<code>Github</code>/<code>StackOverflow</code>/<code>code</code>网站资源，把<code>多年编程经验</code>提炼成<code>指令跟随的工具</code>。</li></ul><p><strong>相关工具</strong></p><ul><li>【辅助插件】<code>GitHub Copilot</code>：VSCode 插件</li><li>【IDE】<code>Cursor</code>：对话式编程</li><li>【国产】CodeGeeX(智谱)：多语言代码</li><li>【云服务】CodeWhisperer(亚马逊)：与AWS服务无缝集成，可调用Claude或Gemini。</li><li>【命令行】<code>Claude Code/Gemini CLI</code>：命令行级别，<code>agentic-coding-workflow</code>。 <ul><li>AI 自助分析文件、运行命令、修正代码</li></ul></li></ul></div><div class="custom-block tip"><div class="custom-block-title">Code LLM 两种分歧</div><p><strong>两种分歧</strong></p><ul><li><strong>通用型LLM (广度)</strong><ul><li><code>自然语言</code>+<code>编程数据</code> <code>混合预训练</code>，在上下文/意图/领域知识等理解细致。</li><li>代表工作：GPT、Claude、LLaMA等。</li></ul></li><li><strong>专用CodeLLM (深度)</strong><ul><li><code>编程数据</code>预训练+<code>算法架构优化</code>。</li><li>代表工作：StarCoder, Code LLaMA, DeepSeek-Coder, CodeGemma, QwenCoder等。</li></ul></li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-llm-overview.jpg" style="display:block;margin:auto;" width="100%"><h3 id="尚未探索的领域" tabindex="-1">尚未探索的领域 <a class="header-anchor" href="#尚未探索的领域" aria-label="Permalink to &quot;尚未探索的领域&quot;">​</a></h3><div class="custom-block warning"><div class="custom-block-title">目前尚缺乏探索的领域</div><p><strong>1. 数据清洗策略</strong></p><ul><li>如何<code>平衡数据质量和数量</code>？ <ul><li>数据并非越多越好，顶级模型如何</li></ul></li><li>如何做<code>指令跟随</code>？ <ul><li>让模型听懂人话。</li></ul></li></ul><p><strong>2. 对齐技术</strong></p><ul><li>code需要能跑、<code>符合人类习惯</code>、是<code>安全</code>的，如何<code>根据人类反馈来做对齐</code>？</li></ul><p><strong>3. 高级提示范式</strong></p><ul><li>CoT、FewShot等。</li></ul><p><strong>4. 自主智能体</strong></p><ul><li>自动拆解任务。</li></ul><p><strong>5. RAG</strong></p><ul><li>模型会有幻觉、编写出不存在的函数。</li><li>做RAG，让模型<code>先看文档</code>，<code>再写代码</code>，保证准确性。</li></ul><p><strong>6. 评估框架</strong></p><ul><li>现在更多是<code>2元的</code>(仅看<code>正确性</code>)。</li><li>但如何评估代码<code>烂不烂</code>、<code>效率如何</code>、<code>可维护性如何</code>？</li></ul></div><h3 id="通用llm-发展和不足" tabindex="-1">通用LLM 发展和不足 <a class="header-anchor" href="#通用llm-发展和不足" aria-label="Permalink to &quot;通用LLM 发展和不足&quot;">​</a></h3><h4 id="发展和涌现" tabindex="-1">发展和涌现 <a class="header-anchor" href="#发展和涌现" aria-label="Permalink to &quot;发展和涌现&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Rise of LLMs</div><p><strong>Transformer 和 Scaling Law</strong></p><ul><li><code>Transformer 一统江湖</code><ul><li>通过<code>预训练</code>和<code>知识迁移</code>，把多种统一到一个支持多种任务和模态的可扩展框架。</li><li>NTP任务</li></ul></li><li><code>Scaling Law 大力出奇迹</code><ul><li>参数、数据、计算越多，模型效果越好，可预测。</li><li>出现一些涌现能力，涌现也可能是评估指标的问题。</li></ul></li></ul><p><strong>LLM爆发出代码能力</strong></p><ul><li>OpenAI：Codex 能写代码 + HumanEval 测试集。</li><li>DeepMind：AlphaCode 能做竞技编程。</li><li><code>代码结构</code> 和<code>人类自然语</code>言在<code>底层逻辑上是相通的</code>。</li></ul><p><strong>LLM + 外部工具 变身 决策agent</strong></p><ul><li><code>外部工具</code>：计算器、搜索、代码解释器等等。</li><li><code>思考行动观察Loop</code>：思考 -&gt; 行动 -&gt; 观察 -&gt; 思考 -&gt; 行动 -&gt; 观察 ....</li><li>典型技术：ReAct，ToolFormer等。</li></ul><p><strong>突破、局限、CodeLLM动机</strong></p><ul><li>突破：SWE-Agent：修bug、通过所有测试用例。需要规划+多文件操作能力。</li><li><code>通用模型</code> 在代码领域<code>有局限性</code>： <ul><li><code>准确性</code>(复杂代码不会写)、<code>安全性</code>(有bug代码)、<code>可靠性</code>(系统级可靠性差)</li></ul></li><li>需要转<code>专有的代码大模型</code></li></ul></div><p>代码生成：HumanEval上的效果</p><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251206183411.jpg" style="display:block;margin:auto;" width="70%"><p>修bug：SWE-Bench上的效果</p><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251206183358.jpg" style="display:block;margin:auto;" width="70%"><h4 id="模型架构-多模态" tabindex="-1">模型架构&amp;多模态 <a class="header-anchor" href="#模型架构-多模态" aria-label="Permalink to &quot;模型架构&amp;多模态&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Dense Model</div><p><strong>1. Dense Model</strong></p><ul><li><a href="http://plmsmile.github.io/posts/llm/basic/04-llm-architecture.html#dense-model" target="_blank" rel="noreferrer">DenseModel</a></li></ul><p><strong>2. MoE</strong></p><ul><li><a href="http://plmsmile.github.io/posts/llm/basic/04-llm-architecture.html#moe-model" target="_blank" rel="noreferrer">MoEModel</a></li></ul><p><strong>3. Recurrent Models</strong></p><ul><li><a href="http://plmsmile.github.io/posts/llm/basic/04-llm-architecture.html#recurrent-model" target="_blank" rel="noreferrer">RecurrentModel</a></li></ul><p><strong>4. Diffusion Models</strong></p><ul><li><a href="http://plmsmile.github.io/posts/llm/basic/04-llm-architecture.html#diffusion-based-model" target="_blank" rel="noreferrer">DiffusionModel</a></li></ul><p><strong>5. Hybrid Architechures</strong></p><ul><li><a href="http://plmsmile.github.io/posts/llm/basic/04-llm-architecture.html#hybrid-architectures" target="_blank" rel="noreferrer">混合架构</a></li></ul></div><div class="custom-block note"><div class="custom-block-title">多模态</div><ul><li>主要依赖<code>视觉能力</code>，需要查看<code>图表</code>、<code>截图</code>、<code>UI元素</code>等内容。</li></ul></div><h4 id="不足" tabindex="-1">不足 <a class="header-anchor" href="#不足" aria-label="Permalink to &quot;不足&quot;">​</a></h4><div class="custom-block warning"><div class="custom-block-title">通用大模型的不足</div><p><strong>核心缺点</strong></p><ul><li><code>有广度</code>、<code>无深度</code></li><li>什么都会一点，能写简单代码、能看图等。</li></ul><p><strong>具体表现</strong></p><ul><li><code>专业和准确性不足</code><ul><li>生成表面看起来没问题的代码，但实际不能满足一些领域约束。 <ul><li><code>看起来对的代码</code>，<code>实际可能一跑就崩</code></li></ul></li></ul></li><li><code>安全和可靠性不足</code><ul><li>尽管功能正确能运行，但仍然不够安全、<code>有bug</code></li></ul></li><li><code>仓库级理解不足</code><ul><li>模型可读长上下文，但经常<code>lost-in-middle</code>。 <ul><li>关键信息藏在几万行代码中间，模型往往会忽略。</li><li><code>跨文件的变量引用</code>、<code>依赖关系</code>，模型经常搞不清楚，导致<code>无法理解整个项目</code>。</li></ul></li></ul></li><li><code>多模态障碍/看不懂界面细节</code><ul><li>能看懂是个网页，但无法看懂具体元素细节、按钮具体交互含义等</li><li>导致 AI 无法像人类一样精准地操作 GUI 界面进行编程或测试。</li></ul></li><li><code>不会用工具(Agentic限制)</code><ul><li><code>通用模型</code>容易出现<code>工具幻觉</code>：<code>假装调用了工具</code>，或者编造了工具的输出。</li><li>任务步骤变多(<code>长程推理</code>)，模型很容易这就<code>“晕”了</code>，忘记之前的步骤或偏离目标。</li></ul></li></ul><p><strong>用模型写代码不够，需要</strong></p><ul><li><code>数据清洗</code>：<code>去掉不安全</code>的代码。</li><li><code>预训练/微调</code>：让模型理解<code>代码结构</code>和<code>跨文件依赖</code></li><li><code>强化学习</code>：教模型如何<code>正确使用工具</code>和进行<code>长期规划</code></li></ul></div><h2 id="代码基础大模型-开源llm" tabindex="-1">代码基础大模型(开源LLM) <a class="header-anchor" href="#代码基础大模型-开源llm" aria-label="Permalink to &quot;代码基础大模型(开源LLM)&quot;">​</a></h2><h3 id="开源和闭源llm" tabindex="-1">开源和闭源LLM <a class="header-anchor" href="#开源和闭源llm" aria-label="Permalink to &quot;开源和闭源LLM&quot;">​</a></h3><p><a href="http://plmsmile.github.io/posts/llm/industry/codellm/05-open-codellm.html#%E5%BC%80%E6%BA%90code-llm" target="_blank" rel="noreferrer">开源CodeLLM</a></p><h3 id="模型训练阶段-预训练-后训练" tabindex="-1">模型训练阶段(预训练+后训练) <a class="header-anchor" href="#模型训练阶段-预训练-后训练" aria-label="Permalink to &quot;模型训练阶段(预训练+后训练)&quot;">​</a></h3><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251210221126.jpg" style="display:block;margin:auto;" width="70%"><h3 id="预训练相关" tabindex="-1">预训练相关 <a class="header-anchor" href="#预训练相关" aria-label="Permalink to &quot;预训练相关&quot;">​</a></h3><p><a href="http://plmsmile.github.io/posts/llm/industry/codellm/08-code-pretrain-summary.html#%E9%A2%84%E8%AE%AD%E7%BB%83%E4%BB%BB%E5%8A%A1" target="_blank" rel="noreferrer">预训练任务</a>+<a href="http://plmsmile.github.io/posts/llm/industry/codellm/08-code-pretrain-summary.html#%E9%A2%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE" target="_blank" rel="noreferrer">预训练数据</a></p><h3 id="未来趋势" tabindex="-1">未来趋势 <a class="header-anchor" href="#未来趋势" aria-label="Permalink to &quot;未来趋势&quot;">​</a></h3><div class="custom-block important"><div class="custom-block-title">趋势</div><p><strong>从通才到专才</strong></p><ul><li>现状：GPT5-Codex、CLaude-4代码变体，都说明了<code>特定领域优化有效果</code>。</li><li>未来：通用AI和编程助手<code>继续分化</code><ul><li>在repo-level 任务、复杂调试、多步软件工程等场景取得突破</li></ul></li></ul><p><strong>Agentic训练&amp;复杂场景攻克</strong></p><ul><li>从<code>被动代码生成</code>向<code>主动软件工程</code>转变，在复杂、多步编程场景自主操作。</li><li>需要RL从执行反馈中学习，渐进式课程学习处理仓库级任务，集成外部工具和环境。</li><li>需要理解整个项目、浏览代码库、执行迭代调试，和人类协作。</li></ul><p><strong>Scaling Law</strong></p><ul><li><code>科学Scaling策略</code>：是把钱花在<code>模型参数</code>、还是清洗<code>更高质量数据</code>。</li><li>MoE架构优化：保持计算效率、实现更优性能。<code>MoE大势所趋</code>。</li></ul></div><h2 id="评估和任务分类" tabindex="-1">评估和任务分类 <a class="header-anchor" href="#评估和任务分类" aria-label="Permalink to &quot;评估和任务分类&quot;">​</a></h2><p>见笔记<a href="http://plmsmile.github.io/posts/llm/industry/codellm/02-eval-task-benchmark.html" target="_blank" rel="noreferrer">Code任务Bench相关 笔记</a></p><h2 id="对齐" tabindex="-1">对齐 <a class="header-anchor" href="#对齐" aria-label="Permalink to &quot;对齐&quot;">​</a></h2><div class="custom-block caution"><div class="custom-block-title">对齐</div><ul><li><p>目的：使预训练模型能遵循指令有效完成code任务，通用llm -&gt; codellm。</p></li><li><p>SFT：覆盖代码生成、修复、翻译等。</p></li><li><p>RL：通过奖励信号来修正模型。</p></li></ul></div><h3 id="sft" tabindex="-1">SFT <a class="header-anchor" href="#sft" aria-label="Permalink to &quot;SFT&quot;">​</a></h3><div class="custom-block caution"><div class="custom-block-title">SFT</div><ul><li>早期代码指令数据：Natrual-Instruct <ul><li>来源：code-comment：Github数据；question-answer：StackExchange等。</li><li>缺陷： <ul><li>真实代码质量不一、难以过滤</li><li>原始并非SFT构建，导致部分可能不满足指令要求。 <ul><li>可能没有注释、或逻辑不一致等。</li></ul></li></ul></li></ul></li><li>Self-instruct 数据方法 <ul><li>给种子，找强力模型，生成许多示例，用示例去训小魔仙。</li><li>Alpaca、<a href="https://github.com/sahil280114/codealpaca" target="_blank" rel="noreferrer">(2023) CodeAlpaca</a></li></ul></li></ul></div><h4 id="单轮sft" tabindex="-1">单轮SFT <a class="header-anchor" href="#单轮sft" aria-label="Permalink to &quot;单轮SFT&quot;">​</a></h4><p>如何构造出比CodeAlpaca更好的训练数据？</p><div class="custom-block tip"><div class="custom-block-title">单轮SFT数据构造</div><p><strong>由浅入深：复杂性，解决太简单的问题</strong></p><ul><li>背景：<code>CodeAlpaca 问题太简单</code></li><li><strong>Evol-Instruct方法</strong> (WizardCoder 技术) <ul><li>通过启发式规则，<code>让GPT4把问题变难</code>，<code>提升问题复杂性</code>。 <ul><li>增加约束条件、增加时间复杂度要求、把这个问题变成错题等。</li></ul></li></ul></li></ul><p><strong>由窄变宽：多样性，解决太重复的问题</strong></p><ul><li>问题：Self-Instruct会生成太多重复数据。</li><li><code>引入人类编写的数据</code>(Natrual-Instruct)，来丰富多样性 <ul><li>Semi-Instruct：使用完整代码。</li><li><strong>OSS-instruct</strong>：使用代码片段，而非完整代码，素材更碎片，发挥空间更大。</li></ul></li><li>CodeOcean数据 严选+验真 <ul><li>通过<code>启发式规则</code>和<code>语义相似度</code>，<code>筛选</code>出多样化的数据。</li><li>利用CoT-like<code>验证数据的正确性</code>。</li></ul></li><li>Self-Correction 逆向生成 <ul><li>先从Evol-Instruct中清洗出output，再有个模型生成多个instruction</li><li>再用模型去判断哪个指令是对的</li></ul></li></ul><p><strong>由粗到细：精细度，解决不听话的问题</strong></p><ul><li>问题：写代码敏感性低，如不要用什么库，但容易忽略这个要求。</li><li>反事实指令(CounterFactual-Instruct)/控制变量法 <ul><li>给模型看一对孪生指令A和B，大都相同，只有小部分不同(<code>如输出格式</code>)。</li><li>训练：如果A和B输出相同，loss会高；如果不同，loss会低。</li></ul></li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251215145052.jpg" style="display:block;margin:auto;" width="70%"><h4 id="多轮sft" tabindex="-1">多轮SFT <a class="header-anchor" href="#多轮sft" aria-label="Permalink to &quot;多轮SFT&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">多轮SFT</div><p><strong>执行反馈</strong></p><ul><li>实际执行，告知对错、成本效率，可以构建自我修正数据流，无需人类介入。</li></ul><p><strong>Multi-Agent</strong></p><ul><li><strong>AIEV-Instruct</strong>：左右互搏，产生多轮对话数据 <ul><li>程序员Agent：写代码；</li><li>环境：执行代码，代码报错</li><li>提问者Agent：看报错信息，进行提问，返回给程序员Agent，进行一轮</li></ul></li><li><strong>Self-Distillation</strong>：解决<code>训练多轮</code> <code>预测单轮</code>的问题 <ul><li>问题：训练时多轮；测试时：用户可能就一轮。</li><li>数据改造：在多轮对话最后，增加<code>总结轮</code>。</li><li>训练策略 <ul><li><code>初期</code>，<code>模型全看</code>，学习中间修改过程；<code>后期</code>：<code>逐渐屏蔽中间过程</code>。</li><li>逼迫模型输出正确答案，从多轮向单轮的能力迁移。</li></ul></li></ul></li></ul></div><h4 id="仓库级sft" tabindex="-1">仓库级SFT <a class="header-anchor" href="#仓库级sft" aria-label="Permalink to &quot;仓库级SFT&quot;">​</a></h4><div class="custom-block caution"><div class="custom-block-title">仓库级SFT</div><p><strong>背景</strong></p><ul><li>仓库级SFT数据：有助于训练 <code>跨文件依赖</code>、<code>多文件编辑</code>、<code>长上下文推理</code>等<code>实际软件工程</code>的场景。</li></ul><p><strong>SWE 数据集</strong></p><ul><li><code>SWE数据</code>是训练<code>自主编程agent</code>的<code>基石数据</code>。<a href="http://plmsmile.github.io/posts/llm/industry/codellm/02-eval-task-benchmark.html#swe-%E4%BB%BB%E5%8A%A1" target="_blank" rel="noreferrer">SWE-任务 笔记</a></li><li>SWE-smith：一套<code>可扩展流程</code>，从<code>Github仓库</code>生成<code>大量的任务</code>实例，数据量比之前提高一个数量级。</li><li>SWE-synth：对上述做补充，合成<code>可验证的bug修复数据</code>。 <ul><li>生成<code>bug修复对</code>、<code>测试用例</code>和结构化的<code>修复轨迹</code>。</li></ul></li><li>SWE-Gym：提供可运行的环境和python任务示实例，RL可训练。</li><li>SWE-Dev：针对<code>feature功能开发</code>，1.4万训练数据，500评估数据</li><li>Skywork-SWE：数据scaling law，数千个实例、多个仓库。</li></ul><p><strong>代码补全和仓库导航</strong></p><ul><li>RepoBench：评估跨文件理解<code>自动补全</code>，10k Python和14k Java库。</li><li>CoEDPilot：增量式<code>代码编辑</code>，预测编辑位置，5种语言，471项目、180k的提交。</li><li>RepoSFT：引入沙盒测试，832仓库，7415个函数。</li><li>RTL-Repo：扩展至Verlog硬件描述语言，4k样本，上下文从2k到128k token。</li></ul><p><strong>挑战</strong></p><ul><li>计算成本高：执行环境成本巨大</li><li>指令和规模难平衡：</li><li>复杂多样性：不同项目之间仓库结构、依赖管理、编码规范不同，训练复杂</li></ul></div><div class="custom-block important"><div class="custom-block-title">AI黑客数据</div><p><strong>AI黑客/进攻网络安全型 数据</strong></p><ul><li>CTF(Capture The Flag)： <ul><li>给选手，一个有漏洞的程序或服务器，让其找到漏洞，并拿到一个特定字符串。</li><li>需要极强推理、工具使用能力。</li></ul></li><li>CyberZero：无环境也能训练(脑补) <ul><li>搭建训练环境麻烦，占资源。Runtime-free方法，不去运行。</li><li>从公开的CTF解题报告(Writeups)，合成高质量agent轨迹数据，反向推理环境行为。 <ul><li>根据解题报告，让<code>大模型扮演环境</code>，脑补输入这个命令，<code>输出可能的结果</code></li></ul></li></ul></li><li>CTF-Dojo：真枪实弹演练(实战流) <ul><li>把几百个CTF题目，封装进Docker容器，安全隔离。自动化构建CTF-FORGE：保证环境能跑通。</li></ul></li></ul></div><h4 id="推理方法" tabindex="-1">推理方法 <a class="header-anchor" href="#推理方法" aria-label="Permalink to &quot;推理方法&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">提示</div><p><strong>推理范式</strong></p><ul><li>转变 <ul><li>传统指令微调模型：输入 —&gt; 输出。能力来自模仿SFT</li><li>推理模型：输入 -&gt; 思考 -&gt; 输出。效果好。能力来自RLHF。</li></ul></li><li>机制 <ul><li>计算草稿纸，强迫把思考过程写出来，相当草稿纸。</li><li>不用死记硬背中间变量，注意力可以回头看之前的步骤，可以专注下一步计算。</li><li>SFT教模型学习推理思维模板，尽管一堆逻辑混乱答案错误的推理过程，微调后，也能提升。</li></ul></li></ul><p><strong>面向推理的SFT</strong></p><ul><li>三个点 <ul><li>数据<code>质量 &gt; 数量</code></li><li>选择<code>难题</code>，特点：包含探索、回溯、自我验证等。</li><li>要<code>干练精简</code>。避免CoT输出废话。训练数据剔除没用的废话。</li></ul></li></ul><p><strong>拒绝采样FT和RL</strong></p><ul><li>RFT(Rejection Sampling Fine-tuning ) <ul><li>生成多个response，通过验证器过滤，仅保留正确case，使用正确case做SFT。</li><li></li></ul></li><li>RLVR：强化学习。</li></ul></div><h4 id="训练策略和挑战" tabindex="-1">训练策略和挑战 <a class="header-anchor" href="#训练策略和挑战" aria-label="Permalink to &quot;训练策略和挑战&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">SFT 训练策略</div><p><strong>数据质量筛选</strong></p><ul><li>去重：聚类、相似度等方法。</li><li>难度和正确性：选择最难、最正确的题。</li></ul><p><strong>多任务平衡</strong></p><ul><li>分阶段训练：</li><li>并行微调：多个loss，多任务并行微调框架</li></ul><p><strong>去噪策略</strong></p><ul><li>抗噪训练：把部分输出token转换成随机噪声。</li></ul></div><div class="custom-block warning"><div class="custom-block-title">挑战</div><p><strong>数据泄露</strong></p><ul><li>微调数据包含测试集信息。</li></ul><p><strong>数据偏差</strong></p><ul><li>任务复杂性偏差，过度集中于简单任务。</li></ul><p><strong>多语言不足、数据不平衡</strong></p><ul><li>主要是python、java这些。</li></ul></div><h3 id="冷启动-数据蒸馏" tabindex="-1">冷启动/数据蒸馏 <a class="header-anchor" href="#冷启动-数据蒸馏" aria-label="Permalink to &quot;冷启动/数据蒸馏&quot;">​</a></h3><h4 id="数据源-蒸馏" tabindex="-1">数据源/蒸馏 <a class="header-anchor" href="#数据源-蒸馏" aria-label="Permalink to &quot;数据源/蒸馏&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">数据源</div><p><strong>少数高质量比数量更重要</strong></p><ul><li>OpenThouhts3：混合少量高质量多源数据效果好。StackExchange、CodeGolf、OpenCodeReasoning</li><li>LIMO/s1：mini集合</li><li>DeepMath-103k、OpenMathReasoning：从非结构化源变结构化</li><li>AceReason-Nemotron、Skywork-OR1：从数学(DeepScaler,NuminaMath)和竞赛编程数据中，收集了高质量可验证数据。RL有用。</li></ul><p><strong>发展方向</strong></p><ul><li>高质量、大规模数据。</li></ul></div><div class="custom-block note"><div class="custom-block-title">推理链生成</div><p><strong>目的</strong></p><ul><li>生成CoT、tool-integrated等<code>推理轨迹</code>，提供认知模板，指导模型学习。</li></ul><p><strong>方法：大模型蒸馏 + 格式处理</strong></p><ul><li>找SOTA模型蒸馏，处理成RL/SFT需要的格式。</li></ul><p><strong>代表工作</strong></p><ul><li>OpenThoughts3、DeepMath-103k(生成3个不同答案)、OpenMathReasoning(复杂流程、工具使用数据)</li><li>AceReason-Nemotron、Skywork-OR1：格式化答案、用于RL验证</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216104756.jpg" style="display:block;margin:auto;" width="70%"><h4 id="数据清洗-质量评估" tabindex="-1">数据清洗/质量评估 <a class="header-anchor" href="#数据清洗-质量评估" aria-label="Permalink to &quot;数据清洗/质量评估&quot;">​</a></h4><div class="custom-block important"><div class="custom-block-title">数据清洗</div><p><strong>具体工作</strong></p><ul><li>去除低质量、不完整、重复样本。</li><li>OpenMathReasoning/OpenThouths3：LLM/N-gram去重，防止污染。</li><li>Skywork-OR1/AceReason-Nemotron：过滤不适合规则验证的数据，比如证明题、多选题等、无测试用例的数据。</li><li>DeepMath-103k：LLM-Judge做去重，去掉不可验证、去掉多次回答不一致的数据。</li><li>S1：去掉太简单或太难的数据，标准：Qwen2.5-32B。</li></ul><p><strong>总结</strong></p><ul><li>LLM去重、去掉不可验证数据、去掉多次不一致数据、去掉太简单或太难数据。</li></ul></div><div class="custom-block important"><div class="custom-block-title">Query过滤和质量评估</div><ul><li>LIMO/s1：保留中档难度，过滤弱模型轻松通过的数据，仅保留强模型少数几次通过的数据。</li><li>难度分级 <ul><li>DeepMath-103k：GPT4o做难度打分(1-10分)，仅保留5分以上数据。</li><li>AceReason-Nemotron：pass rate作为难度，DeepSeek-R1-671B多次rollout来计算，过滤为0的数据</li></ul></li><li>最大化样本效率，RL需要<code>高难度可验证</code>的数据集。</li></ul></div><div class="custom-block tip"><div class="custom-block-title">答案过滤和修正</div><p><strong>背景</strong></p><ul><li>确保蒸馏生成答案的质量高。</li></ul><p><strong>基于元推理的评分</strong></p><ul><li>LIMO，基于3大特征评分，筛选出800条数据 <ul><li>Elaborated Reasoning：有无详细展开？</li><li>Self-Verification：有无自我检查？</li><li>Exploratory：有无常识不同解法。</li></ul></li></ul><p><strong>一致性验证</strong></p><ul><li>做多次(3次)，结果一致，保留。若多次结果不同，则丢掉。</li></ul><p><strong>反直觉：不过滤也很好</strong></p><ul><li>OpenThoughts3：尝试很多清洗方法，发现结果差不多。不如一起给到模型。</li></ul></div><h4 id="最终数据集总结" tabindex="-1">最终数据集总结 <a class="header-anchor" href="#最终数据集总结" aria-label="Permalink to &quot;最终数据集总结&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">最终数据集</div><ul><li>小规模、高质量数据 <ul><li>LIMO-800和 S1-1k样本</li><li>优点：精心筛选数据，<code>数据效率高</code>、<code>计算成本低</code></li></ul></li><li>大规模数据 <ul><li>OpenThought3：120万样本；DeepMath-103k，</li><li>优点：多样性好、高质量数据多，能达天花板性能</li></ul></li><li>多任务-大规模数据 <ul><li>OpenMathReasoning 10w-50w，包括CoT/TIR/Generation等，<code>多种任务</code>。</li></ul></li></ul></div><h3 id="多语言" tabindex="-1">多语言 <a class="header-anchor" href="#多语言" aria-label="Permalink to &quot;多语言&quot;">​</a></h3><div class="custom-block caution"><div class="custom-block-title">多语言CodeLLM</div><p><strong>发展</strong></p><ul><li>早期(2020-2021)：JavaBert, C-Bert。参数小，数据小。</li><li>中期(2022-2023)：Codex, AlphaCode，12B-41B，6-12种语言。</li><li>近期(2024-2025)：DeepSeek-Coder-V2：236B，338语言；StartCoder2：600+语言，4TB训练数据。</li></ul><p><strong>数据</strong></p><ul><li>从单Github数据 -&gt; <code>大规模多源数据 (10TB+)</code></li><li>GitHub, StackOverflow, CodeSearchNet, TheStack系列, The Pile, 合成书籍数据,执行轨迹,翻译语料。</li></ul><p><strong>生态</strong></p><ul><li>开源：StarCoder, DeepSeekCoder</li><li>闭源：Codex, AlphaCode</li><li>指令微调：WizadarCoder, Phind-CodeLLama</li><li>领域模型：CodeFuse, CodeShell(有中文数据)</li><li>Benchmark：VerilogEval等</li></ul><p><strong>近期趋势</strong></p><ul><li>更小的模型：phi系列-1.3B，YiCoder-1.5B</li><li>跨语言翻译：Transcoder、CodeTransOcean、PolyglotCode</li><li>多模态融合：</li><li>特定低资源/领域优化：</li></ul></div><div class="custom-block note"><div class="custom-block-title">多语言代码评估</div><p><strong>早期：python为主</strong></p><ul><li>HumanEval、MBPP，DS-1000、APPS等</li></ul><p><strong>多语言爆发</strong></p><ul><li>MultiPL-E, HumanEval-X。</li></ul><p><strong>趋势：复杂真实</strong></p><ul><li>HumanEval-XL：23自然语言、12编程语言，22k数据。</li><li>SWE-bench-multilinugal(多语言，2025), Multi-SWE-bench(多语言、多模态)，FullStackBench,。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216110144.jpg" style="display:block;margin:auto;" width="70%"><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216110207.jpg" style="display:block;margin:auto;" width="70%"><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216110805.jpg" style="display:block;margin:auto;" width="70%"><h3 id="多模态" tabindex="-1">多模态 <a class="header-anchor" href="#多模态" aria-label="Permalink to &quot;多模态&quot;">​</a></h3><p>整体benchmark</p><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216114403.jpg" style="display:block;margin:auto;" width="70%"><h4 id="vlm-for-code" tabindex="-1">VLM for Code <a class="header-anchor" href="#vlm-for-code" aria-label="Permalink to &quot;VLM for Code&quot;">​</a></h4><div class="custom-block info"><div class="custom-block-title">VLM发展</div><ul><li>早期：<code>对齐和桥接</code><ul><li>通过Connector链接VisionEncoder和LLM</li><li>CLIP, BLIP, BLIP2：轻量adpater有好效果，桥接不同模态</li><li>交错图文训练带来few-shot泛化能力：Flamingo(长上下文)、LLaVA(指令对齐训练)</li></ul></li><li>开源系列：<code>高分辨率挑战</code><ul><li>QwenVL系列：带来<code>grounding</code>(操作UI)、<code>OCR</code>(看清截图)、<code>动态分辨率能力</code>。</li><li>InternVL系列：模型、数据、test-time(推理) <code>3个维度scaling</code>。</li><li>DeepSeek-VL系列：<code>MoE架构</code>，针对真实世界截图、文档、图表等。</li></ul></li><li>基座：<code>原生多模态能力</code><ul><li>LLama-3.2-Vision：为LLaMA增加图像能力</li><li>Geemma3/Gemini，初始源自Gemini，后期Gemini增强长上下文多模态能力、agentic能力。</li><li>GPT-4v / GPT-4o / GPT5：图像理解，文本-视觉-语音，GPT5更先进。</li></ul></li></ul></div><div class="custom-block info"><div class="custom-block-title">多模态code挑战和分类</div><p><strong>多模态Code</strong></p><ul><li>输入不仅是文本，包括图像、草图和各种交互信号。</li><li>需理解视觉设计的意图、生成可执行可渲染的高质量代码</li></ul><p><strong>挑战</strong></p><ul><li>保真度：能还原视觉细节、结构层级、功能语义等。</li><li>可执行：语法正确、渲染正确、功能完整。</li></ul><p><strong>分类</strong></p><ul><li>前端界面生成：Design2Code，要求保真度。</li><li>Web具身智能：Web-agent，像人一样浏览网页，侧重可执行。</li><li>软件工程生成：UML、流程图转代码，侧重结构逻辑。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216114403.jpg" style="display:block;margin:auto;" width="70%"><h4 id="前端界面生成" tabindex="-1">前端界面生成 <a class="header-anchor" href="#前端界面生成" aria-label="Permalink to &quot;前端界面生成&quot;">​</a></h4><div class="custom-block info"><div class="custom-block-title">发展</div><p><strong>Image2Code(早期)</strong></p><ul><li>Pix2code (早期)：把GUI截图生成代码，</li></ul><p><strong>Design2Code (标准化，意图实现)</strong></p><ul><li><code>Design2Code</code>：43k <code>&lt;网页截图, HTML&gt;</code>数据，系统评估9种MLLM能力 <ul><li>评估指标：TreeBLUE、DOM-ED</li></ul></li><li><code>Prototype2Code</code>：使用Figma API 来构建9k <code>&lt;真实原型, ReAct代码&gt;</code> 数据</li></ul><p><strong>Sketch2Code (草图)</strong></p><ul><li>Sketch2Code：731个高质量手绘草图Bench，2种交互评估模式：被动接受和主动提问。</li><li>WireGen：利用llm把简单意图自动生成中等保真度的线框图wireframes</li><li>以及进一步探索在IDE中集成VLM-Code助手的可能性。</li></ul><p><strong>Interaction2Code (动态)</strong></p><ul><li>Interaction2Code：动态，大Bench，127网页、374个交互、31种类型。 <ul><li>主要4种场景MLLM效果不好：事件遗漏、逻辑错误、细节混淆、视觉细节丢失。</li></ul></li></ul></div><div class="custom-block info"><div class="custom-block-title">关键技术创新</div><p><strong>技术1：分而治之。分层生成和布局建模：</strong></p><ul><li>核心：<code>先画骨架</code>、<code>再填细节</code>。</li><li>UICopilot：把HTML生成拆分2阶段，先生成粗粒度层级、再生成细粒度标签和css，<code>降低上下文长度需求</code>。</li><li>LayoutCoder：引入关系图和布局树prompt</li><li>DesignCoder：提出UI Group Chain，自动把设计分组为嵌套的层级结构，分而治之。</li></ul><p><strong>技术2：看着改。自动反馈和自我修正Loop</strong></p><ul><li>核心：<code>Compile-Render-Clip流程</code><ul><li>先<code>检查代码能不能运行</code>，再浏览器<code>运行截图</code>，再使用<code>CLIP对比相似度</code>。</li></ul></li><li>UICoder： <ul><li>编译-渲染-CLIP 3重自动反馈机制；自检模块利用<code>浏览器截图+视觉编码器</code>来修复样式和无效逻辑。</li><li>过滤了300w合成数据做微调，7B-13B在Design2Code上提升12-18pt。</li></ul></li><li>ChatIR：上述应用到图标生成中。通过初试生成和优化2阶段，提升代码质量。</li><li>ReLook：RL框架，<code>生成-诊断-修复</code>循环，利用MLLM做critic训练。</li></ul><p><strong>技术3：像产品经理一样去思考。Agentic 工作流</strong></p><ul><li>核心：<code>草图</code> -&gt; <code>PRD</code> -&gt; <code>代码</code><ul><li>先把草图变成PRD，再根据PRD写代码。</li></ul></li><li>Fronted Diffusion <ul><li>引入外部工具，调用Pexels API 去搜索真的咖啡图，放进去。生成的页面是ready-to-use的。</li><li>自我评估：代码 -&gt; 渲染 -&gt; 自我评估 -&gt; 修改。</li></ul></li></ul></div><div class="custom-block note"><div class="custom-block-title">评估</div><ul><li>BLEU：不太行，因为可能功能没变，但分数会下降。</li><li>TreeBLEU：把HTML解析成DOM数，比较两棵树的相似度。</li><li>DOM-Edit Distance：计算从生成树变成标准答案树，需要几步操作。</li><li>Snap2Code防作弊：使用未见网站来测试。</li><li>WebUIBench：一个综合基准和评估框架，包括元素分类、视觉定位、OCR、布局理解、代码生成等。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216114424.jpg" style="display:block;margin:auto;" width="70%"><h4 id="webagent" tabindex="-1">WebAgent <a class="header-anchor" href="#webagent" aria-label="Permalink to &quot;WebAgent&quot;">​</a></h4><div class="custom-block caution"><div class="custom-block-title">WebAgent</div><p><strong>核心</strong></p><ul><li>不仅是静态代码生成。而是在真实web里，完成复杂任务，<code>observe-reason-act</code>。</li><li>需要推理、计划和环境交互等能力。</li></ul></div><div class="custom-block tip"><div class="custom-block-title">发展阶段1-3</div><p><strong>阶段1：基础框架</strong></p><ul><li>ReAct、CoT。</li><li>ToolFormer 教Agent使用工具。</li></ul><p><strong>阶段2：特定任务</strong></p><ul><li>WebShop：简单购物场景，多模态、多步推理评估。</li><li>WebArena：更真实更复杂的场景，800个<code>长规划任务</code>。</li><li>端到端多模态导航 <ul><li>WebGUM：使用Transformer(T4)+ViT，处理HTML和截图。</li><li><strong>WebVoyager(里程碑)</strong>：通过<code>截图</code>，<code>模拟人类操作网页</code>。GPT-4v做评估。</li><li>WebLINX：支持多轮对话的大Bench，150+真实网站，10w专家演示。</li></ul></li></ul><p><strong>阶段3：游戏环境</strong></p><ul><li>Minicraft (VideoPretraining)： <ul><li><strong>视频预训练</strong>：从<code>人类视频</code>中<code>学习如何行动</code>，利用少量逆动力学标注数据。</li><li>通过原生键盘和鼠标，实现long-horizon控制。</li></ul></li><li>MineDojo： <ul><li>利用互联网攻略视频作为知识库，定义多个任务。</li><li>用语言控制让agent听懂人话，知道自己做得对不对。Video-Language的Reward Shaping。</li></ul></li><li><strong>Voyager(里程碑)</strong><ul><li>通过不断进化的可执行程序库，驱动开放探索和获得终身技能。</li><li>LLM增加感知和代码执行能力后，可在复杂环境获得可复用的能力。</li></ul></li><li>V-GameGym： <ul><li><code>视觉游戏生成</code>，2219 Pygame Benchmark。</li><li><code>多模态评估</code>：代码正确性、视觉质量、游戏动态方面。</li></ul></li></ul></div><div class="custom-block tip"><div class="custom-block-title">发展阶段4-6</div><p><strong>阶段4：架构升级</strong></p><ul><li>Agent-E：层次化架构 <ul><li>复杂任务分解成 <code>planner</code> + <code>browser navigator</code></li></ul></li><li>WebDreamer：三思而后行 <ul><li>LLM作为世界模型，模拟思考动作结果，再做评估和选择最优路径。</li></ul></li></ul><p><strong>阶段5：Multi-Agent：群体智能</strong></p><ul><li>AgentVerse：通用多智能体系统框架</li><li>Voyager：在《我的世界》实现开放、连续式学习。</li><li>Generative Agents：虚拟小镇，25个智能体，模拟人类行为。大规模社会行为模拟。</li></ul><p><strong>阶段6：工具增强的多模态推理</strong></p><ul><li>使用专门的视觉模块，完成感知-动作任务。</li><li>Visual ChatGPT, MM-ReAct：<code>LLM控制</code>，<code>调用视觉模型</code>完成<code>多步推理</code>。</li><li>代码驱动：ViperGPT：通过写python代码，来解决视觉问题。</li><li>真实世界（手机&amp;通用网页） <ul><li>Mind2Web/AndroidWorld：网页指令跟随、安卓手机指令更随。</li><li>在UI-Grounding和Long-horizon上，存在挑战。</li></ul></li></ul></div><h4 id="软件工程制品生成" tabindex="-1">软件工程制品生成 <a class="header-anchor" href="#软件工程制品生成" aria-label="Permalink to &quot;软件工程制品生成&quot;">​</a></h4><p>除了代码以外，Artifacts在整个软件工程周期，都很重要</p><ul><li>Artifacts：副产品，设计文档、测试用例、UML图、需求文档等。</li></ul><div class="custom-block caution"><div class="custom-block-title">子任务和进程</div><p><strong>数据可视化: 最活跃领域</strong></p><ul><li>nvAgent(<strong>多Agent</strong>)：多agent、自然语言转可视化系统，四个角色。 <ul><li>insight miner、可视化推荐者、代码生成者、叙述生成者。</li></ul></li><li>DeepVis(交互式思维了)：CoT推理的交互式视觉界面</li><li><strong>Chart-to-Code：看图写代码，最前沿核心</strong><ul><li>Plot2Code：从科学图表 -&gt; 代码，多模态大模型</li><li>VisCoder：微调，生成可视化代码</li><li>ChartCoder：指令微调，多模态大模型，图表-&gt;代码</li><li>ChartMimic：跨模态推理能力，</li></ul></li><li>nvBench2.0：应对现实模糊指令的</li></ul><p><strong>软件图表和模型生成</strong></p><ul><li>DiagrammerGPT：plan+review，NL -&gt; 开放域图表。</li><li>Draw-with-Thought,</li><li>Flow2code：流程图-&gt;代码，15种编程语言。</li><li>Code-Vision</li><li>Unified UML Generation：从UML图像生成代码。</li><li>MM-Coder：多语言多模态软件开发，能理解设计图和文本。</li></ul><p><strong>多模态软件工程任务</strong></p><ul><li>SWE-Bench-Multimodal：<code>视觉bug修复</code>，js开发，</li><li>CodeV：利用视觉数据来解决图表相关的问题</li><li>MMCode/HumanEval-V(Benchmark)：丰富视觉信息的编程问题</li></ul></div><div class="custom-block info"><div class="custom-block-title">评估</div><p><strong>问题</strong></p><ul><li>传统pass@k，对于程序竞赛这些可以的。</li><li>但不适用于网页、前端代码等。</li></ul><p><strong>ArtifactsBench：像用户一样评估</strong></p><ul><li><strong>多模态评估</strong><ul><li><strong>渲染</strong>：执行代码，浏览器渲染起来</li><li><strong>截图</strong>：捕捉动态行为、关键帧</li><li><code>多模态评估</code>：使用GPT-4v或Gemini多模态大模型做评估。 <ul><li><code>代码正确性</code>、<code>视觉保真度</code>(颜色、字体、布局)、<code>交互完整性</code>(选题、点击、拖拽)</li></ul></li></ul></li><li>示例： “请看这个网页运行的截图和视频。任务要求是‘做一个点击会变色的红色按钮’。请根据 Checklist 评分：1. 按钮是红色的吗？ 2. 点击后变色了吗？ 3. 布局是否美观？”</li></ul></div><h4 id="趋势" tabindex="-1">趋势 <a class="header-anchor" href="#趋势" aria-label="Permalink to &quot;趋势&quot;">​</a></h4><div class="custom-block important"><div class="custom-block-title">多模态趋势</div><p><strong>广泛应用 Agentic Workflow</strong></p><ul><li>计划 -&gt; 执行 -&gt; 观察 -&gt; 反思</li><li>nvAgent -&gt; Agent-E -&gt; Frontend Diffusion 三阶段，多步骤、多模态融合。</li></ul><p><strong>自我修正&amp;迭代优化</strong></p><ul><li>自主检测和修正错误。</li><li>UICoder <code>编译-渲染-Clip </code>三重反馈，DesignCoder 浏览器截图自查</li><li>ChatIR 结构化指令，ReLook，<code>生成-诊断-精炼</code>。</li></ul><p><strong>Code-in-the-Loop 评估</strong></p><ul><li>UICoder, ArtifactsBench <code>多模态渲染评估</code>。</li></ul><p><strong>分层生成</strong></p><ul><li>UICopilot 两阶段生成，DesignCoder分层感知生成，WebDreamer 先思考再选择最佳路径。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216114432.jpg" style="display:block;margin:auto;" width="70%"><h3 id="面向rl的任务" tabindex="-1">面向RL的任务 <a class="header-anchor" href="#面向rl的任务" aria-label="Permalink to &quot;面向RL的任务&quot;">​</a></h3><h2 id="swe-agents" tabindex="-1">SWE Agents <a class="header-anchor" href="#swe-agents" aria-label="Permalink to &quot;SWE Agents&quot;">​</a></h2><h3 id="各生命周期" tabindex="-1">各生命周期 <a class="header-anchor" href="#各生命周期" aria-label="Permalink to &quot;各生命周期&quot;">​</a></h3><h4 id="需求分析" tabindex="-1">需求分析 <a class="header-anchor" href="#需求分析" aria-label="Permalink to &quot;需求分析&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">需求分析</div><p><strong>痛点：需求是模糊的</strong></p><ul><li><p>最难的是<strong>搞清楚到底要写什么</strong>。人类客户说的话往往是<code>模糊、矛盾、不完整</code>的。</p></li><li><p><strong>传统做法：</strong> 靠产品经理（PM）和业务分析师（BA）去开会、吵架、画图、确认。</p></li><li><p><strong>Agent 做法：</strong> 用 AI 扮演不同角色来模拟这个过程。</p></li></ul><p><strong>Agent 如何解决四个阶段的问题</strong></p><ul><li><strong>第一阶段：获取（怎么知道用户想要什么？）</strong><ul><li><strong>思路：</strong> 既然找不到那么多真实用户来访谈，那就造<strong>虚拟用户</strong>。</li><li><strong>黑科技 (Elicitron)：</strong> AI 扮演挑剔的用户，去试用产品原型，然后 AI 采访 AI，问它“你觉得哪里不爽？”。这样可以挖掘出人类可能没想到的隐性需求。</li></ul></li><li><strong>第二阶段：审查（需求打架了怎么办？）</strong><ul><li><strong>思路：</strong> 既然人类团队通过开会吵架来达成一致，那就搞个<strong>虚拟团队</strong>来吵架。</li><li><strong>黑科技 (MAD - Multi-Agent Debate)：</strong> 一个 Agent 扮红脸（提需求），一个 Agent 扮白脸（挑刺），还有一个 Agent 当法官。通过“左右互搏”，把逻辑漏洞和不合理的需求在写代码之前就辩论清楚。</li></ul></li><li><strong>第三阶段：形式化（怎么把话变成图？）</strong><ul><li><strong>思路：</strong> 程序员喜欢看图（UML、UI设计稿），不喜欢看长篇大论的文档。</li><li><strong>黑科技 (PrototypeFlow)：</strong> 给 AI 一段文字描述，它直接生成 UI 设计图，甚至生成代码结构。实现了从“自然语言”到“工程语言”的翻译。</li></ul></li><li><strong>第四阶段：确认（做出来的东西对不对？）</strong><ul><li><strong>思路：</strong> 上线前需要大量测试，但请人测试很贵。</li><li><strong>黑科技 (UXAgent)：</strong> 这是一个“人海战术”。生成 1000 个性格、背景各异的 AI 虚拟用户，让它们去疯狂点击你的 App。它们不仅不会累，还能给出详细的“用户体验报告”。</li></ul></li></ul><p><strong>总结：AI 在软件工程中的角色跃迁</strong></p><ul><li><p><strong>软件工程 Agent 正在向左移（Shift Left）。</strong></p><ul><li><p>以前的 AI（如 Copilot）：帮你<code>补全代码</code>（开发阶段）。</p></li><li><p>现在的 AI（如 SWE-Agent）：<code>帮你修 Bug</code>（测试/维护阶段）。</p></li><li><p><strong>未来的 AI（本节内容）：</strong> 帮你<code>做产品设计</code>、<code>需求分析</code>（需求阶段）。</p></li></ul></li></ul><p>这意味着 AI 开始具备了<strong>同理心（模拟用户）</strong>、<strong>批判性思维（多智能体辩论）<strong>和</strong>全局规划能力（端到端流程）</strong>。</p></div><h4 id="软件开发-程序合成" tabindex="-1">软件开发-程序合成 <a class="header-anchor" href="#软件开发-程序合成" aria-label="Permalink to &quot;软件开发-程序合成&quot;">​</a></h4><p><strong>程序合成</strong></p><div class="custom-block tip"><div class="custom-block-title">程序合成 AI写的</div><p>程序合成 Agent 远不止是我们在 IDE 里见到的代码补全（如 Copilot）。它们通过引入<strong>多步推理</strong>、<strong>基于测试的验证</strong>和<strong>反馈驱动的优化循环</strong>，试图从零开始构建完整的程序，而且尽量不需要人插手。</p><p><strong>1. 问题定义（图 28）：</strong></p><ul><li><strong>输入：</strong> 需求文档（自然语言描述、图表）+ 测试用例。</li><li><strong>输出：</strong> 一个能跑通所有测试的完整程序。</li><li><strong>要求：</strong> 自主完成，中间可能需要自己推理、自己改错。</li></ul><p><strong>2. 架构设计：一个好汉 vs 三个帮</strong> 目前的 Agent 架构主要分两派：</p><ul><li><strong>单智能体迭代系统 (Single-Agent Iterative Systems)：</strong><ul><li><strong>原理：</strong> 一个 AI 分饰多角。自己想、自己写、自己测、自己改。</li><li><strong>代表作 (AlphaCodium)：</strong> 它不急着写代码，而是先用自然语言写个草稿，分析潜在坑点，然后再写代码。写完自己跑测试，报错了再自己改。</li><li><strong>优点：</strong> 简单，思维连贯（毕竟是同一个脑子在想）。</li><li><strong>缺点：</strong> 容易当局者迷，很难发现自己思维的盲区。</li></ul></li><li><strong>多智能体流水线 (Multi-Agent Pipelines)：</strong><ul><li><strong>原理：</strong> 术业有专攻。</li><li><strong>代表作 (PyCapsule, MapCoder, ChatDev)：</strong><ul><li><strong>程序员 (Coder)：</strong> 只管写代码。</li><li><strong>测试员 (Executor/Tester)：</strong> 只管跑代码，报错了把错误信息甩给程序员。</li><li><strong>产品经理/规划师 (Planner)：</strong> 负责拆解任务。</li></ul></li><li><strong>优点：</strong> 分工明确，测试员的反馈更加客观，能模拟真实团队协作。</li><li><strong>缺点：</strong> 沟通成本高（Token 消耗大），容易出现信息传递误差。</li></ul></li></ul><p><strong>3. 核心引擎：反馈驱动的代码搜索 (Feedback as the Engine)</strong> Agent 成功的秘诀不在于一次写对，而在于<strong>怎么改对</strong>。反馈（Feedback）就是把“生成”变成“搜索”的关键。 文中提出了四种“改代码”的策略：</p><ul><li><strong>策略 A：并行采样 (Parallel Sampling / Best-of-N)</strong><ul><li><strong>做法：</strong> 既然 AI 每次发挥不稳定，那就一次性生成 100 个不同的版本。</li><li><strong>筛选：</strong> 挑出那个能跑通最多测试用例的版本。</li><li><strong>代价：</strong> 费钱（算力消耗大）。</li></ul></li><li><strong>策略 B：迭代优化 (Iterative Refinement)</strong><ul><li><strong>做法：</strong> 写完一版 -&gt; 跑测试 -&gt; 报错 -&gt; 根据错误信息修改 -&gt; 再跑测试。</li><li><strong>经验：</strong> 通常改 1-3 轮效果最好，改多了还没对，说明思路彻底错了，再改也是徒劳。</li></ul></li><li><strong>策略 C：混合搜索 (Hybrid Search)</strong><ul><li><strong>做法：</strong> 结合 A 和 B。先生成几个版本，然后对每个版本进行几轮小修小补。最后搞个“比武招亲”，看谁最强。</li><li><strong>效果：</strong> 这种方法最强，能在 LiveCodeBench 这种高难度榜单上拿高分，甚至让小模型战胜大模型。</li></ul></li><li><strong>策略 D：基于一致性的重排序 (Consistency-based Re-ranking)</strong><ul><li><strong>做法：</strong> 让模型用不同的方式思考同一个问题（比如先写文档再写代码，或者先写测试再写代码）。如果殊途同归，得出的结果一致，说明这个结果大概率是对的。</li></ul></li></ul><p><strong>4. 进阶挑战：从函数到仓库 (Scaling to Repository-Level)</strong> 写一个函数容易，写一个完整的 GitHub 仓库（Repository）很难。</p><ul><li><strong>难点：</strong> 依赖关系复杂（A文件调用B文件），上下文太长（塞不进 Prompt）。</li><li><strong>解决方案：</strong><ul><li><strong>依赖图 (Dependency Graph)：</strong> Agent 需要先画出代码的依赖关系图，按照拓扑顺序（先写底层的，再写上层的）来写代码。</li><li><strong>环境集成 (Tool-Integrated)：</strong> 必须把 Agent 扔进真实的 IDE 或沙箱环境里（如 OpenHands），让它能像人一样浏览文件、运行终端命令。</li></ul></li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216162930.jpg" style="display:block;margin:auto;" width="70%"><p><strong>程序分析</strong></p><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216162920.jpg" style="display:block;margin:auto;" width="70%"><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216162812.jpg" style="display:block;margin:auto;" width="70%"><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216163025.jpg" style="display:block;margin:auto;" width="70%"><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216163037.jpg" style="display:block;margin:auto;" width="70%"><h4 id="软件开发-程序编辑" tabindex="-1">软件开发-程序编辑 <a class="header-anchor" href="#软件开发-程序编辑" aria-label="Permalink to &quot;软件开发-程序编辑&quot;">​</a></h4><p>分为<code>补丁生成(Patch Generation)</code>和<code>问题解决(Issue Resolution)</code>。</p><div class="custom-block note"><div class="custom-block-title">Patch Generation</div><p><strong>任务定义</strong></p><ul><li>给一个有bug的代码片段，自动生成一个<code>修复补丁Patch</code>。</li><li>自动程序修复<code>最核心步骤</code>。</li></ul><p><strong>技术演进1：微调和Prompt工程</strong></p><ul><li>核心：使用<code>bug-patch</code>数据做SFT提升能力，或使用CoT Prompt引导模型一步步推理Bug原因。</li><li>相关工作：RepairLLaMA、AlphaRepair。</li></ul><p><strong>技术演进2：任务转化</strong></p><ul><li>核心：把修Bug转为其他形式的问题。 <ul><li>完形填空：Mask bug代码，让模型填空Infilling。</li><li>机器翻译：把Bug代码翻译成正确代码。</li></ul></li><li>相关工作：Recoder、NSEdit。</li></ul><p><strong>技术演进3：静态分析和模板指导</strong></p><ul><li>背景：LLM有时会乱改，破坏原有逻辑。</li><li>核心方法：很多bug有固定模式，先让工具做匹配，再让LLM填空。</li></ul><p><strong>技术演进4：RAG增强</strong></p><ul><li>背景：可能之前有人遇到过类似的bug</li><li>核心：遇到bug时，先去代码库、StackOverFlow等地方，检索到类似方案，再作为Prompt给到LLM。</li><li>相关工作：InferFix、RAP-Gen</li></ul><p><strong>技术演进5：多智能体和对话流</strong></p><ul><li>核心：像人类一样修bug，一个交互的流程。<code>最前沿方向</code>。</li><li>1：对话式修复 <ul><li>ChatRepair, Conversational APR</li><li>AI 写代码 -&gt; 跑测试 -&gt; 报错 -&gt; AI 读报错信息 -&gt; AI：“哦，我懂了，这里越界了” -&gt; AI 再写代码。</li><li>利用对话来维护上下文，报错信息变成线索</li></ul></li><li>2：闭环反馈 <ul><li>整合<code>bug定位</code>、<code>Patch生成</code>、<code>测试验证</code>到一个循环，协调多个agent或工具去动态修复。</li><li>该代码、找bug、跑测试，一个闭环。</li><li>相关工作：RepairAgent、ITER</li><li>RepairAgent：把修bug编程一个Agent的自主任务，可以调用工具、定位错误、搜索方案。</li></ul></li><li>3：仓库级多Agent协作 <ul><li>相关工作：AutoCoderRover、PathPilot、MarsCodeAgent。</li><li>仓库级修复、多agent规划、全项目代码搜索、执行验证，模拟开发工作流。</li></ul></li><li>4：带记忆的持久学习 <ul><li>结合记忆组件，之前的修复经验，进行修复。</li><li>相关工作：ExpeRepair、SpecRover(规范判断)。</li></ul></li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216163057.jpg" style="display:block;margin:auto;" width="70%"><div class="custom-block note"><div class="custom-block-title">Issue Resolving 问题定义</div><p><strong>问题定义</strong></p><ul><li>Patch 生成：给一段代码，修好它，局部的。</li><li><strong>Issue 解决</strong>：给一个Github Issue，自己仓库里<code>找代码</code>、<code>找定位</code>、<code>修复</code>、<code>测试</code>、<code>提交PR</code>。<code>全局</code>的。</li><li>核心流程： <ul><li><code>Fault Localization</code>：在几百个文件里，找到哪一行代码导致bug。最难。</li><li><code>Program Editing</code>：修改代码，生成补丁。</li><li><code>Validation</code>：跑测试用例，确保bug修好、且没有新bug。</li></ul></li></ul><p><strong>技术演进</strong></p><ul><li>基础：AI使用工具</li><li>进阶：AI学会分工，多智能体架构</li><li>高级：AI拥有记忆和反思能力。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216163118.jpg" style="display:block;margin:auto;" width="70%"><div class="custom-block note"><div class="custom-block-title">Issue Resolving - Code Agent</div><p><strong>基础接口层</strong></p><ul><li><a href="https://github.com/SWE-agent/SWE-agent" target="_blank" rel="noreferrer">SWE-Agent</a>、<a href="https://github.com/OpenHands/OpenHands" target="_blank" rel="noreferrer">OpenHands</a>：LLM as agent 概念，把LLM作为新用户，设计了ACI接口。</li><li><strong>Agent-Computer Interface</strong><ul><li><strong>简化命令</strong>：设计了一套<code>LLM容易理解</code>且不容易写错的<code>特殊指令</code>。</li><li><strong>环境反馈优化</strong>：<code>筛选关键错误信息</code>给到模型，并非给全部错误，解决上下文爆炸问题。</li><li><strong>保护机制</strong>： <ul><li><code>自动回滚</code>：AI改坏代码导致环境崩溃，ACI能自动检测并<code>恢复到上一个版本</code>。</li><li><code>动态历史折叠</code>：历史记录会变长，ACI可以自动总结隐藏不必要历史操作，<code>只保留关键记忆</code>。</li></ul></li></ul></li></ul><p><strong>架构层</strong></p><ul><li>单Agent难以管理多文件、依赖、复杂工作流，需要模块化协作架构。</li><li>模块化：<code>代码理解</code>、<code>依赖分析</code>、<code>故障定位</code>、<code>补丁生成</code>、<code>验证</code>。</li><li>多角色协作方法 <ul><li>(2403) <a href="https://arxiv.org/abs/2403.17927" target="_blank" rel="noreferrer">Magis</a>：经理、仓库管理员、开发、QA。</li><li>优点：利用记忆和检索工具(BM25)，适合处理多文件复杂修改。</li></ul></li><li>设计Pipeline：简化和专业化 <ul><li>(2406) <a href="https://arxiv.org/abs/2406.01304" target="_blank" rel="noreferrer">CodeR</a>：使用预定义好的任务图来协调agent。</li><li>(2404) <a href="https://arxiv.org/abs/2404.05427" target="_blank" rel="noreferrer">AutoCoderRover</a>, (2409) <a href="https://arxiv.org/abs/2409.00899" target="_blank" rel="noreferrer">MarseCode Agent</a>： <ul><li>使用高级工具和复杂数据结构，辅助AI理解代码。代码知识图谱、LSP、AutoDiff等。</li></ul></li><li>(2407) <a href="https://arxiv.org/abs/2407.01489" target="_blank" rel="noreferrer">AgentLess</a>：写死流程，三阶段：定位、修复和验证。</li><li>(2501) <a href="https://arxiv.org/abs/2501.05040" target="_blank" rel="noreferrer">SWE-Fixer</a>：侧重于检索策略，先粗找、再精细找。</li><li>(2505) <a href="https://arxiv.org/abs/2505.18955" target="_blank" rel="noreferrer">Co-PatchR</a>：小模型协作。</li></ul></li></ul><p><strong>知识层</strong></p><ul><li>背景：加深对代码语义和依赖关系的理解。因此<code>结构化知识建模</code>，特别是把<code>代码库</code>表示成<code>图</code>，有用。</li><li>方法 <ul><li>(2408) <a href="https://arxiv.org/abs/2408.03910" target="_blank" rel="noreferrer">CodexGraph</a>：把代码存进图数据集，写sql去查询出相关代码。</li><li>(2503) <a href="https://arxiv.org/abs/2503.21710" target="_blank" rel="noreferrer">KGCompass</a>：图谱有代码和Issue，能通过图连接，找到相关代码节点。</li><li>(2505) <a href="https://arxiv.org/abs/2505.16901" target="_blank" rel="noreferrer">CGM</a>：Graph-RAG，修改注意力，关注看图谱部分。</li><li>(2406) <a href="https://arxiv.org/abs/2406.01422" target="_blank" rel="noreferrer">LingmaAgent</a>：MCTS搜索数。</li></ul></li></ul><p><strong>语义层</strong></p><ul><li>背景：传统代码生成只关注代码正确性，即没有编写错误。但没有考虑语义即逻辑错误。</li><li>作用：通过语义层分析，理解根本愿意和意图，避免模型骗过测试用例来生成代码，而是真正修复bug。结果更鲁棒和泛化。</li><li>工作 <ul><li>(2506) <a href="https://arxiv.org/abs/2506.16650" target="_blank" rel="noreferrer">SemAgent</a>：多维语义融合(问题+代码+执行结果)</li><li>(2408) <a href="https://arxiv.org/abs/2408.02232" target="_blank" rel="noreferrer">SpecRover</a>：分析现有测试用例程序结构，反向推断出代码规范，强调可解释性，告知为何补丁是对的。</li><li>(2504) <a href="https://github.com/NVIDIA/Nemotron-CORTEXA" target="_blank" rel="noreferrer">Nemotron-CORREXA</a>：通过AST+LSP等工具构建代码关系图谱。利用集成学习和多步推理。</li></ul></li></ul><p><strong>智能层</strong></p><ul><li>背景：基础修复解决后，希望系统<code>持续学习</code>和<code>自我进化</code>。</li><li>工作 <ul><li>(2507) <a href="https://arxiv.org/abs/2507.23361" target="_blank" rel="noreferrer">SWE-EXp</a>：从成败经验中学习，构建多维经验库，使用MCTS推演可能性，做出最优决策。</li><li>(2507) <a href="https://arxiv.org/abs/2507.23348" target="_blank" rel="noreferrer">SWE-Debate</a>：多视角对抗，通过辩论排除错误路径，定位更精准。</li><li>(2508) <a href="https://arxiv.org/abs/2508.02085" target="_blank" rel="noreferrer">SE-Agent</a>：通过3步迭代，修改-重组-完善，不断打磨。</li></ul></li></ul></div><p><strong>ACI 接口</strong> 示意图</p><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216163127.jpg" style="display:block;margin:auto;" width="70%"><p>Issue Resolving 典型workflow示例：</p><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216163143.jpg" style="display:block;margin:auto;" width="70%"><h4 id="软件测试" tabindex="-1">软件测试 <a class="header-anchor" href="#软件测试" aria-label="Permalink to &quot;软件测试&quot;">​</a></h4><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216171237.jpg" style="display:block;margin:auto;" width="70%"><div class="custom-block info"><div class="custom-block-title">软件测试</div><p><strong>背景</strong></p><ul><li>验证成本低：LLM写测试代码，运行，即可返回对不对。</li><li>反馈闭环明确：报错信息和覆盖率报告很清晰，LLM擅长阅读这些反馈并做自我修正。</li></ul><p><strong>核心技术</strong></p><ul><li><strong>Level 1: 能写出来 (Capability)</strong><ul><li><em>代表</em>：直接把代码扔给 GPT-3，让它生成测试。</li><li><em>问题</em>：生成的测试可能跑不通，或者只是样子货（没有断言，Assert True）。</li></ul></li><li><strong>Level 2: 写得好 (Quality &amp; Coverage)</strong><ul><li><em>代表</em>：<strong>CodaMosa</strong>。</li><li><em>逻辑</em>：传统 Fuzzing 工具（如 AFL）擅长生成随机数据，但不擅长通过复杂的 <code>if (x == &quot;magic_string&quot;)</code> 检查。LLM 擅长理解代码逻辑。CodaMosa 结合两者，当传统工具卡住时，让 LLM 生成代码来突破覆盖率瓶颈。</li></ul></li><li><strong>Level 3: 自主修测试 (Iterative / Feedback-loop)</strong><ul><li><em>代表</em>：<strong>ChatUniTest</strong>, <strong>HITS</strong>。</li><li><em>逻辑</em>：人类写测试从来不是一次写对的。AI 也是。现在的 Agent 会先写一个版本，运行，发现报错 <code>NameError</code>，然后自己读取报错，修正代码，直到测试通过。这就是文中提到的从 One-shot 到 Multi-step 的转变。</li></ul></li><li><strong>Level 4: 安全与攻击 (Fuzzing)</strong><ul><li><em>逻辑</em>：不仅要测“功能对不对”，还要测“能不能被黑掉”。LLM 被用来生成更有针对性的攻击数据（恶意输入），比随机生成的乱码更有效。</li></ul></li></ul></div><h4 id="软件维护" tabindex="-1">软件维护 <a class="header-anchor" href="#软件维护" aria-label="Permalink to &quot;软件维护&quot;">​</a></h4><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216163223.jpg" style="display:block;margin:auto;" width="70%"><div class="custom-block caution"><div class="custom-block-title">软件维护 (AI写的)</div><p>A. 从“翻译”到“理解”：反编译与日志分析</p><ul><li><strong>日志分析的进化</strong>：以前的日志分析是“关键词搜索”（出现 <code>Error</code> 就报警）。现在的 Agent 是**“运维侦探”**。它看到报错后，会自己去查知识库、去对比历史日志、去分析代码变更，然后告诉你：“这个错误是因为昨天张三提交的 DB 配置改动导致的。”</li><li><strong>反编译的进化</strong>：以前的反编译是“硬翻译”。现在的 LLM 是**“脑补大师”**。它看到 <code>v1 = v2 + v3</code>，结合上下文发现这是个银行转账逻辑，它会把代码重构成 <code>balance = old_balance + deposit</code>。这极大地降低了逆向工程的门槛。</li></ul><p>B. 编译器优化：AI 的“炼丹炉”</p><p>编译器优化本质上是一个在一个巨大的搜索空间里找最优解的问题。</p><ul><li>LLM 和 RL（强化学习）在这里表现出色，因为它们可以像下围棋一样，探索成千上万种编译器参数的组合，往往能发现人类专家都想不到的优化路径。这是 <strong>AI for Systems（AI 用于系统优化）</strong> 的经典案例。</li></ul><p>C. DevOps：从脚本到“数字员工”</p><ul><li>在传统的 DevOps 中，如果构建失败了，流水线就停了，得等人来修。</li><li>在 <strong>Agentic DevOps</strong> 中，<strong>AutoDev</strong> 这样的系统就像一个<strong>数字员工</strong>。构建失败了？它会自己看报错日志，如果是环境问题它就重启环境，如果是代码语法错误它甚至能尝试自动修复，然后再次提交构建。它变被动为主动。</li></ul></div><h4 id="端到端软件agent" tabindex="-1">端到端软件agent <a class="header-anchor" href="#端到端软件agent" aria-label="Permalink to &quot;端到端软件agent&quot;">​</a></h4><table tabindex="0"><thead><tr><th style="text-align:left;">特性</th><th style="text-align:left;">瀑布流模式 (Waterfall)</th><th style="text-align:left;">敏捷迭代模式 (Agile)</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>代表</strong></td><td style="text-align:left;">ChatDev, MetaGPT</td><td style="text-align:left;">AgileCoder, LCG</td></tr><tr><td style="text-align:left;"><strong>工作方式</strong></td><td style="text-align:left;">线性流水线 (A -&gt; B -&gt; C -&gt; D)</td><td style="text-align:left;">循环迭代 (Plan -&gt; Code -&gt; Test -&gt; Plan...)</td></tr><tr><td style="text-align:left;"><strong>优点</strong></td><td style="text-align:left;">结构清晰，SOP 标准化，适合明确的小任务</td><td style="text-align:left;">灵活，容错率高，适合复杂、需求模糊的任务</td></tr><tr><td style="text-align:left;"><strong>缺点</strong></td><td style="text-align:left;">上游犯错，下游买单；缺乏灵活性</td><td style="text-align:left;">流程复杂，Token 消耗大，管理难度高</td></tr><tr><td style="text-align:left;"><strong>人类隐喻</strong></td><td style="text-align:left;">传统外包工厂</td><td style="text-align:left;">现代互联网创业团队</td></tr></tbody></table><h3 id="swe中的通用agent" tabindex="-1">SWE中的通用Agent <a class="header-anchor" href="#swe中的通用agent" aria-label="Permalink to &quot;SWE中的通用Agent&quot;">​</a></h3><p>希望构建一个Agent，能跨越整个软件开发周期，而不是只为一个任务做的agent。</p><div class="custom-block tip"><div class="custom-block-title">SWE-通用Agent</div><p><strong>核心能力</strong></p><ul><li>多轮交互：和人类对话、确认需求、汇报进度。</li><li>上下文跟踪：记住项目结构、修改记录、用户偏好配置等等。</li><li>工具调用：需要操作终端、读写文件、运行git命令、调用编译器等。</li></ul></div><div class="custom-block tip"><div class="custom-block-title">SWE-通用Agent 主要工作</div><ul><li>(2402) <a href="https://arxiv.org/abs/2402.01030" target="_blank" rel="noreferrer">CodeAct</a>：Code as Action，<code>直接让模型写代码</code>，再结合解释器去执行代码。</li><li>(2407) <a href="https://arxiv.org/abs/2407.16741" target="_blank" rel="noreferrer">OpenHands</a>：标准化的交互环境，<code>Docker沙盒环境</code>。可写代码、操作终端和浏览。</li><li>(24) <a href="https://github.com/opencode-ai/opencode" target="_blank" rel="noreferrer">OpenCode</a>：SOP <code>多智能体</code>，Plan+Build+General Agent，推理和行动解耦，提高稳定性。</li><li>(24) <a href="https://aider.chat/" target="_blank" rel="noreferrer">Aider</a>：极致的工程化，构建代码地图解析文件依赖关系、提交代码前先运行和测试，自己修复，提高可用性。</li><li>(24) <a href="https://www.augmentcode.com/" target="_blank" rel="noreferrer">Augment</a>：极致上下文引擎，实时的语义化的索引系统。个性化记忆+工业级速度准确性。</li><li>(2507) <a href="https://arxiv.org/abs/2507.23370" target="_blank" rel="noreferrer">Trae Agent</a>：Code Generation as Search，生成-剪枝-选择。同时生成多个方案，选择最合适的。</li><li>(25) <a href="https://refact.ai/" target="_blank" rel="noreferrer">Refact Agent</a>：全生命周期和隐私安全。自托管和全流程集成。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216163604.jpg" style="display:block;margin:auto;" width="70%"><h3 id="训练swe-agent" tabindex="-1">训练SWE-Agent <a class="header-anchor" href="#训练swe-agent" aria-label="Permalink to &quot;训练SWE-Agent&quot;">​</a></h3><h4 id="sft-微调-swe-agent" tabindex="-1">SFT 微调 SWE-Agent <a class="header-anchor" href="#sft-微调-swe-agent" aria-label="Permalink to &quot;SFT 微调 SWE-Agent&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">数据</div><p><strong>整体思想</strong></p><ul><li>不直接使用原数据，而是对数据做精炼合成。 <ul><li>过滤噪声，通过执行来验证正确性，从0开始构建完整结构化实例。</li><li>结构化实例：用户需求-&gt;需求拆解-&gt;代码实现-&gt;测试用例-&gt;修复bug。</li></ul></li></ul><p><strong>数据过滤</strong></p><ul><li>过滤：<a href="https://arxiv.org/abs/2502.02757" target="_blank" rel="noreferrer">paper</a><ul><li>背景：PR中充满许多 “Thanks、Great Job”这种无效评论。</li><li>LLM作为分类器，去掉<code>不可操作/无实质内容</code>的，仅保留<code>明确指出错误</code>的comment。</li></ul></li></ul><p><strong>数据合成</strong></p><ul><li><p>从<code>真实commit历史</code>里，合成逼真的bug，<code>故障定位-bug修复</code> ，来<code>增强数据集</code>。</p></li><li><p><strong>执行验证的数据增强</strong></p><ul><li>Rollout多个轨迹，通过<code>执行反馈</code>来筛选正确数据。</li><li>相关工作：CodeS、SPICE、RewardRepair。</li></ul></li><li><p><strong>端到端数据合成</strong></p><ul><li>(2503) <a href="https://arxiv.org/abs/2503.02240" target="_blank" rel="noreferrer">OminiSQL</a>：先造库、造答案，再造问题，再CoT思考解题思路，最后做过滤。</li><li>(2506) <a href="https://arxiv.org/abs/2506.09003" target="_blank" rel="noreferrer">SWE-Flow</a>：把大任务拆解成多个步骤。step2依赖step1，动态演进代码库。</li><li>(2305) <a href="https://blog.research.google/2023/05/large-sequence-models-for-software.html." target="_blank" rel="noreferrer">DIDACT</a></li></ul></li></ul></div><div class="custom-block note"><div class="custom-block-title">训练目标</div><p><strong>多任务和课程学习</strong></p><ul><li>Comment生成前，先<code>混合训练</code>：MLM、Diff Tag 预测、Code 去噪等任务。</li><li>Patch 生成：也会使用多任务学习</li></ul><p><strong>结构感知：分而治之</strong></p><ul><li>比如SQL：先生成骨架，再填空。</li></ul><p><strong>专门的学习范式</strong></p><ul><li>故障定位：用对比学习来区分bug相关和不相关的代码，拉进正样本距离，拉开负样本距离。</li></ul></div><div class="custom-block note"><div class="custom-block-title">训练模式</div><ul><li>LoRA</li><li>多阶段训练、持续学习。</li><li>直接微调/特定任务。依赖特定数据集。</li></ul></div><h4 id="rl-学习-swe-agent" tabindex="-1">RL 学习 SWE-Agent <a class="header-anchor" href="#rl-学习-swe-agent" aria-label="Permalink to &quot;RL 学习 SWE-Agent&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">RL 算法</div><p><strong>策略梯度</strong></p><ul><li>ITER/RepairAgent：根据当前状态，来确定下一步动作。(retest、尝试不同patch、重新定位故障等)</li></ul><p><strong>Offline RL</strong></p><ul><li>背景：在线可能太慢了，比如编译代码1分钟、跑Benchmark 10分钟。</li><li>核心技术： <ul><li><code>世界模型</code>：基于历史数据训练世界模型，从世界模型中学习，避免真实交互。CompilerDream。</li><li><code>从历史数据中学习</code>：把历史数据构建成一个大的数据集，从中学习。RewardReapair。 <ul><li>包括bug报告、代码变更、测试结果等。</li></ul></li></ul></li></ul><p><strong>Value-based &amp; 偏好学习</strong></p><ul><li>RLHF：训练一个奖励模型，<code>偏好/主观打分</code>。如CodeMentor。</li><li>Multi-agent 辩论：使用裁判模型，来判断谁的论据更扎实。</li></ul></div><div class="custom-block note"><div class="custom-block-title">奖励设计</div><p><strong>自动程序修复 Auto Program Repair</strong></p><ul><li>RewardRepair, Relfxion, ITER：连续生成和验证的循环</li></ul><p><strong>编译器优化</strong></p><ul><li>不同排序优化对代码编译速度有影响。</li><li>奖励：代码编译速度提升。</li></ul><p><strong>安全和漏洞管理</strong></p><ul><li>基于模糊测试的循环，Fuzzing</li><li>多智能体辩论，Audit-LLM</li></ul></div><div class="custom-block note"><div class="custom-block-title">SFT &amp; RL</div><p><strong>SFT 是RL的地基/冷启动</strong></p><ul><li>通过高质量标注数据，初始化策略，缩小搜索空间。但是会导致探索不足吗？</li><li>SFT引导，教会模型目标任务的基本语法语义等内容，缩小RL空间。AlphaRepair、RewardRepair。</li></ul><p><strong>SFT 和 RL的战略平衡</strong></p><ul><li>SFT训太久，就会死记硬背，不探索，导致RL无效。</li></ul><p><strong>循环式改进数据驱动</strong></p><ul><li>SFT -&gt; RL -&gt; 高质量探索样本 -&gt; SFT -&gt; RL</li></ul></div><h3 id="未来趋势-1" tabindex="-1">未来趋势 <a class="header-anchor" href="#未来趋势-1" aria-label="Permalink to &quot;未来趋势&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">全能+记忆好+会成长+听话+安全</div><p><strong>专用agent到全周期的通用Agent</strong></p><ul><li>ChatDev, MetaGPT, AgileCoder</li></ul><p><strong>实现深度上下文和长期记忆</strong></p><p><strong>多智能体、自我进化</strong></p><p><strong>人机协作</strong></p><p><strong>信任、安全、可验证</strong></p></div><h2 id="code-通用助手" tabindex="-1">Code 通用助手 <a class="header-anchor" href="#code-通用助手" aria-label="Permalink to &quot;Code 通用助手&quot;">​</a></h2><h3 id="code作为交互协议" tabindex="-1">Code作为交互协议 <a class="header-anchor" href="#code作为交互协议" aria-label="Permalink to &quot;Code作为交互协议&quot;">​</a></h3><h4 id="tool-use" tabindex="-1">Tool Use <a class="header-anchor" href="#tool-use" aria-label="Permalink to &quot;Tool Use&quot;">​</a></h4><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216163654.jpg" style="display:block;margin:auto;" width="70%"><h4 id="mcp-协议" tabindex="-1">MCP 协议 <a class="header-anchor" href="#mcp-协议" aria-label="Permalink to &quot;MCP 协议&quot;">​</a></h4><h4 id="multi-agent协议" tabindex="-1">Multi-Agent协议 <a class="header-anchor" href="#multi-agent协议" aria-label="Permalink to &quot;Multi-Agent协议&quot;">​</a></h4><h3 id="code-作为-agentic-能力" tabindex="-1">Code 作为 Agentic 能力 <a class="header-anchor" href="#code-作为-agentic-能力" aria-label="Permalink to &quot;Code 作为 Agentic 能力&quot;">​</a></h3><h4 id="thinking-in-code" tabindex="-1">Thinking in Code <a class="header-anchor" href="#thinking-in-code" aria-label="Permalink to &quot;Thinking in Code&quot;">​</a></h4><h4 id="acting-in-code" tabindex="-1">Acting in Code <a class="header-anchor" href="#acting-in-code" aria-label="Permalink to &quot;Acting in Code&quot;">​</a></h4><h4 id="memory-with-code" tabindex="-1">Memory with Code <a class="header-anchor" href="#memory-with-code" aria-label="Permalink to &quot;Memory with Code&quot;">​</a></h4><h3 id="code作为环境接口" tabindex="-1">Code作为环境接口 <a class="header-anchor" href="#code作为环境接口" aria-label="Permalink to &quot;Code作为环境接口&quot;">​</a></h3><h4 id="模拟gym环境" tabindex="-1">模拟Gym环境 <a class="header-anchor" href="#模拟gym环境" aria-label="Permalink to &quot;模拟Gym环境&quot;">​</a></h4><h4 id="computer-use-agent" tabindex="-1">Computer-Use Agent <a class="header-anchor" href="#computer-use-agent" aria-label="Permalink to &quot;Computer-Use Agent&quot;">​</a></h4><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216163917.jpg" style="display:block;margin:auto;" width="70%"><h2 id="代码安全" tabindex="-1">代码安全 <a class="header-anchor" href="#代码安全" aria-label="Permalink to &quot;代码安全&quot;">​</a></h2><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216163943.jpg" style="display:block;margin:auto;" width="70%"><h2 id="训练技巧" tabindex="-1">训练技巧 <a class="header-anchor" href="#训练技巧" aria-label="Permalink to &quot;训练技巧&quot;">​</a></h2><div class="custom-block tip"><div class="custom-block-title">Code LLM 训练</div><p><strong>代码模型的挑战</strong></p><ul><li>严格语法限制。</li><li>长距离依赖：代码一个变量，可能几百行以后才被调用。模型需要记住这种逻辑关系。</li><li>可验证性：需要能跑通，也是一个特点。</li></ul><p><strong>训练流程</strong></p><ul><li>预训练：打基础</li><li>SFT：学指令</li><li>RL：提质量</li></ul></div><h3 id="训练框架" tabindex="-1">训练框架 <a class="header-anchor" href="#训练框架" aria-label="Permalink to &quot;训练框架&quot;">​</a></h3><div class="custom-block note"><div class="custom-block-title">训练框架</div><p><strong>Megatron-LM</strong></p><ul><li>核心：<code>TP</code> + <code>SP</code>，支持超长上下文。PP 1F1B策略，降低气泡。</li><li>场景：超大规模、极致性能</li></ul><p><strong>DeepSpeed</strong></p><ul><li>核心：ZeRo1-3 + Offload</li><li>场景：显存有限</li></ul><p><strong>Pytorch-FSDP</strong></p><ul><li>原生支持，兼容性好</li></ul><p><strong>TorchTitan</strong></p><ul><li>核心：4D并行，Megatron 也有。</li><li>场景：超大模型。</li></ul><p><strong>Colossal-AI</strong></p></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216164815.jpg" style="display:block;margin:auto;" width="70%"><h3 id="预训练-技巧" tabindex="-1">预训练 技巧 <a class="header-anchor" href="#预训练-技巧" aria-label="Permalink to &quot;预训练 技巧&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">Scaling Law</div><p><strong>Scaling Law</strong></p><ul><li><p>代码比通用模型需要<code>更高的数据参数比</code>，参数敏感。</p></li><li><p>N：模型参数；D：训练tokens；</p></li><li><p><mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.357ex;" xmlns="http://www.w3.org/2000/svg" width="3.328ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 1471.1 840.8" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="221E" d="M55 217Q55 305 111 373T254 442Q342 442 419 381Q457 350 493 303L507 284L514 294Q618 442 747 442Q833 442 888 374T944 214Q944 128 889 59T743 -11Q657 -11 580 50Q542 81 506 128L492 147L485 137Q381 -11 252 -11Q166 -11 111 57T55 217ZM907 217Q907 285 869 341T761 397Q740 397 720 392T682 378T648 359T619 335T594 310T574 285T559 263T548 246L543 238L574 198Q605 158 622 138T664 94T714 61T765 51Q827 51 867 100T907 217ZM92 214Q92 145 131 89T239 33Q357 33 456 193L425 233Q364 312 334 337Q285 380 233 380Q171 380 132 331T92 214Z" style="stroke-width:3;"></path></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>L</mi><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">∞</mi></mrow></msub></math></mjx-assistive-mml></mjx-container>：<code>不可约减loss</code>；</p></li><li><p><mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.439ex;" xmlns="http://www.w3.org/2000/svg" width="7.023ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 3104.1 636" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(673,-150) scale(0.707)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(1350.9,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(1795.6,0)"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(673,-150) scale(0.707)"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z" style="stroke-width:3;"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>α</mi><mi>N</mi></msub><mo>,</mo><msub><mi>α</mi><mi>D</mi></msub></math></mjx-assistive-mml></mjx-container>： 模型敏感度、数据敏感度，决定loss随N/D增加而下降的速度。</p></li><li><p><code>每种语言的Scaling Law</code></p><mjx-container tabindex="0" class="MathJax" jax="SVG" display="true" style="direction:ltr;display:block;text-align:center;margin:1em 0;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-2.148ex;" xmlns="http://www.w3.org/2000/svg" width="38.799ex" height="5.517ex" role="img" focusable="false" viewBox="0 -1489.1 17149 2438.6" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(681,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1070,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1958,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2402.7,0)"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3230.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3897.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4953.2,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M701 -940Q701 -943 695 -949H664Q662 -947 636 -922T591 -879T537 -818T475 -737T412 -636T350 -511T295 -362T250 -186T221 17T209 251Q209 962 573 1361Q596 1386 616 1405T649 1437T664 1450H695Q701 1444 701 1441Q701 1436 681 1415T629 1356T557 1261T476 1118T400 927T340 675T308 359Q306 321 306 250Q306 -139 400 -430T690 -924Q701 -936 701 -940Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mfrac" transform="translate(5689.2,0)"><g data-mml-node="msub" transform="translate(220,676)"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(836,-150) scale(0.707)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mi" transform="translate(372.1,-686)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z" style="stroke-width:3;"></path></g><rect width="1392.2" height="60" x="120" y="220"></rect></g><g data-mml-node="msup" transform="translate(7321.4,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="29" d="M34 1438Q34 1446 37 1448T50 1450H56H71Q73 1448 99 1423T144 1380T198 1319T260 1238T323 1137T385 1013T440 864T485 688T514 485T526 251Q526 134 519 53Q472 -519 162 -860Q139 -885 119 -904T86 -936T71 -949H56Q43 -949 39 -947T34 -937Q88 -883 140 -813Q428 -430 428 251Q428 453 402 628T338 922T245 1146T145 1309T46 1425Q44 1427 42 1429T39 1433T36 1436L34 1438Z" style="stroke-width:3;"></path></g></g><g data-mml-node="TeXAtom" transform="translate(769,1176.6) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(673,-150) scale(0.707)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z" style="stroke-width:3;"></path></g></g></g></g><g data-mml-node="mo" transform="translate(9317.9,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(10318.1,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M701 -940Q701 -943 695 -949H664Q662 -947 636 -922T591 -879T537 -818T475 -737T412 -636T350 -511T295 -362T250 -186T221 17T209 251Q209 962 573 1361Q596 1386 616 1405T649 1437T664 1450H695Q701 1444 701 1441Q701 1436 681 1415T629 1356T557 1261T476 1118T400 927T340 675T308 359Q306 321 306 250Q306 -139 400 -430T690 -924Q701 -936 701 -940Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mfrac" transform="translate(11054.1,0)"><g data-mml-node="msub" transform="translate(220,676)"><g data-mml-node="mi"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(861,-150) scale(0.707)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mi" transform="translate(414.6,-686)"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z" style="stroke-width:3;"></path></g><rect width="1417.2" height="60" x="120" y="220"></rect></g><g data-mml-node="msup" transform="translate(12711.3,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="29" d="M34 1438Q34 1446 37 1448T50 1450H56H71Q73 1448 99 1423T144 1380T198 1319T260 1238T323 1137T385 1013T440 864T485 688T514 485T526 251Q526 134 519 53Q472 -519 162 -860Q139 -885 119 -904T86 -936T71 -949H56Q43 -949 39 -947T34 -937Q88 -883 140 -813Q428 -430 428 251Q428 453 402 628T338 922T245 1146T145 1309T46 1425Q44 1427 42 1429T39 1433T36 1436L34 1438Z" style="stroke-width:3;"></path></g></g><g data-mml-node="TeXAtom" transform="translate(769,1176.6) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(673,-150) scale(0.707)"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z" style="stroke-width:3;"></path></g></g></g></g><g data-mml-node="mo" transform="translate(14677.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(15677.9,0)"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="221E" d="M55 217Q55 305 111 373T254 442Q342 442 419 381Q457 350 493 303L507 284L514 294Q618 442 747 442Q833 442 888 374T944 214Q944 128 889 59T743 -11Q657 -11 580 50Q542 81 506 128L492 147L485 137Q381 -11 252 -11Q166 -11 111 57T55 217ZM907 217Q907 285 869 341T761 397Q740 397 720 392T682 378T648 359T619 335T594 310T574 285T559 263T548 246L543 238L574 198Q605 158 622 138T664 94T714 61T765 51Q827 51 867 100T907 217ZM92 214Q92 145 131 89T239 33Q357 33 456 193L425 233Q364 312 334 337Q285 380 233 380Q171 380 132 331T92 214Z" style="stroke-width:3;"></path></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;overflow:hidden;width:100%;"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>L</mi><mo stretchy="false">(</mo><mi>N</mi><mo>,</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mrow data-mjx-texclass="ORD"><mo minsize="2.047em" maxsize="2.047em">(</mo></mrow><mfrac><msub><mi>N</mi><mi>c</mi></msub><mi>N</mi></mfrac><msup><mrow data-mjx-texclass="ORD"><mo minsize="2.047em" maxsize="2.047em">)</mo></mrow><mrow data-mjx-texclass="ORD"><msub><mi>α</mi><mi>N</mi></msub></mrow></msup><mo>+</mo><mrow data-mjx-texclass="ORD"><mo minsize="2.047em" maxsize="2.047em">(</mo></mrow><mfrac><msub><mi>D</mi><mi>c</mi></msub><mi>D</mi></mfrac><msup><mrow data-mjx-texclass="ORD"><mo minsize="2.047em" maxsize="2.047em">)</mo></mrow><mrow data-mjx-texclass="ORD"><msub><mi>α</mi><mi>D</mi></msub></mrow></msup><mo>+</mo><msub><mi>L</mi><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">∞</mi></mrow></msub></math></mjx-assistive-mml></mjx-container></li><li><p>python最难学，比其他语言更吃算力，形式灵活。</p></li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216164844.jpg" style="display:block;margin:auto;" width="70%"><div class="custom-block tip"><div class="custom-block-title">多语言混合和预训练策略</div><p><strong>多语言混合</strong></p><ul><li>混合语言会让单语言提升，整体利大于弊，但非对称： <ul><li>python作为辅助语言能帮助其他语言。</li><li>混合其他语言，会对python有微小的负面影响。</li></ul></li></ul><p><strong>预训练策略</strong></p><ul><li>不同语言有不同的tken预算。 <ul><li>Python/TS等不规范语言： 数据要多一些。</li><li>Java/GO/C+规范语言：数据少一些。</li><li>实操：总100B，Python 40B, TypeScript 20B, Java 15B, Go 10B, C+ 15B</li></ul></li><li>相似语言语料库构建 <ul><li>Java+C+, JavaScript+TypeScript, Rust+Go，相似正向，可以混在一起。</li><li>Python：非对称，要加多。</li></ul></li><li>基于复杂度做算力分配 <ul><li><mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.357ex;" xmlns="http://www.w3.org/2000/svg" width="3.328ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 1471.1 840.8" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="221E" d="M55 217Q55 305 111 373T254 442Q342 442 419 381Q457 350 493 303L507 284L514 294Q618 442 747 442Q833 442 888 374T944 214Q944 128 889 59T743 -11Q657 -11 580 50Q542 81 506 128L492 147L485 137Q381 -11 252 -11Q166 -11 111 57T55 217ZM907 217Q907 285 869 341T761 397Q740 397 720 392T682 378T648 359T619 335T594 310T574 285T559 263T548 246L543 238L574 198Q605 158 622 138T664 94T714 61T765 51Q827 51 867 100T907 217ZM92 214Q92 145 131 89T239 33Q357 33 456 193L425 233Q364 312 334 337Q285 380 233 380Q171 380 132 331T92 214Z" style="stroke-width:3;"></path></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>L</mi><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">∞</mi></mrow></msub></math></mjx-assistive-mml></mjx-container>低，总算力需求小；<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.357ex;" xmlns="http://www.w3.org/2000/svg" width="3.328ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 1471.1 840.8" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="221E" d="M55 217Q55 305 111 373T254 442Q342 442 419 381Q457 350 493 303L507 284L514 294Q618 442 747 442Q833 442 888 374T944 214Q944 128 889 59T743 -11Q657 -11 580 50Q542 81 506 128L492 147L485 137Q381 -11 252 -11Q166 -11 111 57T55 217ZM907 217Q907 285 869 341T761 397Q740 397 720 392T682 378T648 359T619 335T594 310T574 285T559 263T548 246L543 238L574 198Q605 158 622 138T664 94T714 61T765 51Q827 51 867 100T907 217ZM92 214Q92 145 131 89T239 33Q357 33 456 193L425 233Q364 312 334 337Q285 380 233 380Q171 380 132 331T92 214Z" style="stroke-width:3;"></path></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>L</mi><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">∞</mi></mrow></msub></math></mjx-assistive-mml></mjx-container>高，总算力需求高。</li></ul></li><li>默认采用多语言预训练。 <ul><li>涌现能力。</li><li>资源有限：Python-Java-C#，或 JavaScript-TypeScript。</li></ul></li></ul></div><h3 id="sft-技巧" tabindex="-1">SFT 技巧 <a class="header-anchor" href="#sft-技巧" aria-label="Permalink to &quot;SFT 技巧&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">SFT 实验</div><p><strong>基础配置</strong></p><ul><li>模型：Qwen2.5-Coder-14B</li><li>数据集：<a href="https://huggingface.co/datasets/ise-uiuc/Magicoder-OSS-Instruct-75K" target="_blank" rel="noreferrer">Magicoder_OSS_Instruct_75k</a></li><li>超参： <ul><li>3epoch, global bs=256, max_len=8k, lr=1e6, warm_up=0.03，64GPU</li><li>设备批大小=2，梯度累积=2</li><li>Global-BS = N_GPU * 2 * 2。即64*4=256</li></ul></li><li>框架：QwenCoder-SFT, LLaMA-Factory, MS-Swift, VERL</li></ul><p><strong>框架说明</strong></p><ul><li>QwenCoder-SFT (HF Trainer)：Pytorch DDP，吃显存。</li><li>LLaMA-Factory (DeepSpeed ZeRO-3) <ul><li>全精度，好用。50分钟训完。</li></ul></li><li>MS-Swift (Megatron)： <ul><li>TP+PP。20分钟。</li></ul></li><li>VERL (FSDP v2) <ul><li>2小时。重复的All-Gather 通信开销。</li></ul></li></ul></div><div class="custom-block note"><div class="custom-block-title">超参经验</div><ul><li>Global BS 在SFT里和敏感，超过256会下降，不能太大。</li><li>学习率和模型相关。 <ul><li>14B：2e-6 - 5e-6</li><li>30B：1e-6欠拟合，2e-6平衡，峰值5e-6</li></ul></li><li>训练时长 <ul><li>14B：3-5个epoch</li><li>30B：需更多epoch才能稳定</li></ul></li><li>warmup <ul><li>14B：还好</li><li>30B：需要预测，0.03-0.1</li></ul></li></ul></div><div class="custom-block note"><div class="custom-block-title">模型架构经验</div><p><strong>Dense：更稳健</strong></p><ul><li>Epoch：1-5逐渐提升，随后饱和</li><li>Batch size：64-256都可，&gt;1024下降也较少。</li><li>学习率：平滑，2e-6～5e-6之间</li></ul><p><strong>MoE：超参敏感</strong></p><ul><li>潜力高：特定条件下才能达最优分数 <ul><li>10 epoch HumanEVal=0.836，Batch size=64时，MBPP=0.86</li></ul></li><li>不稳定： <ul><li>bs&gt;512 或者 学习率低于1e-6时，性能急剧下降。</li></ul></li><li>训练时间：更长。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216164958.jpg" style="display:block;margin:auto;" width="70%"><div class="custom-block note"><div class="custom-block-title">数据集影响</div><ul><li>可执行、函数级的数据，对MBPP有效果。比如KodCode系列。</li><li>竞赛风格的题对HumanEval有效，但对MBPP无效。 <ul><li>如code_contests 更利于提升算法推理能力，而非入门函数生成能力。</li></ul></li><li>缺乏执行反馈、纯聊天数据效果不行。</li><li>50k数据配比：主力 可执行数据 + 辅助算法竞赛题 + 丢弃纯文本垃圾数据。</li><li>质量 &gt; 数量。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216165048.jpg" style="display:block;margin:auto;" width="70%"><h3 id="rl-技巧" tabindex="-1">RL 技巧 <a class="header-anchor" href="#rl-技巧" aria-label="Permalink to &quot;RL 技巧&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">RL 实验</div><p><strong>基础配置</strong></p><ul><li>模型：Qwen2.5-Coder-14B</li><li>数据集：codecontest_plus</li><li>Reward信号：sandboxfusion</li><li>超参：bs=64, max_len=4k, lr=1e6, 64GPU</li><li>框架：VERL</li></ul></div><div class="custom-block note"><div class="custom-block-title">优势估计 验证</div><ul><li><a href="https://plmsmile.github.io/posts/llm/rl/theory/10-ppo-series.html#_2402-rloo" target="_blank" rel="noreferrer">RLOO</a><ul><li><code>分数最高</code>。</li></ul></li><li><a href="https://plmsmile.github.io/posts/llm/rl/theory/10-ppo-series.html#_2501-reinforce" target="_blank" rel="noreferrer">Reinforce++</a><ul><li><code>训练快</code>，比RLOO低一点点。</li></ul></li><li><a href="https://plmsmile.github.io/posts/llm/rl/theory/09-policy-trpo-ppo.html#grpo" target="_blank" rel="noreferrer">GRPO</a><ul><li>表现平平，收敛慢</li></ul></li><li>GRPO_PASSk：效果差</li></ul></div><div class="custom-block note"><div class="custom-block-title">Response长度 验证</div><ul><li>16k：pass@1最高</li><li>2k：pass@5最好，较短上下文、在训练期间探索更多样。</li></ul></div><div class="custom-block note"><div class="custom-block-title">rollout.n 验证</div><ul><li>rollout.n 太大也会崩溃。比如128,256,512 <ul><li>可能是太多低质量样本，导致方差过大。？</li></ul></li><li>pass@1 对N=4和N=64没区别。</li><li>考虑各方面平衡，16比较均衡。</li></ul></div><h2 id="code-应用" tabindex="-1">Code 应用 <a class="header-anchor" href="#code-应用" aria-label="Permalink to &quot;Code 应用&quot;">​</a></h2><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216165439.jpg" style="display:block;margin:auto;" width="70%"><h3 id="ide集成" tabindex="-1">IDE集成 <a class="header-anchor" href="#ide集成" aria-label="Permalink to &quot;IDE集成&quot;">​</a></h3><h3 id="云原生代码平台" tabindex="-1">云原生代码平台 <a class="header-anchor" href="#云原生代码平台" aria-label="Permalink to &quot;云原生代码平台&quot;">​</a></h3><h3 id="terminal-based" tabindex="-1">Terminal-based <a class="header-anchor" href="#terminal-based" aria-label="Permalink to &quot;Terminal-based&quot;">​</a></h3><h3 id="代码修复和程序验证" tabindex="-1">代码修复和程序验证 <a class="header-anchor" href="#代码修复和程序验证" aria-label="Permalink to &quot;代码修复和程序验证&quot;">​</a></h3><h3 id="pr-revoew和质量检验" tabindex="-1">PR Revoew和质量检验 <a class="header-anchor" href="#pr-revoew和质量检验" aria-label="Permalink to &quot;PR Revoew和质量检验&quot;">​</a></h3></div></div></main><footer class="VPDocFooter" data-v-5a64a79a data-v-54a90a4a><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-54a90a4a><span class="visually-hidden" id="doc-footer-aria-label" data-v-54a90a4a>Pager</span><div class="pager" data-v-54a90a4a><a class="VPLink link pager-link prev" href="/posts/llm/industry/codellm/02-eval-task-benchmark.html" data-v-54a90a4a><!--[--><span class="desc" data-v-54a90a4a>上一页</span><span class="title" data-v-54a90a4a>Code 任务Bench相关</span><!--]--></a></div><div class="pager" data-v-54a90a4a><a class="VPLink link pager-link next" href="/posts/llm/industry/codellm/08-code-pretrain-summary.html" data-v-54a90a4a><!--[--><span class="desc" data-v-54a90a4a>下一页</span><span class="title" data-v-54a90a4a>Code 预训练相关</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--[--><div class="busuanzi"> 总访客数： <span id="busuanzi_value_site_uv"></span>   ·   总访问量： <span id="busuanzi_value_site_pv"></span></div><div class="busuanzi"> PLM&#39;s Blog @ 2016 - 2026</div><!--]--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api-examples.md\":\"Bt59YpwR\",\"index.md\":\"DmRGHmj9\",\"markdown-examples.md\":\"CPJSv--2\",\"posts_archive.md\":\"pZWQT7dp\",\"posts_exps_env_01-blog-env.md\":\"CcTUm41j\",\"posts_exps_env_index.md\":\"BJEZeoT-\",\"posts_exps_mind_index.md\":\"naOB3-Mb\",\"posts_llm_agent_basic_01-lhy-agent-notes.md\":\"BK_CsHNC\",\"posts_llm_agent_basic_02-evaluation-agent.md\":\"Dn02cVtP\",\"posts_llm_agent_basic_03-current-agents.md\":\"C25gmbg8\",\"posts_llm_agent_basic_04-agent-blogs.md\":\"_QbL2Plv\",\"posts_llm_agent_basic_05-comuter-agent.md\":\"D0gJpId6\",\"posts_llm_agent_basic_06-deepresearch-evaluation.md\":\"DdRDcxUJ\",\"posts_llm_agent_basic_index.md\":\"ClGtwUqg\",\"posts_llm_agent_rl_01-agent-rl.md\":\"wOF9bz66\",\"posts_llm_agent_rl_02-agent-tool.md\":\"IB_AqkSe\",\"posts_llm_agent_rl_03-agent-search.md\":\"Cim7OGxb\",\"posts_llm_agent_rl_04-agent-env.md\":\"C_O9BVi3\",\"posts_llm_agent_rl_index.md\":\"BudtoDK9\",\"posts_llm_basic_01-lm-define-information-theory.md\":\"Bl38RTdm\",\"posts_llm_basic_02-llm-components.md\":\"CGM_jRUE\",\"posts_llm_basic_03-transformer-detail.md\":\"BgLyAVDZ\",\"posts_llm_basic_04-llm-architecture.md\":\"jk4T-c21\",\"posts_llm_basic_05-llm-basic-info.md\":\"bdnM02bn\",\"posts_llm_basic_06-llm-attention.md\":\"BRJ9jR-M\",\"posts_llm_basic_07-decode.md\":\"BRytPqZo\",\"posts_llm_basic_08-llm-position-embedding.md\":\"d9dN_RuO\",\"posts_llm_basic_index.md\":\"DjX2HRXy\",\"posts_llm_industry_codellm_01-survey.md\":\"DIZQiOWr\",\"posts_llm_industry_codellm_02-eval-task-benchmark.md\":\"B-okIRAD\",\"posts_llm_industry_codellm_03-rl-task.md\":\"vQDqALFA\",\"posts_llm_industry_codellm_04-safety-code.md\":\"mkEFLxnr\",\"posts_llm_industry_codellm_05-open-codellm.md\":\"C6UU6qcZ\",\"posts_llm_industry_codellm_06-code-taskrl-reading.md\":\"BJI-7ypF\",\"posts_llm_industry_codellm_07-code-fulltrain-reading.md\":\"D7trPw8V\",\"posts_llm_industry_codellm_08-code-pretrain-summary.md\":\"DfgRUz6a\",\"posts_llm_industry_mainllm_01-kimi-series.md\":\"B03hc7IE\",\"posts_llm_industry_mainllm_02-deepseek-series.md\":\"B04zRtyw\",\"posts_llm_industry_mainllm_03-glm-series.md\":\"8i7VdpW8\",\"posts_llm_industry_mainllm_04-minimax-series.md\":\"DjQwki4V\",\"posts_llm_industry_mainllm_05-qwen-series.md\":\"B4DMxRmo\",\"posts_llm_industry_mainllm_06-seed-series.md\":\"BNsIBjBZ\",\"posts_llm_industry_mainllm_07-openai-series.md\":\"ZBquCwKO\",\"posts_llm_industry_mainllm_08-gemini-series.md\":\"Bdm2kU-I\",\"posts_llm_industry_mainllm_09-claude-series.md\":\"0YnEaaXS\",\"posts_llm_industry_mainllm_10-longcat-series.md\":\"DroIAFXW\",\"posts_llm_industry_mainllm_11-tencent-series.md\":\"BVkGSYEM\",\"posts_llm_industry_mainllm_12-kwai-series.md\":\"o6Hut3bE\",\"posts_llm_industry_mainllm_13-nvidia-series.md\":\"BFgUmWZk\",\"posts_llm_industry_mainllm_14-mimo-series.md\":\"DDj7XRZV\",\"posts_llm_industry_mainllm_15-skywork-series.md\":\"pkz98qRT\",\"posts_llm_infra_01-parrallel.md\":\"Dih7M1RJ\",\"posts_llm_infra_02-speed-framework.md\":\"_bUH-n3t\",\"posts_llm_infra_03-inference-tech.md\":\"Hpk9YmXF\",\"posts_llm_infra_04-verl.md\":\"8XtGz01J\",\"posts_llm_infra_05-verl-practice.md\":\"B4gP7J_O\",\"posts_llm_infra_06-verl-code.md\":\"D5bZg4dm\",\"posts_llm_infra_07-verl-core.md\":\"3RS___SF\",\"posts_llm_infra_08-verl-train-loop.md\":\"CQNCgy-d\",\"posts_llm_rl_index.md\":\"iUgEsMU1\",\"posts_llm_rl_theory_01-reinforce-learning.md\":\"Ch0rtQCM\",\"posts_llm_rl_theory_01-rl-introduction.md\":\"CmW63EkM\",\"posts_llm_rl_theory_02-markove-process.md\":\"DVY5XgWd\",\"posts_llm_rl_theory_02-value-learning.md\":\"CeOlmbeS\",\"posts_llm_rl_theory_03-model-based-prediction-control.md\":\"BhVRmo7C\",\"posts_llm_rl_theory_03-strategy-learning.md\":\"DWNvEZXH\",\"posts_llm_rl_theory_04-model-free-prediction-control.md\":\"Cg3qo2Fk\",\"posts_llm_rl_theory_04-reinforce-conclusion-simple.md\":\"C6yTAxwQ\",\"posts_llm_rl_theory_05-dqn.md\":\"BatSdlnZ\",\"posts_llm_rl_theory_06-policy-gradient.md\":\"BXI-eY8I\",\"posts_llm_rl_theory_07-actor-critic.md\":\"B1-83sen\",\"posts_llm_rl_theory_08-deterministic-policy-gradient.md\":\"Dgvru3JE\",\"posts_llm_rl_theory_09-policy-trpo-ppo.md\":\"DU-7PSqU\",\"posts_llm_rl_theory_10-ppo-series.md\":\"B-5Hsj_J\",\"posts_llm_rl_theory_11-grpo-series.md\":\"Ctl1G-Yd\",\"posts_llm_rl_theory_12-entropy.md\":\"BH45bCLH\",\"posts_llm_rl_theory_13-agentrl-algo.md\":\"BfctbxM6\",\"posts_me.md\":\"B9W6CMag\",\"posts_olds_algo_aim2offer.md\":\"jCwzQ4BU\",\"posts_olds_algo_aim2offer2.md\":\"Ga2XS6dR\",\"posts_olds_algo_aim2offer3.md\":\"BP0rCZaJ\",\"posts_olds_algo_aim2offer4.md\":\"BXurWO8W\",\"posts_olds_algo_algorithm-dfs.md\":\"CkUFsStz\",\"posts_olds_algo_index.md\":\"CmdF0Gg2\",\"posts_olds_algo_leetcode-01.md\":\"C_2G2jJT\",\"posts_olds_algo_sort-algorithms.md\":\"tFMUVlmH\",\"posts_olds_bigdata_16-spark-baserdd.md\":\"CBxdArgI\",\"posts_olds_bigdata_17-spark-pairrdd.md\":\"C3n8_zMO\",\"posts_olds_bigdata_18-spark-sql.md\":\"tsaWQLcp\",\"posts_olds_bigdata_19-spark-programming.md\":\"DG5ZAF85\",\"posts_olds_bigdata_20-numpy.md\":\"DucCD22z\",\"posts_olds_bigdata_index.md\":\"CWrZwWPb\",\"posts_olds_dl_23-pytorch-start.md\":\"BokpNeAw\",\"posts_olds_dl_35-nerual-network-optim.md\":\"Cp2SpLoE\",\"posts_olds_dl_38-convolution.md\":\"CC_SQ57z\",\"posts_olds_dl_cs224n-assignment-1.md\":\"BZMSZqOS\",\"posts_olds_dl_cs224n-notes3-neural-networks-2.md\":\"Wd9TmSyb\",\"posts_olds_dl_cs224n-notes3-neural-networks.md\":\"CDZWc4X6\",\"posts_olds_dl_cs231n-linear-notes.md\":\"DLRyzcwJ\",\"posts_olds_dl_index.md\":\"C1dyLGNS\",\"posts_olds_dl_rnn.md\":\"CwYYWZ7N\",\"posts_olds_env_09-linux-notes.md\":\"CyjifvcN\",\"posts_olds_env_12-ide-envs.md\":\"YeELWzR2\",\"posts_olds_env_13-old-blog-problems.md\":\"qamPyucB\",\"posts_olds_env_24-hexo-problems.md\":\"CzxhyjW1\",\"posts_olds_env_index.md\":\"DQpgTXVj\",\"posts_olds_ml_10-trees.md\":\"BkNaj6fL\",\"posts_olds_ml_14-em.md\":\"DIufCP0H\",\"posts_olds_ml_21-lr.md\":\"C-1ms511\",\"posts_olds_ml_22-ml-ch03-bayes.md\":\"Q_M6Gn-a\",\"posts_olds_ml_27-svm-notes.md\":\"C96WS6CL\",\"posts_olds_ml_28-ml-interview-notes.md\":\"0bgezw3n\",\"posts_olds_ml_29-desicion-tree.md\":\"CtwmlbWl\",\"posts_olds_ml_crf.md\":\"CEE5oTqd\",\"posts_olds_ml_index.md\":\"BLMEziB1\",\"posts_olds_ml_maxentmodel.md\":\"CSbOumJx\",\"posts_olds_ml_pgm-01.md\":\"BTwybTMD\",\"posts_olds_nlp_11-nlp-labels.md\":\"Cl0Lb8OT\",\"posts_olds_nlp_25-google-nmt.md\":\"BOM-hoYN\",\"posts_olds_nlp_26-wordpieacemodel.md\":\"Q8-L5j15\",\"posts_olds_nlp_30-dynamic-memory-network.md\":\"wp5ucVxW\",\"posts_olds_nlp_31-co-attention-vqa.md\":\"lzwuVKG5\",\"posts_olds_nlp_32-dynamic-coattention-network.md\":\"Bxl4ABWd\",\"posts_olds_nlp_33-attention-summary.md\":\"DT6np0xG\",\"posts_olds_nlp_36-alime-chat.md\":\"Cu2xkcdT\",\"posts_olds_nlp_39-squard-models.md\":\"B1L3iDEv\",\"posts_olds_nlp_45-match-lstm.md\":\"DkpQKM5B\",\"posts_olds_nlp_46-rnet-selfmatch.md\":\"CzGHQ-PZ\",\"posts_olds_nlp_47-bidaf.md\":\"DFJaLh2v\",\"posts_olds_nlp_48-attention-is-all-you-need.md\":\"BY6XvFQ5\",\"posts_olds_nlp_49-qanet.md\":\"BPKWHzTf\",\"posts_olds_nlp_50-elmo.md\":\"WuOt1elN\",\"posts_olds_nlp_51-opengpt.md\":\"B9pQ3h5W\",\"posts_olds_nlp_52-bert.md\":\"5q3t5Qqh\",\"posts_olds_nlp_53-mrc-brief.md\":\"D9CkYrea\",\"posts_olds_nlp_54-mrc-models.md\":\"Ak4bDf1J\",\"posts_olds_nlp_attention-based-nmt.md\":\"BHef6tM6\",\"posts_olds_nlp_attention-model.md\":\"-xLhHhJE\",\"posts_olds_nlp_cs224n-lecture2-word2vec.md\":\"_MmBTADr\",\"posts_olds_nlp_cs224n-notes1-word2vec.md\":\"DXSi5KGh\",\"posts_olds_nlp_index.md\":\"Bfo4Lwn3\",\"posts_olds_nlp_nlp-notes.md\":\"BUmOZxzi\",\"posts_olds_nlp_nmt.md\":\"DUgy6vHF\",\"posts_olds_nlp_subword-units.md\":\"fR_3dRXr\",\"posts_olds_nlp_word2vec-math.md\":\"agvHiE1x\",\"posts_olds_nlp_word2vec.md\":\"D2TKUstm\",\"posts_olds_other_15-cpp-pointer-object-reference.md\":\"BKRTr8QZ\",\"posts_olds_other_index.md\":\"C1T-ubsz\",\"posts_olds_rl_37-reinforce-learning.md\":\"Cf2nny8k\",\"posts_olds_rl_40-value-learning.md\":\"DcnHvvpH\",\"posts_olds_rl_41-strategy-learning.md\":\"CStMrB-q\",\"posts_olds_rl_42-reinforce-conclusion-simple.md\":\"flRZUmJZ\",\"posts_olds_rl_43-intent-detection-slot-filling.md\":\"DcAUbaZU\",\"posts_olds_rl_44-reinforce-nlp.md\":\"Br2ShITL\",\"posts_olds_rl_index.md\":\"CUsxM3zO\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"📚 plmblog\",\"description\":\"记录一些学习笔记。\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"首页\",\"link\":\"/\"},{\"text\":\"🐲LLM\",\"items\":[{\"text\":\"Basic\",\"items\":[{\"text\":\"🦋基础知识\",\"link\":\"/posts/llm/basic/01-lm-define-information-theory\"},{\"text\":\"🛠基建框架\",\"link\":\"/posts/llm/infra/01-parrallel\"}]},{\"text\":\"强化学习\",\"items\":[{\"text\":\"🎓RL理论基础\",\"link\":\"/posts/llm/rl/theory/01-reinforce-learning\"},{\"text\":\"🚄Agent-RL\",\"link\":\"/posts/llm/agent/rl/02-agent-tool\"}]},{\"text\":\"行业方向\",\"items\":[{\"text\":\"🚀主流模型\",\"link\":\"/posts/llm/industry/mainllm/01-kimi-series\"},{\"text\":\"💻代码模型\",\"link\":\"/posts/llm/industry/codellm/01-survey\"}]},{\"text\":\"Agent\",\"items\":[{\"text\":\"🤖概念及应用\",\"link\":\"/posts/llm/agent/basic\"}]}]},{\"text\":\"📙旧文章\",\"items\":[{\"text\":\"🍓NLP\",\"items\":[{\"text\":\"自然语言处理\",\"link\":\"/posts/olds/nlp\"}]},{\"text\":\"🍑基础知识\",\"items\":[{\"text\":\"深度学习\",\"link\":\"/posts/olds/dl\"},{\"text\":\"强化学习\",\"link\":\"/posts/olds/rl\"},{\"text\":\"机器学习\",\"link\":\"/posts/olds/ml\"}]},{\"text\":\"🍎算法\",\"items\":[{\"text\":\"算法题\",\"link\":\"/posts/olds/algo/\"},{\"text\":\"大数据\",\"link\":\"/posts/olds/bigdata/\"}]},{\"text\":\"🍒其他\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/olds/env/\"},{\"text\":\"其他\",\"link\":\"/posts/olds/other/\"}]}]},{\"text\":\"经验\",\"items\":[{\"text\":\"环境\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/exps/env/01-blog-env\"}]},{\"text\":\"心得\",\"items\":[{\"text\":\"心得体会\",\"link\":\"/posts/exps/mind\"}]}]},{\"text\":\"归档\",\"link\":\"/posts/archive.md\"},{\"text\":\"关于我\",\"link\":\"/posts/me\"}],\"outline\":{\"level\":[1,4],\"label\":\"当前页大纲\"},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/plmsmile\"}],\"search\":{\"provider\":\"local\"},\"docFooter\":{\"prev\":\"上一页\",\"next\":\"下一页\"},\"sidebar\":{\"/posts/olds/nlp/\":{\"base\":\"/posts/olds/nlp/\",\"items\":[{\"text\":\"NLP\",\"items\":[{\"text\":\"机器阅读(二)--模型(未完成)\",\"link\":\"54-mrc-models\"},{\"text\":\"机器阅读(一)--整体概述\",\"link\":\"53-mrc-brief\"},{\"text\":\"BERT 详解\",\"link\":\"52-bert\"},{\"text\":\"OpenAI GPT：Improving Language Understanding by Generative Pre-Training\",\"link\":\"51-opengpt\"},{\"text\":\"ELMo：Deep Contextualized Word Representations\",\"link\":\"50-elmo\"},{\"text\":\"QANet\",\"link\":\"49-qanet\"},{\"text\":\"Transformer\",\"link\":\"48-attention-is-all-you-need\"},{\"text\":\"Bidirectional Attention Flow\",\"link\":\"47-bidaf\"},{\"text\":\"R-Net (Gated Self-Matching Networks)\",\"link\":\"46-rnet-selfmatch\"},{\"text\":\"Match-LSTM and Answer Pointer\",\"link\":\"45-match-lstm\"},{\"text\":\"阅读理解模型总结\",\"link\":\"39-squard-models\"},{\"text\":\"阿里小蜜论文\",\"link\":\"36-alime-chat\"},{\"text\":\"各种注意力总结\",\"link\":\"33-attention-summary\"},{\"text\":\"Dynamic Coattention Network (Plus)\",\"link\":\"32-dynamic-coattention-network\"},{\"text\":\"协同注意力简介\",\"link\":\"31-co-attention-vqa\"},{\"text\":\"使用Dynamic Memory Network实现一个简单QA\",\"link\":\"30-dynamic-memory-network\"},{\"text\":\"词性标注和句法依存的表示符号\",\"link\":\"11-nlp-labels\"},{\"text\":\"Word2vec之总体介绍\",\"link\":\"cs224n-notes1-word2vec\"},{\"text\":\"Word2vec之数学模型\",\"link\":\"word2vec-math\"},{\"text\":\"Word2vec之公式推导笔记\",\"link\":\"cs224n-lecture2-word2vec\"},{\"text\":\"subword-units\",\"link\":\"subword-units\"},{\"text\":\"Wordpiece模型\",\"link\":\"26-wordpieacemodel\"},{\"text\":\"谷歌RNN翻译模型\",\"link\":\"25-google-nmt\"},{\"text\":\"机器翻译注意力机制及其PyTorch实现\",\"link\":\"Attention-based-NMT\"},{\"text\":\"图文介绍RNN注意力机制\",\"link\":\"attention-model\"},{\"text\":\"最初RNN神经翻译简略笔记\",\"link\":\"NMT\"},{\"text\":\"语言模型和平滑方法\",\"link\":\"nlp-notes\"},{\"text\":\"利用tensorflow实现简版word2vec\",\"link\":\"word2vec\"}]}]},\"/posts/olds/dl/\":{\"base\":\"/posts/olds/dl/\",\"items\":[{\"text\":\"DL\",\"items\":[{\"text\":\"卷积神经网络总结\",\"link\":\"38-convolution\"},{\"text\":\"网络优化\",\"link\":\"35-nerual-network-optim\"},{\"text\":\"cs224n作业一\",\"link\":\"cs224n-assignment-1\"},{\"text\":\"cs231n线性分类器和损失函数\",\"link\":\"cs231n-linear-notes\"},{\"text\":\"神经网络-过拟合-预处理-BN\",\"link\":\"cs224n-notes3-neural-networks-2\"},{\"text\":\"神经网络基础-反向传播-激活函数\",\"link\":\"cs224n-notes3-neural-networks\"},{\"text\":\"循环神经网络\",\"link\":\"rnn\"},{\"text\":\"PyTorch快速上手\",\"link\":\"23-pytorch-start\"}]}]},\"/posts/olds/rl/\":{\"base\":\"/posts/olds/rl/\",\"items\":[{\"text\":\"RL\",\"items\":[{\"text\":\"强化学习在NLP中的应用\",\"link\":\"44-reinforce-nlp\"},{\"text\":\"意图识别和槽填充\",\"link\":\"43-intent-detection-slot-filling\"},{\"text\":\"强化学习算法小结\",\"link\":\"42-reinforce-conclusion-simple\"},{\"text\":\"基于策略函数的学习方法\",\"link\":\"41-strategy-learning\"},{\"text\":\"基于值函数的学习\",\"link\":\"40-value-learning\"},{\"text\":\"强化学习\",\"link\":\"37-reinforce-learning\"}]}]},\"/posts/olds/ml/\":{\"base\":\"/posts/olds/ml/\",\"items\":[{\"text\":\"ML\",\"items\":[{\"text\":\"决策树笔记\",\"link\":\"29-desicion-tree\"},{\"text\":\"机器学习知识点汇总整理\",\"link\":\"28-ml-interview-notes\"},{\"text\":\"SVM笔记\",\"link\":\"27-svm-notes\"},{\"text\":\"树的总结\",\"link\":\"10-trees\"},{\"text\":\"条件随机场\",\"link\":\"crf\"},{\"text\":\"最大熵模型\",\"link\":\"maxentmodel\"},{\"text\":\"线性回归和逻辑回归\",\"link\":\"21-lr\"},{\"text\":\"最大期望算法\",\"link\":\"14-em\"},{\"text\":\"马尔可夫模型\",\"link\":\"pgm-01\"},{\"text\":\"朴素贝叶斯算法及其代码实现\",\"link\":\"22-ml-ch03-bayes\"}]}]},\"/posts/olds/algo/\":{\"base\":\"/posts/olds/algo/\",\"items\":[{\"text\":\"ALGO\",\"items\":[{\"text\":\"剑指offer4(51-64)\",\"link\":\"aim2offer4\"},{\"text\":\"剑指offer3(21-40)\",\"link\":\"aim2offer3\"},{\"text\":\"数据结构之搜索算法\",\"link\":\"algorithm-dfs\"},{\"text\":\"leetcode-01\",\"link\":\"leetcode-01\"},{\"text\":\"剑指offer(11-20)\",\"link\":\"aim2offer2\"},{\"text\":\"排序算法总结\",\"link\":\"sort-algorithms\"},{\"text\":\"剑指Offer(1-10)\",\"link\":\"aim2offer\"}]}]},\"/posts/olds/bigdata/\":{\"base\":\"/posts/olds/bigdata/\",\"items\":[{\"text\":\"BIG Data\",\"items\":[{\"text\":\"NumPy\",\"link\":\"20-numpy\"},{\"text\":\"Spark基础编程核心思想介绍\",\"link\":\"19-spark-programming\"},{\"text\":\"Spark-SQL的简略笔记\",\"link\":\"18-spark-sql\"},{\"text\":\"Spark键值对RDD的常用API\",\"link\":\"17-spark-pairrdd\"},{\"text\":\"Spark基础RDD的常用API\",\"link\":\"16-Spark-BaseRDD\"}]}]},\"/posts/olds/env/\":{\"base\":\"/posts/olds/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"IDE配置\",\"link\":\"12-ide-envs\"},{\"text\":\"Linux使用笔记\",\"link\":\"09-linux-notes\"},{\"text\":\"博客搭建及相关问题\",\"link\":\"24-hexo-problems\"},{\"text\":\"旧版博客搭建过程及其问题\",\"link\":\"13-old-blog-problems\"}]}]},\"/posts/olds/other/\":{\"base\":\"/posts/olds/other/\",\"items\":[{\"text\":\"其他\",\"items\":[{\"text\":\"C++类对象和指针的区别\",\"link\":\"15-cpp-pointer-object-reference\"}]}]},\"/posts/llm/agent/rl/\":{\"base\":\"/posts/llm/agent/rl/\",\"items\":[{\"text\":\"Agent-RL\",\"items\":[{\"text\":\"Agent-Interaction-RL 笔记\",\"link\":\"04-agent-env\"},{\"text\":\"Agent-Search-RL 笔记\",\"link\":\"03-agent-search\"},{\"text\":\"Agent-Tool-RL 笔记\",\"link\":\"02-agent-tool\"},{\"text\":\"Agent-RL 综述型笔记\",\"link\":\"01-agent-rl\"}]}]},\"/posts/llm/agent/basic/\":{\"base\":\"/posts/llm/agent/basic/\",\"items\":[{\"text\":\"Agent-基础\",\"items\":[{\"text\":\"DeepResearch 评估\",\"link\":\"06-deepresearch-evaluation\"},{\"text\":\"Computer-Agent\",\"link\":\"05-comuter-agent\"},{\"text\":\"Agent 思考性文章\",\"link\":\"04-agent-blogs\"},{\"text\":\"一些流行的Agents\",\"link\":\"03-current-agents\"},{\"text\":\"Agent 评估 Benchmarks\",\"link\":\"02-evaluation-agent\"},{\"text\":\"Agent基础概念 (李宏毅笔记)\",\"link\":\"01-lhy-agent-notes\"}]}]},\"/posts/llm/rl/theory/\":{\"base\":\"/posts/llm/rl/theory/\",\"items\":[{\"text\":\"RL-Theory\",\"items\":[{\"text\":\"Agent-RL 相关算法\",\"link\":\"13-agentrl-algo\"},{\"text\":\"熵和RL相关文章\",\"link\":\"12-entropy\"},{\"text\":\"GRPO 改进系列\",\"link\":\"11-grpo-series\"},{\"text\":\"PPO 改进系列\",\"link\":\"10-ppo-series\"},{\"text\":\"典型策略提升方法：TRPO+PPO+DPO+GRPO\",\"link\":\"09-policy-trpo-ppo\"},{\"text\":\"确定性策略梯度\",\"link\":\"08-deterministic-policy-gradient\"},{\"text\":\"Actor-Critic 算法\",\"link\":\"07-actor-critic\"},{\"text\":\"策略梯度算法\",\"link\":\"06-policy-gradient\"},{\"text\":\"DQN算法及进阶\",\"link\":\"05-dqn\"},{\"text\":\"免模型预测和控制\",\"link\":\"04-model-free-prediction-control\"},{\"text\":\"有模型预测和控制\",\"link\":\"03-model-based-prediction-control\"},{\"text\":\"马尔可夫决策过程\",\"link\":\"02-markove-process\"},{\"text\":\"强化学习基本概念\",\"link\":\"01-rl-introduction\"},{\"text\":\"(18年笔记)强化学习算法小结\",\"link\":\"04-reinforce-conclusion-simple\"},{\"text\":\"(18年笔记)基于策略函数的学习方法\",\"link\":\"03-strategy-learning\"},{\"text\":\"(18年笔记)基于值函数的学习\",\"link\":\"02-value-learning\"},{\"text\":\"(18年笔记)强化学习基础\",\"link\":\"01-reinforce-learning\"}]}]},\"/posts/llm/rl/rlhf/\":{\"base\":\"/posts/llm/rl/rlhf/\",\"items\":[{\"text\":\"RLHF\",\"items\":[]}]},\"/posts/llm/rl/o1llm/\":{\"base\":\"/posts/llm/rl/o1llm/\",\"items\":[{\"text\":\"推理模型\",\"items\":[]}]},\"/posts/llm/industry/mainllm/\":{\"base\":\"/posts/llm/industry/mainllm/\",\"items\":[{\"text\":\"🚀主流模型\",\"items\":[{\"text\":\"快手系列\",\"link\":\"12-kwai-series\"},{\"text\":\"腾讯系列\",\"link\":\"11-tencent-series\"},{\"text\":\"Claude 系列\",\"link\":\"09-claude-series\"},{\"text\":\"LongCat 系列\",\"link\":\"10-longcat-series\"},{\"text\":\"Gemini 系列\",\"link\":\"08-gemini-series\"},{\"text\":\"Seed 系列\",\"link\":\"06-seed-series\"},{\"text\":\"OpenAI 系列\",\"link\":\"07-openai-series\"},{\"text\":\"Qwen 系列\",\"link\":\"05-qwen-series\"},{\"text\":\"MiniMax 系列\",\"link\":\"04-minimax-series\"},{\"text\":\"GLM 系列\",\"link\":\"03-glm-series\"},{\"text\":\"DeepSeek 系列\",\"link\":\"02-deepseek-series\"},{\"text\":\"Kimi 系列\",\"link\":\"01-kimi-series\"},{\"text\":\"SkyWork 系列\",\"link\":\"15-skywork-series\"},{\"text\":\"小米系列\",\"link\":\"14-mimo-series\"},{\"text\":\"Nvidia 系列\",\"link\":\"13-nvidia-series\"}]}]},\"/posts/llm/industry/codellm/\":{\"base\":\"/posts/llm/industry/codellm/\",\"items\":[{\"text\":\"💻代码模型\",\"items\":[{\"text\":\"Code 全训练 论文阅读\",\"link\":\"07-code-fulltrain-reading\"},{\"text\":\"Code TaskRL 论文阅读\",\"link\":\"06-code-taskrl-reading\"},{\"text\":\"CodeLLM 索引简记\",\"link\":\"05-open-codellm\"},{\"text\":\"Code 安全相关\",\"link\":\"04-safety-code\"},{\"text\":\"Code RL 任务\",\"link\":\"03-rl-task\"},{\"text\":\"Code 任务Bench相关\",\"link\":\"02-eval-task-benchmark\"},{\"text\":\"Code Survey\",\"link\":\"01-survey\"},{\"text\":\"Code 预训练相关\",\"link\":\"08-code-pretrain-summary\"}]}]},\"/posts/llm/basic/\":{\"base\":\"/posts/llm/basic/\",\"items\":[{\"text\":\"LLM-basic\",\"items\":[{\"text\":\"LLM位置编码和长度外推系列\",\"link\":\"08-llm-position-embedding\"},{\"text\":\"LLM 解码相关\",\"link\":\"07-decode\"},{\"text\":\"LLM Attention 系列\",\"link\":\"06-llm-attention\"},{\"text\":\"LLM 基础知识\",\"link\":\"05-llm-basic-info\"},{\"text\":\"LLM 架构相关\",\"link\":\"04-llm-architecture\"},{\"text\":\"Transformer细节\",\"link\":\"03-transformer-detail\"},{\"text\":\"语言模型重要组件\",\"link\":\"02-llm-components\"},{\"text\":\"语言模型定义及信息理论\",\"link\":\"01-lm-define-information-theory\"}]}]},\"/posts/llm/infra/\":{\"base\":\"/posts/llm/infra/\",\"items\":[{\"text\":\"🛠LLM-基建框架\",\"items\":[{\"text\":\"Verl 训练流程源代码阅读\",\"link\":\"08-verl-train-loop\"},{\"text\":\"Verl 有趣的功能\",\"link\":\"07-verl-core\"},{\"text\":\"Verl AgentLoop Rollout 相关\",\"link\":\"06-verl-code\"},{\"text\":\"Verl 常见参数配置和理解\",\"link\":\"05-verl-practice\"},{\"text\":\"Verl 早期概念型学习文章\",\"link\":\"04-verl\"},{\"text\":\"推理优化技术\",\"link\":\"03-inference-tech\"},{\"text\":\"分布式训练框架\",\"link\":\"02-speed-framework\"},{\"text\":\"分布式并行策略\",\"link\":\"01-parrallel\"}]}]},\"/posts/exps/env/\":{\"base\":\"/posts/exps/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"环境搭建的一些坑\",\"link\":\"01-blog-env\"}]}]},\"/posts/exps/mind/\":{\"base\":\"/posts/exps/mind/\",\"items\":[{\"text\":\"心得体会\",\"items\":[]}]}}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>
<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Code Survey From Code Foundation Models to Agents and Applications | 📚 plmblog</title>
    <meta name="description" content="记录一些学习笔记。">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/assets/style.CuIOXX7t.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.DPx3siUU.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.JT-HaNkj.js">
    <link rel="modulepreload" href="/assets/chunks/framework.CvbyeFFO.js">
    <link rel="modulepreload" href="/assets/posts_llm_industry_codellm_01-survey.md.hg7Sj9OW.lean.js">
    <link rel="icon" href="/plm.png">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-cecb633e><!--[--><!--]--><!--[--><span tabindex="-1" data-v-c979f278></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-c979f278>Skip to content</a><!--]--><!----><header class="VPNav" data-v-cecb633e data-v-0ad68676><div class="VPNavBar" data-v-0ad68676 data-v-ce71e4ef><div class="wrapper" data-v-ce71e4ef><div class="container" data-v-ce71e4ef><div class="title" data-v-ce71e4ef><div class="VPNavBarTitle has-sidebar" data-v-ce71e4ef data-v-7e906684><a class="title" href="/" data-v-7e906684><!--[--><!--]--><!----><span data-v-7e906684>📚 plmblog</span><!--[--><!--]--></a></div></div><div class="content" data-v-ce71e4ef><div class="content-body" data-v-ce71e4ef><!--[--><!--]--><div class="VPNavBarSearch search" data-v-ce71e4ef><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-ce71e4ef data-v-e0cd9371><span id="main-nav-aria-label" class="visually-hidden" data-v-e0cd9371> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>首页</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup active" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>🐲LLM</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Basic</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/basic/01-lm-define-information-theory.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🦋基础知识</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/infra/01-parrallel.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🛠基建框架</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>强化学习</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/rl/theory/01-reinforce-learning.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🎓RL理论基础</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/rl/02-agent-tool.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚄Agent-RL</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>行业方向</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/industry/mainllm/01-kimi-series.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚀主流模型</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link active" href="/posts/llm/industry/codellm/01-survey.html" data-v-dc987abe><!--[--><span data-v-dc987abe>💻代码模型</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Agent</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/basic.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🤖概念及应用</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>📙旧文章</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍓NLP</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/nlp.html" data-v-dc987abe><!--[--><span data-v-dc987abe>自然语言处理</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍑基础知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/dl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>深度学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/rl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>强化学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/ml.html" data-v-dc987abe><!--[--><span data-v-dc987abe>机器学习</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍎算法</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/algo/" data-v-dc987abe><!--[--><span data-v-dc987abe>算法题</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/bigdata/" data-v-dc987abe><!--[--><span data-v-dc987abe>大数据</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍒其他</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/env/" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/other/" data-v-dc987abe><!--[--><span data-v-dc987abe>其他</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>经验</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>环境</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/env/01-blog-env.html" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>心得</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/mind.html" data-v-dc987abe><!--[--><span data-v-dc987abe>心得体会</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/archive.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>归档</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/me.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>关于我</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-ce71e4ef data-v-b59ebfac><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-b59ebfac data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-ce71e4ef data-v-e0f2db57 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-ce71e4ef data-v-8897e953 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-ffaaba87><span class="vpi-more-horizontal icon" data-v-ffaaba87></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><!----><!--[--><!--[--><!----><div class="group" data-v-8897e953><div class="item appearance" data-v-8897e953><p class="label" data-v-8897e953>Appearance</p><div class="appearance-action" data-v-8897e953><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-8897e953 data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div></div></div><div class="group" data-v-8897e953><div class="item social-links" data-v-8897e953><div class="VPSocialLinks social-links-list" data-v-8897e953 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-ce71e4ef data-v-37e0f734><span class="container" data-v-37e0f734><span class="top" data-v-37e0f734></span><span class="middle" data-v-37e0f734></span><span class="bottom" data-v-37e0f734></span></span></button></div></div></div></div><div class="divider" data-v-ce71e4ef><div class="divider-line" data-v-ce71e4ef></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-cecb633e data-v-1b409c8b><div class="container" data-v-1b409c8b><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-1b409c8b><span class="vpi-align-left menu-icon" data-v-1b409c8b></span><span class="menu-text" data-v-1b409c8b>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-1b409c8b data-v-a203161a><button data-v-a203161a>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-cecb633e data-v-18f7b5ca><div class="curtain" data-v-18f7b5ca></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-18f7b5ca><span class="visually-hidden" id="sidebar-aria-label" data-v-18f7b5ca> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-7f5b9a39><section class="VPSidebarItem level-0 has-active" data-v-7f5b9a39 data-v-a4affe07><div class="item" role="button" tabindex="0" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><h2 class="text" data-v-a4affe07>💻代码模型</h2><!----></div><div class="items" data-v-a4affe07><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/01-survey.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code Survey From Code Foundation Models to Agents and Applications</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-cecb633e data-v-53a9cb18><div class="VPDoc has-sidebar has-aside" data-v-53a9cb18 data-v-5a64a79a><!--[--><!--]--><div class="container" data-v-5a64a79a><div class="aside" data-v-5a64a79a><div class="aside-curtain" data-v-5a64a79a></div><div class="aside-container" data-v-5a64a79a><div class="aside-content" data-v-5a64a79a><div class="VPDocAside" data-v-5a64a79a data-v-f8ea3c28><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-f8ea3c28 data-v-b94d89ac><div class="content" data-v-b94d89ac><div class="outline-marker" data-v-b94d89ac></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-b94d89ac>当前页大纲</div><ul class="VPDocOutlineItem root" data-v-b94d89ac data-v-80b46526><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-f8ea3c28></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-5a64a79a><div class="content-container" data-v-5a64a79a><!--[--><!--[--><!--[--><article class="post-header" data-v-a99fd7c9><h1 class="title" data-v-a99fd7c9>Code Survey From Code Foundation Models to Agents and Applications</h1><div class="stats-container" data-v-a99fd7c9><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 📅 发表于 <span class="stat-text" data-v-a99fd7c9>2025/12/06</span></div><div class="stat-item" data-v-a99fd7c9> 🔄 更新于 <span class="stat-text" data-v-a99fd7c9>2025/12/06</span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 👁️ <span class="stat-text" data-v-a99fd7c9>-- 次访问</span><span id="busuanzi_value_page_pv" style="display:none;" data-page="/posts/llm/industry/codellm/01-survey.html" data-v-a99fd7c9></span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 📝 <span class="stat-text" data-v-a99fd7c9>0 字</span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> ⏳ <span class="stat-text" data-v-a99fd7c9>0 分钟</span></div><div class="stat-divider" data-v-a99fd7c9></div></div><div class="tag-group" data-v-a99fd7c9><!--[--><div class="category-item" data-v-a99fd7c9>code</div><!--]--><!--[--><div class="tag-item" data-v-a99fd7c9> #survey</div><!--]--></div></article><!--]--><!--]--><!--]--><main class="main" data-v-5a64a79a><div style="position:relative;" class="vp-doc _posts_llm_industry_codellm_01-survey" data-v-5a64a79a><div><h2 id="survey-文章" tabindex="-1">Survey 文章 <a class="header-anchor" href="#survey-文章" aria-label="Permalink to &quot;Survey 文章&quot;">​</a></h2><div class="custom-block caution"><div class="custom-block-title">参考文章</div><ul><li>(2512) <a href="https://www.alphaxiv.org/abs/2511.18538" target="_blank" rel="noreferrer">From Code Foundation Models to Agents and Applications</a></li><li>(2510) <a href="https://www.alphaxiv.org/abs/2510.12399" target="_blank" rel="noreferrer">A Survey of Vibe Coding with Large Language Models</a></li><li>(2508) <a href="https://www.alphaxiv.org/abs/2508.11126" target="_blank" rel="noreferrer">AI Agentic Programming</a></li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251206172440.jpg" style="display:block;margin:auto;" width="100%"><h2 id="背景" tabindex="-1">背景 <a class="header-anchor" href="#背景" aria-label="Permalink to &quot;背景&quot;">​</a></h2><h3 id="发展历程" tabindex="-1">发展历程 <a class="header-anchor" href="#发展历程" aria-label="Permalink to &quot;发展历程&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">背景</div><p><strong>AI Coding 思想</strong></p><ul><li>利用<code>Github</code>/<code>StackOverflow</code>/<code>code</code>网站资源，把<code>多年编程经验</code>提炼成<code>指令跟随的工具</code>。</li></ul><p><strong>相关工具</strong></p><ul><li>【辅助插件】<code>GitHub Copilot</code>：VSCode 插件</li><li>【IDE】<code>Cursor</code>：对话式编程</li><li>【国产】CodeGeeX(智谱)：多语言代码</li><li>【云服务】CodeWhisperer(亚马逊)：与AWS服务无缝集成，可调用Claude或Gemini。</li><li>【命令行】<code>Claude Code/Gemini CLI</code>：命令行级别，<code>agentic-coding-workflow</code>。 <ul><li>AI 自助分析文件、运行命令、修正代码</li></ul></li></ul></div><div class="custom-block tip"><div class="custom-block-title">Code LLM 两种分歧</div><p><strong>两种分歧</strong></p><ul><li><strong>通用型LLM (广度)</strong><ul><li><code>自然语言</code>+<code>编程数据</code> <code>混合预训练</code>，在上下文/意图/领域知识等理解细致。</li><li>代表工作：GPT、Claude、LLaMA等。</li></ul></li><li><strong>专用CodeLLM (深度)</strong><ul><li><code>编程数据</code>预训练+<code>算法架构优化</code>。</li><li>代表工作：StarCoder, Code LLaMA, DeepSeek-Coder, CodeGemma, QwenCoder等。</li></ul></li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-llm-overview.jpg" style="display:block;margin:auto;" width="100%"><h3 id="尚未探索的领域" tabindex="-1">尚未探索的领域 <a class="header-anchor" href="#尚未探索的领域" aria-label="Permalink to &quot;尚未探索的领域&quot;">​</a></h3><div class="custom-block warning"><div class="custom-block-title">目前尚缺乏探索的领域</div><p><strong>1. 数据清洗策略</strong></p><ul><li>如何<code>平衡数据质量和数量</code>？ <ul><li>数据并非越多越好，顶级模型如何</li></ul></li><li>如何做<code>指令跟随</code>？ <ul><li>让模型听懂人话。</li></ul></li></ul><p><strong>2. 对齐技术</strong></p><ul><li>code需要能跑、<code>符合人类习惯</code>、是<code>安全</code>的，如何<code>根据人类反馈来做对齐</code>？</li></ul><p><strong>3. 高级提示范式</strong></p><ul><li>CoT、FewShot等。</li></ul><p><strong>4. 自主智能体</strong></p><ul><li>自动拆解任务。</li></ul><p><strong>5. RAG</strong></p><ul><li>模型会有幻觉、编写出不存在的函数。</li><li>做RAG，让模型<code>先看文档</code>，<code>再写代码</code>，保证准确性。</li></ul><p><strong>6. 评估框架</strong></p><ul><li>现在更多是<code>2元的</code>(仅看<code>正确性</code>)。</li><li>但如何评估代码<code>烂不烂</code>、<code>效率如何</code>、<code>可维护性如何</code>？</li></ul></div><h3 id="通用llm-发展和不足" tabindex="-1">通用LLM 发展和不足 <a class="header-anchor" href="#通用llm-发展和不足" aria-label="Permalink to &quot;通用LLM 发展和不足&quot;">​</a></h3><h4 id="发展和涌现" tabindex="-1">发展和涌现 <a class="header-anchor" href="#发展和涌现" aria-label="Permalink to &quot;发展和涌现&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Rise of LLMs</div><p><strong>Transformer 和 Scaling Law</strong></p><ul><li><code>Transformer 一统江湖</code><ul><li>通过<code>预训练</code>和<code>知识迁移</code>，把多种统一到一个支持多种任务和模态的可扩展框架。</li><li>NTP任务</li></ul></li><li><code>Scaling Law 大力出奇迹</code><ul><li>参数、数据、计算越多，模型效果越好，可预测。</li><li>出现一些涌现能力，涌现也可能是评估指标的问题。</li></ul></li></ul><p><strong>LLM爆发出代码能力</strong></p><ul><li>OpenAI：Codex 能写代码 + HumanEval 测试集。</li><li>DeepMind：AlphaCode 能做竞技编程。</li><li><code>代码结构</code> 和<code>人类自然语</code>言在<code>底层逻辑上是相通的</code>。</li></ul><p><strong>LLM + 外部工具 变身 决策agent</strong></p><ul><li><code>外部工具</code>：计算器、搜索、代码解释器等等。</li><li><code>思考行动观察Loop</code>：思考 -&gt; 行动 -&gt; 观察 -&gt; 思考 -&gt; 行动 -&gt; 观察 ....</li><li>典型技术：ReAct，ToolFormer等。</li></ul><p><strong>突破、局限、CodeLLM动机</strong></p><ul><li>突破：SWE-Agent：修bug、通过所有测试用例。需要规划+多文件操作能力。</li><li><code>通用模型</code> 在代码领域<code>有局限性</code>： <ul><li><code>准确性</code>(复杂代码不会写)、<code>安全性</code>(有bug代码)、<code>可靠性</code>(系统级可靠性差)</li></ul></li><li>需要转<code>专有的代码大模型</code></li></ul></div><p>代码生成：HumanEval上的效果</p><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251206183411.jpg" style="display:block;margin:auto;" width="70%"><p>修bug：SWE-Bench上的效果</p><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251206183358.jpg" style="display:block;margin:auto;" width="70%"><h4 id="模型架构-多模态" tabindex="-1">模型架构&amp;多模态 <a class="header-anchor" href="#模型架构-多模态" aria-label="Permalink to &quot;模型架构&amp;多模态&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Dense Model</div><p><strong>1. Dense Model</strong></p><ul><li><a href="http://plmsmile.github.io/posts/llm/basic/04-llm-architecture.html#dense-model" target="_blank" rel="noreferrer">DenseModel</a></li></ul><p><strong>2. MoE</strong></p><ul><li><a href="http://plmsmile.github.io/posts/llm/basic/04-llm-architecture.html#moe-model" target="_blank" rel="noreferrer">MoEModel</a></li></ul><p><strong>3. Recurrent Models</strong></p><ul><li><a href="http://plmsmile.github.io/posts/llm/basic/04-llm-architecture.html#recurrent-model" target="_blank" rel="noreferrer">RecurrentModel</a></li></ul><p><strong>4. Diffusion Models</strong></p><ul><li><a href="http://plmsmile.github.io/posts/llm/basic/04-llm-architecture.html#diffusion-based-model" target="_blank" rel="noreferrer">DiffusionModel</a></li></ul><p><strong>5. Hybrid Architechures</strong></p><ul><li><a href="http://plmsmile.github.io/posts/llm/basic/04-llm-architecture.html#hybrid-architectures" target="_blank" rel="noreferrer">混合架构</a></li></ul></div><div class="custom-block note"><div class="custom-block-title">多模态</div><ul><li>主要依赖<code>视觉能力</code>，需要查看<code>图表</code>、<code>截图</code>、<code>UI元素</code>等内容。</li></ul></div><h4 id="不足" tabindex="-1">不足 <a class="header-anchor" href="#不足" aria-label="Permalink to &quot;不足&quot;">​</a></h4><div class="custom-block warning"><div class="custom-block-title">通用大模型的不足</div><p><strong>核心缺点</strong></p><ul><li><code>有广度</code>、<code>无深度</code></li><li>什么都会一点，能写简单代码、能看图等。</li></ul><p><strong>具体表现</strong></p><ul><li><code>专业和准确性不足</code><ul><li>生成表面看起来没问题的代码，但实际不能满足一些领域约束。 <ul><li><code>看起来对的代码</code>，<code>实际可能一跑就崩</code></li></ul></li></ul></li><li><code>安全和可靠性不足</code><ul><li>尽管功能正确能运行，但仍然不够安全、<code>有bug</code></li></ul></li><li><code>仓库级理解不足</code><ul><li>模型可读长上下文，但经常<code>lost-in-middle</code>。 <ul><li>关键信息藏在几万行代码中间，模型往往会忽略。</li><li><code>跨文件的变量引用</code>、<code>依赖关系</code>，模型经常搞不清楚，导致<code>无法理解整个项目</code>。</li></ul></li></ul></li><li><code>多模态障碍/看不懂界面细节</code><ul><li>能看懂是个网页，但无法看懂具体元素细节、按钮具体交互含义等</li><li>导致 AI 无法像人类一样精准地操作 GUI 界面进行编程或测试。</li></ul></li><li><code>不会用工具(Agentic限制)</code><ul><li><code>通用模型</code>容易出现<code>工具幻觉</code>：<code>假装调用了工具</code>，或者编造了工具的输出。</li><li>任务步骤变多(<code>长程推理</code>)，模型很容易这就<code>“晕”了</code>，忘记之前的步骤或偏离目标。</li></ul></li></ul><p><strong>用模型写代码不够，需要</strong></p><ul><li><code>数据清洗</code>：<code>去掉不安全</code>的代码。</li><li><code>预训练/微调</code>：让模型理解<code>代码结构</code>和<code>跨文件依赖</code></li><li><code>强化学习</code>：教模型如何<code>正确使用工具</code>和进行<code>长期规划</code></li></ul></div><h2 id="代码基础大模型-开源llm" tabindex="-1">代码基础大模型(开源LLM) <a class="header-anchor" href="#代码基础大模型-开源llm" aria-label="Permalink to &quot;代码基础大模型(开源LLM)&quot;">​</a></h2><h3 id="闭源llm" tabindex="-1">闭源LLM <a class="header-anchor" href="#闭源llm" aria-label="Permalink to &quot;闭源LLM&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">闭源LLM</div><ul><li><a href="https://plmsmile.github.io/posts/llm/industry/mainllm/07-openai-series.html" target="_blank" rel="noreferrer">GPT 系列</a></li><li><a href="https://plmsmile.github.io/posts/llm/industry/mainllm/08-gemini-series.html" target="_blank" rel="noreferrer">Gemini 系列</a></li><li><a href="https://plmsmile.github.io/posts/llm/industry/mainllm/09-claude-series.html" target="_blank" rel="noreferrer">Claude 系列</a></li><li>Grok系列</li></ul></div><h3 id="发展阶段" tabindex="-1">发展阶段 <a class="header-anchor" href="#发展阶段" aria-label="Permalink to &quot;发展阶段&quot;">​</a></h3><div class="custom-block info"><div class="custom-block-title">发展的几个阶段</div><p><strong>阶段1：Encoder 模型</strong></p><ul><li>聚焦在代码<code>理解任务</code>，把代码变成向量，做检索任务。</li><li>主要工作：CodeBert,ERNIE-Code等。</li></ul><p><strong>阶段2：生成式 模型</strong></p><ul><li>从读到写，聚焦在<code>理解和生成代码</code>。</li><li>主要工作：CodeT5, CodeGPT等。</li></ul><p><strong>阶段3：代码 LLM</strong></p><ul><li><p>大模型，能<code>写复杂代码</code>、<code>多轮对话</code>式编程、具有<code>指令遵循能力</code>等。</p></li><li><p>代表：StarCoder, CodeLlama, DeepSeek-Coder, CodeQwen等。</p></li></ul><p><strong>阶段4：Agentic 模型</strong></p><ul><li>通过<code>MoE来扩展参数</code> + 提升<code>agentic能力</code>(<code>工具使用</code>、<code>多步推理</code>等)。</li><li>代表：DeepSeek-Coder-V2、DeepCoder、DeepSWE等。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251209211313.jpg" style="display:block;margin:auto;" width="100%"><h4 id="阶段3-codellm主要工作" tabindex="-1">阶段3-CodeLLM主要工作 <a class="header-anchor" href="#阶段3-codellm主要工作" aria-label="Permalink to &quot;阶段3-CodeLLM主要工作&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">OpenCoder</div><p><strong>参考链接</strong></p><ul><li><a href="https://aclanthology.org/2025.acl-long.1591/" target="_blank" rel="noreferrer">paper</a></li></ul><p><strong>关键技术</strong></p><ul><li>完全开源：权重、预测、<code>RefineCode数据</code>、<code>训练流程</code></li><li>1.5B/8B，LLama-Style (RoPE, SwiGLU)</li><li>两阶段指令微调：<code>通用SFT</code>、<code>code SFT</code></li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>8B HumanEval/MBPP效果不错，debug新年超过StarCode2-15B和CodeLLama-7B</li></ul></div><div class="custom-block tip"><div class="custom-block-title">Qwen1.5&amp;2.5 Coder(2409)</div><p><strong>参考链接</strong></p><ul><li><a href="https://huggingface.co/Qwen/CodeQwen1.5-7B" target="_blank" rel="noreferrer">Qwen/CodeQwen1.5-7B</a>, <a href="https://arxiv.org/abs/2409.12186" target="_blank" rel="noreferrer">Qwen2.5-Coder 技术报告</a></li></ul><p><strong>CodeQwen1.5 (7B)</strong></p><ul><li><strong>关键技术</strong>：64k上下文，多种语言训练。GQA提升推理效率。</li><li><strong>训练数据</strong>：代码数据。</li><li><strong>数据清洗</strong></li><li><strong>关键结果</strong>：较好 bug, SQL, Debug能力。</li></ul><p><strong>Qwen2.5-Coder (0.5B-32B)</strong></p><ul><li><strong>关键技术</strong>： <ul><li>128k上下文(<a href="https://plmsmile.github.io/posts/llm/basic/08-llm-position-embedding.html#yarn" target="_blank" rel="noreferrer">Yarn技术</a>)</li><li>指令微调：<code>多语言合成数据</code> + <code>DPO优化 执行反馈</code>，<a href="https://plmsmile.github.io/posts/llm/rl/theory/09-policy-trpo-ppo.html#dpo" target="_blank" rel="noreferrer">DPO笔记</a></li></ul></li><li><strong>训练数据</strong>：混合代码、数学和文本。</li><li><strong>数据清洗</strong></li><li><strong>关键结果</strong><ul><li>在MultiPL-E, RepoEval, CrossCodeEval上效果不错</li><li><code>不依赖特定提示词格式</code>，泛化性不错。</li></ul></li></ul></div><div class="custom-block tip"><div class="custom-block-title">Yi-Coder (24)</div><p><strong>参考链接</strong></p><ul><li><a href="https://github.com/01-ai/Yi-Coder" target="_blank" rel="noreferrer">Yi-Coder</a></li></ul><p><strong>关键技术</strong></p><ul><li>128k 上下文、52种语言。</li><li>1.5B、9B。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>HumanEval, MBPP, LiveCodeBench 和大尺寸模型相当。</li></ul></div><div class="custom-block important"><div class="custom-block-title">Codestral (2509, Mistral AI)</div><p><strong>参考链接</strong></p><ul><li><a href="https://huggingface.co/mistralai/Codestral-22B-v0.1" target="_blank" rel="noreferrer">mistralai/Codestral-22B-v0.1</a></li></ul><p><strong>关键技术</strong></p><ul><li>多种语言，指令跟随。</li><li>32K上下文，仓库级推理，FIM填充能力。</li><li>22B模型。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>在RepoBench和Python相关评估上，效果不错。</li></ul></div><div class="custom-block tip"><div class="custom-block-title">Granite-Code(2405, IBM)</div><p><strong>参考链接</strong></p><ul><li><a href="https://doi.org/10.48550/arXiv.2405.04324" target="_blank" rel="noreferrer">Granite Code Models</a></li></ul><p><strong>关键技术</strong></p><ul><li>两阶段训练：<code>code预训练</code> + <code>混合code文本增强训练</code>。</li><li>目标：FIM (PSM/SPM)</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p></div><div class="custom-block tip"><div class="custom-block-title">CodeGemma (2406)</div><p><strong>参考链接</strong></p><ul><li><a href="https://arxiv.org/abs/2406.11409" target="_blank" rel="noreferrer">CodeGemma</a> 2B, 7B</li></ul><p><strong>关键技术</strong></p><ul><li><code>代码数据</code> <code>预训练</code>和 <code>指令微调</code>。</li><li>训练目标：<code>FIM</code> 且 <code>比例更高</code>，支持2种模式 <ul><li>前缀-后缀-中间(PSM)：先给P(prefix)，再给S(suffix)，猜中间M</li><li>后缀-前缀-中间(SPM)：先给S，再给P，猜中间M。</li></ul></li><li>2种尺寸：2B IDE场景-更快；7B chat设计、推理逻辑更强。</li></ul><p><strong>训练数据</strong></p><ul><li>代码数据</li></ul><p><strong>数据清洗</strong></p><ul><li>去重、去污染(去除测试数据)</li><li><code>Multi-file packing</code>：依赖<code>图</code>和<code>单元测试</code>的多文件打包策略。</li></ul><p><strong>关键结果</strong></p></div><div class="custom-block tip"><div class="custom-block-title">CodeShell (2403)</div><p><strong>参考链接</strong></p><ul><li><a href="https://arxiv.org/abs/2403.15747" target="_blank" rel="noreferrer">tech report</a></li></ul><p><strong>关键技术</strong></p><ul><li>GPT2(7B) 扩展：8k上下文、GQA、RoPE。</li><li>数据清洗比简单scaling有效。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><ul><li>去重、困惑度筛选、结构规则过滤、模型打分。</li></ul><p><strong>关键结果</strong></p><ul><li>优于同类7B模型，在MultiPL-E和代码补全bench上不错。</li></ul></div><div class="custom-block tip"><div class="custom-block-title">StableCode (23)</div><p><strong>链接</strong></p><ul><li><a href="https://huggingface.co/stabilityai/stable-code-3b" target="_blank" rel="noreferrer">stabilityai/stable-code-3b</a></li></ul><p><strong>关键技术</strong></p><ul><li>3B，代码生成和理解，代码补全和text2code。</li><li>长上下文：16k；<code>多文件推理</code>。</li></ul><p><strong>训练数据</strong></p><ul><li>Github corpora</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>HumanEval/MBPP 效果不错</li></ul></div><p>DeepSeek-Coder (2401) 见下文</p><div class="custom-block tip"><div class="custom-block-title">MFTCoder (2024)</div><p><strong>关键技术</strong></p><ul><li>多任务微调：代码补全、text2code、代码注释、代码翻译、单元测试生成等。</li><li>多任务平衡方法：数据平衡、token-weighted loss、focal-style强调。</li><li>效率优化技术：动态padding、packed SFT、PEFT等。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>相比于单SFT和简单混合SFT，MFTCoder效果更好，具有泛化能力。</li></ul></div><div class="custom-block tip"><div class="custom-block-title">Code LLaMA (2308)</div><p><strong>关键技术</strong></p><ul><li>基于LLaMA2开发，强调<code>长上下文</code>、<code>中间填充</code>、<code>代码指令跟随</code>等。 <ul><li>上下文：<a href="https://plmsmile.github.io/posts/llm/basic/08-llm-position-embedding.html#%E6%97%8B%E8%BD%AC%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81" target="_blank" rel="noreferrer">RoPE</a> base由<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.05ex;" xmlns="http://www.w3.org/2000/svg" width="3.25ex" height="2.022ex" role="img" focusable="false" viewBox="0 -871.8 1436.6 893.8" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1033,393.1) scale(0.707)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" style="stroke-width:3;"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>10</mn><mn>4</mn></msup></math></mjx-assistive-mml></mjx-container>放大至<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.05ex;" xmlns="http://www.w3.org/2000/svg" width="3.25ex" height="2.005ex" role="img" focusable="false" viewBox="0 -864 1436.6 886" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1033,393.1) scale(0.707)"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" style="stroke-width:3;"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>10</mn><mn>6</mn></msup></math></mjx-assistive-mml></mjx-container></li></ul></li></ul><p><strong>训练数据</strong></p><ul><li>初始化：由LLaMA2权重继续预训练。</li><li>语料库：<code>Code-heavy代码语料库</code></li><li>特定数据：Python和Instruct版本使用<code>特定数据集</code>做微调， 强调<code>特定语言</code>和<code>对齐能力</code>。</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li><code>长上下文</code>对<code>repo-level</code>任务有好处。</li><li><code>特定语言数据(python)</code>做微调对<code>语言任务有好处</code>。</li><li>经过<code>安全微调的指令模型</code>降低了毒性。</li></ul></div><div class="custom-block tip"><div class="custom-block-title">CodeGen2 (2305)</div><p><strong>关键技术</strong></p><ul><li>完整的训练配方：架构选择、采样模式、数据混合等。 <ul><li>架构：Casual Decoder就好了。</li></ul></li><li>混合训练目标：<code>NTP</code>(写下文，50% )；<code>Span Corruption</code>(补全中间,Infil Train, 填空题, 50%)</li><li>多轮预训练</li></ul><p><strong>训练数据</strong></p><ul><li>NL + PL (文本+代码)。</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>Infil 填空训练，会导致代码生成能力下降(从头写到尾的能力)。</li></ul></div><div class="custom-block tip"><div class="custom-block-title">StarCoder 1-2 (2023)</div><p><strong>StarCoder1</strong></p><ul><li><strong>关键技术</strong>：<code>长上下文</code> + 中间填充(FIM)训练</li><li><strong>训练数据</strong><ul><li>StarCoderBase：<code>TheStack </code>(宽松许可代码)</li><li>StarCoder：<code>Python数据定向微调</code></li></ul></li><li><strong>数据清洗</strong><ul><li>近似去重、benchmark数据去除、个人隐私去除等。</li></ul></li><li><strong>关键结果</strong><ul><li>benchmark效果好，IDE demo + OpenRAIL_M 许可证。</li></ul></li></ul><p><strong>StarCoder2</strong></p><ul><li><strong>关键技术</strong><ul><li>2阶段训练：<code>先训4k</code> 学基础语法；<code>再训16k</code>，处理长代码，<code>仓库级上下文</code>。</li><li>FIM 中间填充策略。</li></ul></li><li><strong>训练数据</strong><ul><li>TheStack V2：<code>多种语言</code> <code>issue/PR</code>、docs、<code>数学和逻辑</code>数据。</li></ul></li><li><strong>数据清洗</strong></li><li><strong>关键结果</strong><ul><li>3B/7B/15B模型。</li><li>3B超过其他同尺寸模型，15B超过更大模型。</li></ul></li></ul></div><div class="custom-block tip"><div class="custom-block-title">CodeGeeX (2023)</div><p><strong>关键技术</strong></p><ul><li>专注于代码<code>生成</code>和<code>翻译</code>。</li><li>INT8量化+FastTransformer：显存大幅降低。</li><li>上线VSCode插件。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>推出HUmanEval-X，评估<code>跨语言翻译能力</code>，包括C++,Java,JavaScript,Go等。</li></ul></div><div class="custom-block tip"><div class="custom-block-title">OctoCoder (2024)</div><p><strong>关键技术</strong></p><ul><li><code>指令跟随模型</code>，基于StarCoder-16B-Base做微调而来。</li></ul><p><strong>训练数据</strong></p><ul><li>使用了<code>代码提交记录</code>，即包含<code>自然语言</code>和<code>代码</code>。</li><li><code>避免了code-only偏差</code>。</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>释放<code>HumanEvalPack</code>：把HumanEval扩展至代码<code>修复/解释/生成</code>，以及<code>6种</code>语言。</li><li>pass@1效果好，<code>commit-style</code>数据对<code>bug-fix有好处</code>。</li></ul></div><div class="custom-block tip"><div class="custom-block-title">SantaCoder (2023, BigCode)</div><p><strong>关键技术</strong></p><ul><li><a href="https://plmsmile.github.io/posts/llm/basic/06-llm-attention.html#multi-query-attention-2019" target="_blank" rel="noreferrer">MQA</a>：提高推理速度</li><li>两阶段训练方法：先验证设计，再做大规模实验</li></ul><p><strong>训练数据</strong></p><ul><li><code>Python,Java,Javascritp</code>等代码数据。</li></ul><p><strong>数据清洗</strong></p><ul><li><code>去掉个人信息</code>、<code>近似去重</code>、<code>文档质量过滤</code>等。</li></ul><p><strong>关键结果</strong></p><ul><li>在<code>多语言code benc</code>h(Multi-PL-E)上，优于一些参数更大的模型。</li></ul></div><h4 id="阶段4-codellm主要工作" tabindex="-1">阶段4-CodeLLM主要工作 <a class="header-anchor" href="#阶段4-codellm主要工作" aria-label="Permalink to &quot;阶段4-CodeLLM主要工作&quot;">​</a></h4><div class="custom-block important"><div class="custom-block-title">DeepSeek-Coder-V2 (2406)</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2406.11931" target="_blank" rel="noreferrer">DeepSeek-Coder-V2</a></li></ul><p><strong>关键技术</strong></p><ul><li>从DeepSeek-V2继续预训练，对代码和数学继续强化。</li><li>MoE 架构，两个版本：236A21B，16A2.5B。</li><li>YARN：上下文从16k扩展至128K。</li></ul><p><strong>训练数据</strong></p><ul><li>混合数据：代码、数学、文本。数学对编程逻辑重要。6T token。</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>效果和高效。</li></ul></div><div class="custom-block tip"><div class="custom-block-title">DeepSeek-Coder (2401)</div><p><strong>关键技术</strong></p><ul><li><p><code>从0开始预训练</code>，产出1.3-33B 模型</p></li><li><p><code>仓库级预训练</code>：</p><ul><li>模拟跨文件的依赖关系，提升对<code>repo-level</code>的理解和跨文件补全能力。</li></ul></li><li><p><code>中间填充目标</code>(Fill in the Midddle) + <code>长上下文</code>(16k)：</p><ul><li>增强<code>代码补全</code>和<code>长距离代码推理</code>能力。</li></ul></li></ul><p><strong>训练数据</strong></p><ul><li><code>多种编程语言</code>语料库，<code>无私有数据</code>。</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>在HumanEval和MBPP上超过 GPT-3.5</li><li>指令微调版本：<code>多轮</code>问题解决能力更好</li></ul></div><div class="custom-block note"><div class="custom-block-title">MiniMax M1/M2 (2506,2510)</div><p><strong>参考链接</strong></p><ul><li><a href="https://plmsmile.github.io/posts/llm/industry/mainllm/04-minimax-series.html#_2506-minimax-m1-scaling-test-time-compute-efficiently-with-lightning-attention" target="_blank" rel="noreferrer">M1笔记</a>， <a href="https://plmsmile.github.io/posts/llm/industry/mainllm/04-minimax-series.html#_2506-minimax-m1-scaling-test-time-compute-efficiently-with-lightning-attention" target="_blank" rel="noreferrer">M2笔记</a></li></ul><p><strong>关键技术</strong></p><ul><li>M1：线性注意力，</li><li>M2：softmax注意力。参数230B，激活10B</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p></div><div class="custom-block note"><div class="custom-block-title">DeepSeek V3 (24,25)</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2412.19437" target="_blank" rel="noreferrer">DeepSeek-V3 技术报告</a></li></ul><p><strong>关键技术</strong></p><ul><li>整体上：agent能力，混合思考模式，671B激活37B，128k上下文。</li><li>DeepSeek-V3 <ul><li>MLA+多token预测头，14.8T 预训练，无辅助loss做MoE 负载均衡</li><li>SFT + RL 微调</li></ul></li><li>DeepSeek-V3.1 <ul><li>PostTrain：840B语料，上下文由32K扩展至128k，整合DeepThink思维了模式。</li><li>增强多步工具+code-agent能力，超过v3和r1</li></ul></li><li>DeepSeek-V3.2 <ul><li>基于V3.1-Terminus，使用DSA稀疏注意力，推理成本降低50%，质量和v3.1相当</li></ul></li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p></div><div class="custom-block note"><div class="custom-block-title">KAT-Dev (2510, 快手)</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2510.18779" target="_blank" rel="noreferrer">KAT-Coder 技术报告</a></li></ul><p><strong>关键技术</strong></p><ul><li>基于Qwen3底座。</li><li>训练pipeline <ul><li>Mid-Training：针对工具使用+指令遵循</li><li>SFT：</li><li>RL：代码任务</li><li>大规模AgentRL：</li></ul></li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>32B SWE-verified 62.4%</li></ul></div><div class="custom-block note"><div class="custom-block-title">Kimi-K2-Instruct</div><p><strong>参考链接</strong></p><ul><li><a href="https://huggingface.co/moonshotai/Kimi-K2-Instruct" target="_blank" rel="noreferrer">moonshotai/Kimi-K2-Instruct</a>, <a href="https://plmsmile.github.io/posts/llm/industry/mainllm/01-kimi-series.html#_2507-kimi-k2-open-agentic-intelligence" target="_blank" rel="noreferrer">Kimi-K2 笔记</a></li></ul><p><strong>关键技术</strong></p><ul><li>超稀疏MoE：总参数1T，激活32B</li><li>预训练：MuonClip：解决梯度爆炸不收敛的问题。</li><li>SFT：Agent数据合成技术</li><li>RL：可评估和不可评估任务。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>原生工具调用、128k上下文。权重开源。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251210230435.jpg" style="display:block;margin:auto;" width="70%"><div class="custom-block note"><div class="custom-block-title">GLM4.5/4.6 (2508)</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2508.06471" target="_blank" rel="noreferrer">GLM4.5 paper</a>,</li></ul><p><strong>关键技术</strong></p><ul><li>架构：A32B，混合推理模式，GQA+QK-Norm+MoE 多token预测头</li><li>Mid-Training <code>关键数据上采样</code>：<code>仓库级代码</code> + <code>Agent轨迹</code> 数据</li><li>上下文扩展：4k -&gt; 32k -&gt; 128k -&gt; 200k(GLM4.6)</li><li>后训练：监督学习 + 自蒸馏。 <ul><li>RL技巧：难度课程、长输出RL、代码加权loss (给代码更高权重)</li></ul></li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>在TAU-Bench、AIME、SWE-verified、BrowseComp等有较好效果。</li><li>GLM4.6 进一步提升代码、工具使用、agent能力等。</li></ul></div><div class="custom-block note"><div class="custom-block-title">Qwen3-Coder (2507)</div><p><strong>参考链接</strong></p><ul><li><a href="https://qwenlm.github.io/blog/qwen3-coder/" target="_blank" rel="noreferrer">qwen3-coder 博客</a></li></ul><p><strong>关键技术</strong></p><ul><li>MoE, <code>480A35B</code>，上下文<code>256k -&gt; 1M</code>, YaRN。</li><li><code>预训练</code> + <code>所有代码可执行</code>的Code RL训练。</li></ul><p><strong>训练数据</strong></p><ul><li>预训练 <ul><li>通用、数学 + 代码， 7.5T tokens (70%)</li><li>合成数据：利用Qwen2.5-Coder对低质数据做清洗和重写，提升质量。</li></ul></li><li>RL <ul><li>不仅是竞赛代码，对所有代码做执行驱动的RL。</li></ul></li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>Agentic Coding、Agentic Browser-Use 和 Agentic Tool-Use 开源SOTA，可与Claude Sonnet4 媲美</li></ul></div><div class="custom-block note"><div class="custom-block-title">devstral (mistral)</div><p><strong>参考链接</strong></p><ul><li><a href="https://mistral.ai/news/devstral" target="_blank" rel="noreferrer">devstral</a></li></ul><p><strong>关键技术</strong></p><ul><li>目标<code>repo-scale SWE</code>，多文件推理、长上下文编辑、可验证。</li><li>Devstral-Small (24B, 128k上下文)，Devstral-Medium (API)</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>完全开源。</li></ul></div><div class="custom-block note"><div class="custom-block-title">DeepSWE (2508)</div><p><strong>参考链接</strong></p><ul><li><a href="https://huggingface.co/agentica-org/DeepSWE-Preview" target="_blank" rel="noreferrer">agentica-org/DeepSWE-Preview</a>, <a href="https://pretty-radio-b75.notion.site/DeepSWE-Training-a-Fully-Open-sourced-State-of-the-Art-Coding-Agent-by-Scaling-RL-22281902c1468193aabbe9a8c59bbe33" target="_blank" rel="noreferrer">tech blog</a>, <a href="https://www.alphaxiv.org/abs/2508.03501" target="_blank" rel="noreferrer">SWE-RL-paper</a></li></ul><p><strong>关键技术</strong></p><ul><li>基模：Qwen3-32B + 思考模式</li><li><code>纯RL训练</code>，目标repo-level，<code>可执行</code>和 <code>不执行</code>两种验证器。</li><li>R2E-Gym环境，<a href="https://pretty-radio-b75.notion.site/rLLM-A-Framework-for-Post-Training-Language-Agents-21b81902c146819db63cd98a54ba5f31" target="_blank" rel="noreferrer">rLLM 训练框架</a></li></ul><p><strong>训练数据</strong></p><ul><li>R2E-Gym的子集，4.5k。</li></ul><p><strong>数据清洗</strong></p><ul><li>过滤了和bench相关的数据</li></ul><p><strong>关键结果</strong></p><ul><li>SWE-verified：59%</li></ul></div><div class="custom-block note"><div class="custom-block-title">DeepCoder (2503?)</div><p><strong>参考链接</strong></p><ul><li><a href="https://pretty-radio-b75.notion.site/DeepCoder-A-Fully-Open-Source-14B-Coder-at-O3-mini-Level-1cf81902c14680b3bee5eb349a512a51" target="_blank" rel="noreferrer">DeepCoder-14B-Preview</a>, <a href="https://www.alphaxiv.org/abs/2505.05315v2" target="_blank" rel="noreferrer">Scalable CoT via Elastic Reasoning</a></li></ul><p><strong>关键技术</strong></p><ul><li>基于DS-R1-14B，继续做RLVR训练，目标repo-level代码编辑。</li><li>训练32k，测试64k。</li></ul><p><strong>训练数据</strong></p><ul><li>TACO-verified、LiveCodeBench(23-24)</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>完全开源</li></ul></div><div class="custom-block note"><div class="custom-block-title">Skywork-SWE (2506)</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2506.19290" target="_blank" rel="noreferrer">Skywork-SWE-32B</a></li></ul><p><strong>关键技术</strong></p><ul><li><code>可执行的数据清洗pipeline</code><ul><li>收集<code>[PR, Isssue]</code>数据，每个issue配一个docker容器</li><li>让agent去修bug，<code>仅保留能通过</code>测试用例的轨迹数据。</li></ul></li><li>高质量可执行SWE 数据 Scale &gt; 模型尺寸 scale <ul><li>效果和数量，呈log对数增长</li></ul></li><li>在openhands框架，使用轨迹数据，做微调。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>SWE-verifed 有较好结果</li></ul></div><div class="custom-block note"><div class="custom-block-title">Ling-Coder-Lite (2503)</div><p><strong>参考链接</strong></p><ul><li><a href="https://huggingface.co/inclusionAI/Ling-Coder-lite" target="_blank" rel="noreferrer">inclusionAI/Ling-Coder-lite</a>, <a href="https://www.alphaxiv.org/abs/2503.17793" target="_blank" rel="noreferrer">paper</a></li></ul><p><strong>关键技术</strong></p><ul><li>MoE，top6 路由，改进的NormHead。</li><li><code>共享/常驻专家</code>：shared+routed expertes，DeepSeekV2首创设计。</li><li>训练策略：继续预训练、指令优化(<code>SFT</code> + <code>DPO</code>)</li></ul><p><strong>训练数据</strong></p><ul><li>指令优化数据：高质量、<code>可执行</code>、<code>仓库结构数据</code>。</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>HumanEval, MBPP, LiveCodeBench, BigCodeBench等</li></ul></div><h4 id="其他架构" tabindex="-1">其他架构 <a class="header-anchor" href="#其他架构" aria-label="Permalink to &quot;其他架构&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">提示</div><p><strong>Gemini Diffusion / Mercur Coder</strong></p><ul><li>闭源模型。质量不错，时间大幅降低。</li></ul><p><strong>DiffuCoder</strong></p><ul><li>开源模型，130B训练，与AR模型效果差不多。</li><li>Coupled-GRPO： <ul><li>专门适配扩散模型的RL算法，利用非自回归特性， 引入互补噪声，减少似然估计方差，更好利用探索空间</li><li>21k RL样本，在EvalPlus上带来4.4%的提升。</li></ul></li></ul></div><h3 id="模型训练阶段-预训练-后训练" tabindex="-1">模型训练阶段(预训练+后训练) <a class="header-anchor" href="#模型训练阶段-预训练-后训练" aria-label="Permalink to &quot;模型训练阶段(预训练+后训练)&quot;">​</a></h3><div class="custom-block warning"><div class="custom-block-title">预训练</div><p><strong>数据收集和处理</strong></p><ul><li>爬取海量数据：web 网页、书籍、学术文献、专有材料等。</li><li>数据处理：去重、过滤、tokenize、格式标准化、统一编码、增加特殊标记等。 <ul><li>清洗过滤：去掉低质量、敏感数据等。具体可看主要工作怎么清洗的。</li></ul></li></ul><p><strong>预训练</strong></p><ul><li>随机初始化参数进行训练，消耗最大的部分。</li><li>目标：NTP/MTP/FIM等任务，自监督学习，预测mask的部分。</li></ul><p><strong>CPT</strong></p><ul><li><code>在预训练模型基础上</code>，喂<code>大量代码数据</code> 做<code>继续预训练</code>，做领域适配等等。</li></ul><p><strong>退火策略</strong></p><ul><li>在训练后期，动态调整参数，重点是学习率。</li><li>训练初期学习率较大，加速收敛，后期需要逐渐降低学习率，帮助收敛至最优解。</li></ul></div><div class="custom-block warning"><div class="custom-block-title">后训练</div><p><strong>SFT</strong></p><ul><li>给定输入-输出，教模型回答，</li><li>如Repo SFT，角膜型理解多文件直接的依赖关系。</li></ul><p><strong>RL</strong></p><ul><li>通过人类反馈、奖励机制，进一步提升模型性能。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251210214716.jpg" style="display:block;margin:auto;" width="70%"><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251210221126.jpg" style="display:block;margin:auto;" width="70%"><h3 id="预训练相关" tabindex="-1">预训练相关 <a class="header-anchor" href="#预训练相关" aria-label="Permalink to &quot;预训练相关&quot;">​</a></h3><h4 id="预训练任务" tabindex="-1">预训练任务 <a class="header-anchor" href="#预训练任务" aria-label="Permalink to &quot;预训练任务&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">基模预训练任务</div><p><strong>NTP</strong></p><ul><li>猜下一词</li><li>最大化条件概率 <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.566ex;" xmlns="http://www.w3.org/2000/svg" width="17.564ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 7763.1 1000" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(751,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(1140,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(605,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(2953.9,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(3231.9,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(605,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(4240.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(4685.2,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(5129.8,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(5574.5,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(6019.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(6463.8,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(7374.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow data-mjx-texclass="ORD"><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo data-mjx-texclass="ORD" stretchy="false">|</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>,</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></li></ul><p><strong>MTP</strong></p><ul><li>一次猜多个词，预判了你的预判。</li></ul><p><strong>Fill-in-the-Middle (FIM)</strong></p><ul><li>背景：在文件中间插入代码， 需要看<code>前面的代码prefix</code>，也要看<code>后面的代码suffix</code>。</li><li><code>代码模型的特有能力</code>之一，增强代码补全能力。</li></ul><p><strong>Diffusion Coder Training Task</strong></p><ul><li>加噪：把一段<code>好代码</code>随机替换成<code>乱码/噪声</code>。</li><li>去噪：让模型<code>把乱码</code>逐步还原成<code>清晰的代码</code>。</li></ul></div><table tabindex="0"><thead><tr><th style="text-align:left;">任务名称</th><th style="text-align:left;">核心逻辑</th><th style="text-align:left;">典型应用场景</th><th style="text-align:left;">优势</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>NTP</strong> (Next Token Prediction)</td><td style="text-align:left;">猜下一个词</td><td style="text-align:left;">所有的 GPT 类模型</td><td style="text-align:left;">基础能力，学会语法和逻辑</td></tr><tr><td style="text-align:left;"><strong>MTP</strong> (Multi-Token Prediction)</td><td style="text-align:left;">猜下面 N 个词</td><td style="text-align:left;">高级模型训练</td><td style="text-align:left;">提高推理速度，增强逻辑连贯性</td></tr><tr><td style="text-align:left;"><strong>FIM</strong> (Fill-in-the-Middle)</td><td style="text-align:left;">完形填空</td><td style="text-align:left;">IDE 里的光标补全</td><td style="text-align:left;">能同时看上下文，补全更准</td></tr><tr><td style="text-align:left;"><strong>Diffusion</strong> (扩散任务)</td><td style="text-align:left;">降噪去模糊</td><td style="text-align:left;">探索性架构</td><td style="text-align:left;">生成多样性高，可并行生成</td></tr></tbody></table><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251210212946.jpg" style="display:block;margin:auto;" width="70%"><h4 id="预训练数据" tabindex="-1">预训练数据 <a class="header-anchor" href="#预训练数据" aria-label="Permalink to &quot;预训练数据&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">预训练数据</div><p><strong>整体趋势</strong></p><ul><li>从追求庞大数量 -&gt; 追求数据质量/许可等。即粗放收集 -&gt; 精细化清洗 -&gt; 合规与大规模。</li></ul><p><strong>Github 数据</strong></p><ul><li>The Stack v1 <ul><li>358种编程语言，3.1TB数据，宽松许可源代码。</li><li>两阶段去重策略：精准匹配hash和近似去重hash。</li></ul></li><li>The Stack v2(当前行业标准) <ul><li>数据扩大四倍，900B token，600种语言，32TB</li><li>来源引入<code>Software Heritage</code>，加入<code>PR&amp;Issues</code>，包含人类如何<code>讨论</code>和<code>修改</code>代码的<code>逻辑过程</code>。</li></ul></li><li>Open Coder <ul><li>3.3TB，13种语言</li></ul></li></ul><p><strong>StarCoder 数据</strong></p><ul><li>从The Stack里精选出来的一部分数据，783GB，86种语言。</li><li>策略：去掉bench数据更干净，增加github issue和commit。</li></ul><p><strong>其他数据</strong></p><ul><li>The Pile：825GB，有代码、论文、网页等混合数据，早期数据。</li><li>RedPajama：1T，包括59B的代码数据，宽松许可证。最初用来复现LLaMA模型的。</li><li>CodeParrot：专注于python的高质量数据集，去重过滤了70%的原始数据。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251210221622.jpg" style="display:block;margin:auto;" width="70%"><h3 id="未来趋势" tabindex="-1">未来趋势 <a class="header-anchor" href="#未来趋势" aria-label="Permalink to &quot;未来趋势&quot;">​</a></h3><div class="custom-block important"><div class="custom-block-title">趋势</div><p><strong>从通才到专才</strong></p><ul><li>现状：GPT5-Codex、CLaude-4代码变体，都说明了<code>特定领域优化有效果</code>。</li><li>未来：通用AI和编程助手<code>继续分化</code><ul><li>在repo-level 任务、复杂调试、多步软件工程等场景取得突破</li></ul></li></ul><p><strong>Agentic训练&amp;复杂场景攻克</strong></p><ul><li>从<code>被动代码生成</code>向<code>主动软件工程</code>转变，在复杂、多步编程场景自主操作。</li><li>需要RL从执行反馈中学习，渐进式课程学习处理仓库级任务，集成外部工具和环境。</li><li>需要理解整个项目、浏览代码库、执行迭代调试，和人类协作。</li></ul><p><strong>Scaling Law</strong></p><ul><li><code>科学Scaling策略</code>：是把钱花在<code>模型参数</code>、还是清洗<code>更高质量数据</code>。</li><li>MoE架构优化：保持计算效率、实现更优性能。<code>MoE大势所趋</code>。</li></ul></div></div></div></main><footer class="VPDocFooter" data-v-5a64a79a data-v-54a90a4a><!--[--><!--]--><!----><!----></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--[--><div class="busuanzi"> 总访客数： <span id="busuanzi_value_site_uv"></span>   ·   总访问量： <span id="busuanzi_value_site_pv"></span></div><div class="busuanzi"> PLM&#39;s Blog @ 2016 - 2025</div><!--]--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api-examples.md\":\"Bt59YpwR\",\"index.md\":\"DmRGHmj9\",\"markdown-examples.md\":\"CPJSv--2\",\"posts_archive.md\":\"pZWQT7dp\",\"posts_exps_env_01-blog-env.md\":\"CcTUm41j\",\"posts_exps_env_index.md\":\"BJEZeoT-\",\"posts_exps_mind_index.md\":\"naOB3-Mb\",\"posts_llm_agent_basic_01-lhy-agent-notes.md\":\"BK_CsHNC\",\"posts_llm_agent_basic_02-evaluation-agent.md\":\"Dn02cVtP\",\"posts_llm_agent_basic_03-current-agents.md\":\"C25gmbg8\",\"posts_llm_agent_basic_04-agent-blogs.md\":\"_QbL2Plv\",\"posts_llm_agent_basic_05-comuter-agent.md\":\"D0gJpId6\",\"posts_llm_agent_basic_06-deepresearch-evaluation.md\":\"DdRDcxUJ\",\"posts_llm_agent_basic_index.md\":\"ClGtwUqg\",\"posts_llm_agent_rl_01-agent-rl.md\":\"wOF9bz66\",\"posts_llm_agent_rl_02-agent-tool.md\":\"IB_AqkSe\",\"posts_llm_agent_rl_03-agent-search.md\":\"Cim7OGxb\",\"posts_llm_agent_rl_04-agent-env.md\":\"C_O9BVi3\",\"posts_llm_agent_rl_index.md\":\"BudtoDK9\",\"posts_llm_basic_01-lm-define-information-theory.md\":\"SWz74rOE\",\"posts_llm_basic_02-llm-components.md\":\"CGM_jRUE\",\"posts_llm_basic_03-transformer-detail.md\":\"BgLyAVDZ\",\"posts_llm_basic_04-llm-architecture.md\":\"3LsqoiXu\",\"posts_llm_basic_05-llm-basic-info.md\":\"bdnM02bn\",\"posts_llm_basic_06-llm-attention.md\":\"BRJ9jR-M\",\"posts_llm_basic_07-decode.md\":\"BRytPqZo\",\"posts_llm_basic_08-llm-position-embedding.md\":\"d9dN_RuO\",\"posts_llm_basic_index.md\":\"DjX2HRXy\",\"posts_llm_industry_codellm_01-survey.md\":\"hg7Sj9OW\",\"posts_llm_industry_mainllm_01-kimi-series.md\":\"9r61oXF_\",\"posts_llm_industry_mainllm_02-deepseek-series.md\":\"CbFPC7Wl\",\"posts_llm_industry_mainllm_03-glm-series.md\":\"CH_696rq\",\"posts_llm_industry_mainllm_04-minimax-series.md\":\"BSNuXYYT\",\"posts_llm_industry_mainllm_05-qwen-series.md\":\"B4DMxRmo\",\"posts_llm_industry_mainllm_06-seed-series.md\":\"BNsIBjBZ\",\"posts_llm_industry_mainllm_07-openai-series.md\":\"Bdph_ysD\",\"posts_llm_industry_mainllm_08-gemini-series.md\":\"Bdm2kU-I\",\"posts_llm_industry_mainllm_09-claude-series.md\":\"B87guYs4\",\"posts_llm_industry_mainllm_10-longcat-series.md\":\"DroIAFXW\",\"posts_llm_infra_01-parrallel.md\":\"Dih7M1RJ\",\"posts_llm_infra_02-speed-framework.md\":\"D2yd8ryf\",\"posts_llm_infra_03-inference-tech.md\":\"Hpk9YmXF\",\"posts_llm_infra_04-verl.md\":\"8XtGz01J\",\"posts_llm_infra_05-verl-practice.md\":\"ulu95jWD\",\"posts_llm_infra_06-verl-code.md\":\"CiK8Anhz\",\"posts_llm_infra_07-verl-core.md\":\"3RS___SF\",\"posts_llm_infra_08-verl-train-loop.md\":\"Cbduxe-6\",\"posts_llm_rl_index.md\":\"iUgEsMU1\",\"posts_llm_rl_theory_01-reinforce-learning.md\":\"Ch0rtQCM\",\"posts_llm_rl_theory_01-rl-introduction.md\":\"CmW63EkM\",\"posts_llm_rl_theory_02-markove-process.md\":\"DVY5XgWd\",\"posts_llm_rl_theory_02-value-learning.md\":\"CeOlmbeS\",\"posts_llm_rl_theory_03-model-based-prediction-control.md\":\"BhVRmo7C\",\"posts_llm_rl_theory_03-strategy-learning.md\":\"DWNvEZXH\",\"posts_llm_rl_theory_04-model-free-prediction-control.md\":\"Cg3qo2Fk\",\"posts_llm_rl_theory_04-reinforce-conclusion-simple.md\":\"C6yTAxwQ\",\"posts_llm_rl_theory_05-dqn.md\":\"BatSdlnZ\",\"posts_llm_rl_theory_06-policy-gradient.md\":\"BXI-eY8I\",\"posts_llm_rl_theory_07-actor-critic.md\":\"B1-83sen\",\"posts_llm_rl_theory_08-deterministic-policy-gradient.md\":\"Dgvru3JE\",\"posts_llm_rl_theory_09-policy-trpo-ppo.md\":\"0LhhTHu3\",\"posts_llm_rl_theory_10-ppo-series.md\":\"B-5Hsj_J\",\"posts_llm_rl_theory_11-grpo-series.md\":\"MR1zGD8v\",\"posts_llm_rl_theory_12-entropy.md\":\"BH45bCLH\",\"posts_llm_rl_theory_13-agentrl-algo.md\":\"BfctbxM6\",\"posts_me.md\":\"B9W6CMag\",\"posts_olds_algo_aim2offer.md\":\"jCwzQ4BU\",\"posts_olds_algo_aim2offer2.md\":\"Ga2XS6dR\",\"posts_olds_algo_aim2offer3.md\":\"BP0rCZaJ\",\"posts_olds_algo_aim2offer4.md\":\"BXurWO8W\",\"posts_olds_algo_algorithm-dfs.md\":\"CkUFsStz\",\"posts_olds_algo_index.md\":\"CmdF0Gg2\",\"posts_olds_algo_leetcode-01.md\":\"C_2G2jJT\",\"posts_olds_algo_sort-algorithms.md\":\"tFMUVlmH\",\"posts_olds_bigdata_16-spark-baserdd.md\":\"CBxdArgI\",\"posts_olds_bigdata_17-spark-pairrdd.md\":\"C3n8_zMO\",\"posts_olds_bigdata_18-spark-sql.md\":\"tsaWQLcp\",\"posts_olds_bigdata_19-spark-programming.md\":\"DG5ZAF85\",\"posts_olds_bigdata_20-numpy.md\":\"DucCD22z\",\"posts_olds_bigdata_index.md\":\"CWrZwWPb\",\"posts_olds_dl_23-pytorch-start.md\":\"BokpNeAw\",\"posts_olds_dl_35-nerual-network-optim.md\":\"Cp2SpLoE\",\"posts_olds_dl_38-convolution.md\":\"CC_SQ57z\",\"posts_olds_dl_cs224n-assignment-1.md\":\"BZMSZqOS\",\"posts_olds_dl_cs224n-notes3-neural-networks-2.md\":\"Wd9TmSyb\",\"posts_olds_dl_cs224n-notes3-neural-networks.md\":\"CDZWc4X6\",\"posts_olds_dl_cs231n-linear-notes.md\":\"DLRyzcwJ\",\"posts_olds_dl_index.md\":\"C1dyLGNS\",\"posts_olds_dl_rnn.md\":\"CwYYWZ7N\",\"posts_olds_env_09-linux-notes.md\":\"CyjifvcN\",\"posts_olds_env_12-ide-envs.md\":\"YeELWzR2\",\"posts_olds_env_13-old-blog-problems.md\":\"qamPyucB\",\"posts_olds_env_24-hexo-problems.md\":\"CzxhyjW1\",\"posts_olds_env_index.md\":\"DQpgTXVj\",\"posts_olds_ml_10-trees.md\":\"BkNaj6fL\",\"posts_olds_ml_14-em.md\":\"DIufCP0H\",\"posts_olds_ml_21-lr.md\":\"C-1ms511\",\"posts_olds_ml_22-ml-ch03-bayes.md\":\"Q_M6Gn-a\",\"posts_olds_ml_27-svm-notes.md\":\"C96WS6CL\",\"posts_olds_ml_28-ml-interview-notes.md\":\"0bgezw3n\",\"posts_olds_ml_29-desicion-tree.md\":\"CtwmlbWl\",\"posts_olds_ml_crf.md\":\"CEE5oTqd\",\"posts_olds_ml_index.md\":\"BLMEziB1\",\"posts_olds_ml_maxentmodel.md\":\"CSbOumJx\",\"posts_olds_ml_pgm-01.md\":\"BTwybTMD\",\"posts_olds_nlp_11-nlp-labels.md\":\"Cl0Lb8OT\",\"posts_olds_nlp_25-google-nmt.md\":\"BOM-hoYN\",\"posts_olds_nlp_26-wordpieacemodel.md\":\"Q8-L5j15\",\"posts_olds_nlp_30-dynamic-memory-network.md\":\"wp5ucVxW\",\"posts_olds_nlp_31-co-attention-vqa.md\":\"lzwuVKG5\",\"posts_olds_nlp_32-dynamic-coattention-network.md\":\"Bxl4ABWd\",\"posts_olds_nlp_33-attention-summary.md\":\"DT6np0xG\",\"posts_olds_nlp_36-alime-chat.md\":\"Cu2xkcdT\",\"posts_olds_nlp_39-squard-models.md\":\"B1L3iDEv\",\"posts_olds_nlp_45-match-lstm.md\":\"DkpQKM5B\",\"posts_olds_nlp_46-rnet-selfmatch.md\":\"CzGHQ-PZ\",\"posts_olds_nlp_47-bidaf.md\":\"DFJaLh2v\",\"posts_olds_nlp_48-attention-is-all-you-need.md\":\"BY6XvFQ5\",\"posts_olds_nlp_49-qanet.md\":\"BPKWHzTf\",\"posts_olds_nlp_50-elmo.md\":\"WuOt1elN\",\"posts_olds_nlp_51-opengpt.md\":\"B9pQ3h5W\",\"posts_olds_nlp_52-bert.md\":\"5q3t5Qqh\",\"posts_olds_nlp_53-mrc-brief.md\":\"D9CkYrea\",\"posts_olds_nlp_54-mrc-models.md\":\"Ak4bDf1J\",\"posts_olds_nlp_attention-based-nmt.md\":\"BHef6tM6\",\"posts_olds_nlp_attention-model.md\":\"-xLhHhJE\",\"posts_olds_nlp_cs224n-lecture2-word2vec.md\":\"_MmBTADr\",\"posts_olds_nlp_cs224n-notes1-word2vec.md\":\"DXSi5KGh\",\"posts_olds_nlp_index.md\":\"Bfo4Lwn3\",\"posts_olds_nlp_nlp-notes.md\":\"BUmOZxzi\",\"posts_olds_nlp_nmt.md\":\"DUgy6vHF\",\"posts_olds_nlp_subword-units.md\":\"fR_3dRXr\",\"posts_olds_nlp_word2vec-math.md\":\"agvHiE1x\",\"posts_olds_nlp_word2vec.md\":\"D2TKUstm\",\"posts_olds_other_15-cpp-pointer-object-reference.md\":\"BKRTr8QZ\",\"posts_olds_other_index.md\":\"C1T-ubsz\",\"posts_olds_rl_37-reinforce-learning.md\":\"Cf2nny8k\",\"posts_olds_rl_40-value-learning.md\":\"DcnHvvpH\",\"posts_olds_rl_41-strategy-learning.md\":\"CStMrB-q\",\"posts_olds_rl_42-reinforce-conclusion-simple.md\":\"flRZUmJZ\",\"posts_olds_rl_43-intent-detection-slot-filling.md\":\"DcAUbaZU\",\"posts_olds_rl_44-reinforce-nlp.md\":\"Br2ShITL\",\"posts_olds_rl_index.md\":\"CUsxM3zO\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"📚 plmblog\",\"description\":\"记录一些学习笔记。\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"首页\",\"link\":\"/\"},{\"text\":\"🐲LLM\",\"items\":[{\"text\":\"Basic\",\"items\":[{\"text\":\"🦋基础知识\",\"link\":\"/posts/llm/basic/01-lm-define-information-theory\"},{\"text\":\"🛠基建框架\",\"link\":\"/posts/llm/infra/01-parrallel\"}]},{\"text\":\"强化学习\",\"items\":[{\"text\":\"🎓RL理论基础\",\"link\":\"/posts/llm/rl/theory/01-reinforce-learning\"},{\"text\":\"🚄Agent-RL\",\"link\":\"/posts/llm/agent/rl/02-agent-tool\"}]},{\"text\":\"行业方向\",\"items\":[{\"text\":\"🚀主流模型\",\"link\":\"/posts/llm/industry/mainllm/01-kimi-series\"},{\"text\":\"💻代码模型\",\"link\":\"/posts/llm/industry/codellm/01-survey\"}]},{\"text\":\"Agent\",\"items\":[{\"text\":\"🤖概念及应用\",\"link\":\"/posts/llm/agent/basic\"}]}]},{\"text\":\"📙旧文章\",\"items\":[{\"text\":\"🍓NLP\",\"items\":[{\"text\":\"自然语言处理\",\"link\":\"/posts/olds/nlp\"}]},{\"text\":\"🍑基础知识\",\"items\":[{\"text\":\"深度学习\",\"link\":\"/posts/olds/dl\"},{\"text\":\"强化学习\",\"link\":\"/posts/olds/rl\"},{\"text\":\"机器学习\",\"link\":\"/posts/olds/ml\"}]},{\"text\":\"🍎算法\",\"items\":[{\"text\":\"算法题\",\"link\":\"/posts/olds/algo/\"},{\"text\":\"大数据\",\"link\":\"/posts/olds/bigdata/\"}]},{\"text\":\"🍒其他\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/olds/env/\"},{\"text\":\"其他\",\"link\":\"/posts/olds/other/\"}]}]},{\"text\":\"经验\",\"items\":[{\"text\":\"环境\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/exps/env/01-blog-env\"}]},{\"text\":\"心得\",\"items\":[{\"text\":\"心得体会\",\"link\":\"/posts/exps/mind\"}]}]},{\"text\":\"归档\",\"link\":\"/posts/archive.md\"},{\"text\":\"关于我\",\"link\":\"/posts/me\"}],\"outline\":{\"level\":[1,4],\"label\":\"当前页大纲\"},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/plmsmile\"}],\"search\":{\"provider\":\"local\"},\"docFooter\":{\"prev\":\"上一页\",\"next\":\"下一页\"},\"sidebar\":{\"/posts/olds/nlp/\":{\"base\":\"/posts/olds/nlp/\",\"items\":[{\"text\":\"NLP\",\"items\":[{\"text\":\"机器阅读(二)--模型(未完成)\",\"link\":\"54-mrc-models\"},{\"text\":\"机器阅读(一)--整体概述\",\"link\":\"53-mrc-brief\"},{\"text\":\"BERT 详解\",\"link\":\"52-bert\"},{\"text\":\"OpenAI GPT：Improving Language Understanding by Generative Pre-Training\",\"link\":\"51-opengpt\"},{\"text\":\"ELMo：Deep Contextualized Word Representations\",\"link\":\"50-elmo\"},{\"text\":\"QANet\",\"link\":\"49-qanet\"},{\"text\":\"Transformer\",\"link\":\"48-attention-is-all-you-need\"},{\"text\":\"Bidirectional Attention Flow\",\"link\":\"47-bidaf\"},{\"text\":\"R-Net (Gated Self-Matching Networks)\",\"link\":\"46-rnet-selfmatch\"},{\"text\":\"Match-LSTM and Answer Pointer\",\"link\":\"45-match-lstm\"},{\"text\":\"阅读理解模型总结\",\"link\":\"39-squard-models\"},{\"text\":\"阿里小蜜论文\",\"link\":\"36-alime-chat\"},{\"text\":\"各种注意力总结\",\"link\":\"33-attention-summary\"},{\"text\":\"Dynamic Coattention Network (Plus)\",\"link\":\"32-dynamic-coattention-network\"},{\"text\":\"协同注意力简介\",\"link\":\"31-co-attention-vqa\"},{\"text\":\"使用Dynamic Memory Network实现一个简单QA\",\"link\":\"30-dynamic-memory-network\"},{\"text\":\"词性标注和句法依存的表示符号\",\"link\":\"11-nlp-labels\"},{\"text\":\"Word2vec之总体介绍\",\"link\":\"cs224n-notes1-word2vec\"},{\"text\":\"Word2vec之数学模型\",\"link\":\"word2vec-math\"},{\"text\":\"Word2vec之公式推导笔记\",\"link\":\"cs224n-lecture2-word2vec\"},{\"text\":\"subword-units\",\"link\":\"subword-units\"},{\"text\":\"Wordpiece模型\",\"link\":\"26-wordpieacemodel\"},{\"text\":\"谷歌RNN翻译模型\",\"link\":\"25-google-nmt\"},{\"text\":\"机器翻译注意力机制及其PyTorch实现\",\"link\":\"Attention-based-NMT\"},{\"text\":\"图文介绍RNN注意力机制\",\"link\":\"attention-model\"},{\"text\":\"最初RNN神经翻译简略笔记\",\"link\":\"NMT\"},{\"text\":\"语言模型和平滑方法\",\"link\":\"nlp-notes\"},{\"text\":\"利用tensorflow实现简版word2vec\",\"link\":\"word2vec\"}]}]},\"/posts/olds/dl/\":{\"base\":\"/posts/olds/dl/\",\"items\":[{\"text\":\"DL\",\"items\":[{\"text\":\"卷积神经网络总结\",\"link\":\"38-convolution\"},{\"text\":\"网络优化\",\"link\":\"35-nerual-network-optim\"},{\"text\":\"cs224n作业一\",\"link\":\"cs224n-assignment-1\"},{\"text\":\"cs231n线性分类器和损失函数\",\"link\":\"cs231n-linear-notes\"},{\"text\":\"神经网络-过拟合-预处理-BN\",\"link\":\"cs224n-notes3-neural-networks-2\"},{\"text\":\"神经网络基础-反向传播-激活函数\",\"link\":\"cs224n-notes3-neural-networks\"},{\"text\":\"循环神经网络\",\"link\":\"rnn\"},{\"text\":\"PyTorch快速上手\",\"link\":\"23-pytorch-start\"}]}]},\"/posts/olds/rl/\":{\"base\":\"/posts/olds/rl/\",\"items\":[{\"text\":\"RL\",\"items\":[{\"text\":\"强化学习在NLP中的应用\",\"link\":\"44-reinforce-nlp\"},{\"text\":\"意图识别和槽填充\",\"link\":\"43-intent-detection-slot-filling\"},{\"text\":\"强化学习算法小结\",\"link\":\"42-reinforce-conclusion-simple\"},{\"text\":\"基于策略函数的学习方法\",\"link\":\"41-strategy-learning\"},{\"text\":\"基于值函数的学习\",\"link\":\"40-value-learning\"},{\"text\":\"强化学习\",\"link\":\"37-reinforce-learning\"}]}]},\"/posts/olds/ml/\":{\"base\":\"/posts/olds/ml/\",\"items\":[{\"text\":\"ML\",\"items\":[{\"text\":\"决策树笔记\",\"link\":\"29-desicion-tree\"},{\"text\":\"机器学习知识点汇总整理\",\"link\":\"28-ml-interview-notes\"},{\"text\":\"SVM笔记\",\"link\":\"27-svm-notes\"},{\"text\":\"树的总结\",\"link\":\"10-trees\"},{\"text\":\"条件随机场\",\"link\":\"crf\"},{\"text\":\"最大熵模型\",\"link\":\"maxentmodel\"},{\"text\":\"线性回归和逻辑回归\",\"link\":\"21-lr\"},{\"text\":\"最大期望算法\",\"link\":\"14-em\"},{\"text\":\"马尔可夫模型\",\"link\":\"pgm-01\"},{\"text\":\"朴素贝叶斯算法及其代码实现\",\"link\":\"22-ml-ch03-bayes\"}]}]},\"/posts/olds/algo/\":{\"base\":\"/posts/olds/algo/\",\"items\":[{\"text\":\"ALGO\",\"items\":[{\"text\":\"剑指offer4(51-64)\",\"link\":\"aim2offer4\"},{\"text\":\"剑指offer3(21-40)\",\"link\":\"aim2offer3\"},{\"text\":\"数据结构之搜索算法\",\"link\":\"algorithm-dfs\"},{\"text\":\"leetcode-01\",\"link\":\"leetcode-01\"},{\"text\":\"剑指offer(11-20)\",\"link\":\"aim2offer2\"},{\"text\":\"排序算法总结\",\"link\":\"sort-algorithms\"},{\"text\":\"剑指Offer(1-10)\",\"link\":\"aim2offer\"}]}]},\"/posts/olds/bigdata/\":{\"base\":\"/posts/olds/bigdata/\",\"items\":[{\"text\":\"BIG Data\",\"items\":[{\"text\":\"NumPy\",\"link\":\"20-numpy\"},{\"text\":\"Spark基础编程核心思想介绍\",\"link\":\"19-spark-programming\"},{\"text\":\"Spark-SQL的简略笔记\",\"link\":\"18-spark-sql\"},{\"text\":\"Spark键值对RDD的常用API\",\"link\":\"17-spark-pairrdd\"},{\"text\":\"Spark基础RDD的常用API\",\"link\":\"16-Spark-BaseRDD\"}]}]},\"/posts/olds/env/\":{\"base\":\"/posts/olds/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"IDE配置\",\"link\":\"12-ide-envs\"},{\"text\":\"Linux使用笔记\",\"link\":\"09-linux-notes\"},{\"text\":\"博客搭建及相关问题\",\"link\":\"24-hexo-problems\"},{\"text\":\"旧版博客搭建过程及其问题\",\"link\":\"13-old-blog-problems\"}]}]},\"/posts/olds/other/\":{\"base\":\"/posts/olds/other/\",\"items\":[{\"text\":\"其他\",\"items\":[{\"text\":\"C++类对象和指针的区别\",\"link\":\"15-cpp-pointer-object-reference\"}]}]},\"/posts/llm/agent/rl/\":{\"base\":\"/posts/llm/agent/rl/\",\"items\":[{\"text\":\"Agent-RL\",\"items\":[{\"text\":\"Agent-Interaction-RL 笔记\",\"link\":\"04-agent-env\"},{\"text\":\"Agent-Search-RL 笔记\",\"link\":\"03-agent-search\"},{\"text\":\"Agent-Tool-RL 笔记\",\"link\":\"02-agent-tool\"},{\"text\":\"Agent-RL 综述型笔记\",\"link\":\"01-agent-rl\"}]}]},\"/posts/llm/agent/basic/\":{\"base\":\"/posts/llm/agent/basic/\",\"items\":[{\"text\":\"Agent-基础\",\"items\":[{\"text\":\"DeepResearch 评估\",\"link\":\"06-deepresearch-evaluation\"},{\"text\":\"Computer-Agent\",\"link\":\"05-comuter-agent\"},{\"text\":\"Agent 思考性文章\",\"link\":\"04-agent-blogs\"},{\"text\":\"一些流行的Agents\",\"link\":\"03-current-agents\"},{\"text\":\"Agent 评估 Benchmarks\",\"link\":\"02-evaluation-agent\"},{\"text\":\"Agent基础概念 (李宏毅笔记)\",\"link\":\"01-lhy-agent-notes\"}]}]},\"/posts/llm/rl/theory/\":{\"base\":\"/posts/llm/rl/theory/\",\"items\":[{\"text\":\"RL-Theory\",\"items\":[{\"text\":\"Agent-RL 相关算法\",\"link\":\"13-agentrl-algo\"},{\"text\":\"熵和RL相关文章\",\"link\":\"12-entropy\"},{\"text\":\"GRPO 改进系列\",\"link\":\"11-grpo-series\"},{\"text\":\"PPO 改进系列\",\"link\":\"10-ppo-series\"},{\"text\":\"典型策略提升方法：TRPO+PPO+DPO+GRPO\",\"link\":\"09-policy-trpo-ppo\"},{\"text\":\"确定性策略梯度\",\"link\":\"08-deterministic-policy-gradient\"},{\"text\":\"Actor-Critic 算法\",\"link\":\"07-actor-critic\"},{\"text\":\"策略梯度算法\",\"link\":\"06-policy-gradient\"},{\"text\":\"DQN算法及进阶\",\"link\":\"05-dqn\"},{\"text\":\"免模型预测和控制\",\"link\":\"04-model-free-prediction-control\"},{\"text\":\"有模型预测和控制\",\"link\":\"03-model-based-prediction-control\"},{\"text\":\"马尔可夫决策过程\",\"link\":\"02-markove-process\"},{\"text\":\"强化学习基本概念\",\"link\":\"01-rl-introduction\"},{\"text\":\"(18年笔记)强化学习算法小结\",\"link\":\"04-reinforce-conclusion-simple\"},{\"text\":\"(18年笔记)基于策略函数的学习方法\",\"link\":\"03-strategy-learning\"},{\"text\":\"(18年笔记)基于值函数的学习\",\"link\":\"02-value-learning\"},{\"text\":\"(18年笔记)强化学习基础\",\"link\":\"01-reinforce-learning\"}]}]},\"/posts/llm/rl/rlhf/\":{\"base\":\"/posts/llm/rl/rlhf/\",\"items\":[{\"text\":\"RLHF\",\"items\":[]}]},\"/posts/llm/rl/o1llm/\":{\"base\":\"/posts/llm/rl/o1llm/\",\"items\":[{\"text\":\"推理模型\",\"items\":[]}]},\"/posts/llm/industry/mainllm/\":{\"base\":\"/posts/llm/industry/mainllm/\",\"items\":[{\"text\":\"🚀主流模型\",\"items\":[{\"text\":\"Claude 系列\",\"link\":\"09-claude-series\"},{\"text\":\"LongCat 系列\",\"link\":\"10-longcat-series\"},{\"text\":\"Gemini 系列\",\"link\":\"08-gemini-series\"},{\"text\":\"Seed 系列\",\"link\":\"06-seed-series\"},{\"text\":\"OpenAI 系列\",\"link\":\"07-openai-series\"},{\"text\":\"Qwen 系列\",\"link\":\"05-qwen-series\"},{\"text\":\"MiniMax 系列\",\"link\":\"04-minimax-series\"},{\"text\":\"GLM 系列\",\"link\":\"03-glm-series\"},{\"text\":\"DeepSeek 系列\",\"link\":\"02-deepseek-series\"},{\"text\":\"Kimi 系列\",\"link\":\"01-kimi-series\"}]}]},\"/posts/llm/industry/codellm/\":{\"base\":\"/posts/llm/industry/codellm/\",\"items\":[{\"text\":\"💻代码模型\",\"items\":[{\"text\":\"Code Survey From Code Foundation Models to Agents and Applications\",\"link\":\"01-survey\"}]}]},\"/posts/llm/basic/\":{\"base\":\"/posts/llm/basic/\",\"items\":[{\"text\":\"LLM-basic\",\"items\":[{\"text\":\"LLM位置编码和长度外推系列\",\"link\":\"08-llm-position-embedding\"},{\"text\":\"LLM 解码相关\",\"link\":\"07-decode\"},{\"text\":\"LLM Attention 系列\",\"link\":\"06-llm-attention\"},{\"text\":\"LLM 基础知识\",\"link\":\"05-llm-basic-info\"},{\"text\":\"LLM 架构相关\",\"link\":\"04-llm-architecture\"},{\"text\":\"Transformer细节\",\"link\":\"03-transformer-detail\"},{\"text\":\"语言模型重要组件\",\"link\":\"02-llm-components\"},{\"text\":\"语言模型定义及信息理论\",\"link\":\"01-lm-define-information-theory\"}]}]},\"/posts/llm/infra/\":{\"base\":\"/posts/llm/infra/\",\"items\":[{\"text\":\"🛠LLM-基建框架\",\"items\":[{\"text\":\"Verl 训练流程源代码阅读\",\"link\":\"08-verl-train-loop\"},{\"text\":\"Verl 有趣的功能\",\"link\":\"07-verl-core\"},{\"text\":\"Verl AgentLoop Rollout 相关\",\"link\":\"06-verl-code\"},{\"text\":\"Verl 常见参数配置和理解\",\"link\":\"05-verl-practice\"},{\"text\":\"Verl 早期概念型学习文章\",\"link\":\"04-verl\"},{\"text\":\"推理优化技术\",\"link\":\"03-inference-tech\"},{\"text\":\"分布式训练框架\",\"link\":\"02-speed-framework\"},{\"text\":\"分布式并行策略\",\"link\":\"01-parrallel\"}]}]},\"/posts/exps/env/\":{\"base\":\"/posts/exps/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"环境搭建的一些坑\",\"link\":\"01-blog-env\"}]}]},\"/posts/exps/mind/\":{\"base\":\"/posts/exps/mind/\",\"items\":[{\"text\":\"心得体会\",\"items\":[]}]}}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>
<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Code 任务Bench相关 | 📚 plmblog</title>
    <meta name="description" content="记录一些学习笔记。">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/assets/style.CuIOXX7t.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.DpGDoEiv.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.DUEAmsFX.js">
    <link rel="modulepreload" href="/assets/chunks/framework.CvbyeFFO.js">
    <link rel="modulepreload" href="/assets/posts_llm_industry_codellm_02-eval-task-benchmark.md.B-okIRAD.lean.js">
    <link rel="icon" href="/plm.png">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-cecb633e><!--[--><!--]--><!--[--><span tabindex="-1" data-v-c979f278></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-c979f278>Skip to content</a><!--]--><!----><header class="VPNav" data-v-cecb633e data-v-0ad68676><div class="VPNavBar" data-v-0ad68676 data-v-ce71e4ef><div class="wrapper" data-v-ce71e4ef><div class="container" data-v-ce71e4ef><div class="title" data-v-ce71e4ef><div class="VPNavBarTitle has-sidebar" data-v-ce71e4ef data-v-7e906684><a class="title" href="/" data-v-7e906684><!--[--><!--]--><!----><span data-v-7e906684>📚 plmblog</span><!--[--><!--]--></a></div></div><div class="content" data-v-ce71e4ef><div class="content-body" data-v-ce71e4ef><!--[--><!--]--><div class="VPNavBarSearch search" data-v-ce71e4ef><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-ce71e4ef data-v-e0cd9371><span id="main-nav-aria-label" class="visually-hidden" data-v-e0cd9371> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>首页</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>🐲LLM</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Basic</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/basic/01-lm-define-information-theory.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🦋基础知识</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/infra/01-parrallel.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🛠基建框架</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>强化学习</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/rl/theory/01-reinforce-learning.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🎓RL理论基础</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/rl/02-agent-tool.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚄Agent-RL</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>行业方向</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/industry/mainllm/01-kimi-series.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚀主流模型</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/industry/codellm/01-survey.html" data-v-dc987abe><!--[--><span data-v-dc987abe>💻代码模型</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Agent</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/basic.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🤖概念及应用</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>📙旧文章</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍓NLP</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/nlp.html" data-v-dc987abe><!--[--><span data-v-dc987abe>自然语言处理</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍑基础知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/dl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>深度学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/rl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>强化学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/ml.html" data-v-dc987abe><!--[--><span data-v-dc987abe>机器学习</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍎算法</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/algo/" data-v-dc987abe><!--[--><span data-v-dc987abe>算法题</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/bigdata/" data-v-dc987abe><!--[--><span data-v-dc987abe>大数据</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍒其他</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/env/" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/other/" data-v-dc987abe><!--[--><span data-v-dc987abe>其他</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>经验</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>环境</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/env/01-blog-env.html" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>心得</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/mind.html" data-v-dc987abe><!--[--><span data-v-dc987abe>心得体会</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/archive.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>归档</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/me.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>关于我</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-ce71e4ef data-v-b59ebfac><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-b59ebfac data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-ce71e4ef data-v-e0f2db57 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-ce71e4ef data-v-8897e953 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-ffaaba87><span class="vpi-more-horizontal icon" data-v-ffaaba87></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><!----><!--[--><!--[--><!----><div class="group" data-v-8897e953><div class="item appearance" data-v-8897e953><p class="label" data-v-8897e953>Appearance</p><div class="appearance-action" data-v-8897e953><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-8897e953 data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div></div></div><div class="group" data-v-8897e953><div class="item social-links" data-v-8897e953><div class="VPSocialLinks social-links-list" data-v-8897e953 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-ce71e4ef data-v-37e0f734><span class="container" data-v-37e0f734><span class="top" data-v-37e0f734></span><span class="middle" data-v-37e0f734></span><span class="bottom" data-v-37e0f734></span></span></button></div></div></div></div><div class="divider" data-v-ce71e4ef><div class="divider-line" data-v-ce71e4ef></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-cecb633e data-v-1b409c8b><div class="container" data-v-1b409c8b><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-1b409c8b><span class="vpi-align-left menu-icon" data-v-1b409c8b></span><span class="menu-text" data-v-1b409c8b>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-1b409c8b data-v-a203161a><button data-v-a203161a>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-cecb633e data-v-18f7b5ca><div class="curtain" data-v-18f7b5ca></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-18f7b5ca><span class="visually-hidden" id="sidebar-aria-label" data-v-18f7b5ca> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-7f5b9a39><section class="VPSidebarItem level-0 has-active" data-v-7f5b9a39 data-v-a4affe07><div class="item" role="button" tabindex="0" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><h2 class="text" data-v-a4affe07>💻代码模型</h2><!----></div><div class="items" data-v-a4affe07><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/07-code-fulltrain-reading.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 全训练 论文阅读</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/06-code-taskrl-reading.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code TaskRL 论文阅读</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/05-open-codellm.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>CodeLLM 索引简记</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/04-safety-code.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 安全相关</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/03-rl-task.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code RL 任务</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/02-eval-task-benchmark.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 任务Bench相关</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/01-survey.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code Survey</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/08-code-pretrain-summary.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 预训练相关</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-cecb633e data-v-53a9cb18><div class="VPDoc has-sidebar has-aside" data-v-53a9cb18 data-v-5a64a79a><!--[--><!--]--><div class="container" data-v-5a64a79a><div class="aside" data-v-5a64a79a><div class="aside-curtain" data-v-5a64a79a></div><div class="aside-container" data-v-5a64a79a><div class="aside-content" data-v-5a64a79a><div class="VPDocAside" data-v-5a64a79a data-v-f8ea3c28><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-f8ea3c28 data-v-b94d89ac><div class="content" data-v-b94d89ac><div class="outline-marker" data-v-b94d89ac></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-b94d89ac>当前页大纲</div><ul class="VPDocOutlineItem root" data-v-b94d89ac data-v-80b46526><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-f8ea3c28></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-5a64a79a><div class="content-container" data-v-5a64a79a><!--[--><!--[--><!--[--><article class="post-header" data-v-a99fd7c9><h1 class="title" data-v-a99fd7c9>Code 任务Bench相关</h1><div class="stats-container" data-v-a99fd7c9><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 📅 发表于 <span class="stat-text" data-v-a99fd7c9>2025/12/15</span></div><div class="stat-item" data-v-a99fd7c9> 🔄 更新于 <span class="stat-text" data-v-a99fd7c9>2025/12/15</span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 👁️ <span class="stat-text" data-v-a99fd7c9>-- 次访问</span><span id="busuanzi_value_page_pv" style="display:none;" data-page="/posts/llm/industry/codellm/02-eval-task-benchmark.html" data-v-a99fd7c9></span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 📝 <span class="stat-text" data-v-a99fd7c9>0 字</span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> ⏳ <span class="stat-text" data-v-a99fd7c9>0 分钟</span></div><div class="stat-divider" data-v-a99fd7c9></div></div><div class="tag-group" data-v-a99fd7c9><!--[--><div class="category-item" data-v-a99fd7c9>code-task</div><!--]--><!--[--><div class="tag-item" data-v-a99fd7c9> #metrics</div><div class="tag-item" data-v-a99fd7c9> #task</div><!--]--></div></article><!--]--><!--]--><!--]--><main class="main" data-v-5a64a79a><div style="position:relative;" class="vp-doc _posts_llm_industry_codellm_02-eval-task-benchmark" data-v-5a64a79a><div><h2 id="参考文章" tabindex="-1">参考文章 <a class="header-anchor" href="#参考文章" aria-label="Permalink to &quot;参考文章&quot;">​</a></h2><div class="custom-block caution"><div class="custom-block-title">参考文章</div><ul><li><a href="https://www.alphaxiv.org/abs/2511.18538" target="_blank" rel="noreferrer">survey paper</a></li></ul></div><h2 id="评估指标" tabindex="-1">评估指标 <a class="header-anchor" href="#评估指标" aria-label="Permalink to &quot;评估指标&quot;">​</a></h2><div class="custom-block info"><div class="custom-block-title">传统指标</div><p><strong>1. CodeBLEU</strong></p><ul><li>看<code>词汇重合度</code>。</li></ul><p><strong>2. CodeBERTScore / RTC</strong></p><ul><li>CodeBERTScore：<code>向量相似度</code>。</li><li>RTC(Round-Trip Correctness)：把代码翻译成另一种形式，再翻译回来，对比前后一致性。</li></ul><p><strong>3. Pass@k</strong></p><ul><li>评估<code>功能正确性</code>，实际执行。<code>给k次机会</code>，只要有1个成功，就算成功。</li></ul></div><div class="custom-block info"><div class="custom-block-title">LLM-as-a-Judge 指标</div><p><strong>核心思想</strong></p><ul><li>让LLM来评估是否写得好。</li></ul><p><strong>1. ICE-Score</strong></p><ul><li>引入<code>Rubrics打分细则</code>，输出1个量化的分数。 <ul><li>比如完全没用大0分、语法错误打1分、解决问题打4分。</li></ul></li></ul><p><strong>2. CodeJudge/CodeJudgeBench</strong></p><ul><li>输入task和task_code，让模型<code>先思考</code>（哪里写得好/哪里有bug），<code>再打分</code>。</li><li>缺点：不稳定。</li></ul><p><strong>3. BigCodeReward (多模态评估)</strong></p><ul><li>输入<code>代码</code>和<code>代码运行结果</code>，去做打分，<code>更关心实际效果</code>。 <ul><li>运行结果：报错日志、图标、网页截图等。</li></ul></li><li><code>偏好打分</code>：给2个方案及运行结果，判断谁更好。</li></ul></div><div class="custom-block info"><div class="custom-block-title">执行指标</div><p><strong>1. ProbGen/差异测试</strong></p><ul><li>背景：判断代码<code>和标准答案是否一致</code>。</li><li>让llm自动生成<code>多个输入数据</code>(探针)，分别喂给<code>2段代码</code>；若输出<code>结果不同</code>，则<code>功能不同</code>。</li></ul><p><strong>2. REFUTE/反例生成</strong></p><ul><li>给一段有bug的代码，生成输入，让代码跑崩溃。</li></ul><p><strong>3. EvaLooop/循环转换测试</strong></p><ul><li>代码需求循环：需求 -&gt; 代码 -&gt; 需求 -&gt; 代码 -&gt; ...</li><li>多语言转换循环：Python -&gt; Java -&gt; Python -&gt; Java -&gt; ...</li><li>评估标准：如果能坚持多轮，则效果稳健ASL分数高；否则，分数低。</li></ul></div><div class="custom-block info"><div class="custom-block-title">Multi-Agent</div><p><strong>1. MCTS-Judge</strong></p><ul><li>搜索输，每个节点代表一个特定检查视角(边界条件/异常/需求规范等等)。</li><li>沿推理路径做预测和模拟执行，如果推理和执行结果一致，则给一个奖励。</li></ul><p><strong>2. CodeVisionary</strong></p><ul><li><code>让多个模型一起打分</code>。先收集情报，再让n个LLM进行打分。</li><li>指标：共识分数，降低评估方差。</li></ul></div><div class="custom-block info"><div class="custom-block-title">稳定性测试</div><p><strong>1. Incoherence/不连贯性/不一致性</strong></p><ul><li>1个任务，让模型生成2个程序，观察输出是否一致。 <ul><li>高Incoherence：模型随机性很强，不可靠。</li><li>低Incoherence：模型很稳定，一致性好。</li></ul></li></ul><p><strong>2. Mean Absolute Deviation (MAD)/鲁棒性测试</strong></p><ul><li>先测原始代的准确率，做一些表面修改(如变量命名)，计算评分准确率。</li><li>判断两个准确率之间的差距。MAD越小越好。</li></ul></div><div class="custom-block info"><div class="custom-block-title">其他</div><p><strong>1. SBC 语义相似性</strong></p><ul><li>原始需求 -&gt; 模型 -&gt; 代码，再把代码 -&gt; 新需求。</li><li>判断<code>原始需求描述</code>和<code>新需求描述</code>是否一致。</li></ul><p><strong>2. Copilot Arena / BigCodeArena</strong></p><ul><li>系统同时给模型A和B的代码，开发者采纳谁，就算赢。计算排名。</li></ul><p><strong>3. CodeCriticBench</strong></p><ul><li>给一段代码，具体两个指标由大模型来判断 <ul><li><code>Acc准确率</code>：模型对不对</li><li><code>Checklist</code>：比如安全性达标吗、命名规范吗、效率高吗？</li></ul></li><li><code>人类均方误差</code>：LLM打分和人类打分偏离多少。</li></ul></div><h2 id="片段级任务" tabindex="-1">片段级任务 <a class="header-anchor" href="#片段级任务" aria-label="Permalink to &quot;片段级任务&quot;">​</a></h2><h3 id="代码补全和fim" tabindex="-1">代码补全和FIM <a class="header-anchor" href="#代码补全和fim" aria-label="Permalink to &quot;代码补全和FIM&quot;">​</a></h3><p>给定部分上下文，评估模型<code>预测正确代码片段</code>的能力。</p><div class="custom-block caution"><div class="custom-block-title">代码补全</div><p><strong>核心点</strong></p><ul><li>利用上文前缀Prefix，<code>继续编写</code>或<code>修复代码</code>。</li></ul><p><strong>Statement-Level(语句级)</strong></p><ul><li>基于上文预测单行代码或表达式，关注局部语法。</li><li>CodeXGLUE：下一行补全，6种语言，<code>精准匹配</code>作为指标。</li><li>HumanEval-Infill/Qwencoder2.5：给定文档，<code>可执行</code>、<code>单元测试</code>作为指标。</li></ul><p><strong>Function-level(函数级)</strong></p><ul><li><code>给定函数签名</code>或部分代码，<code>生成完整函数</code>，关注算法逻辑。</li><li>BigCodeBench：从github上提取<code>真实代码</code>，做<code>函数还原</code>。评估：<code>正确性</code>和复杂度。</li><li>MultiPL-E：同一个功能，可以有<code>多个写法</code>。</li></ul><p><strong>Class-Level(类级)</strong></p><ul><li>给定部分类定义中，实现整个类、多个方法。</li><li>ClassEval：不仅写一个函数，要写整个类，关注<code>全局类结构理解能力</code>。</li><li>ClassEval-T：口占了Java和CPP，更强调面向对象。</li><li>OOP：关注设计模式。</li></ul></div><div class="custom-block caution"><div class="custom-block-title">FIM</div><p><strong>核心</strong></p><ul><li>利用前缀prefix和后缀suffix，来预测中间部分。</li><li>FIM是一个预训练任务，现在单独出来，评估是否好用。</li></ul><p><strong>主要工作</strong></p><ul><li>CCCI：强调上下文 <ul><li>喂外部知识，如数据库结构关系等；模型懂了业务逻辑，补全代码质量更高。</li></ul></li><li>SAFIM：强调语法感知的评估 <ul><li>挖空的是完整的语法块，避免随机mask。</li><li>如果预训练效果不好，则SAFIM能力就会差。</li></ul></li><li>ASR-FIM <ul><li>也是避免随机mask。</li><li>使用抽象语法树(AST)来做掩码，遮住完整的语法结构。</li><li>强迫模型去预测整个逻辑结构。</li></ul></li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251214181133.jpg" style="display:block;margin:auto;" width="70%"><h3 id="代码生成" tabindex="-1">代码生成 <a class="header-anchor" href="#代码生成" aria-label="Permalink to &quot;代码生成&quot;">​</a></h3><div class="custom-block note"><div class="custom-block-title">Funtion-Level</div><p><strong>早期-简单函数生成</strong></p><ul><li>CodeXPLUG,</li><li><strong>HumanEval&amp;MBPP</strong> (<code>最流行</code>)：<code>Prompt</code> -&gt; <code>Code</code> -&gt; <code>单元测试</code></li><li>缺点：测试用你太少，<code>容易过拟合</code></li></ul><p><strong>增强测试严谨性</strong></p><ul><li>HumanEval+, MBPP+：<code>自动生成测试用例</code>，去验证是否真的懂，避免过拟合</li><li>HumanEval Prom MBPP PRo：<code>增加难度、扩大题库</code>、改进评估方式等。</li></ul><p><strong>多语言扩展</strong></p><ul><li>MBXP/Multi-HumanEval：把测试用例扩展至Java/C++/JS等语言。</li><li>HumanEval-XL：测试自然语言和编程语言的交叉组合。英语中文俄语、python/java 等混搭组合。</li></ul><p><strong>真实场景/上下文/复杂性</strong></p><ul><li><strong>McEval/BigCodeBench</strong>：强调代码不是孤立的，需要结合<code>代码库上下文</code>、显示世界等。</li><li>MERA Code：超越简单函数到复杂系统的<code>全方位评估框架</code>。</li><li>CodeFuseEval：<code>中文指令</code>、多任务能力。</li></ul></div><div class="custom-block note"><div class="custom-block-title">Class-Level</div><ul><li>ClassEval：100个python类，需要内部多个方法调用</li><li>ClassEvalT：</li><li>OOP：面向对象</li></ul></div><div class="custom-block note"><div class="custom-block-title">编程</div><p><strong>核心思想</strong></p><ul><li>不仅要代码能跑通，还要逻辑强、效率高。</li></ul><p><strong>主要工作</strong></p><ul><li>LiveCodeBench, LiveCodeBench Pro：收集模型训练截止日期之后的题目，测试OOD题目。</li><li>CruxEval：让模型<code>写代码</code>、还<code>预测输入输出</code>，测试解题能力。</li><li>CodeNet：多语言数据集。</li><li>APPS：竞赛问题+人类写的代码。</li><li>MultiPL-E：要求模型为每个问题生成多个答案，评估多样性。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251214181216.jpg" style="display:block;margin:auto;" width="70%"><div class="custom-block note"><div class="custom-block-title">领域Benchmark</div><p><strong>垂直技术栈</strong></p><ul><li>Deep-Bench：写pytorch/tensorflow的能力。</li><li>KernelBench/TritonBench：测试GPU编程。</li><li>SciCode：科学计算。</li></ul><p><strong>复杂结构和全栈</strong></p><ul><li>FullStackBench：测试全栈能力(前端、后端、数据库)</li><li>YABLoCo：长上下文，读几千行代码，写新代码。一般用作老旧项目维护。</li></ul><p><strong>评测方法创新</strong></p><ul><li>Meta-Benching/AutoCodeBench：设计框架<code>自动构建Bench</code>，让AI自动<code>抓取代码</code>、<code>生成测试用例</code>。</li><li>RAG/CodeRAG-Bench：考察<code>看文档写代码</code>的能力。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251214181145.jpg" style="display:block;margin:auto;" width="70%"><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251214181226.jpg" style="display:block;margin:auto;" width="70%"><h3 id="代码编辑和修bug" tabindex="-1">代码编辑和修bug <a class="header-anchor" href="#代码编辑和修bug" aria-label="Permalink to &quot;代码编辑和修bug&quot;">​</a></h3><p>改原始代码。</p><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251214181237.jpg" style="display:block;margin:auto;" width="70%"><div class="custom-block info"><div class="custom-block-title">代码编辑&amp;修bug</div><p><strong>语句级Bench</strong></p><ul><li>早期数据集(版本控制的提交历史) <ul><li>MegaDiff：66.3万个Java变更。</li><li>TSSB-3M：300w个python合成的单语句错误。</li><li>特定类型错误：TFix (10.5万个js修复)、FixJS(32.4万个js)、PyTer(python错误)</li></ul></li><li>后来的工作：规模、可执行和语言改进。 <ul><li>RunBugRun：8种语言，45w个可执行错误修复Pair。</li><li>xCodeEval：450个多语言样本，10+语言。</li><li>DebugBench：4.2k的debug任务和配套测试，c++,python,java</li></ul></li><li>最近数据集：把调试集成到指令微调中 <ul><li>HumanEvalPack：把HumanEval扩展到6种语言，并增加调试变体</li><li>MDEval：18种语言、3513个调试任务</li></ul></li></ul><p><strong>交互迭代式Bench</strong></p><ul><li>传统：一次性修复</li><li><strong>迭代与反馈</strong><ul><li>SWT-Bench：1900个，可执行测试用例，真实Github错误</li><li>FeedbackEval：带有结构化外部提示的迭代修复</li><li><code>写代码</code> -&gt; <code>报错</code> -&gt;<code> 改代码</code> -&gt; <code>跑通</code></li></ul></li><li><strong>Agentic &amp; Tool Use</strong><ul><li><strong>CodeEditorBench</strong>：模拟<code>IDE环境</code>，涉及增量编辑和文件间依赖。</li><li><strong>DebugEval</strong>：自我调试，<code>模型生成调试信号</code>来指导多步修复。</li><li><strong>Debug-gym</strong>： <ul><li>教模型<code>使用debug工具(pdb)</code>，包括打断点、单步执行、查看变量值等。</li><li>通过<code>SFT/RL</code>教模型使用<code>有状态工具</code>，解决预训练此类数据稀缺问题。</li></ul></li></ul></li></ul></div><h3 id="代码效率" tabindex="-1">代码效率 <a class="header-anchor" href="#代码效率" aria-label="Permalink to &quot;代码效率&quot;">​</a></h3><div class="custom-block warning"><div class="custom-block-title">代码效率</div><p><strong>背景</strong></p><ul><li>LLM 写的代码可能效果好，但<code>效率很低</code>，希望写对代码-&gt;<code>写好代码</code>。</li><li>效率：运行时间、内存使用、算法复杂度、能耗。</li></ul><p><strong>性能和复杂度测试</strong></p><ul><li>EffiBench：1k+算法任务，GPT4代码比人类代码慢3倍、内存占用多14-44倍。</li><li>Mercury：扩展并提出多维框架，测量各种编程问题在最佳/最差下的执行时间、内存占用和复杂度。</li><li>EffiBench-x：多种编程语言。</li><li>BigO/DynCode：侧重算法复杂度，是否达到算法复杂度。</li><li>COFFE：强调在现实执行负载下的实际运行时间评估，提供了互补的系统级视角。</li><li>EvalPerf：引入了一个差分性能评估框架，评估 LLM代码在性能挑战任务上的效果。</li></ul><p><strong>能耗和效率优化</strong></p><ul><li>ECCO/Solovyeva/Cappendijk：量化了LLMCode和人类Code的能耗开销，探索微调策略降低功耗。</li></ul></div><div class="custom-block warning"><div class="custom-block-title">把效率纳入建模/训练过程的方法</div><p><strong>训练时干预 (Training Objective)</strong></p><ul><li><strong>EffiCoder</strong> 试图在训练阶段就告诉模型：“写得快的代码才是好代码”，<code>把效率信号加入损失函数</code>。</li></ul><p><strong>强化学习 (RL)：</strong></p><ul><li><strong>ACECode</strong> 使用 RL，如果代码运行速度快，则给奖励，来激励模型优化代码。</li></ul><p><strong>事后修补 (Post-generation Refinement)：</strong></p><ul><li><strong>Rethinking Code Refinement</strong> ：先让模型写，再用专门步骤去检查“哪里写慢了”，再重构优化。</li></ul></div><h3 id="代码偏好" tabindex="-1">代码偏好 <a class="header-anchor" href="#代码偏好" aria-label="Permalink to &quot;代码偏好&quot;">​</a></h3><div class="custom-block caution"><div class="custom-block-title">代码偏好</div><p><strong>背景</strong></p><ul><li>不仅是写对代码，还要评估谁的代码更好，更符合人类标准：(<code>正确</code>、<code>快</code>、<code>安全</code>、<code>易读</code>).</li></ul><p><strong>方法1：硬指标打分法</strong></p><ul><li>CodeArena：题越难，分数越高；运行时间越短，分数越高。</li><li>Long CodeArena：项目级，看能否在大项目里理解项目架构。</li></ul><p><strong>方法2：竞技场LLM-as-a-Judge法</strong></p><ul><li>找强力模型做裁判。</li><li><strong>CodePrefBench</strong>：直接测模型有无鉴赏力，能不能挑出好代码。</li><li><strong>AutoCodeArena</strong>：自动化擂台。裁判看2者的<code>代码</code>+<code>各自沙盒运行结果</code>，来打分。</li></ul></div><h3 id="代码推理和问答" tabindex="-1">代码推理和问答 <a class="header-anchor" href="#代码推理和问答" aria-label="Permalink to &quot;代码推理和问答&quot;">​</a></h3><div class="custom-block important"><div class="custom-block-title">代码推理和问答</div><p><strong>背景</strong></p><ul><li>评估模型理解分析代码的能力。</li></ul><p><strong>基于QA的评估</strong></p><ul><li>CodeQA：<code>把代码注释</code>转换成<code>问答对</code>，10w的数据集。</li><li>CS1QA：从python入门课程的聊天记录中收集问答对。</li><li><strong>CodeMMLU</strong>：多种任务，包括代码修复、执行推断和填空挑战。</li><li><strong>CodeSense</strong>：<code>真实软件项目</code>中<code>细粒度的代码语义推理</code>任务。 <ul><li>现有Bench依赖合成数据或教育性编程。</li></ul></li></ul><p><strong>基于代码语义推理的评估 (更具体的任务)</strong></p><ul><li>SpecEval：4个任务来评估，规范判断、选择、补全和生成。</li><li>CRUXEval/CRUXEval-X：执行预测，<code>输出预测</code>和<code>输入预测</code>s。</li><li>EquiBench：程序等价性检查，两段代码，修改了语法结构，看是否一致。</li><li>CORE：通过静态分析来判断，如数据流（Data Flow）和控制流（Control Flow）。 <ul><li>变量 A 的值是否依赖于变量 B？，这段代码的死代码（Dead Code）在哪里？</li></ul></li></ul><p><strong>多模态维度</strong></p><ul><li><strong>ScratchEval</strong> 非常新颖。Scratch 是图形化编程（拖拽积木块），代码是“画”出来的。 <ul><li>这测试了多模态模型（如 GPT-4V）能否看懂<strong>视觉化的逻辑结构</strong>。</li></ul></li></ul></div><h3 id="代码翻译" tabindex="-1">代码翻译 <a class="header-anchor" href="#代码翻译" aria-label="Permalink to &quot;代码翻译&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">Code Translation</div><p><strong>早期方法：语法结构驱动</strong></p><ul><li>AST： 抽象语法树，类似先把英文句子分析成主谓宾结构树，再把树变成中文结构。难以处理复杂结构。</li><li>TransCoder：只给模型看大量的中文书和大量的英文书（单语语料），模型也能通过无监督学习学会翻译</li></ul><p><strong>基于执行反馈的方法 (测试用例)</strong></p><ul><li>保留原有代码结果，LLM翻译成新代码，执行新代码的单元测试， <ul><li>如果结果一致，说明正确；否则，把不同信息给到，让LLM继续改。</li></ul></li></ul><p><strong>Prompt工程</strong></p><ul><li>先解释后翻译，效果好。</li></ul><p><strong>安全</strong></p><ul><li>使用<strong>差分模糊测试（differential fuzzing</strong>来验证等价性。 <ul><li>如c++ -&gt; rust，内存不安全-&gt;内存安全语言。</li></ul></li></ul><p><strong>数据与评估的进化</strong></p><ul><li><strong>数据合成：</strong> 很难找到完全对应的代码对，用 <strong>Back-Translation（回译）</strong> 来造数据。 <ul><li>Python -&gt; Java, 再Java -&gt; Python，看能否复原，以此来造数据，</li></ul></li><li><strong>超越 BLEU：</strong> 之前看BLEU（看词重叠率，发现没用，现在看<strong>功能等价性</strong>（能不能跑通测试）和<strong>复杂度分级</strong>（是简单的改变量名，还是复杂的算法重写）。</li></ul></div><h3 id="测试用例生成" tabindex="-1">测试用例生成 <a class="header-anchor" href="#测试用例生成" aria-label="Permalink to &quot;测试用例生成&quot;">​</a></h3><div class="custom-block important"><div class="custom-block-title">测试用例生成</div><p><strong>面向软件工程</strong></p><ul><li>SWT-Bench/TestGenEval <ul><li>转换了SWE-Bench代码，提供了有bug的代码和对应的补丁。</li><li>要求生成的测试用例，在bug代码不通过、在修复后的代码上通过。</li></ul></li></ul><p><strong>面向程序竞赛</strong></p><ul><li><strong>TestEval</strong>：LeetCode 210个问题；其评估仍然局限于覆盖率指标。</li><li><strong>CodeForce-SAGA</strong>、<strong>TCGBench</strong>、<strong>TestCase-Eval</strong><ul><li>收集了大量的<strong>错误</strong>和<strong>正确</strong>的代码提交，以进行端到端的评估。</li><li>核心指标：测试用例能否<strong>拒绝错误代码</strong>同时<strong>通过正确代码</strong>的比例。</li></ul></li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251214181256.jpg" style="display:block;margin:auto;" width="70%"><h2 id="repo-level-任务" tabindex="-1">Repo-Level 任务 <a class="header-anchor" href="#repo-level-任务" aria-label="Permalink to &quot;Repo-Level 任务&quot;">​</a></h2><h3 id="代码生成和补全" tabindex="-1">代码生成和补全 <a class="header-anchor" href="#代码生成和补全" aria-label="Permalink to &quot;代码生成和补全&quot;">​</a></h3><div class="custom-block important"><div class="custom-block-title">仓库级代码生成和补全</div><ul><li>由<code>单一代码刷题</code> -&gt; <code>写工程代码</code>。</li><li><code>整个代码库上下文</code>(多<strong>文件/项目结构/依赖关系/跨文件关系</strong>），来<code>预测/补全或生成代码片段</code>。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251214181306.jpg" style="display:block;margin:auto;" width="70%"><div class="custom-block danger"><div class="custom-block-title">相关Bench</div><ul><li><strong>RepoBench</strong><ul><li><strong>仓库级</strong>，在检索和<code>补全任务</code>上评估模型。</li><li>训练集：<code>22年之前</code>的代码；测试集：<code>22年之后</code>的代码。</li></ul></li><li><strong>RepoEval</strong><ul><li>处理仓库级时：RAG(检索+生成) &gt; 纯模型。<code>RepoCoder</code>利用<code>完整仓库上下文</code>，效果好于其他模型。</li><li>使用<code>单元测试</code>来评估<code>14个</code>真实代码仓库的<code>代码补全</code>。</li></ul></li><li>Execrepobench <ul><li>重新生成<code>多粒度</code>(表达式/语句/函数)的<code>masked spans</code>，来评估 LLM 的<code>仓库级补全能力</code></li><li>通过<code>仓库测试文件</code>进行验证；并在其上<code>微调Qwen2.5-Coder</code>以增强补全性能。</li></ul></li><li><strong>CoderEval</strong><ul><li>专门测试<code>非独立函数</code>，需要调用<code>其他文件代码</code>等。 <ul><li>模型效果：非独立函数 弱于 独立函数。460 个 Java/Python问题。</li></ul></li></ul></li><li><strong>CrossCodeEval</strong> ：多语言bench，10k，通过静态分析测试<code>跨文件上下文</code>的需求。</li><li><strong>M2rc-Eval</strong>：多语言Bench，使用<code>AST(抽象语法树)</code>来做<code>标注</code>的。</li><li><strong>Codev-Bench</strong>：使用<code>工业数据</code>评估<code>repo补全</code>能力。 <ul><li>CodeLLM 优于通用模型，但在<code>不完整后缀</code>场景<code>效果都不好</code>。</li></ul></li><li><strong>RepoCod</strong>：Python Bench，11个项目，980个任务，50%都需要仓库级上下文。</li><li><strong>DI-Bench</strong>：<code>评估依赖推理</code>，4语言，581仓库。顶级模型效果也不好。</li><li><strong>DependEval</strong>：<code>分层评估</code> <code>仓库级依赖</code>，8种语言，15k仓库。</li><li><strong>REPOST</strong>： <code>沙盒测试</code>构建仓库级环境。 <ul><li><code>REPOST-TRAIN</code>训练的模型在<code>HumanEval/RepoEval</code> 有效果</li><li>但在 <code>REPOST-EVAL 效果一般</code>。</li></ul></li><li><strong>SecRepoBench</strong>：在仓库级别评估<code>安全代码生成</code>（318 个任务，C/C++ 中的 15 种 CWE 类型）。</li><li><strong>DevEval</strong>：<code>人工注释的Bench</code>（1.8k样本，117 仓库）；有难度，当前 LLM 表现很差。</li></ul></div><h3 id="领域复杂代码生成" tabindex="-1">领域复杂代码生成 <a class="header-anchor" href="#领域复杂代码生成" aria-label="Permalink to &quot;领域复杂代码生成&quot;">​</a></h3><p>需要特别的<strong>领域知识</strong>，<code>逻辑复杂</code>、<code>多重依赖</code>等。</p><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251214181328.jpg" style="display:block;margin:auto;" width="70%"><div class="custom-block danger"><div class="custom-block-title">相关Bench</div><ul><li><p>BioCoder</p><ul><li><code>生物学代码</code>生成Bench，1.7k生物学仓库、2.2k高质量代码问题。</li></ul></li><li><p>PaperBench</p><ul><li>要求模型<code>去复现论文</code>，20篇ICML2024的论文。 <ul><li>论文写公式原理，模型需深刻理解，才能写出和跑通代码。</li></ul></li><li><code>评分树(Rubric Tree)</code>：不只看最终结果，而是把<code>大任务</code>拆解为<code>8.3k个小步骤子任务</code>，一步步打分。 <ul><li>如数据预处理、模型定义、loss函数等。</li></ul></li><li>也有一个llm-as-a-judge方法</li></ul></li><li><p>Commit0</p><ul><li>输入<code>文档</code>和<code>空函数体</code>，<code>从0开始编写代码库</code>，实现所有函数，通过<code>单元测试</code>。54个python库。</li></ul></li><li><p>HackerRank-ASTRA</p><ul><li>评估跨领域、多文件的能力。每个问题运行32次做评估。</li></ul></li><li><p>ProjectEval</p><ul><li>模拟<code>用户交互</code>，来测试repo-level 代码生成能力，284个测试用例，共3级输入 <ul><li>Level1：<code>NL Prompt</code>；Level2：<code>NL Checklist</code>；Level3：<code>Skeleton</code>。</li></ul></li><li>模型在需要<code>系统性思维</code>和<code>全项目理解</code>的任务上表现很差。</li></ul></li><li><p>DA-Code</p><ul><li>数据科学上的代码生成。500个任务。存在挑战。</li></ul></li></ul></div><h3 id="代码编辑重构agent合作" tabindex="-1">代码编辑重构Agent合作 <a class="header-anchor" href="#代码编辑重构agent合作" aria-label="Permalink to &quot;代码编辑重构Agent合作&quot;">​</a></h3><div class="custom-block important"><div class="custom-block-title">**代码编辑、重构和智能体协作**</div><ul><li>对代码进行修改、重组以改进质量。</li><li>并由多个Agent协同工作以完成编程目标。</li><li>从简单代码补全插件 -&gt; 能干脏活的agent。</li><li>可靠性(不能影响别的代码)、长代码不懒惰、大局观(复杂计划、跨文件依赖处理)。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251214181345.jpg" style="display:block;margin:auto;" width="70%"><div class="custom-block warning"><div class="custom-block-title">代码编辑重构Bench</div><ul><li><p>Aider Edit Bench</p><ul><li><code>编辑python源文件</code>，完成133个Exercism的<code>编程练习</code>。</li></ul></li><li><p>Aider Refactor Bench</p><ul><li>重构大python类的<code>89个大方法</code>。</li><li>需要<code>长上下文能力</code>。</li></ul></li><li><p>Aider Polyglot Bench</p><ul><li>基于edit bench，扩展了多种语言，共225个case。</li></ul></li><li><p>RES-Q</p><ul><li>100个真实repo的评估bench，在重构、编辑和问答中都有测试用例。</li></ul></li><li><p>LiveRepoReflection</p><ul><li>提出一个<code>系统</code>来<code>收集仓库数据</code>，RepoReflect数据集，包含580个reflection实例。</li><li>集成执行反馈，解决当前llm的局限性(复杂/长上下文等)</li></ul></li><li><p>RepoExec</p><ul><li>仓库级代码生成测试，构建<code>可执行环境</code>来分析<code>上下文</code>如何<code>影响代码的质量</code>。</li><li>指标：pass@k, 依赖调用率(DIR)。</li><li>结果：完整依赖能提高模型效果，指令微调模型比base模型更善于使用依赖。</li></ul></li><li><p>CodePlan</p><ul><li><p>解决复杂任务，<code>Planning</code> + <code>Multi-step Edits</code>。</p><ul><li>先生成<code>多步计划</code>，再<code>一步步编辑</code>，确保每一步的依赖关系都正确。</li></ul></li><li><p>仓库级编码的框架。自动化了需在<code>整个仓库</code>中进行<code>广泛编辑</code>的任务。</p></li></ul></li></ul></div><h3 id="commit-message-生成" tabindex="-1">Commit Message 生成 <a class="header-anchor" href="#commit-message-生成" aria-label="Permalink to &quot;Commit Message 生成&quot;">​</a></h3><div class="custom-block note"><div class="custom-block-title">提交信息生成</div><p><strong>任务</strong></p><ul><li>根据<code>代码差异</code>，自动生成<code>简单</code>、<code>信息丰富</code>的文本描述。</li></ul><p><strong>早早期方法：统计和规则</strong></p><ul><li>猜词，用朴素贝叶斯猜提交是fix还是add。</li></ul><p><strong>早期方法：检索&amp;NMT</strong></p><ul><li>NMT：把diff使用翻译模型翻译成英文</li><li>检索：去数据库里检索一个最像的diff，抄这个message。</li></ul><p><strong>Bert/大模型</strong></p><ul><li>CommitBert：</li><li>CoRec：</li><li>ExGroFi：整合链接的issue描述，增强消息的rationale</li><li>CommitChronicle：利用提交历史，提高对时间和风格的连贯性。</li></ul><p><strong>评估的挑战</strong></p><ul><li>BELU有局限：传统指标看词重叠，一般commit消息比较短暂，稍微换个词，意思一样，但bleu分数会很低。</li><li>B-Norm：通过平滑和忽略大小写，尽量让打分接近人类直观感受。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251214181359.jpg" style="display:block;margin:auto;" width="70%"><h3 id="swe-任务" tabindex="-1">SWE 任务 <a class="header-anchor" href="#swe-任务" aria-label="Permalink to &quot;SWE 任务&quot;">​</a></h3><div class="custom-block note"><div class="custom-block-title">软件工程任务</div><ul><li>来源真实的github开源项目，给定真实的issue，</li><li>徐自己去读代码、复现bug、定位文件、修改代码并通过测试。</li></ul></div><div class="custom-block danger"><div class="custom-block-title">SWE-Bench</div><p><strong>SWE-Bench 家族</strong></p><ul><li><code>SWE-bench</code>：2.2k <code>issuse-PR对</code>，真实github python <code>问题</code> ，<code>fail-to-pass</code> <code>单元测试</code>。</li><li>Java bench：SWE-Bench扩展至Java。</li><li>SWE-bench-light：为降低计算成本，仅保留300个任务。</li><li>SWE-bench-Multilingual：9种编程语言、42个仓库、300个手动验证的任务。</li><li>SWE-bench-Multimodal：517个基于图像的问题，测试是否解释视觉线索(屏幕截图/GUI错误等)。</li><li><code>SWE-bench-verified</code>：<code>500个人工策划</code>的例子，基于docker评估，确保<code>一致性</code>。</li></ul><p><strong>SWE-Bench 扩展</strong></p><ul><li>SWE-bench-Live：持续纳入新的github问题，164仓库、1565任务，更动态、比静态数据难。</li><li>SWE-rebench：自动化大规模问题收集(&gt;21k任务)，实现时间纵向评估。</li><li><strong>SWE-dev</strong>：从bug修复转到<code>功能实现</code>，<code>1.4万个训练数据</code>和<code>500个评估数据</code>。</li><li><strong>BugPilot</strong>：让<code>LLM添加新功能</code>而非直接插入bug，来<code>合成更逼真的bug</code>。 <ul><li>使用<code>Qwen3</code>在swe-bench-verified达到<code>SOTA</code>。</li></ul></li><li>Gistfy：要求agent把仓库提炼为复制其运行时行为的<code>最小单文件代码</code>。</li><li>SWE-PolyBench：跨语言推理能力，21仓库，2110任务。</li><li>Multi-SWE-Bench：7语言，1632 issue，c/c++/rust性能最弱。</li><li>SWE-Bench+：包括截止日期后的仓库，避免数据泄露/</li><li>SWE-bench-M：<code>视觉调试</code>，17个JS项目，619个视觉issue。很有挑战。</li></ul><p><strong>超越SWE-Bench</strong></p><ul><li>SWE-Lancer：经济价值，1.4k真实Upwork任务(100万美元)，</li><li>FAUN-Eval：300个github细粒度问题。</li><li>FEA-Bench：跨83个仓库的仓库级功能实现，最好模型仅10%</li><li>SwingArea/CoreCodeBench：分别把评估扩展至持续集成和复合任务。</li><li>AgentIssue-Bench：agent的自我维护能力，201个问题、50个任务，长期记忆挑战。</li></ul></div><h3 id="综合软件开发" tabindex="-1">综合软件开发 <a class="header-anchor" href="#综合软件开发" aria-label="Permalink to &quot;综合软件开发&quot;">​</a></h3><div class="custom-block caution"><div class="custom-block-title">综合软件开发</div><ul><li>代码只是一小部分。</li><li>还需要：写文档、看图修bug、用git、跟进项目等。</li></ul></div><div class="custom-block info"><div class="custom-block-title">关键Bench</div><ul><li>README Eval：文档生成，根据项目的issue和commits等数据生成readme</li><li>OminiGIRL：评估github issue能力，引入多模态挑战，错误包括图像。</li><li>GitGoodBench：版本控制。</li><li>EvoCodeBench：动态范式，不断演进真实的仓库。</li><li>Stack-Repo：策划<code>大规模</code>、<code>去重的源代码</code>数据，对提高真实任务性能很重要。</li></ul></div><h3 id="repo-level和长上下文理解" tabindex="-1">Repo-Level和长上下文理解 <a class="header-anchor" href="#repo-level和长上下文理解" aria-label="Permalink to &quot;Repo-Level和长上下文理解&quot;">​</a></h3><div class="custom-block note"><div class="custom-block-title">仓库级和长上下文理解</div><p><strong>思想</strong></p><ul><li>在整个代码库或大量文档做理解推理，需要跨越多个文件、可能需保持高达数百万token的上下文。</li></ul><p><strong>基准测试：海量代码大海捞针</strong></p><ul><li>RepoQA：仓库级问答，需对<code>多个文件</code>进行<code>检索和推理</code>。</li><li>CodeRepoQA：仓库级问答</li><li>CoreQA：真实github仓库问题和评论构建的数据集</li><li>LongCodeU：更全面和挑战的任务，四个方面来评估： <ul><li>代码单元感知、代码单元内部理解、代码单元关系理解、长文档理解</li></ul></li></ul><p><strong>长上下文压缩</strong></p><ul><li>LongCodeZip：减少上下文长度，高效压缩长代码上下文 <ul><li><a href="https://plmsmile.github.io/posts/llm/basic/01-lm-define-information-theory.html#%E5%9B%B0%E6%83%91%E5%BA%A6" target="_blank" rel="noreferrer">困惑度</a>：如果一段代码对当前问题重要，去掉其以后，模型对该问题的困惑度会飙升。</li><li>粗粒度压缩：以函数为单位，计算每个函数对当问题的贡献度(互信息)，只保留贡献大的函数。</li><li>细粒度压缩：基于困惑度的边界检测，把保留的函数分割成快，使用背包算法进行token预算优化</li></ul></li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251214181418.jpg" style="display:block;margin:auto;" width="70%"><h2 id="agentic-system" tabindex="-1">Agentic System <a class="header-anchor" href="#agentic-system" aria-label="Permalink to &quot;Agentic System&quot;">​</a></h2><h3 id="agentic-tool-use" tabindex="-1">Agentic Tool Use <a class="header-anchor" href="#agentic-tool-use" aria-label="Permalink to &quot;Agentic Tool Use&quot;">​</a></h3><div class="custom-block note"><div class="custom-block-title">Agentic Tool Use</div><p><strong>核心</strong></p><ul><li>考察选择和使用工具的能力。</li></ul><p><strong>入门级</strong></p><ul><li>API-Bank：天气如何，意图识别。</li><li>ToolBench</li></ul><p><strong>多轮交互</strong></p><ul><li>BFCL：多步多轮交互。</li><li>还有AppWorld。</li></ul><p><strong>领域任务</strong></p><ul><li>TauBench：复杂的公司内部流程(客服)</li></ul></div><h3 id="deep-research-bench" tabindex="-1">Deep Research Bench <a class="header-anchor" href="#deep-research-bench" aria-label="Permalink to &quot;Deep Research Bench&quot;">​</a></h3><div class="custom-block note"><div class="custom-block-title">DeepResearch</div><p><strong>核心</strong></p><ul><li>信息检索、深度推理。</li></ul><p><strong>Bench</strong></p><ul><li>GAIA：真实问题，结合推理、网页浏览、工具使用。</li><li>xbench：人才搜寻和市场营销领域。</li><li>DeepResearch Bench：学术标准，需达phd-level，自主研究和生成报告。</li></ul></div><h3 id="websearch-bench" tabindex="-1">WebSearch Bench <a class="header-anchor" href="#websearch-bench" aria-label="Permalink to &quot;WebSearch Bench&quot;">​</a></h3><div class="custom-block note"><div class="custom-block-title">WebSearch</div><p><strong>核心</strong></p><ul><li>开放的、不受约束的网络环境。需要持久、适应和过滤噪声和矛盾信息的能力。</li></ul><p><strong>Bench</strong></p><ul><li>BrowseComp：把信息检索构建为组合推理任务，要求聚合多个网站上的碎片化信息。</li><li>BrowseComp-ZH：多语言版本。</li><li>BrowseComp-Plus：推理和检索解耦，分为<code>找信息</code>和<code>根据信息推理</code>2步。</li><li>WebWalker-QA：强调<code>网页之间的跳转</code>，像人逛维基百科一样。</li><li>Widesearch：大规模、开放域的信息综合synthesis。</li></ul></div><h3 id="gui-bench" tabindex="-1">GUI Bench <a class="header-anchor" href="#gui-bench" aria-label="Permalink to &quot;GUI Bench&quot;">​</a></h3><div class="custom-block note"><div class="custom-block-title">GUI Bench</div><p><strong>核心</strong></p><ul><li>要求理解图像用户界面。</li><li>把NL指令变成Grounding的UI动作，多步计划、泛化性仍然存在挑战。</li></ul><p><strong>前端导航Bench</strong></p><ul><li>WebShop/Mind2Web：数千个目标导向的任务，要求在真实网站中操作。</li><li>OminiACT：扩展，引入跨网页、桌面和移动设置的bench。</li><li>WebChoreArena：长期记忆和计算的复合家务任务。</li><li>PersonalWAB：用户历史和偏好引入个性化。</li><li>Sphinx/NovelScreenSpot：GUI分解子技能，如目标理解、UI落地和规划。</li></ul><p><strong>前端开发Bench</strong></p><ul><li>Design2Code/WebCode2M：设计和代码实现的pair数据集。看图写代码。</li><li>Sketch2Code：看草图写代码</li><li>Interaction2Code：生成动态交互式的网站。</li><li>WebGen-Bench：从0开始生成多文件网站。</li><li>Web-Bench：模拟了具有顺序依赖任务的真实软件开发，不仅是一次生成，还有后续修改和迭代。</li></ul></div><h3 id="terminal-use" tabindex="-1">Terminal Use <a class="header-anchor" href="#terminal-use" aria-label="Permalink to &quot;Terminal Use&quot;">​</a></h3><div class="custom-block note"><div class="custom-block-title">Terminal Use</div><p><strong>核心</strong></p><ul><li>在终端环境中做真实任务的自主操作能力。</li><li>超越了自定义环境，还需要在真实系统里做操作。 <ul><li>SWE-Bench：定义好环境，边界清晰。</li><li>Terminal-Bench：无边界，整个系统都是环境。</li></ul></li></ul><p><strong>Bench</strong></p><ul><li>Terminal-Bench： <ul><li>需要系统级开发能力，探索系统、执行shell和各种命令行工具，完成复杂系统任务。 <ul><li>比如从源码编译和启动一个完整的linux内核。</li></ul></li><li>整个环境都是待解的空间。</li></ul></li></ul></div></div></div></main><footer class="VPDocFooter" data-v-5a64a79a data-v-54a90a4a><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-54a90a4a><span class="visually-hidden" id="doc-footer-aria-label" data-v-54a90a4a>Pager</span><div class="pager" data-v-54a90a4a><a class="VPLink link pager-link prev" href="/posts/llm/industry/codellm/03-rl-task.html" data-v-54a90a4a><!--[--><span class="desc" data-v-54a90a4a>上一页</span><span class="title" data-v-54a90a4a>Code RL 任务</span><!--]--></a></div><div class="pager" data-v-54a90a4a><a class="VPLink link pager-link next" href="/posts/llm/industry/codellm/01-survey.html" data-v-54a90a4a><!--[--><span class="desc" data-v-54a90a4a>下一页</span><span class="title" data-v-54a90a4a>Code Survey</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--[--><div class="busuanzi"> 总访客数： <span id="busuanzi_value_site_uv"></span>   ·   总访问量： <span id="busuanzi_value_site_pv"></span></div><div class="busuanzi"> PLM&#39;s Blog @ 2016 - 2026</div><!--]--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api-examples.md\":\"Bt59YpwR\",\"index.md\":\"DmRGHmj9\",\"markdown-examples.md\":\"CPJSv--2\",\"posts_archive.md\":\"pZWQT7dp\",\"posts_exps_env_01-blog-env.md\":\"CcTUm41j\",\"posts_exps_env_index.md\":\"BJEZeoT-\",\"posts_exps_mind_index.md\":\"naOB3-Mb\",\"posts_llm_agent_basic_01-lhy-agent-notes.md\":\"BK_CsHNC\",\"posts_llm_agent_basic_02-evaluation-agent.md\":\"Dn02cVtP\",\"posts_llm_agent_basic_03-current-agents.md\":\"C25gmbg8\",\"posts_llm_agent_basic_04-agent-blogs.md\":\"_QbL2Plv\",\"posts_llm_agent_basic_05-comuter-agent.md\":\"D0gJpId6\",\"posts_llm_agent_basic_06-deepresearch-evaluation.md\":\"DdRDcxUJ\",\"posts_llm_agent_basic_index.md\":\"ClGtwUqg\",\"posts_llm_agent_rl_01-agent-rl.md\":\"wOF9bz66\",\"posts_llm_agent_rl_02-agent-tool.md\":\"IB_AqkSe\",\"posts_llm_agent_rl_03-agent-search.md\":\"Cim7OGxb\",\"posts_llm_agent_rl_04-agent-env.md\":\"C_O9BVi3\",\"posts_llm_agent_rl_index.md\":\"BudtoDK9\",\"posts_llm_basic_01-lm-define-information-theory.md\":\"Bl38RTdm\",\"posts_llm_basic_02-llm-components.md\":\"CGM_jRUE\",\"posts_llm_basic_03-transformer-detail.md\":\"BgLyAVDZ\",\"posts_llm_basic_04-llm-architecture.md\":\"jk4T-c21\",\"posts_llm_basic_05-llm-basic-info.md\":\"bdnM02bn\",\"posts_llm_basic_06-llm-attention.md\":\"BRJ9jR-M\",\"posts_llm_basic_07-decode.md\":\"BRytPqZo\",\"posts_llm_basic_08-llm-position-embedding.md\":\"d9dN_RuO\",\"posts_llm_basic_index.md\":\"DjX2HRXy\",\"posts_llm_industry_codellm_01-survey.md\":\"DIZQiOWr\",\"posts_llm_industry_codellm_02-eval-task-benchmark.md\":\"B-okIRAD\",\"posts_llm_industry_codellm_03-rl-task.md\":\"vQDqALFA\",\"posts_llm_industry_codellm_04-safety-code.md\":\"mkEFLxnr\",\"posts_llm_industry_codellm_05-open-codellm.md\":\"C6UU6qcZ\",\"posts_llm_industry_codellm_06-code-taskrl-reading.md\":\"BJI-7ypF\",\"posts_llm_industry_codellm_07-code-fulltrain-reading.md\":\"D7trPw8V\",\"posts_llm_industry_codellm_08-code-pretrain-summary.md\":\"DfgRUz6a\",\"posts_llm_industry_mainllm_01-kimi-series.md\":\"B03hc7IE\",\"posts_llm_industry_mainllm_02-deepseek-series.md\":\"B04zRtyw\",\"posts_llm_industry_mainllm_03-glm-series.md\":\"8i7VdpW8\",\"posts_llm_industry_mainllm_04-minimax-series.md\":\"DjQwki4V\",\"posts_llm_industry_mainllm_05-qwen-series.md\":\"B4DMxRmo\",\"posts_llm_industry_mainllm_06-seed-series.md\":\"BNsIBjBZ\",\"posts_llm_industry_mainllm_07-openai-series.md\":\"ZBquCwKO\",\"posts_llm_industry_mainllm_08-gemini-series.md\":\"Bdm2kU-I\",\"posts_llm_industry_mainllm_09-claude-series.md\":\"0YnEaaXS\",\"posts_llm_industry_mainllm_10-longcat-series.md\":\"DroIAFXW\",\"posts_llm_industry_mainllm_11-tencent-series.md\":\"BVkGSYEM\",\"posts_llm_industry_mainllm_12-kwai-series.md\":\"o6Hut3bE\",\"posts_llm_industry_mainllm_13-nvidia-series.md\":\"BFgUmWZk\",\"posts_llm_industry_mainllm_14-mimo-series.md\":\"DDj7XRZV\",\"posts_llm_industry_mainllm_15-skywork-series.md\":\"pkz98qRT\",\"posts_llm_infra_01-parrallel.md\":\"Dih7M1RJ\",\"posts_llm_infra_02-speed-framework.md\":\"_bUH-n3t\",\"posts_llm_infra_03-inference-tech.md\":\"Hpk9YmXF\",\"posts_llm_infra_04-verl.md\":\"8XtGz01J\",\"posts_llm_infra_05-verl-practice.md\":\"B4gP7J_O\",\"posts_llm_infra_06-verl-code.md\":\"D5bZg4dm\",\"posts_llm_infra_07-verl-core.md\":\"3RS___SF\",\"posts_llm_infra_08-verl-train-loop.md\":\"CQNCgy-d\",\"posts_llm_rl_index.md\":\"iUgEsMU1\",\"posts_llm_rl_theory_01-reinforce-learning.md\":\"Ch0rtQCM\",\"posts_llm_rl_theory_01-rl-introduction.md\":\"CmW63EkM\",\"posts_llm_rl_theory_02-markove-process.md\":\"DVY5XgWd\",\"posts_llm_rl_theory_02-value-learning.md\":\"CeOlmbeS\",\"posts_llm_rl_theory_03-model-based-prediction-control.md\":\"BhVRmo7C\",\"posts_llm_rl_theory_03-strategy-learning.md\":\"DWNvEZXH\",\"posts_llm_rl_theory_04-model-free-prediction-control.md\":\"Cg3qo2Fk\",\"posts_llm_rl_theory_04-reinforce-conclusion-simple.md\":\"C6yTAxwQ\",\"posts_llm_rl_theory_05-dqn.md\":\"BatSdlnZ\",\"posts_llm_rl_theory_06-policy-gradient.md\":\"BXI-eY8I\",\"posts_llm_rl_theory_07-actor-critic.md\":\"B1-83sen\",\"posts_llm_rl_theory_08-deterministic-policy-gradient.md\":\"Dgvru3JE\",\"posts_llm_rl_theory_09-policy-trpo-ppo.md\":\"DU-7PSqU\",\"posts_llm_rl_theory_10-ppo-series.md\":\"B-5Hsj_J\",\"posts_llm_rl_theory_11-grpo-series.md\":\"Ctl1G-Yd\",\"posts_llm_rl_theory_12-entropy.md\":\"BH45bCLH\",\"posts_llm_rl_theory_13-agentrl-algo.md\":\"BfctbxM6\",\"posts_me.md\":\"B9W6CMag\",\"posts_olds_algo_aim2offer.md\":\"jCwzQ4BU\",\"posts_olds_algo_aim2offer2.md\":\"Ga2XS6dR\",\"posts_olds_algo_aim2offer3.md\":\"BP0rCZaJ\",\"posts_olds_algo_aim2offer4.md\":\"BXurWO8W\",\"posts_olds_algo_algorithm-dfs.md\":\"CkUFsStz\",\"posts_olds_algo_index.md\":\"CmdF0Gg2\",\"posts_olds_algo_leetcode-01.md\":\"C_2G2jJT\",\"posts_olds_algo_sort-algorithms.md\":\"tFMUVlmH\",\"posts_olds_bigdata_16-spark-baserdd.md\":\"CBxdArgI\",\"posts_olds_bigdata_17-spark-pairrdd.md\":\"C3n8_zMO\",\"posts_olds_bigdata_18-spark-sql.md\":\"tsaWQLcp\",\"posts_olds_bigdata_19-spark-programming.md\":\"DG5ZAF85\",\"posts_olds_bigdata_20-numpy.md\":\"DucCD22z\",\"posts_olds_bigdata_index.md\":\"CWrZwWPb\",\"posts_olds_dl_23-pytorch-start.md\":\"BokpNeAw\",\"posts_olds_dl_35-nerual-network-optim.md\":\"Cp2SpLoE\",\"posts_olds_dl_38-convolution.md\":\"CC_SQ57z\",\"posts_olds_dl_cs224n-assignment-1.md\":\"BZMSZqOS\",\"posts_olds_dl_cs224n-notes3-neural-networks-2.md\":\"Wd9TmSyb\",\"posts_olds_dl_cs224n-notes3-neural-networks.md\":\"CDZWc4X6\",\"posts_olds_dl_cs231n-linear-notes.md\":\"DLRyzcwJ\",\"posts_olds_dl_index.md\":\"C1dyLGNS\",\"posts_olds_dl_rnn.md\":\"CwYYWZ7N\",\"posts_olds_env_09-linux-notes.md\":\"CyjifvcN\",\"posts_olds_env_12-ide-envs.md\":\"YeELWzR2\",\"posts_olds_env_13-old-blog-problems.md\":\"qamPyucB\",\"posts_olds_env_24-hexo-problems.md\":\"CzxhyjW1\",\"posts_olds_env_index.md\":\"DQpgTXVj\",\"posts_olds_ml_10-trees.md\":\"BkNaj6fL\",\"posts_olds_ml_14-em.md\":\"DIufCP0H\",\"posts_olds_ml_21-lr.md\":\"C-1ms511\",\"posts_olds_ml_22-ml-ch03-bayes.md\":\"Q_M6Gn-a\",\"posts_olds_ml_27-svm-notes.md\":\"C96WS6CL\",\"posts_olds_ml_28-ml-interview-notes.md\":\"0bgezw3n\",\"posts_olds_ml_29-desicion-tree.md\":\"CtwmlbWl\",\"posts_olds_ml_crf.md\":\"CEE5oTqd\",\"posts_olds_ml_index.md\":\"BLMEziB1\",\"posts_olds_ml_maxentmodel.md\":\"CSbOumJx\",\"posts_olds_ml_pgm-01.md\":\"BTwybTMD\",\"posts_olds_nlp_11-nlp-labels.md\":\"Cl0Lb8OT\",\"posts_olds_nlp_25-google-nmt.md\":\"BOM-hoYN\",\"posts_olds_nlp_26-wordpieacemodel.md\":\"Q8-L5j15\",\"posts_olds_nlp_30-dynamic-memory-network.md\":\"wp5ucVxW\",\"posts_olds_nlp_31-co-attention-vqa.md\":\"lzwuVKG5\",\"posts_olds_nlp_32-dynamic-coattention-network.md\":\"Bxl4ABWd\",\"posts_olds_nlp_33-attention-summary.md\":\"DT6np0xG\",\"posts_olds_nlp_36-alime-chat.md\":\"Cu2xkcdT\",\"posts_olds_nlp_39-squard-models.md\":\"B1L3iDEv\",\"posts_olds_nlp_45-match-lstm.md\":\"DkpQKM5B\",\"posts_olds_nlp_46-rnet-selfmatch.md\":\"CzGHQ-PZ\",\"posts_olds_nlp_47-bidaf.md\":\"DFJaLh2v\",\"posts_olds_nlp_48-attention-is-all-you-need.md\":\"BY6XvFQ5\",\"posts_olds_nlp_49-qanet.md\":\"BPKWHzTf\",\"posts_olds_nlp_50-elmo.md\":\"WuOt1elN\",\"posts_olds_nlp_51-opengpt.md\":\"B9pQ3h5W\",\"posts_olds_nlp_52-bert.md\":\"5q3t5Qqh\",\"posts_olds_nlp_53-mrc-brief.md\":\"D9CkYrea\",\"posts_olds_nlp_54-mrc-models.md\":\"Ak4bDf1J\",\"posts_olds_nlp_attention-based-nmt.md\":\"BHef6tM6\",\"posts_olds_nlp_attention-model.md\":\"-xLhHhJE\",\"posts_olds_nlp_cs224n-lecture2-word2vec.md\":\"_MmBTADr\",\"posts_olds_nlp_cs224n-notes1-word2vec.md\":\"DXSi5KGh\",\"posts_olds_nlp_index.md\":\"Bfo4Lwn3\",\"posts_olds_nlp_nlp-notes.md\":\"BUmOZxzi\",\"posts_olds_nlp_nmt.md\":\"DUgy6vHF\",\"posts_olds_nlp_subword-units.md\":\"fR_3dRXr\",\"posts_olds_nlp_word2vec-math.md\":\"agvHiE1x\",\"posts_olds_nlp_word2vec.md\":\"D2TKUstm\",\"posts_olds_other_15-cpp-pointer-object-reference.md\":\"BKRTr8QZ\",\"posts_olds_other_index.md\":\"C1T-ubsz\",\"posts_olds_rl_37-reinforce-learning.md\":\"Cf2nny8k\",\"posts_olds_rl_40-value-learning.md\":\"DcnHvvpH\",\"posts_olds_rl_41-strategy-learning.md\":\"CStMrB-q\",\"posts_olds_rl_42-reinforce-conclusion-simple.md\":\"flRZUmJZ\",\"posts_olds_rl_43-intent-detection-slot-filling.md\":\"DcAUbaZU\",\"posts_olds_rl_44-reinforce-nlp.md\":\"Br2ShITL\",\"posts_olds_rl_index.md\":\"CUsxM3zO\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"📚 plmblog\",\"description\":\"记录一些学习笔记。\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"首页\",\"link\":\"/\"},{\"text\":\"🐲LLM\",\"items\":[{\"text\":\"Basic\",\"items\":[{\"text\":\"🦋基础知识\",\"link\":\"/posts/llm/basic/01-lm-define-information-theory\"},{\"text\":\"🛠基建框架\",\"link\":\"/posts/llm/infra/01-parrallel\"}]},{\"text\":\"强化学习\",\"items\":[{\"text\":\"🎓RL理论基础\",\"link\":\"/posts/llm/rl/theory/01-reinforce-learning\"},{\"text\":\"🚄Agent-RL\",\"link\":\"/posts/llm/agent/rl/02-agent-tool\"}]},{\"text\":\"行业方向\",\"items\":[{\"text\":\"🚀主流模型\",\"link\":\"/posts/llm/industry/mainllm/01-kimi-series\"},{\"text\":\"💻代码模型\",\"link\":\"/posts/llm/industry/codellm/01-survey\"}]},{\"text\":\"Agent\",\"items\":[{\"text\":\"🤖概念及应用\",\"link\":\"/posts/llm/agent/basic\"}]}]},{\"text\":\"📙旧文章\",\"items\":[{\"text\":\"🍓NLP\",\"items\":[{\"text\":\"自然语言处理\",\"link\":\"/posts/olds/nlp\"}]},{\"text\":\"🍑基础知识\",\"items\":[{\"text\":\"深度学习\",\"link\":\"/posts/olds/dl\"},{\"text\":\"强化学习\",\"link\":\"/posts/olds/rl\"},{\"text\":\"机器学习\",\"link\":\"/posts/olds/ml\"}]},{\"text\":\"🍎算法\",\"items\":[{\"text\":\"算法题\",\"link\":\"/posts/olds/algo/\"},{\"text\":\"大数据\",\"link\":\"/posts/olds/bigdata/\"}]},{\"text\":\"🍒其他\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/olds/env/\"},{\"text\":\"其他\",\"link\":\"/posts/olds/other/\"}]}]},{\"text\":\"经验\",\"items\":[{\"text\":\"环境\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/exps/env/01-blog-env\"}]},{\"text\":\"心得\",\"items\":[{\"text\":\"心得体会\",\"link\":\"/posts/exps/mind\"}]}]},{\"text\":\"归档\",\"link\":\"/posts/archive.md\"},{\"text\":\"关于我\",\"link\":\"/posts/me\"}],\"outline\":{\"level\":[1,4],\"label\":\"当前页大纲\"},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/plmsmile\"}],\"search\":{\"provider\":\"local\"},\"docFooter\":{\"prev\":\"上一页\",\"next\":\"下一页\"},\"sidebar\":{\"/posts/olds/nlp/\":{\"base\":\"/posts/olds/nlp/\",\"items\":[{\"text\":\"NLP\",\"items\":[{\"text\":\"机器阅读(二)--模型(未完成)\",\"link\":\"54-mrc-models\"},{\"text\":\"机器阅读(一)--整体概述\",\"link\":\"53-mrc-brief\"},{\"text\":\"BERT 详解\",\"link\":\"52-bert\"},{\"text\":\"OpenAI GPT：Improving Language Understanding by Generative Pre-Training\",\"link\":\"51-opengpt\"},{\"text\":\"ELMo：Deep Contextualized Word Representations\",\"link\":\"50-elmo\"},{\"text\":\"QANet\",\"link\":\"49-qanet\"},{\"text\":\"Transformer\",\"link\":\"48-attention-is-all-you-need\"},{\"text\":\"Bidirectional Attention Flow\",\"link\":\"47-bidaf\"},{\"text\":\"R-Net (Gated Self-Matching Networks)\",\"link\":\"46-rnet-selfmatch\"},{\"text\":\"Match-LSTM and Answer Pointer\",\"link\":\"45-match-lstm\"},{\"text\":\"阅读理解模型总结\",\"link\":\"39-squard-models\"},{\"text\":\"阿里小蜜论文\",\"link\":\"36-alime-chat\"},{\"text\":\"各种注意力总结\",\"link\":\"33-attention-summary\"},{\"text\":\"Dynamic Coattention Network (Plus)\",\"link\":\"32-dynamic-coattention-network\"},{\"text\":\"协同注意力简介\",\"link\":\"31-co-attention-vqa\"},{\"text\":\"使用Dynamic Memory Network实现一个简单QA\",\"link\":\"30-dynamic-memory-network\"},{\"text\":\"词性标注和句法依存的表示符号\",\"link\":\"11-nlp-labels\"},{\"text\":\"Word2vec之总体介绍\",\"link\":\"cs224n-notes1-word2vec\"},{\"text\":\"Word2vec之数学模型\",\"link\":\"word2vec-math\"},{\"text\":\"Word2vec之公式推导笔记\",\"link\":\"cs224n-lecture2-word2vec\"},{\"text\":\"subword-units\",\"link\":\"subword-units\"},{\"text\":\"Wordpiece模型\",\"link\":\"26-wordpieacemodel\"},{\"text\":\"谷歌RNN翻译模型\",\"link\":\"25-google-nmt\"},{\"text\":\"机器翻译注意力机制及其PyTorch实现\",\"link\":\"Attention-based-NMT\"},{\"text\":\"图文介绍RNN注意力机制\",\"link\":\"attention-model\"},{\"text\":\"最初RNN神经翻译简略笔记\",\"link\":\"NMT\"},{\"text\":\"语言模型和平滑方法\",\"link\":\"nlp-notes\"},{\"text\":\"利用tensorflow实现简版word2vec\",\"link\":\"word2vec\"}]}]},\"/posts/olds/dl/\":{\"base\":\"/posts/olds/dl/\",\"items\":[{\"text\":\"DL\",\"items\":[{\"text\":\"卷积神经网络总结\",\"link\":\"38-convolution\"},{\"text\":\"网络优化\",\"link\":\"35-nerual-network-optim\"},{\"text\":\"cs224n作业一\",\"link\":\"cs224n-assignment-1\"},{\"text\":\"cs231n线性分类器和损失函数\",\"link\":\"cs231n-linear-notes\"},{\"text\":\"神经网络-过拟合-预处理-BN\",\"link\":\"cs224n-notes3-neural-networks-2\"},{\"text\":\"神经网络基础-反向传播-激活函数\",\"link\":\"cs224n-notes3-neural-networks\"},{\"text\":\"循环神经网络\",\"link\":\"rnn\"},{\"text\":\"PyTorch快速上手\",\"link\":\"23-pytorch-start\"}]}]},\"/posts/olds/rl/\":{\"base\":\"/posts/olds/rl/\",\"items\":[{\"text\":\"RL\",\"items\":[{\"text\":\"强化学习在NLP中的应用\",\"link\":\"44-reinforce-nlp\"},{\"text\":\"意图识别和槽填充\",\"link\":\"43-intent-detection-slot-filling\"},{\"text\":\"强化学习算法小结\",\"link\":\"42-reinforce-conclusion-simple\"},{\"text\":\"基于策略函数的学习方法\",\"link\":\"41-strategy-learning\"},{\"text\":\"基于值函数的学习\",\"link\":\"40-value-learning\"},{\"text\":\"强化学习\",\"link\":\"37-reinforce-learning\"}]}]},\"/posts/olds/ml/\":{\"base\":\"/posts/olds/ml/\",\"items\":[{\"text\":\"ML\",\"items\":[{\"text\":\"决策树笔记\",\"link\":\"29-desicion-tree\"},{\"text\":\"机器学习知识点汇总整理\",\"link\":\"28-ml-interview-notes\"},{\"text\":\"SVM笔记\",\"link\":\"27-svm-notes\"},{\"text\":\"树的总结\",\"link\":\"10-trees\"},{\"text\":\"条件随机场\",\"link\":\"crf\"},{\"text\":\"最大熵模型\",\"link\":\"maxentmodel\"},{\"text\":\"线性回归和逻辑回归\",\"link\":\"21-lr\"},{\"text\":\"最大期望算法\",\"link\":\"14-em\"},{\"text\":\"马尔可夫模型\",\"link\":\"pgm-01\"},{\"text\":\"朴素贝叶斯算法及其代码实现\",\"link\":\"22-ml-ch03-bayes\"}]}]},\"/posts/olds/algo/\":{\"base\":\"/posts/olds/algo/\",\"items\":[{\"text\":\"ALGO\",\"items\":[{\"text\":\"剑指offer4(51-64)\",\"link\":\"aim2offer4\"},{\"text\":\"剑指offer3(21-40)\",\"link\":\"aim2offer3\"},{\"text\":\"数据结构之搜索算法\",\"link\":\"algorithm-dfs\"},{\"text\":\"leetcode-01\",\"link\":\"leetcode-01\"},{\"text\":\"剑指offer(11-20)\",\"link\":\"aim2offer2\"},{\"text\":\"排序算法总结\",\"link\":\"sort-algorithms\"},{\"text\":\"剑指Offer(1-10)\",\"link\":\"aim2offer\"}]}]},\"/posts/olds/bigdata/\":{\"base\":\"/posts/olds/bigdata/\",\"items\":[{\"text\":\"BIG Data\",\"items\":[{\"text\":\"NumPy\",\"link\":\"20-numpy\"},{\"text\":\"Spark基础编程核心思想介绍\",\"link\":\"19-spark-programming\"},{\"text\":\"Spark-SQL的简略笔记\",\"link\":\"18-spark-sql\"},{\"text\":\"Spark键值对RDD的常用API\",\"link\":\"17-spark-pairrdd\"},{\"text\":\"Spark基础RDD的常用API\",\"link\":\"16-Spark-BaseRDD\"}]}]},\"/posts/olds/env/\":{\"base\":\"/posts/olds/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"IDE配置\",\"link\":\"12-ide-envs\"},{\"text\":\"Linux使用笔记\",\"link\":\"09-linux-notes\"},{\"text\":\"博客搭建及相关问题\",\"link\":\"24-hexo-problems\"},{\"text\":\"旧版博客搭建过程及其问题\",\"link\":\"13-old-blog-problems\"}]}]},\"/posts/olds/other/\":{\"base\":\"/posts/olds/other/\",\"items\":[{\"text\":\"其他\",\"items\":[{\"text\":\"C++类对象和指针的区别\",\"link\":\"15-cpp-pointer-object-reference\"}]}]},\"/posts/llm/agent/rl/\":{\"base\":\"/posts/llm/agent/rl/\",\"items\":[{\"text\":\"Agent-RL\",\"items\":[{\"text\":\"Agent-Interaction-RL 笔记\",\"link\":\"04-agent-env\"},{\"text\":\"Agent-Search-RL 笔记\",\"link\":\"03-agent-search\"},{\"text\":\"Agent-Tool-RL 笔记\",\"link\":\"02-agent-tool\"},{\"text\":\"Agent-RL 综述型笔记\",\"link\":\"01-agent-rl\"}]}]},\"/posts/llm/agent/basic/\":{\"base\":\"/posts/llm/agent/basic/\",\"items\":[{\"text\":\"Agent-基础\",\"items\":[{\"text\":\"DeepResearch 评估\",\"link\":\"06-deepresearch-evaluation\"},{\"text\":\"Computer-Agent\",\"link\":\"05-comuter-agent\"},{\"text\":\"Agent 思考性文章\",\"link\":\"04-agent-blogs\"},{\"text\":\"一些流行的Agents\",\"link\":\"03-current-agents\"},{\"text\":\"Agent 评估 Benchmarks\",\"link\":\"02-evaluation-agent\"},{\"text\":\"Agent基础概念 (李宏毅笔记)\",\"link\":\"01-lhy-agent-notes\"}]}]},\"/posts/llm/rl/theory/\":{\"base\":\"/posts/llm/rl/theory/\",\"items\":[{\"text\":\"RL-Theory\",\"items\":[{\"text\":\"Agent-RL 相关算法\",\"link\":\"13-agentrl-algo\"},{\"text\":\"熵和RL相关文章\",\"link\":\"12-entropy\"},{\"text\":\"GRPO 改进系列\",\"link\":\"11-grpo-series\"},{\"text\":\"PPO 改进系列\",\"link\":\"10-ppo-series\"},{\"text\":\"典型策略提升方法：TRPO+PPO+DPO+GRPO\",\"link\":\"09-policy-trpo-ppo\"},{\"text\":\"确定性策略梯度\",\"link\":\"08-deterministic-policy-gradient\"},{\"text\":\"Actor-Critic 算法\",\"link\":\"07-actor-critic\"},{\"text\":\"策略梯度算法\",\"link\":\"06-policy-gradient\"},{\"text\":\"DQN算法及进阶\",\"link\":\"05-dqn\"},{\"text\":\"免模型预测和控制\",\"link\":\"04-model-free-prediction-control\"},{\"text\":\"有模型预测和控制\",\"link\":\"03-model-based-prediction-control\"},{\"text\":\"马尔可夫决策过程\",\"link\":\"02-markove-process\"},{\"text\":\"强化学习基本概念\",\"link\":\"01-rl-introduction\"},{\"text\":\"(18年笔记)强化学习算法小结\",\"link\":\"04-reinforce-conclusion-simple\"},{\"text\":\"(18年笔记)基于策略函数的学习方法\",\"link\":\"03-strategy-learning\"},{\"text\":\"(18年笔记)基于值函数的学习\",\"link\":\"02-value-learning\"},{\"text\":\"(18年笔记)强化学习基础\",\"link\":\"01-reinforce-learning\"}]}]},\"/posts/llm/rl/rlhf/\":{\"base\":\"/posts/llm/rl/rlhf/\",\"items\":[{\"text\":\"RLHF\",\"items\":[]}]},\"/posts/llm/rl/o1llm/\":{\"base\":\"/posts/llm/rl/o1llm/\",\"items\":[{\"text\":\"推理模型\",\"items\":[]}]},\"/posts/llm/industry/mainllm/\":{\"base\":\"/posts/llm/industry/mainllm/\",\"items\":[{\"text\":\"🚀主流模型\",\"items\":[{\"text\":\"快手系列\",\"link\":\"12-kwai-series\"},{\"text\":\"腾讯系列\",\"link\":\"11-tencent-series\"},{\"text\":\"Claude 系列\",\"link\":\"09-claude-series\"},{\"text\":\"LongCat 系列\",\"link\":\"10-longcat-series\"},{\"text\":\"Gemini 系列\",\"link\":\"08-gemini-series\"},{\"text\":\"Seed 系列\",\"link\":\"06-seed-series\"},{\"text\":\"OpenAI 系列\",\"link\":\"07-openai-series\"},{\"text\":\"Qwen 系列\",\"link\":\"05-qwen-series\"},{\"text\":\"MiniMax 系列\",\"link\":\"04-minimax-series\"},{\"text\":\"GLM 系列\",\"link\":\"03-glm-series\"},{\"text\":\"DeepSeek 系列\",\"link\":\"02-deepseek-series\"},{\"text\":\"Kimi 系列\",\"link\":\"01-kimi-series\"},{\"text\":\"SkyWork 系列\",\"link\":\"15-skywork-series\"},{\"text\":\"小米系列\",\"link\":\"14-mimo-series\"},{\"text\":\"Nvidia 系列\",\"link\":\"13-nvidia-series\"}]}]},\"/posts/llm/industry/codellm/\":{\"base\":\"/posts/llm/industry/codellm/\",\"items\":[{\"text\":\"💻代码模型\",\"items\":[{\"text\":\"Code 全训练 论文阅读\",\"link\":\"07-code-fulltrain-reading\"},{\"text\":\"Code TaskRL 论文阅读\",\"link\":\"06-code-taskrl-reading\"},{\"text\":\"CodeLLM 索引简记\",\"link\":\"05-open-codellm\"},{\"text\":\"Code 安全相关\",\"link\":\"04-safety-code\"},{\"text\":\"Code RL 任务\",\"link\":\"03-rl-task\"},{\"text\":\"Code 任务Bench相关\",\"link\":\"02-eval-task-benchmark\"},{\"text\":\"Code Survey\",\"link\":\"01-survey\"},{\"text\":\"Code 预训练相关\",\"link\":\"08-code-pretrain-summary\"}]}]},\"/posts/llm/basic/\":{\"base\":\"/posts/llm/basic/\",\"items\":[{\"text\":\"LLM-basic\",\"items\":[{\"text\":\"LLM位置编码和长度外推系列\",\"link\":\"08-llm-position-embedding\"},{\"text\":\"LLM 解码相关\",\"link\":\"07-decode\"},{\"text\":\"LLM Attention 系列\",\"link\":\"06-llm-attention\"},{\"text\":\"LLM 基础知识\",\"link\":\"05-llm-basic-info\"},{\"text\":\"LLM 架构相关\",\"link\":\"04-llm-architecture\"},{\"text\":\"Transformer细节\",\"link\":\"03-transformer-detail\"},{\"text\":\"语言模型重要组件\",\"link\":\"02-llm-components\"},{\"text\":\"语言模型定义及信息理论\",\"link\":\"01-lm-define-information-theory\"}]}]},\"/posts/llm/infra/\":{\"base\":\"/posts/llm/infra/\",\"items\":[{\"text\":\"🛠LLM-基建框架\",\"items\":[{\"text\":\"Verl 训练流程源代码阅读\",\"link\":\"08-verl-train-loop\"},{\"text\":\"Verl 有趣的功能\",\"link\":\"07-verl-core\"},{\"text\":\"Verl AgentLoop Rollout 相关\",\"link\":\"06-verl-code\"},{\"text\":\"Verl 常见参数配置和理解\",\"link\":\"05-verl-practice\"},{\"text\":\"Verl 早期概念型学习文章\",\"link\":\"04-verl\"},{\"text\":\"推理优化技术\",\"link\":\"03-inference-tech\"},{\"text\":\"分布式训练框架\",\"link\":\"02-speed-framework\"},{\"text\":\"分布式并行策略\",\"link\":\"01-parrallel\"}]}]},\"/posts/exps/env/\":{\"base\":\"/posts/exps/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"环境搭建的一些坑\",\"link\":\"01-blog-env\"}]}]},\"/posts/exps/mind/\":{\"base\":\"/posts/exps/mind/\",\"items\":[{\"text\":\"心得体会\",\"items\":[]}]}}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>
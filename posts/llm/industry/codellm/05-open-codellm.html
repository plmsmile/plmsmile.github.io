<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>CodeLLM 索引简记 | 📚 plmblog</title>
    <meta name="description" content="记录一些学习笔记。">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/assets/style.CuIOXX7t.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.BFE1LV5h.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.BH5f_aZi.js">
    <link rel="modulepreload" href="/assets/chunks/framework.CvbyeFFO.js">
    <link rel="modulepreload" href="/assets/posts_llm_industry_codellm_05-open-codellm.md.C6UU6qcZ.lean.js">
    <link rel="icon" href="/plm.png">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-cecb633e><!--[--><!--]--><!--[--><span tabindex="-1" data-v-c979f278></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-c979f278>Skip to content</a><!--]--><!----><header class="VPNav" data-v-cecb633e data-v-0ad68676><div class="VPNavBar" data-v-0ad68676 data-v-ce71e4ef><div class="wrapper" data-v-ce71e4ef><div class="container" data-v-ce71e4ef><div class="title" data-v-ce71e4ef><div class="VPNavBarTitle has-sidebar" data-v-ce71e4ef data-v-7e906684><a class="title" href="/" data-v-7e906684><!--[--><!--]--><!----><span data-v-7e906684>📚 plmblog</span><!--[--><!--]--></a></div></div><div class="content" data-v-ce71e4ef><div class="content-body" data-v-ce71e4ef><!--[--><!--]--><div class="VPNavBarSearch search" data-v-ce71e4ef><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-ce71e4ef data-v-e0cd9371><span id="main-nav-aria-label" class="visually-hidden" data-v-e0cd9371> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>首页</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>🐲LLM</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Basic</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/basic/01-lm-define-information-theory.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🦋基础知识</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/infra/01-parrallel.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🛠基建框架</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>强化学习</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/rl/theory/01-reinforce-learning.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🎓RL理论基础</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/rl/02-agent-tool.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚄Agent-RL</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>行业方向</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/industry/mainllm/01-kimi-series.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚀主流模型</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/industry/codellm/01-survey.html" data-v-dc987abe><!--[--><span data-v-dc987abe>💻代码模型</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Agent</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/basic.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🤖概念及应用</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>📙旧文章</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍓NLP</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/nlp.html" data-v-dc987abe><!--[--><span data-v-dc987abe>自然语言处理</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍑基础知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/dl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>深度学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/rl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>强化学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/ml.html" data-v-dc987abe><!--[--><span data-v-dc987abe>机器学习</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍎算法</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/algo/" data-v-dc987abe><!--[--><span data-v-dc987abe>算法题</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/bigdata/" data-v-dc987abe><!--[--><span data-v-dc987abe>大数据</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍒其他</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/env/" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/other/" data-v-dc987abe><!--[--><span data-v-dc987abe>其他</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>经验</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>环境</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/env/01-blog-env.html" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>心得</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/mind.html" data-v-dc987abe><!--[--><span data-v-dc987abe>心得体会</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/archive.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>归档</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/me.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>关于我</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-ce71e4ef data-v-b59ebfac><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-b59ebfac data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-ce71e4ef data-v-e0f2db57 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-ce71e4ef data-v-8897e953 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-ffaaba87><span class="vpi-more-horizontal icon" data-v-ffaaba87></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><!----><!--[--><!--[--><!----><div class="group" data-v-8897e953><div class="item appearance" data-v-8897e953><p class="label" data-v-8897e953>Appearance</p><div class="appearance-action" data-v-8897e953><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-8897e953 data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div></div></div><div class="group" data-v-8897e953><div class="item social-links" data-v-8897e953><div class="VPSocialLinks social-links-list" data-v-8897e953 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-ce71e4ef data-v-37e0f734><span class="container" data-v-37e0f734><span class="top" data-v-37e0f734></span><span class="middle" data-v-37e0f734></span><span class="bottom" data-v-37e0f734></span></span></button></div></div></div></div><div class="divider" data-v-ce71e4ef><div class="divider-line" data-v-ce71e4ef></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-cecb633e data-v-1b409c8b><div class="container" data-v-1b409c8b><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-1b409c8b><span class="vpi-align-left menu-icon" data-v-1b409c8b></span><span class="menu-text" data-v-1b409c8b>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-1b409c8b data-v-a203161a><button data-v-a203161a>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-cecb633e data-v-18f7b5ca><div class="curtain" data-v-18f7b5ca></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-18f7b5ca><span class="visually-hidden" id="sidebar-aria-label" data-v-18f7b5ca> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-7f5b9a39><section class="VPSidebarItem level-0 has-active" data-v-7f5b9a39 data-v-a4affe07><div class="item" role="button" tabindex="0" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><h2 class="text" data-v-a4affe07>💻代码模型</h2><!----></div><div class="items" data-v-a4affe07><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/07-code-fulltrain-reading.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 全训练 论文阅读</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/06-code-taskrl-reading.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code TaskRL 论文阅读</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/05-open-codellm.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>CodeLLM 索引简记</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/04-safety-code.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 安全相关</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/03-rl-task.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code RL 任务</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/02-eval-task-benchmark.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 任务Bench相关</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/01-survey.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code Survey</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/09-swe-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>SWE 系列</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/08-code-pretrain-summary.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 预训练相关</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-cecb633e data-v-53a9cb18><div class="VPDoc has-sidebar has-aside" data-v-53a9cb18 data-v-5a64a79a><!--[--><!--]--><div class="container" data-v-5a64a79a><div class="aside" data-v-5a64a79a><div class="aside-curtain" data-v-5a64a79a></div><div class="aside-container" data-v-5a64a79a><div class="aside-content" data-v-5a64a79a><div class="VPDocAside" data-v-5a64a79a data-v-f8ea3c28><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-f8ea3c28 data-v-b94d89ac><div class="content" data-v-b94d89ac><div class="outline-marker" data-v-b94d89ac></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-b94d89ac>当前页大纲</div><ul class="VPDocOutlineItem root" data-v-b94d89ac data-v-80b46526><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-f8ea3c28></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-5a64a79a><div class="content-container" data-v-5a64a79a><!--[--><!--[--><!--[--><article class="post-header" data-v-a99fd7c9><h1 class="title" data-v-a99fd7c9>CodeLLM 索引简记</h1><div class="stats-container" data-v-a99fd7c9><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 📅 发表于 <span class="stat-text" data-v-a99fd7c9>2025/12/18</span></div><div class="stat-item" data-v-a99fd7c9> 🔄 更新于 <span class="stat-text" data-v-a99fd7c9>2025/12/18</span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 👁️ <span class="stat-text" data-v-a99fd7c9>-- 次访问</span><span id="busuanzi_value_page_pv" style="display:none;" data-page="/posts/llm/industry/codellm/05-open-codellm.html" data-v-a99fd7c9></span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 📝 <span class="stat-text" data-v-a99fd7c9>0 字</span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> ⏳ <span class="stat-text" data-v-a99fd7c9>0 分钟</span></div><div class="stat-divider" data-v-a99fd7c9></div></div><div class="tag-group" data-v-a99fd7c9><!--[--><div class="category-item" data-v-a99fd7c9>code-llm</div><!--]--><!--[--><div class="tag-item" data-v-a99fd7c9> #code-llm</div><!--]--></div></article><!--]--><!--]--><!--]--><main class="main" data-v-5a64a79a><div style="position:relative;" class="vp-doc _posts_llm_industry_codellm_05-open-codellm" data-v-5a64a79a><div><h2 id="概览内容" tabindex="-1">概览内容 <a class="header-anchor" href="#概览内容" aria-label="Permalink to &quot;概览内容&quot;">​</a></h2><h3 id="开源codellm-发展阶段" tabindex="-1">开源CodeLLM 发展阶段 <a class="header-anchor" href="#开源codellm-发展阶段" aria-label="Permalink to &quot;开源CodeLLM 发展阶段&quot;">​</a></h3><div class="custom-block info"><div class="custom-block-title">发展的几个阶段</div><p><strong>阶段1：Encoder 模型</strong></p><ul><li>聚焦在代码<code>理解任务</code>，把代码变成向量，做检索任务。</li><li>主要工作：CodeBert,ERNIE-Code等。</li></ul><p><strong>阶段2：生成式 模型</strong></p><ul><li>从读到写，聚焦在<code>理解和生成代码</code>。</li><li>主要工作：CodeT5, CodeGPT等。</li></ul><p><strong>阶段3：代码 LLM</strong></p><ul><li><p>大模型，能<code>写复杂代码</code>、<code>多轮对话</code>式编程、具有<code>指令遵循能力</code>等。</p></li><li><p>代表：StarCoder, CodeLlama, DeepSeek-Coder, CodeQwen等。</p></li></ul><p><strong>阶段4：Agentic 模型</strong></p><ul><li>通过<code>MoE来扩展参数</code> + 提升<code>agentic能力</code>(<code>工具使用</code>、<code>多步推理</code>等)。</li><li>代表：DeepSeek-Coder-V2、DeepCoder、DeepSWE等。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251209211313.jpg" style="display:block;margin:auto;" width="100%"><h2 id="rlvr-后训练相关" tabindex="-1">RLVR 后训练相关 <a class="header-anchor" href="#rlvr-后训练相关" aria-label="Permalink to &quot;RLVR 后训练相关&quot;">​</a></h2><div class="custom-block danger"><div class="custom-block-title">RLVR 开源CodeLLM</div><p>(2503) ACECoder</p><ul><li>REINCORCE++ 算法，偏好和二元两种奖励。</li></ul><p>(2503) Open-R1</p><ul><li>RoPE：300k 上下文</li></ul><p>(2503) Skywork-OR1</p><ul><li>代码和数学混合训练，多阶段RL，长度从16k -&gt; 32k</li></ul><p>(2503) Code-R1</p><ul><li>12k小数据做微调。</li></ul><p>(2503) DeepCoder</p><ul><li>去掉了KL和熵约束。</li></ul><p>(2503) Seed-Coder</p><ul><li>2阶段：DPO构建指令Instruct模型，PPO创建Reason模型</li></ul><p>(2503) AceReason</p><ul><li>2阶段课程学习：<code>先数学</code>，<code>再代码</code>。</li></ul><p>(2503) Klear-Reasoner</p><ul><li>GPPO算法，保留更多有用的梯度信息，提高梯度利用率，强制模型保持好奇心，缓解了熵坍塌。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251216162559.jpg" style="display:block;margin:auto;" width="70%"><h4 id="_2508-klear-reasoner" tabindex="-1">(2508) Klear-Reasoner <a class="header-anchor" href="#_2508-klear-reasoner" aria-label="Permalink to &quot;(2508) Klear-Reasoner&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">提示</div><p><strong>参考链接</strong></p><ul><li><a href="https://arxiv.org/abs/2508.07629" target="_blank" rel="noreferrer">paper</a>, <a href="https://huggingface.co/Kwai-Klear/Klear-Reasoner-8B" target="_blank" rel="noreferrer">Klear-Reasoner-8B</a></li></ul><p><strong>基模</strong></p><p><strong>关键技术</strong></p><p><strong>训练数据</strong></p><p><strong>关键结果</strong></p></div><h4 id="_2505-code-r1" tabindex="-1">(2505) Code-R1 <a class="header-anchor" href="#_2505-code-r1" aria-label="Permalink to &quot;(2505) Code-R1&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">提示</div><p><strong>参考链接</strong></p><ul><li><a href="https://arxiv.org/abs/2505.21668" target="_blank" rel="noreferrer">paper</a>, <a href="https://github.com/ganler/code-r1" target="_blank" rel="noreferrer">coder-1</a></li></ul><p><strong>基模</strong></p><p><strong>关键技术</strong></p><p><strong>训练数据</strong></p><p><strong>关键结果</strong></p></div><h4 id="_2505-seed-coder" tabindex="-1">(2505) Seed-Coder <a class="header-anchor" href="#_2505-seed-coder" aria-label="Permalink to &quot;(2505) Seed-Coder&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">提示</div><p><strong>参考链接</strong></p><ul><li><a href="https://github.com/ByteDance-Seed/Seed-Coder" target="_blank" rel="noreferrer">Seed-Coder</a></li></ul><p><strong>基模</strong></p><p><strong>关键技术</strong></p><p><strong>训练数据</strong></p><p><strong>关键结果</strong></p></div><h4 id="_2505-acereason-nemotron" tabindex="-1">(2505) AceReason-Nemotron <a class="header-anchor" href="#_2505-acereason-nemotron" aria-label="Permalink to &quot;(2505) AceReason-Nemotron&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">提示</div><p><strong>参考链接</strong></p><ul><li><a href="https://arxiv.org/abs/2505.16400" target="_blank" rel="noreferrer">AceReason-Nemotron paper</a>, <a href="https://huggingface.co/collections/nvidia/acereason" target="_blank" rel="noreferrer">hf collection</a></li></ul><p><strong>基模</strong></p><p><strong>关键技术</strong></p><p><strong>训练数据</strong></p><p><strong>关键结果</strong></p></div><h4 id="_2505-skywork-or1" tabindex="-1">(2505) Skywork-OR1 <a class="header-anchor" href="#_2505-skywork-or1" aria-label="Permalink to &quot;(2505) Skywork-OR1&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">提示</div><p><strong>参考链接</strong></p><ul><li><a href="https://arxiv.org/abs/2505.22312" target="_blank" rel="noreferrer">tech report</a>, <a href="https://huggingface.co/collections/Skywork/skywork-or1" target="_blank" rel="noreferrer">hfmodel</a></li></ul><p><strong>基模</strong></p><p><strong>关键技术</strong></p><p><strong>训练数据</strong></p><p><strong>关键结果</strong></p></div><h4 id="_2503-deepcoder" tabindex="-1">(2503) DeepCoder <a class="header-anchor" href="#_2503-deepcoder" aria-label="Permalink to &quot;(2503) DeepCoder&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">DeepCoder (2503)</div><p><strong>参考链接</strong></p><ul><li><a href="https://pretty-radio-b75.notion.site/DeepCoder-A-Fully-Open-Source-14B-Coder-at-O3-mini-Level-1cf81902c14680b3bee5eb349a512a51" target="_blank" rel="noreferrer">DeepCoder-14B-Preview</a>, <a href="https://www.alphaxiv.org/abs/2505.05315v2" target="_blank" rel="noreferrer">Scalable CoT via Elastic Reasoning</a>, <a href="https://huggingface.co/datasets/agentica-org/DeepCoder-Preview-Dataset/tree/main" target="_blank" rel="noreferrer">agentica-org/DeepCoder-Preview-Dataset</a></li></ul><p><strong>关键技术</strong></p><ul><li>基于DS-R1-14B，继续做RLVR训练，目标repo-level代码编辑。</li><li>训练32k，测试64k。</li></ul><p><strong>训练数据</strong></p><ul><li>TACO-verified、LiveCodeBench(23-24)</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>完全开源</li></ul></div><h4 id="_2503-olympiccoder-open-r1" tabindex="-1">(2503) OlympicCoder (Open-R1) <a class="header-anchor" href="#_2503-olympiccoder-open-r1" aria-label="Permalink to &quot;(2503) OlympicCoder (Open-R1)&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">提示</div><p><strong>参考链接</strong></p><ul><li><a href="https://huggingface.co/blog/open-r1/update-3" target="_blank" rel="noreferrer">blog</a>, <a href="https://huggingface.co/open-r1/OlympicCoder-32B" target="_blank" rel="noreferrer">open-r1/OlympicCoder-32B</a></li></ul><p><strong>基模</strong></p><p><strong>关键技术</strong></p><p><strong>训练数据</strong></p><p><strong>关键结果</strong></p></div><h4 id="_2502-acecoder" tabindex="-1">(2502) AceCoder <a class="header-anchor" href="#_2502-acecoder" aria-label="Permalink to &quot;(2502) AceCoder&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">提示</div><p><strong>参考链接</strong></p><ul><li><a href="https://arxiv.org/pdf/2502.01718" target="_blank" rel="noreferrer">AceCoder</a>, <a href="https://tiger-ai-lab.github.io/AceCoder/" target="_blank" rel="noreferrer">Blog</a></li></ul><p><strong>基模</strong></p><ul><li></li></ul><p><strong>关键技术</strong></p><p><strong>训练数据</strong></p><p><strong>关键结果</strong></p></div><h2 id="闭源code-llm" tabindex="-1">闭源Code LLM <a class="header-anchor" href="#闭源code-llm" aria-label="Permalink to &quot;闭源Code LLM&quot;">​</a></h2><div class="custom-block tip"><div class="custom-block-title">闭源LLM</div><ul><li><a href="https://plmsmile.github.io/posts/llm/industry/mainllm/07-openai-series.html" target="_blank" rel="noreferrer">GPT 系列</a></li><li><a href="https://plmsmile.github.io/posts/llm/industry/mainllm/08-gemini-series.html" target="_blank" rel="noreferrer">Gemini 系列</a></li><li><a href="https://plmsmile.github.io/posts/llm/industry/mainllm/09-claude-series.html" target="_blank" rel="noreferrer">Claude 系列</a></li><li>Grok系列</li></ul></div><h2 id="开源code-llm" tabindex="-1">开源Code LLM <a class="header-anchor" href="#开源code-llm" aria-label="Permalink to &quot;开源Code LLM&quot;">​</a></h2><h3 id="阶段4-codellm-列表" tabindex="-1">阶段4-CodeLLM 列表 <a class="header-anchor" href="#阶段4-codellm-列表" aria-label="Permalink to &quot;阶段4-CodeLLM 列表&quot;">​</a></h3><h4 id="_2406-deepseek-coder-v1-v2" tabindex="-1">(2406) DeepSeek-Coder V1-V2 <a class="header-anchor" href="#_2406-deepseek-coder-v1-v2" aria-label="Permalink to &quot;(2406) DeepSeek-Coder V1-V2&quot;">​</a></h4><div class="custom-block important"><div class="custom-block-title">DeepSeek-Coder-V2 (2406)</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2406.11931" target="_blank" rel="noreferrer">DeepSeek-Coder-V2</a></li></ul><p><strong>关键技术</strong></p><ul><li>从DeepSeek-V2继续预训练，对代码和数学继续强化。</li><li>MoE 架构，两个版本：236A21B，16A2.5B。</li><li>YARN：上下文从16k扩展至128K。</li></ul><p><strong>训练数据</strong></p><ul><li>混合数据：代码、数学、文本。数学对编程逻辑重要。6T token。</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>效果和高效。</li></ul></div><div class="custom-block tip"><div class="custom-block-title">DeepSeek-Coder (2401)</div><p><strong>关键技术</strong></p><ul><li><p><code>从0开始预训练</code>，产出1.3-33B 模型</p></li><li><p><code>仓库级预训练</code>：</p><ul><li>模拟跨文件的依赖关系，提升对<code>repo-level</code>的理解和跨文件补全能力。</li></ul></li><li><p><code>中间填充目标</code>(Fill in the Midddle) + <code>长上下文</code>(16k)：</p><ul><li>增强<code>代码补全</code>和<code>长距离代码推理</code>能力。</li></ul></li></ul><p><strong>训练数据</strong></p><ul><li><code>多种编程语言</code>语料库，<code>无私有数据</code>。</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>在HumanEval和MBPP上超过 GPT-3.5</li><li>指令微调版本：<code>多轮</code>问题解决能力更好</li></ul></div><h4 id="_2510-minimax-m1-m2" tabindex="-1">(2510) MiniMax M1/M2 <a class="header-anchor" href="#_2510-minimax-m1-m2" aria-label="Permalink to &quot;(2510) MiniMax M1/M2&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">MiniMax M1/M2 (2506,2510)</div><p><strong>参考链接</strong></p><ul><li><a href="https://plmsmile.github.io/posts/llm/industry/mainllm/04-minimax-series.html#_2506-minimax-m1-scaling-test-time-compute-efficiently-with-lightning-attention" target="_blank" rel="noreferrer">M1笔记</a>， <a href="https://plmsmile.github.io/posts/llm/industry/mainllm/04-minimax-series.html#_2506-minimax-m1-scaling-test-time-compute-efficiently-with-lightning-attention" target="_blank" rel="noreferrer">M2笔记</a></li></ul><p><strong>关键技术</strong></p><ul><li>M1：线性注意力，</li><li>M2：softmax注意力。参数230B，激活10B</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p></div><h4 id="_24-25-deepseek-v3" tabindex="-1">(24,25) DeepSeek V3 <a class="header-anchor" href="#_24-25-deepseek-v3" aria-label="Permalink to &quot;(24,25) DeepSeek V3&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">DeepSeek V3 (24,25)</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2412.19437" target="_blank" rel="noreferrer">DeepSeek-V3 技术报告</a></li></ul><p><strong>关键技术</strong></p><ul><li>整体上：agent能力，混合思考模式，671B激活37B，128k上下文。</li><li>DeepSeek-V3 <ul><li>MLA+多token预测头，14.8T 预训练，无辅助loss做MoE 负载均衡</li><li>SFT + RL 微调</li></ul></li><li>DeepSeek-V3.1 <ul><li>PostTrain：840B语料，上下文由32K扩展至128k，整合DeepThink思维了模式。</li><li>增强多步工具+code-agent能力，超过v3和r1</li></ul></li><li>DeepSeek-V3.2 <ul><li>基于V3.1-Terminus，使用DSA稀疏注意力，推理成本降低50%，质量和v3.1相当</li></ul></li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p></div><h4 id="_2510-kat-dev" tabindex="-1">(2510) KAT-Dev <a class="header-anchor" href="#_2510-kat-dev" aria-label="Permalink to &quot;(2510) KAT-Dev&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">KAT-Dev (2510, 快手)</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2510.18779" target="_blank" rel="noreferrer">KAT-Coder 技术报告</a></li></ul><p><strong>关键技术</strong></p><ul><li>基于Qwen3底座。</li><li>训练pipeline <ul><li>Mid-Training：针对工具使用+指令遵循</li><li>SFT：</li><li>RL：代码任务</li><li>大规模AgentRL：</li></ul></li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>32B SWE-verified 62.4%</li></ul></div><div class="custom-block note"><div class="custom-block-title">Kimi-K2-Instruct</div><p><strong>参考链接</strong></p><ul><li><a href="https://huggingface.co/moonshotai/Kimi-K2-Instruct" target="_blank" rel="noreferrer">moonshotai/Kimi-K2-Instruct</a>, <a href="https://plmsmile.github.io/posts/llm/industry/mainllm/01-kimi-series.html#_2507-kimi-k2-open-agentic-intelligence" target="_blank" rel="noreferrer">Kimi-K2 笔记</a></li></ul><p><strong>关键技术</strong></p><ul><li>超稀疏MoE：总参数1T，激活32B</li><li>预训练：MuonClip：解决梯度爆炸不收敛的问题。</li><li>SFT：Agent数据合成技术</li><li>RL：可评估和不可评估任务。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>原生工具调用、128k上下文。权重开源。</li></ul></div><img src="http://plm-images.oss-cn-hongkong.aliyuncs.com/codellm/code-survey/20251210230435.jpg" style="display:block;margin:auto;" width="70%"><h4 id="_2508-glm-4-5-4-6" tabindex="-1">(2508) GLM 4.5/4.6 <a class="header-anchor" href="#_2508-glm-4-5-4-6" aria-label="Permalink to &quot;(2508) GLM 4.5/4.6&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">GLM4.5/4.6 (2508)</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2508.06471" target="_blank" rel="noreferrer">GLM4.5 paper</a>,</li></ul><p><strong>关键技术</strong></p><ul><li>架构：A32B，混合推理模式，GQA+QK-Norm+MoE 多token预测头</li><li>Mid-Training <code>关键数据上采样</code>：<code>仓库级代码</code> + <code>Agent轨迹</code> 数据</li><li>上下文扩展：4k -&gt; 32k -&gt; 128k -&gt; 200k(GLM4.6)</li><li>后训练：监督学习 + 自蒸馏。 <ul><li>RL技巧：难度课程、长输出RL、代码加权loss (给代码更高权重)</li></ul></li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>在TAU-Bench、AIME、SWE-verified、BrowseComp等有较好效果。</li><li>GLM4.6 进一步提升代码、工具使用、agent能力等。</li></ul></div><h4 id="_2507-qwen3-coder" tabindex="-1">(2507) Qwen3-Coder <a class="header-anchor" href="#_2507-qwen3-coder" aria-label="Permalink to &quot;(2507) Qwen3-Coder&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Qwen3-Coder (2507)</div><p><strong>参考链接</strong></p><ul><li><a href="https://qwenlm.github.io/blog/qwen3-coder/" target="_blank" rel="noreferrer">qwen3-coder 博客</a></li></ul><p><strong>关键技术</strong></p><ul><li>MoE, <code>480A35B</code>，上下文<code>256k -&gt; 1M</code>, YaRN。</li><li><code>预训练</code> + <code>所有代码可执行</code>的Code RL训练。</li></ul><p><strong>训练数据</strong></p><ul><li>预训练 <ul><li>通用、数学 + 代码， 7.5T tokens (70%)</li><li>合成数据：利用Qwen2.5-Coder对低质数据做清洗和重写，提升质量。</li></ul></li><li>RL <ul><li>不仅是竞赛代码，对所有代码做执行驱动的RL。</li></ul></li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>Agentic Coding、Agentic Browser-Use 和 Agentic Tool-Use 开源SOTA，可与Claude Sonnet4 媲美</li></ul></div><h4 id="_2505-devstral" tabindex="-1">(2505) Devstral <a class="header-anchor" href="#_2505-devstral" aria-label="Permalink to &quot;(2505) Devstral&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">devstral (2505, mistral)</div><p><strong>参考链接</strong></p><ul><li><a href="https://mistral.ai/news/devstral" target="_blank" rel="noreferrer">devstral</a>, <a href="https://huggingface.co/mistralai/Devstral-Small-2505" target="_blank" rel="noreferrer">mistralai/Devstral-Small-2505</a></li></ul><p><strong>关键技术</strong></p><ul><li>目标<code>repo-scale SWE</code>，多文件推理、长上下文编辑、可验证。</li><li>Devstral-Small (24B, 128k上下文)，Devstral-Medium (API)</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>完全开源。</li></ul></div><h4 id="_2508-deepswe" tabindex="-1">(2508) DeepSWE <a class="header-anchor" href="#_2508-deepswe" aria-label="Permalink to &quot;(2508) DeepSWE&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">DeepSWE (2508)</div><p><strong>参考链接</strong></p><ul><li><a href="https://huggingface.co/agentica-org/DeepSWE-Preview" target="_blank" rel="noreferrer">agentica-org/DeepSWE-Preview</a>, <a href="https://pretty-radio-b75.notion.site/DeepSWE-Training-a-Fully-Open-sourced-State-of-the-Art-Coding-Agent-by-Scaling-RL-22281902c1468193aabbe9a8c59bbe33" target="_blank" rel="noreferrer">tech blog</a>, <a href="https://www.alphaxiv.org/abs/2508.03501" target="_blank" rel="noreferrer">SWE-RL-paper</a></li></ul><p><strong>关键技术</strong></p><ul><li>基模：Qwen3-32B + 思考模式</li><li><code>纯RL训练</code>，目标repo-level，<code>可执行</code>和 <code>不执行</code>两种验证器。</li><li>R2E-Gym环境，<a href="https://pretty-radio-b75.notion.site/rLLM-A-Framework-for-Post-Training-Language-Agents-21b81902c146819db63cd98a54ba5f31" target="_blank" rel="noreferrer">rLLM 训练框架</a></li></ul><p><strong>训练数据</strong></p><ul><li>R2E-Gym的子集，4.5k。</li></ul><p><strong>数据清洗</strong></p><ul><li>过滤了和bench相关的数据</li></ul><p><strong>关键结果</strong></p><ul><li>SWE-verified：59%</li></ul></div><h4 id="_2503-deepcoder-1" tabindex="-1">(2503) DeepCoder <a class="header-anchor" href="#_2503-deepcoder-1" aria-label="Permalink to &quot;(2503) DeepCoder&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">DeepCoder (2503)</div><p><strong>参考链接</strong></p><ul><li><a href="https://pretty-radio-b75.notion.site/DeepCoder-A-Fully-Open-Source-14B-Coder-at-O3-mini-Level-1cf81902c14680b3bee5eb349a512a51" target="_blank" rel="noreferrer">DeepCoder-14B-Preview</a>, <a href="https://www.alphaxiv.org/abs/2505.05315v2" target="_blank" rel="noreferrer">Scalable CoT via Elastic Reasoning</a>, <a href="https://huggingface.co/datasets/agentica-org/DeepCoder-Preview-Dataset/tree/main" target="_blank" rel="noreferrer">agentica-org/DeepCoder-Preview-Dataset</a></li></ul><p><strong>关键技术</strong></p><ul><li>基于DS-R1-14B，继续做RLVR训练，目标repo-level代码编辑。</li><li>训练32k，测试64k。</li></ul><p><strong>训练数据</strong></p><ul><li>TACO-verified、LiveCodeBench(23-24)</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>完全开源</li></ul></div><h4 id="_2506-skywork-swe" tabindex="-1">(2506) Skywork-SWE <a class="header-anchor" href="#_2506-skywork-swe" aria-label="Permalink to &quot;(2506) Skywork-SWE&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Skywork-SWE (2506)</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2506.19290" target="_blank" rel="noreferrer">Skywork-SWE-32B</a></li></ul><p><strong>关键技术</strong></p><ul><li><code>可执行的数据清洗pipeline</code><ul><li>收集<code>[PR, Isssue]</code>数据，每个issue配一个docker容器</li><li>让agent去修bug，<code>仅保留能通过</code>测试用例的轨迹数据。</li></ul></li><li>高质量可执行SWE 数据 Scale &gt; 模型尺寸 scale <ul><li>效果和数量，呈log对数增长</li></ul></li><li>在openhands框架，使用轨迹数据，做微调。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>SWE-verifed 有较好结果</li></ul></div><h4 id="_2503-ling-coder-lite" tabindex="-1">(2503) Ling-Coder-Lite <a class="header-anchor" href="#_2503-ling-coder-lite" aria-label="Permalink to &quot;(2503) Ling-Coder-Lite&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Ling-Coder-Lite (2503)</div><p><strong>参考链接</strong></p><ul><li><a href="https://huggingface.co/inclusionAI/Ling-Coder-lite" target="_blank" rel="noreferrer">inclusionAI/Ling-Coder-lite</a>, <a href="https://www.alphaxiv.org/abs/2503.17793" target="_blank" rel="noreferrer">paper</a></li></ul><p><strong>关键技术</strong></p><ul><li>MoE，top6 路由，改进的NormHead。</li><li><code>共享/常驻专家</code>：shared+routed expertes，DeepSeekV2首创设计。</li><li>训练策略：继续预训练、指令优化(<code>SFT</code> + <code>DPO</code>)</li></ul><p><strong>训练数据</strong></p><ul><li>指令优化数据：高质量、<code>可执行</code>、<code>仓库结构数据</code>。</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>HumanEval, MBPP, LiveCodeBench, BigCodeBench等</li></ul></div><h3 id="阶段3-早期工作" tabindex="-1">阶段3-早期工作 <a class="header-anchor" href="#阶段3-早期工作" aria-label="Permalink to &quot;阶段3-早期工作&quot;">​</a></h3><h4 id="_2411-opencoder" tabindex="-1">(2411) OpenCoder <a class="header-anchor" href="#_2411-opencoder" aria-label="Permalink to &quot;(2411) OpenCoder&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">OpenCoder (2411)</div><p><strong>参考链接</strong></p><ul><li><a href="https://aclanthology.org/2025.acl-long.1591/" target="_blank" rel="noreferrer">paper</a>, <a href="https://arxiv.org/pdf/2411.04905" target="_blank" rel="noreferrer">paper 2411</a>, <a href="https://opencoder-llm.github.io/" target="_blank" rel="noreferrer">OpenCoder</a></li></ul><p><strong>关键技术</strong></p><ul><li>完全开源：权重、预测、<code>RefineCode数据</code>、<code>训练流程</code></li><li>1.5B/8B，LLama-Style (RoPE, SwiGLU)</li><li>两阶段指令微调：<code>通用SFT</code>、<code>code SFT</code></li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>8B HumanEval/MBPP效果不错，debug新年超过StarCode2-15B和CodeLLama-7B</li></ul></div><h4 id="_2409-qwen1-5-2-5-coder" tabindex="-1">(2409) Qwen1.5&amp;2.5 Coder <a class="header-anchor" href="#_2409-qwen1-5-2-5-coder" aria-label="Permalink to &quot;(2409) Qwen1.5&amp;2.5 Coder&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">Qwen1.5&amp;2.5 Coder(2409)</div><p><strong>参考链接</strong></p><ul><li><a href="https://huggingface.co/Qwen/CodeQwen1.5-7B" target="_blank" rel="noreferrer">Qwen/CodeQwen1.5-7B</a>, <a href="https://arxiv.org/abs/2409.12186" target="_blank" rel="noreferrer">Qwen2.5-Coder 技术报告</a></li></ul><p><strong>CodeQwen1.5 (7B)</strong></p><ul><li><strong>关键技术</strong>：64k上下文，多种语言训练。GQA提升推理效率。</li><li><strong>训练数据</strong>：代码数据。</li><li><strong>数据清洗</strong></li><li><strong>关键结果</strong>：较好 bug, SQL, Debug能力。</li></ul><p><strong>Qwen2.5-Coder (0.5B-32B)</strong></p><ul><li><strong>关键技术</strong>： <ul><li>128k上下文(<a href="https://plmsmile.github.io/posts/llm/basic/08-llm-position-embedding.html#yarn" target="_blank" rel="noreferrer">Yarn技术</a>)</li><li>指令微调：<code>多语言合成数据</code> + <code>DPO优化 执行反馈</code>，<a href="https://plmsmile.github.io/posts/llm/rl/theory/09-policy-trpo-ppo.html#dpo" target="_blank" rel="noreferrer">DPO笔记</a></li></ul></li><li><strong>训练数据</strong>：混合代码、数学和文本。</li><li><strong>数据清洗</strong></li><li><strong>关键结果</strong><ul><li>在MultiPL-E, RepoEval, CrossCodeEval上效果不错</li><li><code>不依赖特定提示词格式</code>，泛化性不错。</li></ul></li></ul></div><h4 id="_2403-yi-coder-9b" tabindex="-1">(2403) Yi-Coder-9B <a class="header-anchor" href="#_2403-yi-coder-9b" aria-label="Permalink to &quot;(2403) Yi-Coder-9B&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">Yi-Coder (24)</div><p><strong>参考链接</strong></p><ul><li><a href="https://github.com/01-ai/Yi-Coder" target="_blank" rel="noreferrer">Yi-Coder</a>, <a href="https://huggingface.co/01-ai/Yi-Coder-9B-Chat" target="_blank" rel="noreferrer">01-ai/Yi-Coder-9B-Chat</a></li></ul><p><strong>关键技术</strong></p><ul><li>128k 上下文、52种语言。</li><li>1.5B、9B。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>HumanEval, MBPP, LiveCodeBench 和大尺寸模型相当。</li></ul></div><h4 id="_2409-codestral-22b-mistral-ai" tabindex="-1">(2409) Codestral-22B (Mistral AI) <a class="header-anchor" href="#_2409-codestral-22b-mistral-ai" aria-label="Permalink to &quot;(2409) Codestral-22B (Mistral AI)&quot;">​</a></h4><div class="custom-block important"><div class="custom-block-title">Codestral (2409, Mistral AI)</div><p><strong>参考链接</strong></p><ul><li><a href="https://huggingface.co/mistralai/Codestral-22B-v0.1" target="_blank" rel="noreferrer">mistralai/Codestral-22B-v0.1</a></li></ul><p><strong>关键技术</strong></p><ul><li>多种语言，指令跟随。</li><li>32K上下文，仓库级推理，FIM填充能力。</li><li>22B模型。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>在RepoBench和Python相关评估上，效果不错。</li></ul></div><h4 id="_2405-granite-code-ibm" tabindex="-1">(2405) Granite-Code (IBM) <a class="header-anchor" href="#_2405-granite-code-ibm" aria-label="Permalink to &quot;(2405) Granite-Code (IBM)&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">Granite-Code(2405, IBM)</div><p><strong>参考链接</strong></p><ul><li><a href="https://doi.org/10.48550/arXiv.2405.04324" target="_blank" rel="noreferrer">Granite Code Models</a></li></ul><p><strong>关键技术</strong></p><ul><li>两阶段训练：<code>code预训练</code> + <code>混合code文本增强训练</code>。</li><li>目标：FIM (PSM/SPM)</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p></div><h4 id="_2406-codegemma" tabindex="-1">(2406) CodeGemma <a class="header-anchor" href="#_2406-codegemma" aria-label="Permalink to &quot;(2406) CodeGemma&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">CodeGemma (2406)</div><p><strong>参考链接</strong></p><ul><li><a href="https://arxiv.org/abs/2406.11409" target="_blank" rel="noreferrer">CodeGemma</a> 2B, 7B</li></ul><p><strong>关键技术</strong></p><ul><li><code>代码数据</code> <code>预训练</code>和 <code>指令微调</code>。</li><li>训练目标：<code>FIM</code> 且 <code>比例更高</code>，支持2种模式 <ul><li>前缀-后缀-中间(PSM)：先给P(prefix)，再给S(suffix)，猜中间M</li><li>后缀-前缀-中间(SPM)：先给S，再给P，猜中间M。</li></ul></li><li>2种尺寸：2B IDE场景-更快；7B chat设计、推理逻辑更强。</li></ul><p><strong>训练数据</strong></p><ul><li>代码数据</li></ul><p><strong>数据清洗</strong></p><ul><li>去重、去污染(去除测试数据)</li><li><code>Multi-file packing</code>：依赖<code>图</code>和<code>单元测试</code>的多文件打包策略。</li></ul><p><strong>关键结果</strong></p></div><h4 id="_2403-codesheel" tabindex="-1">(2403) CodeSheel <a class="header-anchor" href="#_2403-codesheel" aria-label="Permalink to &quot;(2403) CodeSheel&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">CodeShell (2403)</div><p><strong>参考链接</strong></p><ul><li><a href="https://arxiv.org/abs/2403.15747" target="_blank" rel="noreferrer">tech report</a></li></ul><p><strong>关键技术</strong></p><ul><li>GPT2(7B) 扩展：8k上下文、GQA、RoPE。</li><li>数据清洗比简单scaling有效。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><ul><li>去重、困惑度筛选、结构规则过滤、模型打分。</li></ul><p><strong>关键结果</strong></p><ul><li>优于同类7B模型，在MultiPL-E和代码补全bench上不错。</li></ul></div><h4 id="_23-stable-code-3b" tabindex="-1">(23) stable-code-3B <a class="header-anchor" href="#_23-stable-code-3b" aria-label="Permalink to &quot;(23) stable-code-3B&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">StableCode (23)</div><p><strong>链接</strong></p><ul><li><a href="https://huggingface.co/stabilityai/stable-code-3b" target="_blank" rel="noreferrer">stabilityai/stable-code-3b</a></li></ul><p><strong>关键技术</strong></p><ul><li>3B，代码生成和理解，代码补全和text2code。</li><li>长上下文：16k；<code>多文件推理</code>。</li></ul><p><strong>训练数据</strong></p><ul><li>Github corpora</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>HumanEval/MBPP 效果不错</li></ul></div><h4 id="_2401-deepseek-coder见下文" tabindex="-1">(2401) DeepSeek-Coder见下文 <a class="header-anchor" href="#_2401-deepseek-coder见下文" aria-label="Permalink to &quot;(2401) DeepSeek-Coder见下文&quot;">​</a></h4><h4 id="_24-mftcoder" tabindex="-1">(24) MFTCoder <a class="header-anchor" href="#_24-mftcoder" aria-label="Permalink to &quot;(24) MFTCoder&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">MFTCoder (2024)</div><p><strong>关键技术</strong></p><ul><li>多任务微调：代码补全、text2code、代码注释、代码翻译、单元测试生成等。</li><li>多任务平衡方法：数据平衡、token-weighted loss、focal-style强调。</li><li>效率优化技术：动态padding、packed SFT、PEFT等。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>相比于单SFT和简单混合SFT，MFTCoder效果更好，具有泛化能力。</li></ul></div><h4 id="_2308-codellama" tabindex="-1">(2308) CodeLLaMA <a class="header-anchor" href="#_2308-codellama" aria-label="Permalink to &quot;(2308) CodeLLaMA&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">Code LLaMA (2308)</div><p><strong>关键技术</strong></p><ul><li>基于LLaMA2开发，强调<code>长上下文</code>、<code>中间填充</code>、<code>代码指令跟随</code>等。 <ul><li>上下文：<a href="https://plmsmile.github.io/posts/llm/basic/08-llm-position-embedding.html#%E6%97%8B%E8%BD%AC%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81" target="_blank" rel="noreferrer">RoPE</a> base由<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.05ex;" xmlns="http://www.w3.org/2000/svg" width="3.25ex" height="2.022ex" role="img" focusable="false" viewBox="0 -871.8 1436.6 893.8" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1033,393.1) scale(0.707)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" style="stroke-width:3;"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>10</mn><mn>4</mn></msup></math></mjx-assistive-mml></mjx-container>放大至<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.05ex;" xmlns="http://www.w3.org/2000/svg" width="3.25ex" height="2.005ex" role="img" focusable="false" viewBox="0 -864 1436.6 886" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1033,393.1) scale(0.707)"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" style="stroke-width:3;"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mn>10</mn><mn>6</mn></msup></math></mjx-assistive-mml></mjx-container></li></ul></li></ul><p><strong>训练数据</strong></p><ul><li>初始化：由LLaMA2权重继续预训练。</li><li>语料库：<code>Code-heavy代码语料库</code></li><li>特定数据：Python和Instruct版本使用<code>特定数据集</code>做微调， 强调<code>特定语言</code>和<code>对齐能力</code>。</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li><code>长上下文</code>对<code>repo-level</code>任务有好处。</li><li><code>特定语言数据(python)</code>做微调对<code>语言任务有好处</code>。</li><li>经过<code>安全微调的指令模型</code>降低了毒性。</li></ul></div><h4 id="_2305-codegen2" tabindex="-1">(2305) CodeGen2 <a class="header-anchor" href="#_2305-codegen2" aria-label="Permalink to &quot;(2305) CodeGen2&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">CodeGen2 (2305)</div><p><strong>关键技术</strong></p><ul><li>完整的训练配方：架构选择、采样模式、数据混合等。 <ul><li>架构：Casual Decoder就好了。</li></ul></li><li>混合训练目标：<code>NTP</code>(写下文，50% )；<code>Span Corruption</code>(补全中间,Infil Train, 填空题, 50%)</li><li>多轮预训练</li></ul><p><strong>训练数据</strong></p><ul><li>NL + PL (文本+代码)。</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>Infil 填空训练，会导致代码生成能力下降(从头写到尾的能力)。</li></ul></div><h4 id="_23-starcoder-1-2" tabindex="-1">(23) StarCoder 1-2 <a class="header-anchor" href="#_23-starcoder-1-2" aria-label="Permalink to &quot;(23) StarCoder 1-2&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">StarCoder 1-2 (2023)</div><p><strong>StarCoder1</strong></p><ul><li><strong>关键技术</strong>：<code>长上下文</code> + 中间填充(FIM)训练</li><li><strong>训练数据</strong><ul><li>StarCoderBase：<code>TheStack </code>(宽松许可代码)</li><li>StarCoder：<code>Python数据定向微调</code></li></ul></li><li><strong>数据清洗</strong><ul><li>近似去重、benchmark数据去除、个人隐私去除等。</li></ul></li><li><strong>关键结果</strong><ul><li>benchmark效果好，IDE demo + OpenRAIL_M 许可证。</li></ul></li></ul><p><strong>StarCoder2</strong></p><ul><li><strong>关键技术</strong><ul><li>2阶段训练：<code>先训4k</code> 学基础语法；<code>再训16k</code>，处理长代码，<code>仓库级上下文</code>。</li><li>FIM 中间填充策略。</li></ul></li><li><strong>训练数据</strong><ul><li>TheStack V2：<code>多种语言</code> <code>issue/PR</code>、docs、<code>数学和逻辑</code>数据。</li></ul></li><li><strong>数据清洗</strong></li><li><strong>关键结果</strong><ul><li>3B/7B/15B模型。</li><li>3B超过其他同尺寸模型，15B超过更大模型。</li></ul></li></ul></div><h4 id="_23-codegeex" tabindex="-1">(23) CodeGeex <a class="header-anchor" href="#_23-codegeex" aria-label="Permalink to &quot;(23) CodeGeex&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">CodeGeeX (2023)</div><p><strong>关键技术</strong></p><ul><li>专注于代码<code>生成</code>和<code>翻译</code>。</li><li>INT8量化+FastTransformer：显存大幅降低。</li><li>上线VSCode插件。</li></ul><p><strong>训练数据</strong></p><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>推出HUmanEval-X，评估<code>跨语言翻译能力</code>，包括C++,Java,JavaScript,Go等。</li></ul></div><h4 id="_24-octocoder" tabindex="-1">(24) OctoCoder <a class="header-anchor" href="#_24-octocoder" aria-label="Permalink to &quot;(24) OctoCoder&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">OctoCoder (2024)</div><p><strong>关键技术</strong></p><ul><li><code>指令跟随模型</code>，基于StarCoder-16B-Base做微调而来。</li></ul><p><strong>训练数据</strong></p><ul><li>使用了<code>代码提交记录</code>，即包含<code>自然语言</code>和<code>代码</code>。</li><li><code>避免了code-only偏差</code>。</li></ul><p><strong>数据清洗</strong></p><p><strong>关键结果</strong></p><ul><li>释放<code>HumanEvalPack</code>：把HumanEval扩展至代码<code>修复/解释/生成</code>，以及<code>6种</code>语言。</li><li>pass@1效果好，<code>commit-style</code>数据对<code>bug-fix有好处</code>。</li></ul></div><h4 id="_23-santacoder" tabindex="-1">(23) SantaCoder <a class="header-anchor" href="#_23-santacoder" aria-label="Permalink to &quot;(23) SantaCoder&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">SantaCoder (2023, BigCode)</div><p><strong>关键技术</strong></p><ul><li><a href="https://plmsmile.github.io/posts/llm/basic/06-llm-attention.html#multi-query-attention-2019" target="_blank" rel="noreferrer">MQA</a>：提高推理速度</li><li>两阶段训练方法：先验证设计，再做大规模实验</li></ul><p><strong>训练数据</strong></p><ul><li><code>Python,Java,Javascritp</code>等代码数据。</li></ul><p><strong>数据清洗</strong></p><ul><li><code>去掉个人信息</code>、<code>近似去重</code>、<code>文档质量过滤</code>等。</li></ul><p><strong>关键结果</strong></p><ul><li>在<code>多语言code benc</code>h(Multi-PL-E)上，优于一些参数更大的模型。</li></ul></div><h4 id="其他架构" tabindex="-1">其他架构 <a class="header-anchor" href="#其他架构" aria-label="Permalink to &quot;其他架构&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">提示</div><p><strong>Gemini Diffusion / Mercur Coder</strong></p><ul><li>闭源模型。质量不错，时间大幅降低。</li></ul><p><strong>DiffuCoder</strong></p><ul><li>开源模型，130B训练，与AR模型效果差不多。</li><li>Coupled-GRPO： <ul><li>专门适配扩散模型的RL算法，利用非自回归特性， 引入互补噪声，减少似然估计方差，更好利用探索空间</li><li>21k RL样本，在EvalPlus上带来4.4%的提升。</li></ul></li></ul></div></div></div></main><footer class="VPDocFooter" data-v-5a64a79a data-v-54a90a4a><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-54a90a4a><span class="visually-hidden" id="doc-footer-aria-label" data-v-54a90a4a>Pager</span><div class="pager" data-v-54a90a4a><a class="VPLink link pager-link prev" href="/posts/llm/industry/codellm/06-code-taskrl-reading.html" data-v-54a90a4a><!--[--><span class="desc" data-v-54a90a4a>上一页</span><span class="title" data-v-54a90a4a>Code TaskRL 论文阅读</span><!--]--></a></div><div class="pager" data-v-54a90a4a><a class="VPLink link pager-link next" href="/posts/llm/industry/codellm/04-safety-code.html" data-v-54a90a4a><!--[--><span class="desc" data-v-54a90a4a>下一页</span><span class="title" data-v-54a90a4a>Code 安全相关</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--[--><div class="busuanzi"> 总访客数： <span id="busuanzi_value_site_uv"></span>   ·   总访问量： <span id="busuanzi_value_site_pv"></span></div><div class="busuanzi"> PLM&#39;s Blog @ 2016 - 2026</div><!--]--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api-examples.md\":\"Bt59YpwR\",\"index.md\":\"DmRGHmj9\",\"markdown-examples.md\":\"CPJSv--2\",\"posts_archive.md\":\"pZWQT7dp\",\"posts_exps_env_01-blog-env.md\":\"CcTUm41j\",\"posts_exps_env_index.md\":\"BJEZeoT-\",\"posts_exps_mind_index.md\":\"naOB3-Mb\",\"posts_llm_agent_basic_01-lhy-agent-notes.md\":\"BK_CsHNC\",\"posts_llm_agent_basic_02-evaluation-agent.md\":\"Dn02cVtP\",\"posts_llm_agent_basic_03-current-agents.md\":\"C25gmbg8\",\"posts_llm_agent_basic_04-agent-blogs.md\":\"_QbL2Plv\",\"posts_llm_agent_basic_05-comuter-agent.md\":\"D0gJpId6\",\"posts_llm_agent_basic_06-deepresearch-evaluation.md\":\"DdRDcxUJ\",\"posts_llm_agent_basic_index.md\":\"ClGtwUqg\",\"posts_llm_agent_rl_01-agent-rl.md\":\"wOF9bz66\",\"posts_llm_agent_rl_02-agent-tool.md\":\"IB_AqkSe\",\"posts_llm_agent_rl_03-agent-search.md\":\"Cim7OGxb\",\"posts_llm_agent_rl_04-agent-env.md\":\"C_O9BVi3\",\"posts_llm_agent_rl_index.md\":\"BudtoDK9\",\"posts_llm_basic_01-lm-define-information-theory.md\":\"Bl38RTdm\",\"posts_llm_basic_02-llm-components.md\":\"CGM_jRUE\",\"posts_llm_basic_03-transformer-detail.md\":\"BgLyAVDZ\",\"posts_llm_basic_04-llm-architecture.md\":\"jk4T-c21\",\"posts_llm_basic_05-llm-basic-info.md\":\"bdnM02bn\",\"posts_llm_basic_06-llm-attention.md\":\"BRJ9jR-M\",\"posts_llm_basic_07-decode.md\":\"BRytPqZo\",\"posts_llm_basic_08-llm-position-embedding.md\":\"d9dN_RuO\",\"posts_llm_basic_index.md\":\"DjX2HRXy\",\"posts_llm_industry_codellm_01-survey.md\":\"DIZQiOWr\",\"posts_llm_industry_codellm_02-eval-task-benchmark.md\":\"B-okIRAD\",\"posts_llm_industry_codellm_03-rl-task.md\":\"vQDqALFA\",\"posts_llm_industry_codellm_04-safety-code.md\":\"mkEFLxnr\",\"posts_llm_industry_codellm_05-open-codellm.md\":\"C6UU6qcZ\",\"posts_llm_industry_codellm_06-code-taskrl-reading.md\":\"BJI-7ypF\",\"posts_llm_industry_codellm_07-code-fulltrain-reading.md\":\"D7trPw8V\",\"posts_llm_industry_codellm_08-code-pretrain-summary.md\":\"DfgRUz6a\",\"posts_llm_industry_codellm_09-swe-series.md\":\"CkVwDnqY\",\"posts_llm_industry_mainllm_01-kimi-series.md\":\"B03hc7IE\",\"posts_llm_industry_mainllm_02-deepseek-series.md\":\"B04zRtyw\",\"posts_llm_industry_mainllm_03-glm-series.md\":\"8i7VdpW8\",\"posts_llm_industry_mainllm_04-minimax-series.md\":\"DjQwki4V\",\"posts_llm_industry_mainllm_05-qwen-series.md\":\"B4DMxRmo\",\"posts_llm_industry_mainllm_06-seed-series.md\":\"BNsIBjBZ\",\"posts_llm_industry_mainllm_07-openai-series.md\":\"ZBquCwKO\",\"posts_llm_industry_mainllm_08-gemini-series.md\":\"Bdm2kU-I\",\"posts_llm_industry_mainllm_09-claude-series.md\":\"0YnEaaXS\",\"posts_llm_industry_mainllm_10-longcat-series.md\":\"DroIAFXW\",\"posts_llm_industry_mainllm_11-tencent-series.md\":\"BVkGSYEM\",\"posts_llm_industry_mainllm_12-kwai-series.md\":\"o6Hut3bE\",\"posts_llm_industry_mainllm_13-nvidia-series.md\":\"BFgUmWZk\",\"posts_llm_industry_mainllm_14-mimo-series.md\":\"DDj7XRZV\",\"posts_llm_industry_mainllm_15-skywork-series.md\":\"pkz98qRT\",\"posts_llm_infra_01-parrallel.md\":\"Dih7M1RJ\",\"posts_llm_infra_02-speed-framework.md\":\"_bUH-n3t\",\"posts_llm_infra_03-inference-tech.md\":\"Hpk9YmXF\",\"posts_llm_infra_04-verl.md\":\"8XtGz01J\",\"posts_llm_infra_05-verl-practice.md\":\"B4gP7J_O\",\"posts_llm_infra_06-verl-code.md\":\"D5bZg4dm\",\"posts_llm_infra_07-verl-core.md\":\"3RS___SF\",\"posts_llm_infra_08-verl-train-loop.md\":\"CQNCgy-d\",\"posts_llm_rl_index.md\":\"iUgEsMU1\",\"posts_llm_rl_theory_01-reinforce-learning.md\":\"Ch0rtQCM\",\"posts_llm_rl_theory_01-rl-introduction.md\":\"CmW63EkM\",\"posts_llm_rl_theory_02-markove-process.md\":\"DVY5XgWd\",\"posts_llm_rl_theory_02-value-learning.md\":\"CeOlmbeS\",\"posts_llm_rl_theory_03-model-based-prediction-control.md\":\"BhVRmo7C\",\"posts_llm_rl_theory_03-strategy-learning.md\":\"DWNvEZXH\",\"posts_llm_rl_theory_04-model-free-prediction-control.md\":\"Cg3qo2Fk\",\"posts_llm_rl_theory_04-reinforce-conclusion-simple.md\":\"C6yTAxwQ\",\"posts_llm_rl_theory_05-dqn.md\":\"BatSdlnZ\",\"posts_llm_rl_theory_06-policy-gradient.md\":\"BXI-eY8I\",\"posts_llm_rl_theory_07-actor-critic.md\":\"B1-83sen\",\"posts_llm_rl_theory_08-deterministic-policy-gradient.md\":\"Dgvru3JE\",\"posts_llm_rl_theory_09-policy-trpo-ppo.md\":\"DU-7PSqU\",\"posts_llm_rl_theory_10-ppo-series.md\":\"B-5Hsj_J\",\"posts_llm_rl_theory_11-grpo-series.md\":\"Ctl1G-Yd\",\"posts_llm_rl_theory_12-entropy.md\":\"BH45bCLH\",\"posts_llm_rl_theory_13-agentrl-algo.md\":\"BfctbxM6\",\"posts_me.md\":\"B9W6CMag\",\"posts_olds_algo_aim2offer.md\":\"jCwzQ4BU\",\"posts_olds_algo_aim2offer2.md\":\"Ga2XS6dR\",\"posts_olds_algo_aim2offer3.md\":\"BP0rCZaJ\",\"posts_olds_algo_aim2offer4.md\":\"BXurWO8W\",\"posts_olds_algo_algorithm-dfs.md\":\"CkUFsStz\",\"posts_olds_algo_index.md\":\"CmdF0Gg2\",\"posts_olds_algo_leetcode-01.md\":\"C_2G2jJT\",\"posts_olds_algo_sort-algorithms.md\":\"tFMUVlmH\",\"posts_olds_bigdata_16-spark-baserdd.md\":\"CBxdArgI\",\"posts_olds_bigdata_17-spark-pairrdd.md\":\"C3n8_zMO\",\"posts_olds_bigdata_18-spark-sql.md\":\"tsaWQLcp\",\"posts_olds_bigdata_19-spark-programming.md\":\"DG5ZAF85\",\"posts_olds_bigdata_20-numpy.md\":\"DucCD22z\",\"posts_olds_bigdata_index.md\":\"CWrZwWPb\",\"posts_olds_dl_23-pytorch-start.md\":\"BokpNeAw\",\"posts_olds_dl_35-nerual-network-optim.md\":\"Cp2SpLoE\",\"posts_olds_dl_38-convolution.md\":\"CC_SQ57z\",\"posts_olds_dl_cs224n-assignment-1.md\":\"BZMSZqOS\",\"posts_olds_dl_cs224n-notes3-neural-networks-2.md\":\"Wd9TmSyb\",\"posts_olds_dl_cs224n-notes3-neural-networks.md\":\"CDZWc4X6\",\"posts_olds_dl_cs231n-linear-notes.md\":\"DLRyzcwJ\",\"posts_olds_dl_index.md\":\"C1dyLGNS\",\"posts_olds_dl_rnn.md\":\"CwYYWZ7N\",\"posts_olds_env_09-linux-notes.md\":\"CyjifvcN\",\"posts_olds_env_12-ide-envs.md\":\"YeELWzR2\",\"posts_olds_env_13-old-blog-problems.md\":\"qamPyucB\",\"posts_olds_env_24-hexo-problems.md\":\"CzxhyjW1\",\"posts_olds_env_index.md\":\"DQpgTXVj\",\"posts_olds_ml_10-trees.md\":\"BkNaj6fL\",\"posts_olds_ml_14-em.md\":\"DIufCP0H\",\"posts_olds_ml_21-lr.md\":\"C-1ms511\",\"posts_olds_ml_22-ml-ch03-bayes.md\":\"Q_M6Gn-a\",\"posts_olds_ml_27-svm-notes.md\":\"C96WS6CL\",\"posts_olds_ml_28-ml-interview-notes.md\":\"0bgezw3n\",\"posts_olds_ml_29-desicion-tree.md\":\"CtwmlbWl\",\"posts_olds_ml_crf.md\":\"CEE5oTqd\",\"posts_olds_ml_index.md\":\"BLMEziB1\",\"posts_olds_ml_maxentmodel.md\":\"CSbOumJx\",\"posts_olds_ml_pgm-01.md\":\"BTwybTMD\",\"posts_olds_nlp_11-nlp-labels.md\":\"Cl0Lb8OT\",\"posts_olds_nlp_25-google-nmt.md\":\"BOM-hoYN\",\"posts_olds_nlp_26-wordpieacemodel.md\":\"Q8-L5j15\",\"posts_olds_nlp_30-dynamic-memory-network.md\":\"wp5ucVxW\",\"posts_olds_nlp_31-co-attention-vqa.md\":\"lzwuVKG5\",\"posts_olds_nlp_32-dynamic-coattention-network.md\":\"Bxl4ABWd\",\"posts_olds_nlp_33-attention-summary.md\":\"DT6np0xG\",\"posts_olds_nlp_36-alime-chat.md\":\"Cu2xkcdT\",\"posts_olds_nlp_39-squard-models.md\":\"B1L3iDEv\",\"posts_olds_nlp_45-match-lstm.md\":\"DkpQKM5B\",\"posts_olds_nlp_46-rnet-selfmatch.md\":\"CzGHQ-PZ\",\"posts_olds_nlp_47-bidaf.md\":\"DFJaLh2v\",\"posts_olds_nlp_48-attention-is-all-you-need.md\":\"BY6XvFQ5\",\"posts_olds_nlp_49-qanet.md\":\"BPKWHzTf\",\"posts_olds_nlp_50-elmo.md\":\"WuOt1elN\",\"posts_olds_nlp_51-opengpt.md\":\"B9pQ3h5W\",\"posts_olds_nlp_52-bert.md\":\"5q3t5Qqh\",\"posts_olds_nlp_53-mrc-brief.md\":\"D9CkYrea\",\"posts_olds_nlp_54-mrc-models.md\":\"Ak4bDf1J\",\"posts_olds_nlp_attention-based-nmt.md\":\"BHef6tM6\",\"posts_olds_nlp_attention-model.md\":\"-xLhHhJE\",\"posts_olds_nlp_cs224n-lecture2-word2vec.md\":\"_MmBTADr\",\"posts_olds_nlp_cs224n-notes1-word2vec.md\":\"DXSi5KGh\",\"posts_olds_nlp_index.md\":\"Bfo4Lwn3\",\"posts_olds_nlp_nlp-notes.md\":\"BUmOZxzi\",\"posts_olds_nlp_nmt.md\":\"DUgy6vHF\",\"posts_olds_nlp_subword-units.md\":\"fR_3dRXr\",\"posts_olds_nlp_word2vec-math.md\":\"agvHiE1x\",\"posts_olds_nlp_word2vec.md\":\"D2TKUstm\",\"posts_olds_other_15-cpp-pointer-object-reference.md\":\"BKRTr8QZ\",\"posts_olds_other_index.md\":\"C1T-ubsz\",\"posts_olds_rl_37-reinforce-learning.md\":\"Cf2nny8k\",\"posts_olds_rl_40-value-learning.md\":\"DcnHvvpH\",\"posts_olds_rl_41-strategy-learning.md\":\"CStMrB-q\",\"posts_olds_rl_42-reinforce-conclusion-simple.md\":\"flRZUmJZ\",\"posts_olds_rl_43-intent-detection-slot-filling.md\":\"DcAUbaZU\",\"posts_olds_rl_44-reinforce-nlp.md\":\"Br2ShITL\",\"posts_olds_rl_index.md\":\"CUsxM3zO\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"📚 plmblog\",\"description\":\"记录一些学习笔记。\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"首页\",\"link\":\"/\"},{\"text\":\"🐲LLM\",\"items\":[{\"text\":\"Basic\",\"items\":[{\"text\":\"🦋基础知识\",\"link\":\"/posts/llm/basic/01-lm-define-information-theory\"},{\"text\":\"🛠基建框架\",\"link\":\"/posts/llm/infra/01-parrallel\"}]},{\"text\":\"强化学习\",\"items\":[{\"text\":\"🎓RL理论基础\",\"link\":\"/posts/llm/rl/theory/01-reinforce-learning\"},{\"text\":\"🚄Agent-RL\",\"link\":\"/posts/llm/agent/rl/02-agent-tool\"}]},{\"text\":\"行业方向\",\"items\":[{\"text\":\"🚀主流模型\",\"link\":\"/posts/llm/industry/mainllm/01-kimi-series\"},{\"text\":\"💻代码模型\",\"link\":\"/posts/llm/industry/codellm/01-survey\"}]},{\"text\":\"Agent\",\"items\":[{\"text\":\"🤖概念及应用\",\"link\":\"/posts/llm/agent/basic\"}]}]},{\"text\":\"📙旧文章\",\"items\":[{\"text\":\"🍓NLP\",\"items\":[{\"text\":\"自然语言处理\",\"link\":\"/posts/olds/nlp\"}]},{\"text\":\"🍑基础知识\",\"items\":[{\"text\":\"深度学习\",\"link\":\"/posts/olds/dl\"},{\"text\":\"强化学习\",\"link\":\"/posts/olds/rl\"},{\"text\":\"机器学习\",\"link\":\"/posts/olds/ml\"}]},{\"text\":\"🍎算法\",\"items\":[{\"text\":\"算法题\",\"link\":\"/posts/olds/algo/\"},{\"text\":\"大数据\",\"link\":\"/posts/olds/bigdata/\"}]},{\"text\":\"🍒其他\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/olds/env/\"},{\"text\":\"其他\",\"link\":\"/posts/olds/other/\"}]}]},{\"text\":\"经验\",\"items\":[{\"text\":\"环境\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/exps/env/01-blog-env\"}]},{\"text\":\"心得\",\"items\":[{\"text\":\"心得体会\",\"link\":\"/posts/exps/mind\"}]}]},{\"text\":\"归档\",\"link\":\"/posts/archive.md\"},{\"text\":\"关于我\",\"link\":\"/posts/me\"}],\"outline\":{\"level\":[1,4],\"label\":\"当前页大纲\"},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/plmsmile\"}],\"search\":{\"provider\":\"local\"},\"docFooter\":{\"prev\":\"上一页\",\"next\":\"下一页\"},\"sidebar\":{\"/posts/olds/nlp/\":{\"base\":\"/posts/olds/nlp/\",\"items\":[{\"text\":\"NLP\",\"items\":[{\"text\":\"机器阅读(二)--模型(未完成)\",\"link\":\"54-mrc-models\"},{\"text\":\"机器阅读(一)--整体概述\",\"link\":\"53-mrc-brief\"},{\"text\":\"BERT 详解\",\"link\":\"52-bert\"},{\"text\":\"OpenAI GPT：Improving Language Understanding by Generative Pre-Training\",\"link\":\"51-opengpt\"},{\"text\":\"ELMo：Deep Contextualized Word Representations\",\"link\":\"50-elmo\"},{\"text\":\"QANet\",\"link\":\"49-qanet\"},{\"text\":\"Transformer\",\"link\":\"48-attention-is-all-you-need\"},{\"text\":\"Bidirectional Attention Flow\",\"link\":\"47-bidaf\"},{\"text\":\"R-Net (Gated Self-Matching Networks)\",\"link\":\"46-rnet-selfmatch\"},{\"text\":\"Match-LSTM and Answer Pointer\",\"link\":\"45-match-lstm\"},{\"text\":\"阅读理解模型总结\",\"link\":\"39-squard-models\"},{\"text\":\"阿里小蜜论文\",\"link\":\"36-alime-chat\"},{\"text\":\"各种注意力总结\",\"link\":\"33-attention-summary\"},{\"text\":\"Dynamic Coattention Network (Plus)\",\"link\":\"32-dynamic-coattention-network\"},{\"text\":\"协同注意力简介\",\"link\":\"31-co-attention-vqa\"},{\"text\":\"使用Dynamic Memory Network实现一个简单QA\",\"link\":\"30-dynamic-memory-network\"},{\"text\":\"词性标注和句法依存的表示符号\",\"link\":\"11-nlp-labels\"},{\"text\":\"Word2vec之总体介绍\",\"link\":\"cs224n-notes1-word2vec\"},{\"text\":\"Word2vec之数学模型\",\"link\":\"word2vec-math\"},{\"text\":\"Word2vec之公式推导笔记\",\"link\":\"cs224n-lecture2-word2vec\"},{\"text\":\"subword-units\",\"link\":\"subword-units\"},{\"text\":\"Wordpiece模型\",\"link\":\"26-wordpieacemodel\"},{\"text\":\"谷歌RNN翻译模型\",\"link\":\"25-google-nmt\"},{\"text\":\"机器翻译注意力机制及其PyTorch实现\",\"link\":\"Attention-based-NMT\"},{\"text\":\"图文介绍RNN注意力机制\",\"link\":\"attention-model\"},{\"text\":\"最初RNN神经翻译简略笔记\",\"link\":\"NMT\"},{\"text\":\"语言模型和平滑方法\",\"link\":\"nlp-notes\"},{\"text\":\"利用tensorflow实现简版word2vec\",\"link\":\"word2vec\"}]}]},\"/posts/olds/dl/\":{\"base\":\"/posts/olds/dl/\",\"items\":[{\"text\":\"DL\",\"items\":[{\"text\":\"卷积神经网络总结\",\"link\":\"38-convolution\"},{\"text\":\"网络优化\",\"link\":\"35-nerual-network-optim\"},{\"text\":\"cs224n作业一\",\"link\":\"cs224n-assignment-1\"},{\"text\":\"cs231n线性分类器和损失函数\",\"link\":\"cs231n-linear-notes\"},{\"text\":\"神经网络-过拟合-预处理-BN\",\"link\":\"cs224n-notes3-neural-networks-2\"},{\"text\":\"神经网络基础-反向传播-激活函数\",\"link\":\"cs224n-notes3-neural-networks\"},{\"text\":\"循环神经网络\",\"link\":\"rnn\"},{\"text\":\"PyTorch快速上手\",\"link\":\"23-pytorch-start\"}]}]},\"/posts/olds/rl/\":{\"base\":\"/posts/olds/rl/\",\"items\":[{\"text\":\"RL\",\"items\":[{\"text\":\"强化学习在NLP中的应用\",\"link\":\"44-reinforce-nlp\"},{\"text\":\"意图识别和槽填充\",\"link\":\"43-intent-detection-slot-filling\"},{\"text\":\"强化学习算法小结\",\"link\":\"42-reinforce-conclusion-simple\"},{\"text\":\"基于策略函数的学习方法\",\"link\":\"41-strategy-learning\"},{\"text\":\"基于值函数的学习\",\"link\":\"40-value-learning\"},{\"text\":\"强化学习\",\"link\":\"37-reinforce-learning\"}]}]},\"/posts/olds/ml/\":{\"base\":\"/posts/olds/ml/\",\"items\":[{\"text\":\"ML\",\"items\":[{\"text\":\"决策树笔记\",\"link\":\"29-desicion-tree\"},{\"text\":\"机器学习知识点汇总整理\",\"link\":\"28-ml-interview-notes\"},{\"text\":\"SVM笔记\",\"link\":\"27-svm-notes\"},{\"text\":\"树的总结\",\"link\":\"10-trees\"},{\"text\":\"条件随机场\",\"link\":\"crf\"},{\"text\":\"最大熵模型\",\"link\":\"maxentmodel\"},{\"text\":\"线性回归和逻辑回归\",\"link\":\"21-lr\"},{\"text\":\"最大期望算法\",\"link\":\"14-em\"},{\"text\":\"马尔可夫模型\",\"link\":\"pgm-01\"},{\"text\":\"朴素贝叶斯算法及其代码实现\",\"link\":\"22-ml-ch03-bayes\"}]}]},\"/posts/olds/algo/\":{\"base\":\"/posts/olds/algo/\",\"items\":[{\"text\":\"ALGO\",\"items\":[{\"text\":\"剑指offer4(51-64)\",\"link\":\"aim2offer4\"},{\"text\":\"剑指offer3(21-40)\",\"link\":\"aim2offer3\"},{\"text\":\"数据结构之搜索算法\",\"link\":\"algorithm-dfs\"},{\"text\":\"leetcode-01\",\"link\":\"leetcode-01\"},{\"text\":\"剑指offer(11-20)\",\"link\":\"aim2offer2\"},{\"text\":\"排序算法总结\",\"link\":\"sort-algorithms\"},{\"text\":\"剑指Offer(1-10)\",\"link\":\"aim2offer\"}]}]},\"/posts/olds/bigdata/\":{\"base\":\"/posts/olds/bigdata/\",\"items\":[{\"text\":\"BIG Data\",\"items\":[{\"text\":\"NumPy\",\"link\":\"20-numpy\"},{\"text\":\"Spark基础编程核心思想介绍\",\"link\":\"19-spark-programming\"},{\"text\":\"Spark-SQL的简略笔记\",\"link\":\"18-spark-sql\"},{\"text\":\"Spark键值对RDD的常用API\",\"link\":\"17-spark-pairrdd\"},{\"text\":\"Spark基础RDD的常用API\",\"link\":\"16-Spark-BaseRDD\"}]}]},\"/posts/olds/env/\":{\"base\":\"/posts/olds/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"IDE配置\",\"link\":\"12-ide-envs\"},{\"text\":\"Linux使用笔记\",\"link\":\"09-linux-notes\"},{\"text\":\"博客搭建及相关问题\",\"link\":\"24-hexo-problems\"},{\"text\":\"旧版博客搭建过程及其问题\",\"link\":\"13-old-blog-problems\"}]}]},\"/posts/olds/other/\":{\"base\":\"/posts/olds/other/\",\"items\":[{\"text\":\"其他\",\"items\":[{\"text\":\"C++类对象和指针的区别\",\"link\":\"15-cpp-pointer-object-reference\"}]}]},\"/posts/llm/agent/rl/\":{\"base\":\"/posts/llm/agent/rl/\",\"items\":[{\"text\":\"Agent-RL\",\"items\":[{\"text\":\"Agent-Interaction-RL 笔记\",\"link\":\"04-agent-env\"},{\"text\":\"Agent-Search-RL 笔记\",\"link\":\"03-agent-search\"},{\"text\":\"Agent-Tool-RL 笔记\",\"link\":\"02-agent-tool\"},{\"text\":\"Agent-RL 综述型笔记\",\"link\":\"01-agent-rl\"}]}]},\"/posts/llm/agent/basic/\":{\"base\":\"/posts/llm/agent/basic/\",\"items\":[{\"text\":\"Agent-基础\",\"items\":[{\"text\":\"DeepResearch 评估\",\"link\":\"06-deepresearch-evaluation\"},{\"text\":\"Computer-Agent\",\"link\":\"05-comuter-agent\"},{\"text\":\"Agent 思考性文章\",\"link\":\"04-agent-blogs\"},{\"text\":\"一些流行的Agents\",\"link\":\"03-current-agents\"},{\"text\":\"Agent 评估 Benchmarks\",\"link\":\"02-evaluation-agent\"},{\"text\":\"Agent基础概念 (李宏毅笔记)\",\"link\":\"01-lhy-agent-notes\"}]}]},\"/posts/llm/rl/theory/\":{\"base\":\"/posts/llm/rl/theory/\",\"items\":[{\"text\":\"RL-Theory\",\"items\":[{\"text\":\"Agent-RL 相关算法\",\"link\":\"13-agentrl-algo\"},{\"text\":\"熵和RL相关文章\",\"link\":\"12-entropy\"},{\"text\":\"GRPO 改进系列\",\"link\":\"11-grpo-series\"},{\"text\":\"PPO 改进系列\",\"link\":\"10-ppo-series\"},{\"text\":\"典型策略提升方法：TRPO+PPO+DPO+GRPO\",\"link\":\"09-policy-trpo-ppo\"},{\"text\":\"确定性策略梯度\",\"link\":\"08-deterministic-policy-gradient\"},{\"text\":\"Actor-Critic 算法\",\"link\":\"07-actor-critic\"},{\"text\":\"策略梯度算法\",\"link\":\"06-policy-gradient\"},{\"text\":\"DQN算法及进阶\",\"link\":\"05-dqn\"},{\"text\":\"免模型预测和控制\",\"link\":\"04-model-free-prediction-control\"},{\"text\":\"有模型预测和控制\",\"link\":\"03-model-based-prediction-control\"},{\"text\":\"马尔可夫决策过程\",\"link\":\"02-markove-process\"},{\"text\":\"强化学习基本概念\",\"link\":\"01-rl-introduction\"},{\"text\":\"(18年笔记)强化学习算法小结\",\"link\":\"04-reinforce-conclusion-simple\"},{\"text\":\"(18年笔记)基于策略函数的学习方法\",\"link\":\"03-strategy-learning\"},{\"text\":\"(18年笔记)基于值函数的学习\",\"link\":\"02-value-learning\"},{\"text\":\"(18年笔记)强化学习基础\",\"link\":\"01-reinforce-learning\"}]}]},\"/posts/llm/rl/rlhf/\":{\"base\":\"/posts/llm/rl/rlhf/\",\"items\":[{\"text\":\"RLHF\",\"items\":[]}]},\"/posts/llm/rl/o1llm/\":{\"base\":\"/posts/llm/rl/o1llm/\",\"items\":[{\"text\":\"推理模型\",\"items\":[]}]},\"/posts/llm/industry/mainllm/\":{\"base\":\"/posts/llm/industry/mainllm/\",\"items\":[{\"text\":\"🚀主流模型\",\"items\":[{\"text\":\"快手系列\",\"link\":\"12-kwai-series\"},{\"text\":\"腾讯系列\",\"link\":\"11-tencent-series\"},{\"text\":\"Claude 系列\",\"link\":\"09-claude-series\"},{\"text\":\"LongCat 系列\",\"link\":\"10-longcat-series\"},{\"text\":\"Gemini 系列\",\"link\":\"08-gemini-series\"},{\"text\":\"Seed 系列\",\"link\":\"06-seed-series\"},{\"text\":\"OpenAI 系列\",\"link\":\"07-openai-series\"},{\"text\":\"Qwen 系列\",\"link\":\"05-qwen-series\"},{\"text\":\"MiniMax 系列\",\"link\":\"04-minimax-series\"},{\"text\":\"GLM 系列\",\"link\":\"03-glm-series\"},{\"text\":\"DeepSeek 系列\",\"link\":\"02-deepseek-series\"},{\"text\":\"Kimi 系列\",\"link\":\"01-kimi-series\"},{\"text\":\"SkyWork 系列\",\"link\":\"15-skywork-series\"},{\"text\":\"小米系列\",\"link\":\"14-mimo-series\"},{\"text\":\"Nvidia 系列\",\"link\":\"13-nvidia-series\"}]}]},\"/posts/llm/industry/codellm/\":{\"base\":\"/posts/llm/industry/codellm/\",\"items\":[{\"text\":\"💻代码模型\",\"items\":[{\"text\":\"Code 全训练 论文阅读\",\"link\":\"07-code-fulltrain-reading\"},{\"text\":\"Code TaskRL 论文阅读\",\"link\":\"06-code-taskrl-reading\"},{\"text\":\"CodeLLM 索引简记\",\"link\":\"05-open-codellm\"},{\"text\":\"Code 安全相关\",\"link\":\"04-safety-code\"},{\"text\":\"Code RL 任务\",\"link\":\"03-rl-task\"},{\"text\":\"Code 任务Bench相关\",\"link\":\"02-eval-task-benchmark\"},{\"text\":\"Code Survey\",\"link\":\"01-survey\"},{\"text\":\"SWE 系列\",\"link\":\"09-swe-series\"},{\"text\":\"Code 预训练相关\",\"link\":\"08-code-pretrain-summary\"}]}]},\"/posts/llm/basic/\":{\"base\":\"/posts/llm/basic/\",\"items\":[{\"text\":\"LLM-basic\",\"items\":[{\"text\":\"LLM位置编码和长度外推系列\",\"link\":\"08-llm-position-embedding\"},{\"text\":\"LLM 解码相关\",\"link\":\"07-decode\"},{\"text\":\"LLM Attention 系列\",\"link\":\"06-llm-attention\"},{\"text\":\"LLM 基础知识\",\"link\":\"05-llm-basic-info\"},{\"text\":\"LLM 架构相关\",\"link\":\"04-llm-architecture\"},{\"text\":\"Transformer细节\",\"link\":\"03-transformer-detail\"},{\"text\":\"语言模型重要组件\",\"link\":\"02-llm-components\"},{\"text\":\"语言模型定义及信息理论\",\"link\":\"01-lm-define-information-theory\"}]}]},\"/posts/llm/infra/\":{\"base\":\"/posts/llm/infra/\",\"items\":[{\"text\":\"🛠LLM-基建框架\",\"items\":[{\"text\":\"Verl 训练流程源代码阅读\",\"link\":\"08-verl-train-loop\"},{\"text\":\"Verl 有趣的功能\",\"link\":\"07-verl-core\"},{\"text\":\"Verl AgentLoop Rollout 相关\",\"link\":\"06-verl-code\"},{\"text\":\"Verl 常见参数配置和理解\",\"link\":\"05-verl-practice\"},{\"text\":\"Verl 早期概念型学习文章\",\"link\":\"04-verl\"},{\"text\":\"推理优化技术\",\"link\":\"03-inference-tech\"},{\"text\":\"分布式训练框架\",\"link\":\"02-speed-framework\"},{\"text\":\"分布式并行策略\",\"link\":\"01-parrallel\"}]}]},\"/posts/exps/env/\":{\"base\":\"/posts/exps/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"环境搭建的一些坑\",\"link\":\"01-blog-env\"}]}]},\"/posts/exps/mind/\":{\"base\":\"/posts/exps/mind/\",\"items\":[{\"text\":\"心得体会\",\"items\":[]}]}}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>
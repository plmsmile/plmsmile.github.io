<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>SWE 训练方法 系列 | 📚 plmblog</title>
    <meta name="description" content="记录一些学习笔记。">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/assets/style.CuIOXX7t.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.CpFa0R23.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.DrNSUXfy.js">
    <link rel="modulepreload" href="/assets/chunks/framework.CvbyeFFO.js">
    <link rel="modulepreload" href="/assets/posts_llm_industry_codellm_09-swe-series.md.njRlhnZH.lean.js">
    <link rel="icon" href="/plm.png">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-cecb633e><!--[--><!--]--><!--[--><span tabindex="-1" data-v-c979f278></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-c979f278>Skip to content</a><!--]--><!----><header class="VPNav" data-v-cecb633e data-v-0ad68676><div class="VPNavBar" data-v-0ad68676 data-v-ce71e4ef><div class="wrapper" data-v-ce71e4ef><div class="container" data-v-ce71e4ef><div class="title" data-v-ce71e4ef><div class="VPNavBarTitle has-sidebar" data-v-ce71e4ef data-v-7e906684><a class="title" href="/" data-v-7e906684><!--[--><!--]--><!----><span data-v-7e906684>📚 plmblog</span><!--[--><!--]--></a></div></div><div class="content" data-v-ce71e4ef><div class="content-body" data-v-ce71e4ef><!--[--><!--]--><div class="VPNavBarSearch search" data-v-ce71e4ef><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-ce71e4ef data-v-e0cd9371><span id="main-nav-aria-label" class="visually-hidden" data-v-e0cd9371> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>首页</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>🐲LLM</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Basic</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/basic/01-lm-define-information-theory.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🦋基础知识</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/infra/01-parrallel.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🛠基建框架</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>强化学习</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/rl/theory/01-reinforce-learning.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🎓RL理论基础</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/rl/02-agent-tool.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚄Agent-RL</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>行业方向</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/industry/mainllm/01-kimi-series.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚀主流模型</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/industry/codellm/01-survey.html" data-v-dc987abe><!--[--><span data-v-dc987abe>💻代码模型</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Agent</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/basic.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🤖概念及应用</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>📙旧文章</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍓NLP</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/nlp.html" data-v-dc987abe><!--[--><span data-v-dc987abe>自然语言处理</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍑基础知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/dl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>深度学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/rl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>强化学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/ml.html" data-v-dc987abe><!--[--><span data-v-dc987abe>机器学习</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍎算法</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/algo/" data-v-dc987abe><!--[--><span data-v-dc987abe>算法题</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/bigdata/" data-v-dc987abe><!--[--><span data-v-dc987abe>大数据</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍒其他</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/env/" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/other/" data-v-dc987abe><!--[--><span data-v-dc987abe>其他</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>经验</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>环境</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/env/01-blog-env.html" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>心得</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/mind.html" data-v-dc987abe><!--[--><span data-v-dc987abe>心得体会</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/archive.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>归档</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/me.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>关于我</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-ce71e4ef data-v-b59ebfac><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-b59ebfac data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-ce71e4ef data-v-e0f2db57 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-ce71e4ef data-v-8897e953 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-ffaaba87><span class="vpi-more-horizontal icon" data-v-ffaaba87></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><!----><!--[--><!--[--><!----><div class="group" data-v-8897e953><div class="item appearance" data-v-8897e953><p class="label" data-v-8897e953>Appearance</p><div class="appearance-action" data-v-8897e953><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-8897e953 data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div></div></div><div class="group" data-v-8897e953><div class="item social-links" data-v-8897e953><div class="VPSocialLinks social-links-list" data-v-8897e953 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-ce71e4ef data-v-37e0f734><span class="container" data-v-37e0f734><span class="top" data-v-37e0f734></span><span class="middle" data-v-37e0f734></span><span class="bottom" data-v-37e0f734></span></span></button></div></div></div></div><div class="divider" data-v-ce71e4ef><div class="divider-line" data-v-ce71e4ef></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-cecb633e data-v-1b409c8b><div class="container" data-v-1b409c8b><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-1b409c8b><span class="vpi-align-left menu-icon" data-v-1b409c8b></span><span class="menu-text" data-v-1b409c8b>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-1b409c8b data-v-a203161a><button data-v-a203161a>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-cecb633e data-v-18f7b5ca><div class="curtain" data-v-18f7b5ca></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-18f7b5ca><span class="visually-hidden" id="sidebar-aria-label" data-v-18f7b5ca> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-7f5b9a39><section class="VPSidebarItem level-0 has-active" data-v-7f5b9a39 data-v-a4affe07><div class="item" role="button" tabindex="0" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><h2 class="text" data-v-a4affe07>💻代码模型</h2><!----></div><div class="items" data-v-a4affe07><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/11-swe-data-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>SWE 合成数据 系列</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/10-swe-summary.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>SWE 总结索引</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/07-code-fulltrain-reading.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 全训练 论文阅读</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/06-code-taskrl-reading.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code TaskRL 论文阅读</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/05-open-codellm.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>CodeLLM 索引简记</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/04-safety-code.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 安全相关</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/03-rl-task.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code RL 任务</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/02-eval-task-benchmark.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 任务Bench相关</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/01-survey.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code Survey</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/09-swe-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>SWE 训练方法 系列</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/08-code-pretrain-summary.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 预训练相关</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-cecb633e data-v-53a9cb18><div class="VPDoc has-sidebar has-aside" data-v-53a9cb18 data-v-5a64a79a><!--[--><!--]--><div class="container" data-v-5a64a79a><div class="aside" data-v-5a64a79a><div class="aside-curtain" data-v-5a64a79a></div><div class="aside-container" data-v-5a64a79a><div class="aside-content" data-v-5a64a79a><div class="VPDocAside" data-v-5a64a79a data-v-f8ea3c28><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-f8ea3c28 data-v-b94d89ac><div class="content" data-v-b94d89ac><div class="outline-marker" data-v-b94d89ac></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-b94d89ac>当前页大纲</div><ul class="VPDocOutlineItem root" data-v-b94d89ac data-v-80b46526><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-f8ea3c28></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-5a64a79a><div class="content-container" data-v-5a64a79a><!--[--><!--[--><!--[--><article class="post-header" data-v-a99fd7c9><h1 class="title" data-v-a99fd7c9>SWE 训练方法 系列</h1><div class="stats-container" data-v-a99fd7c9><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 📅 发表于 <span class="stat-text" data-v-a99fd7c9>2025/01/02</span></div><div class="stat-item" data-v-a99fd7c9> 🔄 更新于 <span class="stat-text" data-v-a99fd7c9>2025/01/02</span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 👁️ <span class="stat-text" data-v-a99fd7c9>-- 次访问</span><span id="busuanzi_value_page_pv" style="display:none;" data-page="/posts/llm/industry/codellm/09-swe-series.html" data-v-a99fd7c9></span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 📝 <span class="stat-text" data-v-a99fd7c9>0 字</span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> ⏳ <span class="stat-text" data-v-a99fd7c9>0 分钟</span></div><div class="stat-divider" data-v-a99fd7c9></div></div><div class="tag-group" data-v-a99fd7c9><!--[--><div class="category-item" data-v-a99fd7c9>swe</div><!--]--><!--[--><div class="tag-item" data-v-a99fd7c9> #Self-play SWE-RL</div><div class="tag-item" data-v-a99fd7c9> #写Bug修Bug自我博弈JointRL</div><div class="tag-item" data-v-a99fd7c9> #SKyRL-Agent</div><div class="tag-item" data-v-a99fd7c9> #AST工具增强</div><div class="tag-item" data-v-a99fd7c9> #增加环境提示信息</div><div class="tag-item" data-v-a99fd7c9> #留一法估计优势</div><div class="tag-item" data-v-a99fd7c9> #InfoCode</div><div class="tag-item" data-v-a99fd7c9> #对抗生成代码和测试</div><div class="tag-item" data-v-a99fd7c9> #Kimi-Dev</div><div class="tag-item" data-v-a99fd7c9> #Agentless训练</div><div class="tag-item" data-v-a99fd7c9> #SWE-Agent适配</div><div class="tag-item" data-v-a99fd7c9> #MidTrain</div><div class="tag-item" data-v-a99fd7c9> #CodeEditRL</div><div class="tag-item" data-v-a99fd7c9> #SWE-Swiss</div><div class="tag-item" data-v-a99fd7c9> #3任务SFT</div><div class="tag-item" data-v-a99fd7c9> #2阶段课程RL</div><div class="tag-item" data-v-a99fd7c9> #NEBIUS-SWE</div><div class="tag-item" data-v-a99fd7c9> #Mask错误动作SFT</div><div class="tag-item" data-v-a99fd7c9> #DeepSWE</div><div class="tag-item" data-v-a99fd7c9> #GRPO++</div><div class="tag-item" data-v-a99fd7c9> #Devstral2</div><div class="tag-item" data-v-a99fd7c9> #Devstral</div><div class="tag-item" data-v-a99fd7c9> #SWE-RL</div><div class="tag-item" data-v-a99fd7c9> #Patch相似度奖励信号</div><div class="tag-item" data-v-a99fd7c9> #SWE-Agent</div><div class="tag-item" data-v-a99fd7c9> #ACI</div><div class="tag-item" data-v-a99fd7c9> #Agent-Computer-Interface</div><!--]--></div></article><!--]--><!--]--><!--]--><main class="main" data-v-5a64a79a><div style="position:relative;" class="vp-doc _posts_llm_industry_codellm_09-swe-series" data-v-5a64a79a><div><h2 id="_2512-self-play-swe-rl-51-4分-meta" tabindex="-1">(2512) Self-Play SWE-RL (51.4分, Meta) <a class="header-anchor" href="#_2512-self-play-swe-rl-51-4分-meta" aria-label="Permalink to &quot;(2512) Self-Play SWE-RL (51.4分, Meta)&quot;">​</a></h2><p>🌺 <strong>论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">Self-Play SWE-RL 摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2512.18552" target="_blank" rel="noreferrer">paper</a>, <a href="http://plmsmile.github.io/posts/llm/industry/codellm/09-swe-series.html#_2512-self-play-swe-rl-51-4%E5%88%86-meta" target="_blank" rel="noreferrer">论文笔记</a></li></ul><p><strong>核心方法</strong></p><ul><li><code>Self-Play SWE-RL框架</code><ul><li>给定<code>仓库+环境</code>，通过<code>写Bug</code>+<code>修Bug</code> <code>自我博弈联合RL训练</code>。<code>无需人工Issue</code></li></ul></li><li><code>仓库数据</code>：<code>未知</code></li><li><code>CWM scaffold</code>：<code>bash</code> + <code>search-replace 编辑器</code></li></ul><p><strong>模型效果(CWM-32B-sft)</strong></p><ul><li>在SWE-V和SWE-Pro上，<code>SSR方法</code>都超过<code>RL+人类Issue</code>训练的模型，但<code>也没高多少</code>。</li><li><code>SWE-V</code>达<code>51.4分</code>，<code>SWE-P</code>达<code>28.9分</code>。</li></ul><p><strong>重要结论</strong></p><ul><li><code>Self-Play RL</code>比<code>Repair/Injection-Only RL</code> 性能<code>更好</code>，<code>Inject-Only</code> 效果最差。</li><li><code>大幅删除代码的Bug</code>更好比<code>仅改一行代码的Bug</code>的好。<code>后者太简单</code>，学习信号弱。</li><li>由于共享1个Policy，<code>Solver解决率信号</code> <code>对训练效果影响不大</code>。</li></ul><p><strong>关键贡献</strong></p><ul><li><code>Self-Play SWE-RL 思想</code>，很有<code>启发意义的工作</code>。</li></ul></div><h3 id="问题背景" tabindex="-1">问题背景 <a class="header-anchor" href="#问题背景" aria-label="Permalink to &quot;问题背景&quot;">​</a></h3><p>❓<strong>问题背景</strong></p><h4 id="合成数据是静态的" tabindex="-1">合成数据是静态的 <a class="header-anchor" href="#合成数据是静态的" aria-label="Permalink to &quot;合成数据是静态的&quot;">​</a></h4><div class="custom-block warning"><div class="custom-block-title">问题背景</div><p><strong>RL 受限于人类天花板</strong></p><ul><li><code>训练数据和环境</code> <code>依赖人工</code>：Issue、PR、环境、单元测试等。</li><li><code>人类数据噪音多</code>，<code>不可靠</code>，<code>难扩展</code>。</li><li><code>导致RL本质</code>：<code>模仿和优化</code> <code>人类写代码</code>的过程。</li></ul><p><strong>当前合成数据存在局限性</strong></p><ul><li><p>思想：LLM合成Bug，再去蒸馏数据。</p></li><li><p>缺点：</p><ul><li><code>依赖人类</code>：测试套件、解析器等。</li><li><code>依赖TeacherModel</code>：LLM去操作、LLM去蒸馏数据。</li><li><code>扩展受限</code>。</li><li><code>Bug是静态合成的</code>：模型进化，但Bug却无法进化，导致<code>系统无法持续自我改进</code>。</li></ul></li><li><p>代表工作：<a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#_2504-swe-smith-swe-agent-lm" target="_blank" rel="noreferrer">SWE-smith</a>/<a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#_2510-bugpilot" target="_blank" rel="noreferrer">BugPilot</a>.</p></li></ul></div><h4 id="self-play结合真实动态仓库" tabindex="-1">Self-Play结合真实动态仓库 <a class="header-anchor" href="#self-play结合真实动态仓库" aria-label="Permalink to &quot;Self-Play结合真实动态仓库&quot;">​</a></h4><div class="custom-block warning"><div class="custom-block-title">Self-Play + 真实动态Repo</div><p><strong>Self-Play</strong></p><ul><li>AlphaZero：自我博弈，自我改进。</li><li>RL：<a href="https://plmsmile.github.io/posts/llm/rl/theory/01-rl-introduction.html#%E6%8E%A2%E7%B4%A2%E5%92%8C%E5%88%A9%E7%94%A8" target="_blank" rel="noreferrer">探索和利用</a>。</li></ul><p><strong>Zero Self-Play</strong></p><ul><li>代表工作： <ul><li><code>Absolute Zero</code>：训单个推理模型。 <ul><li><code>只和Python解释器交互</code>，只能学到Python细节，<code>无法学到真实知识经验</code>。</li></ul></li><li>R-Zero：共同进化挑战者和求解者。</li><li>LSP：自我博弈。</li></ul></li><li>缺点：<code>无法获得</code> 超出<code>固定环境</code>和<code>模型现有储备</code>之外的<code>新知识</code>。</li></ul><p><strong>想法</strong></p><ul><li>基于<code>真实动态Repo</code>，Agent<code>和代码环境交互</code>来<code>学习</code>，不依赖人类训练数据。</li><li><code>Self-Play</code> + <code>真实世界仓库</code></li></ul></div><h3 id="self-play-swe-rl" tabindex="-1">Self-Play SWE-RL <a class="header-anchor" href="#self-play-swe-rl" aria-label="Permalink to &quot;Self-Play SWE-RL&quot;">​</a></h3><p>📕<strong>核心方法</strong></p><h4 id="核心思想" tabindex="-1">核心思想 <a class="header-anchor" href="#核心思想" aria-label="Permalink to &quot;核心思想&quot;">​</a></h4><div class="custom-block important"><div class="custom-block-title">Self-Play SWE-RL</div><p><strong>核心思想</strong></p><ul><li><code>沙盒环境</code> + <code>代码仓库 </code>+ <code>工具集</code>(来自CWM, <code>Bash+Editor</code>) <ul><li><code>无需</code>：单元测试、Issue描述、执行测试命令、特定语言先验知识等。</li></ul></li><li><code>1个LLM</code>，<code>2个角色</code>(不同prompt)，<code>Injector-造Bug</code>，<code>Solver-修复Bug</code></li><li>通过<code>造Bug+修Bug</code>，<code>迭代式循环提升</code>，<code>共同对抗式-RL训练</code></li></ul><p><strong>优点</strong></p><ul><li>通过self-play，模型生成<code>多样化</code>+<code>有挑战</code>+<code>不断进化</code>的<code>课程</code>。</li><li><code>静态bug无法比拟</code>。</li></ul><p><strong>高阶Bug</strong></p><ul><li><code>Solver失败的尝试</code>，作为<code>高阶Bug</code></li><li>类似真实开发中多步骤、相互依赖的修改。</li></ul></div><img src="https://paper-assets.alphaxiv.org/figures/2512.18552v1/img-0.jpeg" style="display:block;margin:auto;" width="70%"><h4 id="生成bug-injector" tabindex="-1">生成Bug(Injector) <a class="header-anchor" href="#生成bug-injector" aria-label="Permalink to &quot;生成Bug(Injector)&quot;">​</a></h4><div class="custom-block important"><div class="custom-block-title">Bug 套件</div><p><strong>Bug本身</strong></p><ul><li><code>bug_inject.diff</code>：向代码注入Bug</li></ul><p><strong>隐蔽手段</strong></p><ul><li><code>test_weaken.diff</code>：<code>移除或削弱测试</code>，<code>隐藏Bug</code>。</li></ul><p><strong>防作弊手段</strong></p><ul><li><code>test_files.txt</code>：测试文件列表，避免AI直接修改测试文件，每次测试时直接恢复。</li></ul><p><strong>验证工具</strong></p><ul><li><code>test_scripts.sh</code>：运行测试套件，检测错误、验证修复</li><li><code>test_parser.py</code>：解析测试输出结果，每个测试ID映射到结果。</li></ul></div><div class="custom-block note"><div class="custom-block-title">Bug Injector Agent</div><p><strong>目标</strong></p><ul><li>探索仓库，生成<code>高质量</code>、<code>适配Solver</code>的<code>Bug</code>，并给到Bug Solver。</li></ul><p><strong>Bug制造策略</strong></p><ul><li><code>代码移除</code><ul><li><code>删掉某个文件</code>、删掉大段<code>核心逻辑</code></li><li>迫使Solver重写代码，功能开发。</li></ul></li><li><code>历史回滚</code><ul><li>AI 去翻阅历史Git Log，找到以前的修改，撤销，<code>重新引入旧 Bug</code></li><li>利用人类程序员的历史智慧。</li></ul></li><li><code>高阶Bug</code><ul><li>Injector<code>制造Bug</code>，<code>Solver失败的解法</code>，这个<code>烂代码</code>就变成<code>新Bug 题目</code>。</li><li>优点：<code>非常真实</code>(人类就这样的)，<code>多样性好</code>、<code>覆盖全</code></li></ul></li></ul><p><strong>约束和质量控制</strong></p><ul><li><code>约束条件</code><ul><li><code>避免低级情况</code>：直接删除某函数，<code>直接报错缺乏xx函数</code></li><li>删除函数后，需<code>修改调用地方</code>，保证<code>代码能跑通</code>，<code>但结果是错的</code>。</li></ul></li><li><code>质量控制</code><ul><li>设置<code>最小文件更改数</code></li><li>必须<code>有测试失败</code>(有bug)，必须<code>有测试通过</code>(环境没崩)</li></ul></li></ul><p><strong>一致性验证</strong></p><ul><li><code>基础检查</code><ul><li><code>测试文件检查</code>：AI指导的<code>测试文件是否真存在</code>，而不是幻觉。</li><li><code>解析器检查</code>：AI写的python解析脚本能不能跑。</li><li><code>脚本检查</code>：在源代码库上运行测试，必须通过。</li></ul></li><li>Bug质量检查 <ul><li>规模检查：<code>修改的文件数量</code> <code>不能太少</code>(如5个)</li><li>Bug检查：注入Bug后，<code>必须有测试Fail</code></li></ul></li><li><code>隐蔽性检查</code><ul><li>注入Bug，<code>删掉部分测试</code>，<code>原报错消失</code></li></ul></li><li><code>逆向高级检查</code>(<code>无冗余检查</code>) <ul><li>避免AI注水无关紧要的更改，剔除冗余代码。</li><li>所有文件都改坏，然后逐个恢复，检查Bug是佛会减少。</li></ul></li></ul></div><div class="custom-block important"><div class="custom-block-title">Bug Injector 奖励学习信号</div><p><strong>概览</strong></p><ul><li><code>一致性反馈</code>：生成<code>正确可用的Bug</code>。</li><li><code>Solver反馈</code><ul><li>Solver 秒解决 - <code>题目太简单</code>：Injector <code>得分低</code></li><li>Solver 解不开 - <code>题目太困难</code>：Injector <code>得分低</code></li><li>寻找<code>处于Solver能力边界</code>上的难题</li></ul></li></ul><p><strong>公式</strong></p><ul><li>权衡<code>Bug一致性</code>和<code>Solver解决率</code>(<code>s</code>)，<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.186ex;" xmlns="http://www.w3.org/2000/svg" width="7.356ex" height="1.692ex" role="img" focusable="false" viewBox="0 -666 3251.6 748" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(917.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1973.6,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" style="stroke-width:3;"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(778,0)" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>α</mi><mo>=</mo><mn>0.8</mn></math></mjx-assistive-mml></mjx-container>超参<mjx-container tabindex="0" class="MathJax" jax="SVG" display="true" style="direction:ltr;display:block;text-align:center;margin:1em 0;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-3.281ex;" xmlns="http://www.w3.org/2000/svg" width="42.529ex" height="7.692ex" role="img" focusable="false" viewBox="0 -1950 18798 3400" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="6A" d="M98 609Q98 637 116 653T160 669Q183 667 200 652T217 609Q217 579 200 564T158 549Q133 549 116 564T98 609ZM28 -163Q58 -168 64 -168Q124 -168 135 -77Q137 -65 137 141T136 353Q132 371 120 377T72 385H52V408Q52 431 54 431L58 432Q62 432 70 432T87 433T108 434T133 436Q151 437 171 438T202 441T214 442H218V184Q217 -36 217 -59T211 -98Q195 -145 153 -175T58 -205Q9 -205 -23 -179T-55 -117Q-55 -94 -40 -79T-2 -64T36 -79T52 -118Q52 -143 28 -163Z" transform="translate(834,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1140,0)" style="stroke-width:3;"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(1584,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(2028,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(2520.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mrow" transform="translate(3576.6,0)"><g data-mml-node="mo"><path data-c="23A7" d="M712 899L718 893V876V865Q718 854 704 846Q627 793 577 710T510 525Q510 524 509 521Q505 493 504 349Q504 345 504 334Q504 277 504 240Q504 -2 503 -4Q502 -8 494 -9T444 -10Q392 -10 390 -9Q387 -8 386 -5Q384 5 384 230Q384 262 384 312T383 382Q383 481 392 535T434 656Q510 806 664 892L677 899H712Z" transform="translate(0,1051)" style="stroke-width:3;"></path><path data-c="23A9" d="M718 -893L712 -899H677L666 -893Q542 -825 468 -714T385 -476Q384 -466 384 -282Q384 3 385 5L389 9Q392 10 444 10Q486 10 494 9T503 4Q504 2 504 -239V-310V-366Q504 -470 508 -513T530 -609Q546 -657 569 -698T617 -767T661 -812T699 -843T717 -856T718 -876V-893Z" transform="translate(0,-551)" style="stroke-width:3;"></path><path data-c="23A8" d="M389 1159Q391 1160 455 1160Q496 1160 498 1159Q501 1158 502 1155Q504 1145 504 924Q504 691 503 682Q494 549 425 439T243 259L229 250L243 241Q349 175 421 66T503 -182Q504 -191 504 -424Q504 -600 504 -629T499 -659H498Q496 -660 444 -660T390 -659Q387 -658 386 -655Q384 -645 384 -425V-282Q384 -176 377 -116T342 10Q325 54 301 92T255 155T214 196T183 222T171 232Q170 233 170 250T171 268Q171 269 191 284T240 331T300 407T354 524T383 679Q384 691 384 925Q384 1152 385 1155L389 1159Z" transform="translate(0,0)" style="stroke-width:3;"></path><svg width="889" height="81" y="1060" x="0" viewBox="0 14.3 889 81"><path data-c="23AA" d="M384 150V266Q384 304 389 309Q391 310 455 310Q496 310 498 309Q502 308 503 298Q504 283 504 150Q504 32 504 12T499 -9H498Q496 -10 444 -10T390 -9Q386 -8 385 2Q384 17 384 150Z" transform="scale(1,0.398)" style="stroke-width:3;"></path></svg><svg width="889" height="81" y="-641" x="0" viewBox="0 14.3 889 81"><path data-c="23AA" d="M384 150V266Q384 304 389 309Q391 310 455 310Q496 310 498 309Q502 308 503 298Q504 283 504 150Q504 32 504 12T499 -9H498Q496 -10 444 -10T390 -9Q386 -8 385 2Q384 17 384 150Z" transform="scale(1,0.398)" style="stroke-width:3;"></path></svg></g><g data-mml-node="mtable" transform="translate(889,0)"><g data-mml-node="mtr" transform="translate(0,1200)"><g data-mml-node="mtd"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1278,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mtd" transform="translate(7332.3,0)"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">一</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">致</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">性</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">验</text><text data-variant="normal" transform="translate(4000,0) scale(1,-1)" font-size="884px" font-family="serif">证</text><text data-variant="normal" transform="translate(5000,0) scale(1,-1)" font-size="884px" font-family="serif">失</text><text data-variant="normal" transform="translate(6000,0) scale(1,-1)" font-size="884px" font-family="serif">败</text></g></g></g><g data-mml-node="mtr" transform="translate(0,0)"><g data-mml-node="mtd"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(778,0)"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1418,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mtd" transform="translate(7332.3,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(746.8,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1691.6,0)"><path data-c="7B" d="M434 -231Q434 -244 428 -250H410Q281 -250 230 -184Q225 -177 222 -172T217 -161T213 -148T211 -133T210 -111T209 -84T209 -47T209 0Q209 21 209 53Q208 142 204 153Q203 154 203 155Q189 191 153 211T82 231Q71 231 68 234T65 250T68 266T82 269Q116 269 152 289T203 345Q208 356 208 377T209 529V579Q209 634 215 656T244 698Q270 724 324 740Q361 748 377 749Q379 749 390 749T408 750H428Q434 744 434 732Q434 719 431 716Q429 713 415 713Q362 710 332 689T296 647Q291 634 291 499V417Q291 370 288 353T271 314Q240 271 184 255L170 250L184 245Q202 239 220 230T262 196T290 137Q291 131 291 1Q291 -134 296 -147Q306 -174 339 -192T415 -213Q429 -213 431 -216Q434 -219 434 -231Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(2191.6,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(2691.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(3136.2,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3636.2,0)"><path data-c="7D" d="M65 731Q65 745 68 747T88 750Q171 750 216 725T279 670Q288 649 289 635T291 501Q292 362 293 357Q306 312 345 291T417 269Q428 269 431 266T434 250T431 234T417 231Q380 231 345 210T298 157Q293 143 292 121T291 -28V-79Q291 -134 285 -156T256 -198Q202 -250 89 -250Q71 -250 68 -247T65 -230Q65 -224 65 -223T66 -218T69 -214T77 -213Q91 -213 108 -210T146 -200T183 -177T207 -139Q208 -134 209 3L210 139Q223 196 280 230Q315 247 330 250Q305 257 280 270Q225 304 212 352L210 362L209 498Q208 635 207 640Q195 680 154 696T77 713Q68 713 67 716T65 731Z" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mtr" transform="translate(0,-1200)"><g data-mml-node="mtd"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1722.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(2111.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(2833.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(3833.9,0)"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(4473.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(5085.1,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(5585.3,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(6054.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mtd" transform="translate(7332.3,0)"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(777.8,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1833.6,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(2580.3,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(3636.1,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g></g></g></g><g data-mml-node="mo" transform="translate(15221.3,0) translate(0 250)"></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;overflow:hidden;width:100%;"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>r</mi><mrow data-mjx-texclass="ORD"><mtext>inject</mtext></mrow></msub><mo>=</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><mtable columnalign="left left" columnspacing="1em" rowspacing=".2em"><mtr><mtd><mo>−</mo><mn>1</mn><mo>,</mo></mtd><mtd><mtext>一致性验证失败</mtext></mtd></mtr><mtr><mtd><mo>−</mo><mi>α</mi><mo>,</mo></mtd><mtd><mi>s</mi><mo>∈</mo><mo fence="false" stretchy="false">{</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo fence="false" stretchy="false">}</mo></mtd></mtr><mtr><mtd><mn>1</mn><mo>−</mo><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mi>α</mi><mo stretchy="false">)</mo><mo>⋅</mo><mi>s</mi><mo>,</mo></mtd><mtd><mn>0</mn><mo>&lt;</mo><mi>s</mi><mo>&lt;</mo><mn>1</mn></mtd></mtr></mtable><mo data-mjx-texclass="CLOSE" fence="true" stretchy="true" symmetric="true"></mo></mrow></math></mjx-assistive-mml></mjx-container></li></ul></div><h4 id="修复bug-solver" tabindex="-1">修复Bug(Solver) <a class="header-anchor" href="#修复bug-solver" aria-label="Permalink to &quot;修复Bug(Solver)&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Bug Solver Agent</div><p><strong>Bug 代码构建</strong></p><ul><li><p><code>注入Bug</code>：<code>应用bug_inject.diff</code></p></li><li><p><code>掩盖测试</code>：<code>应用test_weaken.diff</code></p></li><li><p>高阶Bug(可选)：应用<code>pred_patch.diff</code></p></li><li><p><code>销毁证据</code>：不能保留.git 历史，防止Solver查看git diff或 git log</p></li></ul><p><strong>Prompt 设计</strong></p><ul><li>Issue 很难写、数据少，因此<code>不使用自然语言描述</code>。</li><li>给模型看代码差异：<code>test_weaken.diff</code>的反转版。 <ul><li><code>请修复源代码</code>，<code>保证把这个测试加回去</code>，<code>代码能跑通</code>。</li></ul></li></ul><p><strong>修复过程</strong></p><ul><li>输入：坏代码库 + 请修好它的初始Prompt</li><li>过程：<code>思考</code> -&gt; <code>调用工具</code> -&gt; <code>环境交互运行测试</code>，<code>迭代循环</code></li><li>输出：<code>pred_patch.diff</code></li></ul><p><strong>奖励设计</strong></p><ul><li>所有测试都通过，得1分。<mjx-container tabindex="0" class="MathJax" jax="SVG" display="true" style="direction:ltr;display:block;text-align:center;margin:1em 0;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-2.148ex;" xmlns="http://www.w3.org/2000/svg" width="28.709ex" height="5.428ex" role="img" focusable="false" viewBox="0 -1449.5 12689.6 2399" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(484,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" style="stroke-width:3;"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(394,0)" style="stroke-width:3;"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(894,0)" style="stroke-width:3;"></path><path data-c="76" d="M338 431Q344 429 422 429Q479 429 503 431H508V385H497Q439 381 423 345Q421 341 356 172T288 -2Q283 -11 263 -11Q244 -11 239 -2Q99 359 98 364Q93 378 82 381T43 385H19V431H25L33 430Q41 430 53 430T79 430T104 429T122 428Q217 428 232 431H240V385H226Q187 384 184 370Q184 366 235 234L286 102L377 341V349Q377 363 367 372T349 383T335 385H331V431H338Z" transform="translate(1172,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1700,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(2327.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mrow" transform="translate(3383.6,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7B" d="M618 -943L612 -949H582L568 -943Q472 -903 411 -841T332 -703Q327 -682 327 -653T325 -350Q324 -28 323 -18Q317 24 301 61T264 124T221 171T179 205T147 225T132 234Q130 238 130 250Q130 255 130 258T131 264T132 267T134 269T139 272T144 275Q207 308 256 367Q310 436 323 519Q324 529 325 851Q326 1124 326 1154T332 1205Q369 1358 566 1443L582 1450H612L618 1444V1429Q618 1413 616 1411L608 1406Q599 1402 585 1393T552 1372T515 1343T479 1305T449 1257T429 1200Q425 1180 425 1152T423 851Q422 579 422 549T416 498Q407 459 388 424T346 364T297 318T250 284T214 264T197 254L188 251L205 242Q290 200 345 138T416 3Q421 -18 421 -48T423 -349Q423 -397 423 -472Q424 -677 428 -694Q429 -697 429 -699Q434 -722 443 -743T465 -782T491 -816T519 -845T548 -868T574 -886T595 -899T610 -908L616 -910Q618 -912 618 -928V-943Z" style="stroke-width:3;"></path></g><g data-mml-node="mtable" transform="translate(750,0)"><g data-mml-node="mtr" transform="translate(0,600)"><g data-mml-node="mtd"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(500,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mtd" transform="translate(2556,0)"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">通</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">过</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">所</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">有</text><text data-variant="normal" transform="translate(4000,0) scale(1,-1)" font-size="884px" font-family="serif">测</text><text data-variant="normal" transform="translate(5000,0) scale(1,-1)" font-size="884px" font-family="serif">试</text></g></g></g><g data-mml-node="mtr" transform="translate(0,-600)"><g data-mml-node="mtd"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1278,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mtd" transform="translate(2556,0)"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">其</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">他</text></g></g></g></g><g data-mml-node="mo" transform="translate(9306,0) translate(0 250)"></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;overflow:hidden;width:100%;"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>r</mi><mrow data-mjx-texclass="ORD"><mtext>solve</mtext></mrow></msub><mo>=</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><mtable columnalign="left left" columnspacing="1em" rowspacing=".2em"><mtr><mtd><mn>1</mn><mo>,</mo></mtd><mtd><mtext>通过所有测试</mtext></mtd></mtr><mtr><mtd><mo>−</mo><mn>1</mn><mo>,</mo></mtd><mtd><mtext>其他</mtext></mtd></mtr></mtable><mo data-mjx-texclass="CLOSE" fence="true" stretchy="true" symmetric="true"></mo></mrow></math></mjx-assistive-mml></mjx-container></li></ul><p><strong>对抗奖励</strong></p><ul><li><code>Solver</code>：受益于<code>更高的解决率</code></li><li><code>Injector</code>：受益于<code>更低的解决率</code></li></ul></div><h3 id="实验设置-对抗联合学习rl" tabindex="-1">实验设置(对抗联合学习RL) <a class="header-anchor" href="#实验设置-对抗联合学习rl" aria-label="Permalink to &quot;实验设置(对抗联合学习RL)&quot;">​</a></h3><p>✍️<strong>实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li>CWM-sft-32B，<code>没有RL训练过</code></li></ul><p><strong>训练任务/数据</strong></p><ul><li>Baseline：人类的Issue + RL，仓库可能是SWE-B-Verified + SWE-B-Pro里的。</li><li>Self-PlayRL：SSR</li></ul><p><strong>评测任务/数据</strong></p><ul><li>SWE-Bench-Verified, SWE-Bench-Pro</li><li>超参：温度=1，topp=0.95</li></ul><p><strong>算法/策略</strong></p><ul><li><p><code>对抗式联合RL训练</code>。<code>1个LLM</code>，同时<code>生成Bug</code>和<code>修复Bug</code>。</p></li><li><p><code>大Batch</code>、<code>尽量On-Policy</code> (small-policy-staleness)，<code>让梯度更新更稳定</code></p><ul><li>去掉超过8 off-policy的数据</li></ul></li><li><p><code>CWM scaffold</code>：<code>bash</code> + <code>search-replace 编辑器</code></p></li></ul><p><strong>超参</strong></p><ul><li>512 H100，<code>64卡训练</code>，<code>448卡Rollout</code></li><li><code>128k</code></li><li>Global Batch Size：<code>16M token</code>，整体<code>150步</code>，2.5B tokens</li></ul></div><h3 id="关键结果-cwm-32b-sft-对抗rl" tabindex="-1">关键结果(CWM-32B-sft + 对抗RL) <a class="header-anchor" href="#关键结果-cwm-32b-sft-对抗rl" aria-label="Permalink to &quot;关键结果(CWM-32B-sft + 对抗RL)&quot;">​</a></h3><p>🍑<strong>关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><p><strong>模型效果(CWM-32B-sft)</strong></p><ul><li>在SWE-V和SWE-Pro上，<code>SSR方法</code>都超过<code>RL+人类Issue</code>训练的模型，但<code>也没高多少</code>。</li><li><code>SWE-V</code>达<code>51.4分</code>，<code>SWE-P</code>达<code>28.9分</code>。</li></ul><p><strong>重要结论</strong></p><ul><li><code>Self-Play RL</code>比<code>Repair/Injection-Only RL</code> 性能<code>更好</code>，<code>Inject-Only</code> 效果最差。</li><li><code>大幅删除代码的Bug</code>更好比<code>仅改一行代码的Bug</code>的好。<code>后者太简单</code>，学习信号弱。</li><li>由于共享1个Policy，<code>Solver解决率信号</code> <code>对训练效果影响不大</code>。</li></ul><p><strong>关键贡献</strong></p><ul><li><code>Self-Play-RL</code>思想，只需环境+代码， LLM自我博弈，写Bug+修Bug，联合RL训练。</li></ul></div><h3 id="未来方向" tabindex="-1">未来方向 <a class="header-anchor" href="#未来方向" aria-label="Permalink to &quot;未来方向&quot;">​</a></h3><p>⛳ <strong>未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div><p><strong>不足点</strong></p><ul><li><code>Solver可能会作弊</code>，面向测试编程。因为读取了所有测试用例 <ul><li><code>Public Tests 给AI看</code>, <code>Private Tests实际测试</code>。</li></ul></li><li><code>测试单一</code>，仅靠单元测试。 <ul><li>引入<code>高级验证标准</code>。</li></ul></li><li>Injector和Solver是同1个模型，可能导致思维趋同。 <ul><li>引入<code>不同模型博弈</code>，<code>MoE</code>等。</li></ul></li></ul><p><strong>Self-Play 研究方向</strong></p><ul><li><code>更聪明的出题方法</code>。 <ul><li>需要指定Seed，给Injector指定目标，避免随机重复写Bug，保证多样性。</li></ul></li><li>合成<code>复杂的多步骤SWE任务</code>。 <ul><li>多上下文回放、上下文压缩、高阶Bug升级等。</li></ul></li><li>更高效的Long-Horizon SWE训练方法。 <ul><li>目前很长+Outcome RL，存在信用分配问题。</li><li>每跑一公里，就自我检查一下。</li><li>给出结构化建议，比如某一步出错等。</li></ul></li></ul></div><h2 id="_2511-skyrl-agent-39分" tabindex="-1">(2511) SkyRL-Agent(39分) <a class="header-anchor" href="#_2511-skyrl-agent-39分" aria-label="Permalink to &quot;(2511) SkyRL-Agent(39分)&quot;">​</a></h2><p>🌺 <strong>论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">SkyRL-Agent 论文摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2511.16108" target="_blank" rel="noreferrer">paper</a>, <a href="https://github.com/NovaSky-AI/skyrl/tree/main/skyrl-train/examples/mini_swe_agent" target="_blank" rel="noreferrer">SkyRL代码</a>, <a href="https://huggingface.co/NovaSky-AI/SA-SWE-32B" target="_blank" rel="noreferrer">SA-SWE-32B</a>, <a href="https://skyrl.readthedocs.io/en/latest/examples/mini_swe_agent.html" target="_blank" rel="noreferrer">doc</a>, <a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#_2504-r2e-gym-34-4%E5%88%86" target="_blank" rel="noreferrer">R2E-Gym</a>, <a href="http://plmsmile.github.io/posts/llm/industry/mainllm/15-skywork-series.html#_2511-skyrl-agent" target="_blank" rel="noreferrer">论文笔记</a></li></ul><p><strong>核心方法</strong></p><ul><li><code>SkyRL-Agent 框架</code>：<code>Tool-接口</code> + <code>异步Dispatcher</code> + <code>桥接后端</code></li><li><code>SWE-RL实验</code>：<code>AST工具增强 鼓励检索</code> + <code>增加环境提示信息</code> + <code>On-Policy</code> + <code>留一法优势估计</code></li><li><code>数据</code>：<code>4.5k R2E-Gym</code> ，<code>Scaffold</code>：<code>Simple ReAct Agent</code></li></ul><p><strong>模型效果(Qwen3-32B + RL)</strong></p><ul><li><code>纯RL</code>，SWE <code>pass@1 达 39分</code>，相比基模<code>提升15pt</code>。</li><li>超过DeepSWE <code>36分</code> (报告42分)，训练成本降一半。</li><li><code>弱于蒸馏模型</code> SWE-Agent-LM-32B <code>38分</code>。</li><li>泛化性：Terminal-Bench(+2.5%), BrowseComp-Plus(+1.3%), WebArena(+1.2 turns)</li></ul><p><strong>重要结论</strong></p><p><strong>关键贡献</strong></p><ul><li><code>SKyRL-Agent</code> 框架。<code>SkyRL-Agent-SWE 开源实现</code>。</li></ul></div><h2 id="_2511-infcode-没训练模型" tabindex="-1">(2511) InfCode(没训练模型) <a class="header-anchor" href="#_2511-infcode-没训练模型" aria-label="Permalink to &quot;(2511) InfCode(没训练模型)&quot;">​</a></h2><p>🌺 <strong>论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">InfCode 摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2511.16004" target="_blank" rel="noreferrer">paper</a>, <a href="http://plmsmile.github.io/posts/llm/industry/codellm/09-swe-series.html#_2511-infcode-%E6%B2%A1%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B" target="_blank" rel="noreferrer">论文笔记</a></li></ul><p><strong>核心方法</strong></p><ul><li><p><code>框架</code>：<code>对抗式PatchGeneration</code> + <code>Patch Selection</code></p><ul><li><code>对抗</code>生成<code>代码</code>和<code>单元测试</code>：<code>TestGenerator</code> + <code>CodeGenerator</code>，</li></ul></li><li><p><code>没有训练模型</code>。</p></li></ul><p><strong>模型效果</strong></p><ul><li><code>Claude4.5</code> + <code>InfCode</code>：SWE-Verified <code>79.4分</code>。不知尝试了多少次。</li><li>轻微超过<code>TRAE</code>+<code>DoubaoSeedCode</code> <code>78.8分</code></li></ul><p><strong>重要结论</strong></p><ul><li>对抗生成贡献4pt，选择贡献8pt。</li></ul><p><strong>关键贡献</strong></p><ul><li>对抗<code>Bug修复</code>和<code>测试生成</code>的迭代修复框架。</li><li>虽然没有训练模型，但思路挺好的。</li><li>后来的<code>Self-Play SWE-RL</code> 就和其思路相同，但区别是<code>使用了RL训练</code>。</li></ul></div><img src="https://arxiv.org/html/2511.16004v1/x1.png" style="display:block;margin:auto;" width="70%"><p>❓<strong>问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">问题背景</div><p><strong>生成测试比较弱</strong></p><ul><li>不仅依赖原测试，而<code>依赖生成的测试</code>。</li><li>但生成测试：<code>比较弱</code>、<code>无法覆盖边缘+核心情况</code>、<code>导致代码Genertor过拟合</code>等。</li><li>根本原因：把<code>测试生成</code>和<code>Bug修复</code>，作为<code>2个分散的步骤</code>，<code>缺乏联系和验证</code>。</li></ul></div><p>📕<strong>核心方法</strong></p><div class="custom-block note"><div class="custom-block-title">Patch Generation</div><p><strong>Test Generator</strong></p><ul><li>生成测试，找bug，找边缘/核心bug</li></ul><p><strong>Code Generator</strong></p><ul><li>生成代码，修bug，迭代编辑代码</li></ul><p><strong>对抗式迭代修复</strong></p><ul><li>当Code Patch<code>通过测试用例时</code><ul><li>Tes tGenerator：<code>重新分析问题</code>，识别边缘/不足的地方，<code>生成更强的测试用例</code>。</li><li>Code Generator：重新优化代码，以通过测试。</li></ul></li><li>迭代次数：<code>设置上限</code></li></ul></div><div class="custom-block note"><div class="custom-block-title">Patch Selection</div><ul><li>Patch集合：选择所有阶段的Patch，并非只选择最后一个阶段的Patch</li><li>验证方法：放到真实环境中去做执行。</li><li>选择：<code>通过原测试</code> + <code>通过加强版测试</code></li></ul></div><p>✍️<strong>实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li>DeepSeek-V3, Claude 4.5 Sonnet</li></ul><p><strong>训练任务/数据</strong></p><ul><li><code>无需训练</code></li></ul><p><strong>评测任务/数据</strong></p><ul><li>SWE-Verified, SWE-light</li></ul><p><strong>算法/策略</strong></p><ul><li>Scaffold：agent-based, pipeline-based</li></ul><p><strong>超参</strong></p></div><div class="custom-block tip"><div class="custom-block-title">RL环境</div><ul><li>一个Issue 一个Docker环境</li><li>工具箱集合 <ul><li><code>Bash</code>：执行命令，实现任务自动化，运行测试、管理依赖、构建脚本等。</li><li><code>编辑器</code>：文件创建、内容插入、内容替换、指定行检索。</li><li><code>搜索器</code>：ripgrep 命令，高效迭代是目录搜索，支持正则表达式</li><li><code>Submitter</code>：运行git diff 提取并提交补丁内容。</li><li><code>Executor</code>：工具和Docker容器的接口，转发请求、管理输入输出。</li></ul></li></ul></div><p>🍑<strong>关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><p><strong>模型效果(Claude4.5)</strong></p><ul><li><code>Claude4.5</code> + <code>InfCode</code>：SWE-Verified <code>79.4分</code></li><li>轻微超过<code>TRAE</code>+<code>DoubaoSeedCode</code> <code>78.8分</code></li></ul><p><strong>重要结论</strong></p><ul><li><p>InfCode带来提升：<code>InfCode 40.3</code> &gt; <code>KGCompass 36.7</code> &gt; <code>Moatless 30</code>。</p><ul><li>但是你<code>尝试次数也多</code>啊。</li></ul></li><li><p><code>对抗生成</code>贡献<code>4pt</code>，<code>选择</code>贡献<code>8pt</code></p></li></ul><p><strong>关键贡献</strong></p><ul><li>对抗多智能体框架。</li><li>repo-aware的工具套件：增强理解、真实代码操作等。</li></ul></div><p>⛳ <strong>未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div></div><h2 id="_2509-kimi-dev-48分" tabindex="-1">(2509) Kimi-Dev(48分) <a class="header-anchor" href="#_2509-kimi-dev-48分" aria-label="Permalink to &quot;(2509) Kimi-Dev(48分)&quot;">​</a></h2><p>🌺 <strong>论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">Kimi-Dev 论文摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2509.23045" target="_blank" rel="noreferrer">paper</a>, <a href="https://huggingface.co/moonshotai/Kimi-Dev-72B" target="_blank" rel="noreferrer">Kimi-Dev-72B</a>, <a href="https://github.com/MoonshotAI/Kimi-Dev" target="_blank" rel="noreferrer">Kimi-Dev</a>, <a href="http://plmsmile.github.io/posts/llm/industry/codellm/09-swe-series.html#_2509-kimi-dev-48%E5%88%86" target="_blank" rel="noreferrer">论文笔记</a></li></ul><p><strong>核心方法</strong></p><ul><li><p><code>Agentless 训练</code>(3阶段) + <code>SWE-Agent适配</code>(SFT)。</p></li><li><p>Agentless训练：<code>BugFixer</code> + <code>TestWriter</code></p><ul><li><code>MidTrain</code>：<code>Diff Patch</code> + <code>PR Commit</code> + <code>定位推理合成数据</code> +<code>agent交互合成数据</code></li><li><code>CoT SFT</code> ：DeepSeek-R1 蒸馏(SWE-Gym, SWE-bench-extra)</li><li><code>CodeEdit RL</code>：<code>执行结果奖励</code> + <code>难度课程学习</code> + <code>正样本强化</code></li></ul></li><li><p>SWE-Agent适配：<a href="https://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#_2504-swe-smith-swe-agent-lm" target="_blank" rel="noreferrer">5.7k SWE-smith 轨迹数据</a> 做SFT</p></li><li><p><code>训练数据</code>：<code>是不可能开源的</code>。</p></li></ul><p><strong>模型效果(Qwen2.5-72B-Base)</strong></p><ul><li><code>Agentless 训练</code> SWE-verified <code>Pass@1 48分</code>，<code>TTS(40) 达60分</code>。</li><li><code>SWE-Agent SFT适配</code><ul><li><code>Pass@1 48分</code>，优于<a href="https://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#%E5%85%B3%E9%94%AE%E7%BB%93%E6%9E%9C-swe-agent-lm-32b" target="_blank" rel="noreferrer">SWE-Agent-LM-32B </a><code>40.2分</code>；</li><li><code>Pass@10达74分</code>，优于Agentless <code>Pass@30 73.8分</code>，推理次数仅1/3。</li></ul></li></ul><p><strong>重要结论</strong></p><ul><li>Agentless训练可以带来<code>Skill Priors</code>，更好<code>适配SWE-Agent</code></li><li><code>RL的先验最强</code>：做SFT学的快好、做RL效果也更好。</li></ul><p><strong>关键贡献</strong></p><ul><li><code>多阶段CodeAgent训练方法论</code><ul><li><code>Agentless 训练</code>(MT+SFT+RL) + <code>SWE-Agent适配</code>(SFT)。</li><li>先从Agentless打基础，再逐步做Agent，模型不偏科、适应性强。</li></ul></li></ul></div><h3 id="问题背景-1" tabindex="-1">问题背景 <a class="header-anchor" href="#问题背景-1" aria-label="Permalink to &quot;问题背景&quot;">​</a></h3><p>❓<strong>问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">问题背景</div><p><strong>SWE 2条线路各有弊端</strong></p><ul><li><p><code>SWE-Agent/OpenHands</code>：更灵活，<code>端到端难训练</code></p></li><li><p><code>Agentles</code>s：流程模块化更好，更易RLVR训练。但<code>探索空间</code>灵活性<code>有限</code>。</p></li></ul><p><strong>Trade-off</strong></p><ul><li>不从0开始训<code>SWE-agent</code>，先通过<code>Agentless训练</code>诱导出<code>技能先验</code>。</li><li>先用<code>Agentless打基础</code>，再<code>训SWE-agent</code></li></ul></div><h3 id="agentless-训练框架-bugfixer-testwriter" tabindex="-1">Agentless 训练框架(BugFixer+TestWriter) <a class="header-anchor" href="#agentless-训练框架-bugfixer-testwriter" aria-label="Permalink to &quot;Agentless 训练框架(BugFixer+TestWriter)&quot;">​</a></h3><div class="custom-block info"><div class="custom-block-title">Agentless 框架</div><p><strong>BugFixer</strong></p><ul><li><code>生成patch</code>，<code>解决bug</code></li></ul><p><strong>TestWriter</strong></p><ul><li><code>生成单元测试</code>，<code>复现bug</code></li></ul><p><strong>成功标准</strong></p><ul><li><code>Patch</code>(BugFixer) <code>通过</code> <code>测试用例</code>(TestWriter)。修复前：fail；修复后：成功。</li></ul><p><strong>依赖2个技能</strong></p><ul><li><code>问题定位</code>：修Bug<code>找源文件</code>；写测试<code>找测试文件</code>。</li><li><code>代码编辑</code>：修Bug<code>改源文件</code>；写测试<code>插入新测试函数</code>。</li></ul></div><img src="https://arxiv.org/html/2509.23045v3/x3.png" style="display:block;margin:auto;" width="70%"><h3 id="mid-training" tabindex="-1">Mid-Training <a class="header-anchor" href="#mid-training" aria-label="Permalink to &quot;Mid-Training&quot;">​</a></h3><h4 id="midtrain-概览" tabindex="-1">MidTrain 概览 <a class="header-anchor" href="#midtrain-概览" aria-label="Permalink to &quot;MidTrain 概览&quot;">​</a></h4><div class="custom-block info"><div class="custom-block-title">Mid-Training</div><p><strong>基础配置</strong></p><ul><li>模型：<code>Qwen2.5-72B-Base</code></li><li>任务：<code>Next Token Prediction</code></li></ul><p><strong>MidTrain 数据</strong></p><ul><li><code>150B</code> <code>高质量</code>、<code>真实数据</code>。</li><li>数据构成：包括：<code>百万</code>级的<code>Github Issue</code> + <code>PR commit</code>数据。 <ul><li><code>Diff Patch数据</code>：<code>50B</code>，类似Agentless</li><li><code>PR commit 数据</code>：<code>20B</code>，类似SWE-Agent</li><li><code>推理交互 合成数据</code>：20B，<code>上采样4倍</code> 即<code>80B</code>，包括<code>思考推理</code>、<code>agent交互</code>数据。</li></ul></li></ul><p><strong>超参</strong></p><ul><li>Global batch size：256</li><li>上下文长度：<code>32k</code></li><li>学习率：2e-5, cosine decay, 2e-6</li><li>Warmup：3B tokens, Decay：150B tokens</li></ul></div><div class="custom-block info"><div class="custom-block-title">仓库和PR收集</div><ul><li><p><strong>仓库过滤</strong>：<code>低于5star</code>、SWE-bench已包含的仓库。</p></li><li><p><strong>PR 收集</strong>：GithubAPI 查询<code>已合并的PR</code></p><ul><li>丢弃<code>废弃</code>、<code>未审核</code>、<code>被替代</code>的PR。</li></ul></li><li><p><strong>代码变更2种格式</strong></p><ul><li><code>Natural Diff Patch</code> + <code>PR Commit Pack</code></li></ul></li></ul></div><h4 id="diff-patch-数据处理-agentless" tabindex="-1">Diff Patch 数据处理 (Agentless) <a class="header-anchor" href="#diff-patch-数据处理-agentless" aria-label="Permalink to &quot;Diff Patch 数据处理 (Agentless)&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">Diff Patch 数据</div><p><strong>Diff Patch</strong></p><ul><li><code>Search-Replace</code> 格式，<code>模型最终输出</code>，和<code>Agentless</code>一致。</li></ul><p><strong>Issue 描述</strong></p><ul><li>PR <code>关联的Issue内容</code> 或 <code>PR 标题</code>。</li></ul><p><strong>PR 过滤规则</strong></p><ul><li>仅保留<code>py, md, rst</code>文件修改的<code>PR</code></li><li>仅保留<code>python的diff</code>，重写为<code>search-replace块</code></li><li>删除<code>文件新增和删除</code>的PR。</li><li>每个PR <code>修改的文件</code> 不超过<code>3个</code>。</li><li>每个PR的 <code>search-replace</code> 不超过<code>5个</code>。</li></ul><p><strong>4 类Prompt 模板 (Agentless)</strong></p><ul><li><code>BugFixer</code> <strong>定位和修复</strong>，<code>TestWriter</code> <strong>定位和修复</strong>。</li><li>作用：用于后续冷启动、RL、TTS。训练时：Prompt做Mask。</li></ul><p><strong>最终数据规模</strong></p><ul><li><code>50B</code> <code>DiffPatch 数据</code></li></ul></div><h4 id="pr-commit-pack-数据处理-swe-agent" tabindex="-1">PR Commit Pack 数据处理 (SWE-agent) <a class="header-anchor" href="#pr-commit-pack-数据处理-swe-agent" aria-label="Permalink to &quot;PR Commit Pack 数据处理 (SWE-agent)&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">PR Commit Pack</div><p><strong>Commit Pack 说明</strong></p><ul><li>人类的<code>提交序列</code>，每一步包含<code>commit</code> + <code>代码变更</code></li><li>和<code>SWE-Agent</code>相似</li></ul><p><strong>处理逻辑</strong></p><ul><li>仅保留<code>py, md, rst</code>文件修改的<code>PR</code>。</li><li>每个PR 最多<code>修改5个python文件</code></li><li>过滤开发者签名和Github ID</li></ul><p><strong>最终数据规模</strong></p><ul><li><code>20B</code> <code>Commit Pack 数据</code>。</li></ul></div><h4 id="agent推理数据-合成" tabindex="-1">Agent推理数据 合成 <a class="header-anchor" href="#agent推理数据-合成" aria-label="Permalink to &quot;Agent推理数据 合成&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Agent推理数据 合成</div><p><strong>背景</strong></p><ul><li><code>有代码diff数据</code>，但<code>无思考过程</code>，为什么修改这个文件?</li></ul><p><strong>方法</strong></p><ul><li><p>使用<code>LLM去预测修改文件</code>，保留<code>正确预测修改文件</code>的数据。</p></li><li><p>LLM：<code>Qwen2.5-72B-Instruct</code></p><ul><li>但需经过<code>SFT微调提升推理质量</code></li><li>微调数据：<code>DeepSeekR1</code>蒸馏的<code>2k数据</code>。</li></ul></li><li><p>数据：<code>海量Github题目</code>。</p></li><li><p>筛选：仅<code>保留推理正确</code>的数据。</p></li></ul><p><strong>最终数据规模</strong></p><ul><li><code>10B</code> <code>推理合成数据</code></li></ul></div><h4 id="agent交互数据-合成" tabindex="-1">Agent交互数据 合成 <a class="header-anchor" href="#agent交互数据-合成" aria-label="Permalink to &quot;Agent交互数据 合成&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Agent交互数据 合成</div><p><strong>背景</strong></p><ul><li>目的：<code>加强agent能力</code>。</li><li>方法：<code>自定义工具</code>，<code>模拟agent-环境交互</code>，<code>不执行</code>，<code>模仿文件系统操作</code>，<code>降低成本</code>。</li></ul><p><strong>文件定位 (Agentless Stage1)</strong></p><ul><li><code>自定义模拟工具</code>： <ul><li>仅允许<code>文件查看</code>和<code>关键词搜索</code>，<code>禁止shell</code>，<code>无需实际执行</code>。</li><li><code>工具集</code>放在<code>SystemPrompt</code>里。</li></ul></li><li><strong>Rollout模型</strong>：Qwen2.5-72B-Instruct。</li><li><strong>对应后续训练策略</strong>： <ul><li><code>仅对SystemPrompt</code>做<code>Loss Mask</code>，轨迹的<code>action</code>和<code>observation</code>都做学习训练。</li><li>一般<code>环境返回是需要mask的</code>。但这里<code>保留</code>，是为了学习<code>理解环境返回结果</code>。</li></ul></li></ul><p><strong>代码编辑 (Agentless Stage2)</strong></p><ul><li><code>定位结果</code>来自<code>stage1</code>，现在进入<code>stage2</code>做<code>代码编辑</code>。</li><li><code>负样本训练</code><ul><li>故意给出<code>定位错误文件</code>，手动<code>注入Pattern</code>：<code>我意识到，不需要修改这个文件</code>。</li><li><code>增强模型反思能力</code>。</li></ul></li><li><code>PR Commit Pack</code> 转换成<code>轨迹形式</code><ul><li><code>Commit</code>：<code>推理步骤</code>。</li><li><code>Code Update</code>：<code>动作</code>，<code>str_replace</code>、<code>insert</code>工具格式。</li></ul></li><li>Rollout模型：Qwen2.5-72B-Instruct。</li></ul><p><strong>最终数据规模</strong></p><ul><li><code>10B</code> <code>Agent交互数据</code>。</li></ul></div><h3 id="longcot-冷启动" tabindex="-1">LongCoT 冷启动 <a class="header-anchor" href="#longcot-冷启动" aria-label="Permalink to &quot;LongCoT 冷启动&quot;">​</a></h3><div class="custom-block note"><div class="custom-block-title">冷启动</div><p><strong>冷启动数据蒸馏</strong></p><ul><li>任务：<a href="https://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#_2412-swe-gym" target="_blank" rel="noreferrer">SWE-Gym</a>, <code>SWE-bench-extra</code></li><li>角色：<code>Bugfixer</code>， <code>TestWriter</code></li><li>蒸馏模型：<code>DeepSeek-R1-250120</code></li><li>数据量：BugFixer大约2k？</li></ul><p><strong>SFT 效果</strong></p><ul><li>获得<code>推理技能</code>：<code>问题分析</code>、<code>方法规划</code>、<code>自我完善</code>、<code>探索替代方案</code>等。</li></ul></div><h3 id="code-edit-rl" tabindex="-1">Code-Edit RL <a class="header-anchor" href="#code-edit-rl" aria-label="Permalink to &quot;Code-Edit RL&quot;">​</a></h3><h4 id="rl-策略" tabindex="-1">RL 策略 <a class="header-anchor" href="#rl-策略" aria-label="Permalink to &quot;RL 策略&quot;">​</a></h4><div class="custom-block important"><div class="custom-block-title">RL 策略</div><p><strong>背景</strong></p><ul><li>经过<code>MidTrain</code>+<code>LongCoT SFT</code>，模型已具有<code>较强定位能力</code>。</li><li>RL仅关注：<code>代码编辑</code>。</li></ul><p><strong>数据集</strong></p><ul><li>数据源：SWE-Gym, SWE-bench-extra ?</li><li>每<code>1个Prompt</code>均有<code>1个环境</code>。</li><li>数据多样性：使用<code>多种</code> <code>Bug定位结果</code>，作为<code>LLM输入</code>。</li><li>数据难度(<code>课程学习</code>) <ul><li><code>难题标准</code>：<code>pass@16=0</code></li><li><code>简单数据集</code>：<code>1.2k</code>，</li><li><code>难数据</code>：除开简单的</li></ul></li></ul><p><strong>RL策略(GRPO)</strong></p><ul><li><strong>奖励</strong>：只看<code>执行结果</code>，<code>0、1</code>，不看格式注释等内容。 <ul><li><code>BugFixer</code>：<code>通过所有测试</code>得1</li><li><code>TestWriter</code>：Fail2Pass。修复前： <code>有Bug</code>；修复后：<code>无Bug</code>。</li></ul></li><li><strong>课程学习</strong><ul><li><code>先只学简单</code>，待<code>分数超过阈值</code>，再<code>逐渐加入难样本</code>。</li><li><code>每100step</code> 加入<code>500难样本</code>。</li></ul></li><li><strong>正样本强化</strong><ul><li>后期性能进入<code>平台期</code>，很<code>难探索</code>新解法。</li><li>使用<code>之前的正样本</code>，<code>加入迭代</code>，做<code>强化巩固记忆</code>，冲刺效果。</li></ul></li></ul></div><p>正样本强化 后期训练要稳定一些。</p><img src="https://arxiv.org/html/2509.23045v3/figs/sec3_rl_scaling/RL_bugfix_ablation_figure.png" style="display:block;margin:auto;" width="70%"><h4 id="rl-环境" tabindex="-1">RL 环境 <a class="header-anchor" href="#rl-环境" aria-label="Permalink to &quot;RL 环境&quot;">​</a></h4><div class="custom-block caution"><div class="custom-block-title">Sandbox</div><p><strong>并发度</strong></p><ul><li>支持<code>1w 并发</code>，<code>2.5w docker镜像</code>(来自各种数据集)</li></ul><p><strong>特点</strong></p><ul><li><code>Use-and-Destroy</code>：沙盒只为1次执行，任务跑完后，立即摧毁。</li><li>一套<code>自动构建镜像</code>的<code>流水线</code>。</li></ul><p><strong>技术栈 (K8s + Sdecar)</strong></p><ul><li><code>Kubernetes(K8s)</code>：行业标准，容器编排，管理2.5w docker</li><li><code>Sidecar Pattern</code>：边车模式 <ul><li>主容器：跑具体任务代码</li><li>Sidecar容器：辅助工作，收集日志等。</li></ul></li></ul></div><h3 id="swe-agent-适配" tabindex="-1">SWE-Agent 适配 <a class="header-anchor" href="#swe-agent-适配" aria-label="Permalink to &quot;SWE-Agent 适配&quot;">​</a></h3><h4 id="sft-适配" tabindex="-1">SFT 适配 <a class="header-anchor" href="#sft-适配" aria-label="Permalink to &quot;SFT 适配&quot;">​</a></h4><div class="custom-block important"><div class="custom-block-title">SWE-Agent 适配</div><p><strong>背景</strong></p><ul><li><code>Kimi-Dev</code> 基于<code>Agentless训练</code>，<code>已有Skill Priors</code></li><li>但<code>SWE-Agent自由性更高</code>，希望<code>适配SWE-Agent</code></li></ul><p><strong>方法</strong></p><ul><li>SFT 数据集：<code>SWE-smith 轨迹数据</code>，<code>5.7k</code> (Claude蒸馏)</li><li>SFT 微调：<code>64k</code></li><li>推理时：<code>128k</code> + <code>100轮交互</code>。</li></ul></div><h4 id="skill-prior-验证" tabindex="-1">Skill Prior 验证 <a class="header-anchor" href="#skill-prior-验证" aria-label="Permalink to &quot;Skill Prior 验证&quot;">​</a></h4><div class="custom-block important"><div class="custom-block-title">技能先验</div><p><strong>背景</strong></p><ul><li>原则：先验越好，给一点数据，应该就快。</li><li>测试方法，基于<code>SWE-Agent</code><ul><li><code>SFT实验</code>：给<code>不同数量数据做SFT</code>。</li><li><code>RL实验</code>：做<code>1步SFT</code>，然后<code>做RL</code>。</li></ul></li><li>对比：<code>Base</code>、<code>MidTrain模型</code>(MT先验)、<code>SFT模型</code>(SFT先验)、<code>RL模型</code>(先验)。</li></ul><p><strong>RL 模型 (RL先验)</strong></p><ul><li><code>RL先验最好</code>，SFT训练 <code>学的最快</code>、<code>效果最好</code>。</li><li><code>更擅长做长线任务</code>：LongCot转化为Agent长交互能力。 <ul><li>RL 模型到70步，仍然可解新问题；对比Base止于50步。</li></ul></li><li><code>RL实验</code>上，<code>RL先验</code>也<code>比SFT先验</code> <code>好</code>。RL自行悟出<code>解题模式</code> ，不同于Claude。</li></ul><p><strong>Mid-Train 模型 (MT先验)</strong></p><ul><li>SFT 起步慢，但只要数据够，很快追上第一梯队。</li><li>直接做RL，不会使用工具，没有正反馈，训练直接崩溃。说明：<code>冷启动+RL</code>是必要的。</li></ul><p><strong>SFT 模型 (SFT 先验)</strong></p><ul><li>Zero-Shot比RL强，但200条数据时，容易过拟合死记硬背。</li></ul></div><img src="https://arxiv.org/html/2509.23045v3/figs/sec4_main/v-sweeping-new-FINAL.png" style="display:block;margin:auto;" width="70%"><h3 id="test-time-self-play" tabindex="-1">Test-time self-play <a class="header-anchor" href="#test-time-self-play" aria-label="Permalink to &quot;Test-time self-play&quot;">​</a></h3><div class="custom-block caution"><div class="custom-block-title">Test-time self-play</div><p><strong>背景</strong></p><ul><li>RL之后，模型已掌握<code>BugFixer</code>和<code>TestWriter</code>能力。</li><li>测试时，使用self-paly来协调2种能力。</li></ul><p><strong>生成阶段</strong></p><ul><li>遵循Agentless，为每个实例生成<code>40个patch</code>和<code>40个测试</code>。</li><li><strong>BugFixer</strong>：第1个：<code>贪婪解码</code>；剩余39个：<code>温度=1</code> 采样，保证<code>多样性</code>。</li><li><strong>TestWriter</strong>：独立生成<code>40个测试</code>。仅保留<code>代码没修复</code>时<code>能报错的单元测试</code>。 <ul><li>过滤：去掉没有报错的测试。</li></ul></li></ul><p><strong>验证阶段</strong></p><ul><li><p>解法<code>Patch集合</code>：<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:0;" xmlns="http://www.w3.org/2000/svg" width="1.717ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 759 683" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mstyle" fill="blue" stroke="blue"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z" style="stroke-width:3;"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mstyle mathcolor="blue"><mi>B</mi></mstyle></math></mjx-assistive-mml></mjx-container>；单元<code>测试集合</code>：<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:0;" xmlns="http://www.w3.org/2000/svg" width="1.593ex" height="1.532ex" role="img" focusable="false" viewBox="0 -677 704 677" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mstyle" fill="blue" stroke="blue"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z" style="stroke-width:3;"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mstyle mathcolor="blue"><mi>T</mi></mstyle></math></mjx-assistive-mml></mjx-container>。</p></li><li><p><code>每个Patch</code> <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.357ex;" xmlns="http://www.w3.org/2000/svg" width="1.71ex" height="1.927ex" role="img" focusable="false" viewBox="0 -694 756 851.8" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mstyle" fill="red" stroke="red"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(462,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mstyle mathcolor="red"><msub><mi>b</mi><mi>i</mi></msub></mstyle></math></mjx-assistive-mml></mjx-container>，去<code>验证每1个单元测试</code> <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.666ex;" xmlns="http://www.w3.org/2000/svg" width="1.664ex" height="2.082ex" role="img" focusable="false" viewBox="0 -626 735.3 920.2" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mstyle" fill="red" stroke="red"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(394,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z" style="stroke-width:3;"></path></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mstyle mathcolor="red"><msub><mi>t</mi><mi>j</mi></msub></mstyle></math></mjx-assistive-mml></mjx-container>；针对<code>有无补丁2种情况</code></p><ul><li><p>分别记录下<code>报错数</code><mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.566ex;" xmlns="http://www.w3.org/2000/svg" width="4.387ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 1939 1000" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(749,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1138,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1550,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>F</mi><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>和<code>通过数</code><mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.566ex;" xmlns="http://www.w3.org/2000/svg" width="4.391ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 1941 1000" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(751,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1140,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1552,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></p></li><li><p>并计算<code>Fail2Pass</code>, <code>Pass2Pass</code>数量。</p></li></ul></li><li><p>最终Patch <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.357ex;" xmlns="http://www.w3.org/2000/svg" width="1.71ex" height="1.927ex" role="img" focusable="false" viewBox="0 -694 756 851.8" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mstyle" fill="red" stroke="red"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(462,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mstyle mathcolor="red"><msub><mi>b</mi><mi>i</mi></msub></mstyle></math></mjx-assistive-mml></mjx-container>的得分：<code>高FP率</code> + <code>高PP率</code>，<code>能修bug</code> + <code>不会破坏原有功能</code>。</p><mjx-container tabindex="0" class="MathJax" jax="SVG" display="true" style="direction:ltr;display:block;text-align:center;margin:1em 0;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-2.578ex;" xmlns="http://www.w3.org/2000/svg" width="31.09ex" height="6.288ex" role="img" focusable="false" viewBox="0 -1639.6 13741.6 2779.2" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(646,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(1217.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mfrac" transform="translate(2273.5,0)"><g data-mml-node="mrow" transform="translate(220,889.6)"><g data-mml-node="munder"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1089,-285.4) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mi" transform="translate(1597,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2346,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3097,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(3486,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3831,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(4275.7,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(4687.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mrow" transform="translate(990.3,-710)"><g data-mml-node="munder"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1089,-285.4) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mi" transform="translate(1597,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(2346,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2735,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3147,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g><rect width="5276.7" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(8012.4,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mfrac" transform="translate(9012.6,0)"><g data-mml-node="mrow" transform="translate(220,889.6)"><g data-mml-node="munder"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1089,-285.4) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mi" transform="translate(1597,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2348,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3099,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(3488,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3900,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mrow" transform="translate(595.5,-710)"><g data-mml-node="munder"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(1089,-285.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mi" transform="translate(1597,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(2348,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2737,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3149,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g><rect width="4489" height="60" x="120" y="220"></rect></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;overflow:hidden;width:100%;"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>S</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><munder><mo data-mjx-texclass="OP">∑</mo><mi>j</mi></munder><mi>F</mi><mi>P</mi><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo></mrow><mrow><munder><mo data-mjx-texclass="OP">∑</mo><mi>j</mi></munder><mi>F</mi><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo><mfrac><mrow><munder><mo data-mjx-texclass="OP">∑</mo><mi>j</mi></munder><mi>P</mi><mi>P</mi><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow><mrow><munder><mo data-mjx-texclass="OP">∑</mo><mrow data-mjx-texclass="ORD"><mi>j</mi></mrow></munder><mi>P</mi><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></mfrac></math></mjx-assistive-mml></mjx-container></li></ul></div><p>Self-play 效果不如 Pass@N，优于投票。</p><img src="https://arxiv.org/html/2509.23045v3/figs/sec3_sp_scaling/selfplay_figure_v2.png" style="display:block;margin:auto;" width="70%"><h3 id="实验设置-midtrain-sft-rl" tabindex="-1">实验设置(MidTrain+SFT+RL) <a class="header-anchor" href="#实验设置-midtrain-sft-rl" aria-label="Permalink to &quot;实验设置(MidTrain+SFT+RL)&quot;">​</a></h3><p>✍️<strong>实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li>Qwen2.5-72B-Base</li></ul><p><strong>训练任务/数据</strong></p><ul><li><code>MidTrain</code>：<code>150B</code> token，<code>DiffPatch</code> + <code>PR Commit</code> + <code>推理数据</code> + <code>交互数据</code></li><li><code>LongCoT SFT</code>：<code>2k+数据</code>，SWE-Gym + SWE-Bench-extra</li><li><code>Code-Edit RL</code>：<code>1k数据</code>，SWE-Gym + SWE-Bench-extra</li></ul><p><strong>评测任务/数据</strong></p><ul><li>SWE-Verified</li></ul><p><strong>算法/策略</strong></p><ul><li><code>Agentless 框架</code> ：<code>BugFixer</code> + <code>TestWriter</code>，都依赖<code>定位</code>和<code>编辑</code>能力。</li><li><code>Mid-Train</code>：<code>NTP任务</code>，<code>Diff</code>+<code>PR</code>+<code>推理</code>+<code>交互模拟</code>(<code>文件定位</code>和<code>代码编辑</code>)。</li><li><code>SFT</code>：DeepSeekR1 + <code>2角色蒸馏</code>，提升推理技能。</li><li><code>RL (GRPO)</code>：<code>结果奖励</code> + <code>难度课程学习</code> + <code>后期正样本强化</code></li></ul><p><strong>超参</strong></p><ul><li>RL： <code>rollout=10</code>，<code>64k</code></li></ul></div><h3 id="关键结果-qwen2-5-72b-base-midtrain-sft-rl" tabindex="-1">关键结果(Qwen2.5-72B-Base, MidTrain+SFT+RL) <a class="header-anchor" href="#关键结果-qwen2-5-72b-base-midtrain-sft-rl" aria-label="Permalink to &quot;关键结果(Qwen2.5-72B-Base, MidTrain+SFT+RL)&quot;">​</a></h3><p>🍑<strong>关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><p><strong>模型效果(Qwen2.5-72B-Base)</strong></p><ul><li><code>Agentless 训练</code>：SWE-verified <code>pass@1 48分</code>，使用<code>TTS(40)</code>后，达<code>60.4分</code>。</li><li>SWE-Agent SFT适配： <ul><li>SWE <code>pass@1 48分</code>，优于<a href="https://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#%E5%85%B3%E9%94%AE%E7%BB%93%E6%9E%9C-swe-agent-lm-32b" target="_blank" rel="noreferrer">SWE-Agent-LM-32B </a><code>40.2分</code>。</li><li>SWE <code>Pass@10 74分</code>，优于Agentless <code>Pass@30 73.8分</code>，推理次数仅1/3。</li></ul></li></ul><p><strong>重要结论</strong></p><ul><li>Agentless训练可以带来<code>Skill Priors</code>，更好<code>适配SWE-Agent</code></li><li><code>RL的先验最强</code>：做SFT学的快好、做RL效果也更好。</li><li>RL性能和回复长度正相关。</li></ul><p><strong>关键贡献</strong></p><ul><li><code>多阶段CodeAgent训练方法论</code>。<code>Agentless 训练</code>(MT+SFT+RL) + <code>SWE-Agent适配</code>(SFT)。 <ul><li>先从Agentless打基础，再逐步做Agent，模型不偏科、适应性强。</li></ul></li></ul></div><p>MidTrain各阶段，使用2k 冷启动数据后，评测SWE</p><img src="https://arxiv.org/html/2509.23045v3/figs/sec3_mid_training/mid-train_perf.png" style="display:block;margin:auto;" width="70%"><p>RL 效果和训练长度有关。</p><img src="https://arxiv.org/html/2509.23045v3/figs/sec3_rl_scaling/quick_plot_M3_bf.png" style="display:block;margin:auto;" width="70%"><h3 id="未来方向-1" tabindex="-1">未来方向 <a class="header-anchor" href="#未来方向-1" aria-label="Permalink to &quot;未来方向&quot;">​</a></h3><p>⛳ <strong>未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div><ul><li><code>TestWriter 改进</code>：目前生成测试不够全面，需提升质量。</li><li><code>端到端SWE-Agent RL</code>：目前Agent仅做了SFT，未来可做<code>RL</code>。</li><li><code>环境扩展</code>：利用<code>合成环境</code>进一步<code>扩大训练数据规模</code>。</li></ul></div><h2 id="_2508-swe-swiss-45分" tabindex="-1">(2508) SWE-Swiss(45分) <a class="header-anchor" href="#_2508-swe-swiss-45分" aria-label="Permalink to &quot;(2508) SWE-Swiss(45分)&quot;">​</a></h2><p>🌺 <strong>论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">SWE-Swiss 论文摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.notion.so/SWE-Swiss-A-Multi-Task-Fine-Tuning-and-RL-Recipe-for-High-Performance-Issue-Resolution-21e174dedd4880ea829ed4c861c44f88" target="_blank" rel="noreferrer">SWE-Swiss Blog</a>, <a href="https://github.com/zhenyuhe00/SWE-Swiss" target="_blank" rel="noreferrer">SWE-Siwss</a>, <a href="https://huggingface.co/SWE-Swiss/datasets" target="_blank" rel="noreferrer">datasets</a>, <a href="http://plmsmile.github.io/posts/llm/industry/codellm/09-swe-series.html#_2508-swe-swiss-45%E5%88%86" target="_blank" rel="noreferrer">论文笔记</a></li></ul><p><strong>核心方法</strong></p><ul><li><code>3任务SFT数据构建</code>：<code>问题定位</code>+ <code>问题修复</code>+ <code>测试生成</code></li><li><code>2阶段训练方法</code>：<code>3任务SFT</code> + <code>2阶段RL 课程学习</code>，难样本：过滤<code>正确率&gt;90</code>的数据。</li><li><code>3任务-SFT</code> <code>10k轨迹</code> (<code>蒸馏DSR1</code>)，<code>Bug修复-RL</code> <code>12k</code>，来自<code>SWE-Gym</code>,<code>SWE-smith</code>等。</li><li><code>TTS方法</code>：EM + <code>GT代码相似度</code>。</li><li><code>Scaffold</code>：<code>Agentless</code>，<code>不是Agent</code></li></ul><p><strong>模型效果(Qwen2.5-32B-Instruct, SFT+RL)</strong></p><ul><li>SWE-Verified <code>SFT达36</code>，<code>RL达45</code>，<code>RL提升9pt</code>，增加TTS(best-120) 达60分。</li><li>在<code>通用任务</code>、<code>Math任务</code>、<code>代码生成任务</code>上，<code>均有提升</code>。</li></ul><p><strong>重要结论</strong></p><ul><li>虽然<code>训练3任务用SFT</code>，但也<code>可用RL做定位</code>，<code>也很有效果</code>，后续可以基于此。</li></ul><p><strong>关键贡献</strong></p><ul><li><code>开源数据代码</code></li></ul></div><img src="https://www.notion.so/image/attachment%3A491020da-2334-4ce6-9d4a-6c95d88dbb59%3Afigure1.png?table=block&amp;id=226174de-dd48-801a-8fb7-c2cda8e12d3f&amp;spaceId=558c58f3-e263-4a36-8c1e-9fd21d8fda44&amp;width=1420&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><p>❓<strong>问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">问题背景</div><ul><li><code>Agentless</code> 把SWE分解为<code>固定workflow</code></li><li>如何通过提升<code>各子任务能力</code>，来<code>提升SWE效果</code>？</li></ul></div><p>📕<strong>核心方法</strong></p><div class="custom-block note"><div class="custom-block-title">核心方法</div><p><strong>核心思想</strong></p><ul><li><p>提升<code>3技能</code>：<code>定位</code>、<code>修复</code>、<code>单元测试生成</code>。</p></li><li><p><strong>2阶段训练</strong></p><ul><li><p><code>3任务SFT</code>：分别构造SFT数据</p></li><li><p><code>2阶段RL</code>：通过<code>执行反馈</code> 提升<code>修复能力</code></p></li></ul></li></ul></div><h3 id="_3任务sft数据构建-定位-修复-测试生成" tabindex="-1">3任务SFT数据构建(定位+修复+测试生成) <a class="header-anchor" href="#_3任务sft数据构建-定位-修复-测试生成" aria-label="Permalink to &quot;3任务SFT数据构建(定位+修复+测试生成)&quot;">​</a></h3><div class="custom-block note"><div class="custom-block-title">定位+修复+测试生成 SFT数据构建</div><p><strong>背景</strong></p><ul><li>通过提升3任务能力，来提升SWE能力。</li><li>模型：均使用<code>DeepSeek-R1-0528</code>做<code>蒸馏模型</code>。</li></ul><p><strong>问题定位</strong></p><ul><li>数据源：SWE-Bench、SWE-Gym-Raw</li><li>提取<code>GT修改文件</code>。</li><li><strong>LLM预测修改文件</strong>。 <ul><li>输入：<code>Issue</code> + <code>项目结构</code>；输出：<code>需要修改的文件</code></li></ul></li><li>筛选标准：<code>recall=1</code> + <code>预测文件数&lt;5</code></li><li>最终：<code>5.3k 定位数据</code>。</li></ul><p><strong>问题修复</strong></p><ul><li><strong>数据+环境</strong>：<a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#_2412-swe-gym-19-7%E5%88%86" target="_blank" rel="noreferrer">SWE-gym</a>、<a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#_2504-swe-smith-40%E5%88%86-swe-agent-lm" target="_blank" rel="noreferrer">SWE-smith</a>。</li><li><strong>LLM预测Patch</strong>。 <ul><li>输入： <code>Issue </code>+ <code>GT修改文件</code> + <code>相关文件</code>；输出：<code>Patch</code></li></ul></li><li>筛选标准：单元测试。保留通过的。</li><li>最终：<code>3.9k 修复数据</code>。</li></ul><p><strong>测试生成</strong></p><ul><li>数据源：<a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#_2412-swe-gym-19-7%E5%88%86" target="_blank" rel="noreferrer">SWE-gym</a>、<a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#_2504-swe-smith-40%E5%88%86-swe-agent-lm" target="_blank" rel="noreferrer">SWE-smith</a>，同<code>问题修复数据</code>。</li><li><strong>LLM生成单元测试</strong>。</li><li>筛选标准：<code>实际执行测试结果</code>，需<code>和原测试保持一致</code>。</li><li>最终：<code>1k 单元测试生成数据</code>。</li></ul></div><img src="https://www.notion.so/image/attachment%3A24d3c1fd-2566-4a39-804d-99defb9fffa8%3AWX20250707-1428302x.png?table=block&amp;id=226174de-dd48-80bf-9730-ca54187ed782&amp;spaceId=558c58f3-e263-4a36-8c1e-9fd21d8fda44&amp;width=1420&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><h3 id="_2阶段训练-3任务sft-2阶段rl" tabindex="-1">2阶段训练(3任务SFT + 2阶段RL) <a class="header-anchor" href="#_2阶段训练-3任务sft-2阶段rl" aria-label="Permalink to &quot;2阶段训练(3任务SFT + 2阶段RL)&quot;">​</a></h3><div class="custom-block info"><div class="custom-block-title">2阶段训练 (SFT + RL)</div><p><strong>3任务SFT</strong></p><ul><li>10k SFT数据集。</li><li>把<code>不同的多任务能力</code>，训进<code>一个单模型</code>。</li></ul><p><strong>2阶段RL (课程学习)</strong></p><ul><li><code>奖励设计</code>：<code>通过单元测试</code>：<code>1</code>，<code>其他</code>：<code>-1</code></li><li><code>阶段1</code>：训200步，<code>全部数据</code>。</li><li><code>阶段2</code>：训90步，<code>过滤正确率超90%的样本</code>。</li></ul></div><img src="https://www.notion.so/image/attachment%3Af77aac41-24be-4d6f-befd-3a5be530979f%3Aswe_bench_performance_with_dashed_line.png?table=block&amp;id=240174de-dd48-80f7-bf2a-d6af90915244&amp;spaceId=558c58f3-e263-4a36-8c1e-9fd21d8fda44&amp;width=1420&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><h3 id="测试和tts" tabindex="-1">测试和TTS <a class="header-anchor" href="#测试和tts" aria-label="Permalink to &quot;测试和TTS&quot;">​</a></h3><div class="custom-block info"><div class="custom-block-title">TTS</div><p><strong>单Patch生成</strong></p><ul><li>2阶段 <code>定位</code> + <code>修复</code>。 <ul><li>定位模块：先<code>预测相关文件</code></li><li>修复模块：<code>预测文件</code> + <code>检索文件</code> --&gt; <code>生成修复Patch</code>，检索使用text-embedding3-small</li></ul></li></ul><p><strong>多Patch + TTS</strong></p><ul><li><p>核心：<code>生成多个patch</code> + <code>过滤patch</code> + <code>选择最优patch</code>。</p></li><li><p>过滤patch：<code>原测试过滤</code> + <code>生成测试过滤</code></p><ul><li>生成测试：Issue+预测相关文件，生成测试用例。测试用例通过一致性选择过滤。</li></ul></li><li><p>最优patch选择：</p><ul><li><p>传统self-consistency：基于EM做投票选择，数学居多。</p></li><li><p>增强self-consitency：除<code>EM</code>以外，增加与<code>GT代码相似度</code>得分。</p><mjx-container tabindex="0" class="MathJax" jax="SVG" display="true" style="direction:ltr;display:block;text-align:center;margin:1em 0;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.566ex;" xmlns="http://www.w3.org/2000/svg" width="35.456ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 15671.7 1000" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z" style="stroke-width:3;"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(556,0)" style="stroke-width:3;"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1000,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(1500,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1892,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(2336,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2725,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3158,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3824.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(4880.6,0)"><g data-mml-node="mtext"><path data-c="53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z" style="stroke-width:3;"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(556,0)" style="stroke-width:3;"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1000,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(1500,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1892,0)" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(2369,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="45" d="M128 619Q121 626 117 628T101 631T58 634H25V680H597V676Q599 670 611 560T625 444V440H585V444Q584 447 582 465Q578 500 570 526T553 571T528 601T498 619T457 629T411 633T353 634Q266 634 251 633T233 622Q233 622 233 621Q232 619 232 497V376H286Q359 378 377 385Q413 401 416 469Q416 471 416 473V493H456V213H416V233Q415 268 408 288T383 317T349 328T297 330Q290 330 286 330H232V196V114Q232 57 237 52Q243 47 289 47H340H391Q428 47 452 50T505 62T552 92T584 146Q594 172 599 200T607 247T612 270V273H652V270Q651 267 632 137T610 3V0H25V46H58Q100 47 109 49T128 61V619Z" style="stroke-width:3;"></path><path data-c="4D" d="M132 622Q125 629 121 631T105 634T62 637H29V683H135Q221 683 232 682T249 675Q250 674 354 398L458 124L562 398Q666 674 668 675Q671 681 683 682T781 683H887V637H854Q814 636 803 634T785 622V61Q791 51 802 49T854 46H887V0H876Q855 3 736 3Q605 3 596 0H585V46H618Q660 47 669 49T688 61V347Q688 424 688 461T688 546T688 613L687 632Q454 14 450 7Q446 1 430 1T410 7Q409 9 292 316L176 624V606Q175 588 175 543T175 463T175 356L176 86Q187 50 261 46H278V0H269Q254 3 154 3Q52 3 37 0H29V46H46Q78 48 98 56T122 69T132 86V622Z" transform="translate(681,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(8429.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(8818.5,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(9251.5,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(9862.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(10863,0)"><g data-mml-node="mtext"><path data-c="53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z" style="stroke-width:3;"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(556,0)" style="stroke-width:3;"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1000,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(1500,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1892,0)" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(2369,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z" style="stroke-width:3;"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(556,0)" style="stroke-width:3;"></path><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(834,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(14460.7,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(14849.7,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(15282.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;overflow:hidden;width:100%;"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Score</mtext><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mtext>Score</mtext><mrow data-mjx-texclass="ORD"><mtext>EM</mtext></mrow></msub><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo><mo>+</mo><msub><mtext>Score</mtext><mrow data-mjx-texclass="ORD"><mtext>Sim</mtext></mrow></msub><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></li></ul></li></ul></div><img src="https://www.notion.so/image/attachment%3Abeeb51dc-f5c8-48b3-bf28-48e4892d223d%3A%E5%9B%BE4.png?table=block&amp;id=242174de-dd48-80fd-8cd8-d89961f18e46&amp;spaceId=558c58f3-e263-4a36-8c1e-9fd21d8fda44&amp;width=1420&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><h3 id="实验设置和结果-qwen2-5-32b-instruct-sft-rl" tabindex="-1">实验设置和结果(Qwen2.5-32B-Instruct+SFT+RL) <a class="header-anchor" href="#实验设置和结果-qwen2-5-32b-instruct-sft-rl" aria-label="Permalink to &quot;实验设置和结果(Qwen2.5-32B-Instruct+SFT+RL)&quot;">​</a></h3><p>✍️<strong>实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li>Qwen2.5-32B-Instruct</li></ul><p><strong>训练任务/数据</strong></p><ul><li>SFT(定位+修复+测试生成)：<code>10k 数据</code></li><li>RL(修复)：<code>SWE-Gym</code>, <code>SWE-smith</code></li></ul><p><strong>评测任务/数据</strong></p><ul><li>SWE-verified</li></ul><p><strong>算法/策略</strong></p><ul><li>Scaffold：<code>Agentless</code></li><li><code>3任务SFT</code> + <code>RL</code></li><li>DAPO技巧：<code>no kl loss</code>，<code>clip_higher</code>, <code>动态采样</code>，<code>token-level loss</code></li></ul><p><strong>超参</strong></p></div><p>🍑<strong>关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><p><strong>模型效果(Qwen2.5-32B-Instruct, SFT+RL)</strong></p><ul><li>SWE-Verified <code>SFT达36</code>，<code>RL达45</code>，<code>RL提升9pt</code>。</li><li>增加TTS后，<code>Best-of-120</code>：<code>达60分</code>。</li><li>在<code>通用任务</code>、<code>Math任务</code>、<code>代码生成任务</code>上，<code>均有提升</code>。 <ul><li>Instruct &lt; SFT &lt; SFT + RL</li></ul></li></ul><p><strong>重要结论</strong></p><ul><li>虽然<code>训练3任务用SFT</code>，但也<code>可用RL做定位</code>，<code>也很有效果</code>，后续可以基于此。</li></ul><p><strong>关键贡献</strong></p><ul><li>完全开源。</li></ul></div><p>⛳ <strong>未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div></div><h2 id="_2508-nebius-swe-agent-39分-筛选swe-rebench数据" tabindex="-1">(2508) NEBIUS SWE-Agent (39分, 筛选SWE-rebench数据) <a class="header-anchor" href="#_2508-nebius-swe-agent-39分-筛选swe-rebench数据" aria-label="Permalink to &quot;(2508) NEBIUS SWE-Agent (39分, 筛选SWE-rebench数据)&quot;">​</a></h2><p><strong>🌺 论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">NEBIUS-SWE论文摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2508.03501" target="_blank" rel="noreferrer">paper</a>, <a href="https://nebius.com/blog/posts/training-and-search-for-software-engineering-agents" target="_blank" rel="noreferrer">blog</a>, <a href="https://huggingface.co/nebius" target="_blank" rel="noreferrer">nebius datasets</a>, <a href="http://plmsmile.github.io/posts/llm/industry/codellm/09-swe-series.html#_2508-nebius-swe-agent-39%E5%88%86-%E7%AD%9B%E9%80%89swe-rebench%E6%95%B0%E6%8D%AE" target="_blank" rel="noreferrer">笔记</a></li></ul><p><strong>核心方法</strong></p><ul><li><p><code>SWE-rebench数据筛选</code>：<code>过滤有误数据</code>+<code>控制复杂度</code>+<code>LLM质量评估</code>+<code>确定性测试</code></p></li><li><p><code>数据</code>：<code>7k任务</code> + <code>自蒸馏6.5k轨迹数据</code> + <code>Verified-50</code>做快速验证</p></li><li><p><code>RFT冷启动</code>： <code>Mask错误格式动作</code>，仅<code>学习有效动作</code>。</p></li><li><p><code>2阶段RL课程学习</code></p><ul><li><code>65k</code> -&gt; <code>131k</code>，<code>7k全部样本</code> -&gt; <code>2k难度样本</code></li><li><code>难样本</code>：过滤阶段1 <code>正确率 &gt; 2/3</code>、<code>正确率=0</code>的样本</li></ul></li><li><p><code>DAPO技巧</code></p><ul><li><code>超长步数惩罚</code> + <code>去掉0优势样本</code> + <code>Token-level Loss</code>，<code>阶段2减小CLIP-Higher</code></li><li><code>步数惩罚</code>：鼓励高效和<code>惩罚死循环</code>动作</li></ul></li><li><p><code>Scaffold</code>：<code>SWE-Agent</code></p></li></ul><p><strong>模型效果 (Qwen2.5-72B-Inst, SFT+2RL)</strong></p><ul><li>训练后，SWE <code>pass@1达39分</code>，<code>pass@10达58分</code>，<code>持平DeeepSeek-V3-0324</code></li></ul><p><strong>重要结论</strong></p><ul><li><code>不要过滤超长样本</code>，<code>要惩罚死循环</code>。</li><li><code>训推不一致</code>：采样<code>topk, topp</code>导致<code>词表被截断</code>，解法：<code>关闭filter</code>。</li><li>未来难题方向：<code>长程信用分配问题</code>、<code>盲目自信问题</code>。</li></ul></div><h3 id="swe方法及挑战" tabindex="-1">SWE方法及挑战 <a class="header-anchor" href="#swe方法及挑战" aria-label="Permalink to &quot;SWE方法及挑战&quot;">​</a></h3><p><strong>❓问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">目前SWE方法</div><ul><li>复杂的scaffold + 闭源LLM</li><li>大量的<code>Test-Time-Scaling</code>技术，(2410)<a href="https://arxiv.org/abs/2410.20285" target="_blank" rel="noreferrer">SWE-search</a></li><li>使用<code>强LLM做数据蒸馏</code> <code>微调小模型</code><ul><li>(2504) <a href="https://arxiv.org/abs/2504.21798" target="_blank" rel="noreferrer">SWE-smith</a>, (2506) <a href="http://plmsmile.github.io/posts/llm/industry/mainllm/15-skywork-series.html#_2506-skywork-swe" target="_blank" rel="noreferrer">Skywork-SWE</a>, (2412) <a href="https://arxiv.org/abs/2412.21139" target="_blank" rel="noreferrer">SWE-Gym</a></li></ul></li></ul></div><div class="custom-block warning"><div class="custom-block-title">SWE 存在挑战</div><ul><li><code>Long-Horizon 多轮交互</code><ul><li>2阶段RL，<a href="https://plmsmile.github.io/posts/llm/basic/08-llm-position-embedding.html#yarn" target="_blank" rel="noreferrer">YaRN 技术</a> 扩展至131k</li></ul></li><li><code>反馈复杂</code>：反馈一大堆报错，可能看不懂 <ul><li>RFT 冷启动</li></ul></li><li><code>数据难以构建</code><ul><li>对策：使<code>用rebench做清洗</code>，一套<code>清洗策略</code></li></ul></li><li><code>奖励稀疏</code><ul><li>对策：GRPO/DAPO，Token-Level Loss</li></ul></li><li><code>评估贵且有噪声</code>：跑1次要几分钟，还学不到东西； <ul><li>对策：<code>Verified-50子集</code>、<code>去掉Noisy不稳定数据</code></li></ul></li></ul></div><img src="https://arxiv.org/html/2508.03501v1/figures/problem_illustration.png" style="display:block;margin:auto;" width="70%"><h3 id="核心方法" tabindex="-1">核心方法 <a class="header-anchor" href="#核心方法" aria-label="Permalink to &quot;核心方法&quot;">​</a></h3><p><strong>📕核心方法</strong></p><h4 id="筛选-swe-rebench数据" tabindex="-1">筛选 SWE-rebench数据 <a class="header-anchor" href="#筛选-swe-rebench数据" aria-label="Permalink to &quot;筛选 SWE-rebench数据&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">SWE-ReBench 数据筛选</div><p><strong>SWE-ReBench</strong></p><ul><li>原始：<code>21k任务</code> + <code>3.4k python仓库</code></li><li>筛选后：<code>7.2k 任务</code></li></ul><p><strong>数据筛选策略</strong></p><ul><li><code>过滤任务本身有误的数据</code>：如属性错误、引用错误导致不能通过测试等。</li><li><code>控制复杂度</code>：<code>修改文件数&lt;7</code> + <code>修改代码数&lt;500行</code></li><li><code>LLM评估质量</code>：去掉问题<code>描述不清楚</code>、任务<code>过于复杂</code>、<code>test patch有问题</code>的数据。</li><li><code>确定性测试</code>：执行50次，需要结果一致，不一致则过滤。</li></ul><p><strong>评测集</strong></p><ul><li><code>Verified-50</code>：从SWE-verified 随机选择 <code>50个任务</code>，做训练时验证。</li><li><code>SWE-rebench 5月和6月版</code>：</li></ul></div><h4 id="环境动作空间-swe-agent-scaffold-react" tabindex="-1">环境动作空间 (SWE-Agent Scaffold + ReAct) <a class="header-anchor" href="#环境动作空间-swe-agent-scaffold-react" aria-label="Permalink to &quot;环境动作空间 (SWE-Agent Scaffold + ReAct)&quot;">​</a></h4><div class="custom-block info"><div class="custom-block-title">SWE-Agent Scaffold + ReAct</div><p><strong>动作空间</strong></p><ul><li><code>任意shell命令</code>：ls, cat, grep等。</li><li><code>编辑命令</code>：新闻部替换指定行</li><li><code>自定义搜索和查找</code>：search_file、open、`goto</li><li><code>submit</code>：终止</li></ul><p><strong>SWE Task</strong></p><ul><li><code>Issue描述</code>、<code>测试套件</code>、<code>sandbox 环境快照</code></li></ul></div><h4 id="rft冷启动-筛选正确轨迹-mask错误动作" tabindex="-1">RFT冷启动 (筛选正确轨迹+Mask错误动作) <a class="header-anchor" href="#rft冷启动-筛选正确轨迹-mask错误动作" aria-label="Permalink to &quot;RFT冷启动 (筛选正确轨迹+Mask错误动作)&quot;">​</a></h4><div class="custom-block info"><div class="custom-block-title">Rejection Finetuning 冷启动</div><p><strong>背景</strong></p><ul><li>Qwen2.5-72B-Instruct：<code>SWE 仅11分</code>，因为<code>指令格式不遵循</code>。</li></ul><p><strong>方法</strong></p><ul><li>在选定的<code>SWE-rebench任务</code>上，<code>Rollout 10次</code>，仅保留<code>成功的6.5k轨迹</code></li><li>SFT <code>1个epoch</code>：<code>Mask 错误格式动作</code>，<code>只学习有效动作</code>。</li><li>准确率由<code>11</code>提升至<code>20分</code>。</li></ul></div><img src="https://arxiv.org/html/2508.03501v1/figures/rft_trajectory_example.png" style="display:block;margin:auto;" width="70%"><h4 id="dapo算法-2阶段rl训练" tabindex="-1">DAPO算法+2阶段RL训练 <a class="header-anchor" href="#dapo算法-2阶段rl训练" aria-label="Permalink to &quot;DAPO算法+2阶段RL训练&quot;">​</a></h4><div class="custom-block important"><div class="custom-block-title">GRPO 算法配置</div><p><strong>奖励配置</strong></p><ul><li><p>整体奖励：<code>稀疏奖励</code> + <code>步数超长惩罚</code>，全部正确才为1</p><mjx-container tabindex="0" class="MathJax" jax="SVG" display="true" style="direction:ltr;display:block;text-align:center;margin:1em 0;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.8ex;" xmlns="http://www.w3.org/2000/svg" width="27.454ex" height="2.497ex" role="img" focusable="false" viewBox="0 -750 12134.7 1103.5" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mstyle" fill="blue" stroke="blue"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(792,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" style="stroke-width:3;"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(306,0)" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(584,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1140,0)" style="stroke-width:3;"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(1640,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(2198.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2587.2,0)"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3104.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(3771,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(4826.8,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(792,-176.7) scale(0.707)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mi" transform="translate(5943.9,0)"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(6460.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(7072.1,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mstyle" fill="red" stroke="red" transform="translate(8072.3,0)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(792,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(722,0)" style="stroke-width:3;"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(1278,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1778,0)" style="stroke-width:3;"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(2167,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(2767.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(3156.5,0)"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3673.5,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;overflow:hidden;width:100%;"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mstyle mathcolor="blue"><msub><mi>R</mi><mrow data-mjx-texclass="ORD"><mtext>final</mtext></mrow></msub><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo></mstyle><mo>=</mo><msub><mi>R</mi><mo stretchy="false">(</mo></msub><mi>τ</mi><mo stretchy="false">)</mo><mo>+</mo><mstyle mathcolor="red"><msub><mi>R</mi><mrow data-mjx-texclass="ORD"><mtext>length</mtext></mrow></msub><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo></mstyle></math></mjx-assistive-mml></mjx-container></li><li><p><code>步数超长惩罚</code>：<code>惩罚死循环</code> + <code>鼓励高效方案</code></p><ul><li><mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.357ex;" xmlns="http://www.w3.org/2000/svg" width="4.486ex" height="1.889ex" role="img" focusable="false" viewBox="0 -677 1982.9 834.8" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(617,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(833,0)" style="stroke-width:3;"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(1333,0)" style="stroke-width:3;"></path></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mrow data-mjx-texclass="ORD"><mtext>max</mtext></mrow></msub></math></mjx-assistive-mml></mjx-container>：<code>最大步数</code>，<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.355ex;" xmlns="http://www.w3.org/2000/svg" width="3.867ex" height="1.901ex" role="img" focusable="false" viewBox="0 -683 1709.4 840.1" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" style="stroke-width:3;"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(389,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(945,0)" style="stroke-width:3;"></path></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>L</mi><mrow data-mjx-texclass="ORD"><mtext>thr</mtext></mrow></msub></math></mjx-assistive-mml></mjx-container>：<code>开始惩罚的阈值</code>。类似<a href="https://plmsmile.github.io/posts/llm/rl/theory/11-grpo-series.html#overlong-%E5%A5%96%E5%8A%B1%E8%AE%BE%E8%AE%A1" target="_blank" rel="noreferrer">DAPO 长度超长惩罚</a>。</li></ul><mjx-container tabindex="0" class="MathJax" jax="SVG" display="true" style="direction:ltr;display:block;text-align:center;margin:1em 0;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-2.827ex;" xmlns="http://www.w3.org/2000/svg" width="34.382ex" height="6.785ex" role="img" focusable="false" viewBox="0 -1749.5 15197 2999" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(792,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(722,0)" style="stroke-width:3;"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(1278,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1778,0)" style="stroke-width:3;"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(2167,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(2767.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(3156.5,0)"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3673.5,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(4340.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mrow" transform="translate(5396,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7B" d="M661 -1243L655 -1249H622L604 -1240Q503 -1190 434 -1107T348 -909Q346 -897 346 -499L345 -98L343 -82Q335 3 287 87T157 223Q146 232 145 236Q144 240 144 250Q144 265 145 268T157 278Q242 333 288 417T343 583L345 600L346 1001Q346 1398 348 1410Q379 1622 600 1739L622 1750H655L661 1744V1727V1721Q661 1712 661 1710T657 1705T648 1700T630 1690T602 1668Q589 1659 574 1643T531 1593T484 1508T459 1398Q458 1389 458 1001Q458 614 457 605Q441 435 301 316Q254 277 202 251L250 222Q260 216 301 185Q443 66 457 -104Q458 -113 458 -501Q458 -888 459 -897Q463 -944 478 -988T509 -1060T548 -1114T580 -1149T602 -1167Q620 -1183 634 -1192T653 -1202T659 -1207T661 -1220V-1226V-1243Z" style="stroke-width:3;"></path></g><g data-mml-node="mtable" transform="translate(806,0)"><g data-mml-node="mtr" transform="translate(0,851.5)"><g data-mml-node="mtd"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(500,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mtd" transform="translate(4879,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(278,0)"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(795,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1350.8,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(2406.6,0)"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" style="stroke-width:3;"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(389,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(945,0)" style="stroke-width:3;"></path></g></g></g></g></g><g data-mml-node="mtr" transform="translate(0,-644.9)"><g data-mml-node="mtd"><g data-mml-node="mfrac"><g data-mml-node="mstyle" transform="translate(541.7,516.4) scale(0.707)" fill="red" stroke="red"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" style="stroke-width:3;"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(389,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(945,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(1709.4,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(2487.4,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2765.4,0)"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3282.4,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mstyle" transform="translate(220,-345) scale(0.707)" fill="blue" stroke="blue"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(617,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(833,0)" style="stroke-width:3;"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(1333,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(1982.9,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(2760.9,0)"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" style="stroke-width:3;"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(389,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(945,0)" style="stroke-width:3;"></path></g></g></g></g><rect width="3361" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(3601,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mtd" transform="translate(4879,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(278,0)"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(795,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1350.8,0)"><path data-c="2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(2406.6,0)"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" style="stroke-width:3;"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(389,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(945,0)" style="stroke-width:3;"></path></g></g></g></g></g></g><g data-mml-node="mo" transform="translate(9801,0) translate(0 250)"></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;overflow:hidden;width:100%;"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>R</mi><mrow data-mjx-texclass="ORD"><mtext>length</mtext></mrow></msub><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo><mo>=</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><mtable columnalign="left left" columnspacing="1em" rowspacing=".2em"><mtr><mtd><mn>0</mn><mo>,</mo></mtd><mtd><mo data-mjx-texclass="ORD" stretchy="false">|</mo><mi>τ</mi><mo data-mjx-texclass="ORD" stretchy="false">|</mo><mo>&lt;</mo><msub><mi>L</mi><mrow data-mjx-texclass="ORD"><mtext>thr</mtext></mrow></msub></mtd></mtr><mtr><mtd><mfrac><mstyle mathcolor="red"><msub><mi>L</mi><mrow data-mjx-texclass="ORD"><mtext>thr</mtext></mrow></msub><mo>−</mo><mo data-mjx-texclass="ORD" stretchy="false">|</mo><mi>τ</mi><mo data-mjx-texclass="ORD" stretchy="false">|</mo></mstyle><mstyle mathcolor="blue"><msub><mi>T</mi><mrow data-mjx-texclass="ORD"><mtext>max</mtext></mrow></msub><mo>−</mo><msub><mi>L</mi><mrow data-mjx-texclass="ORD"><mtext>thr</mtext></mrow></msub></mstyle></mfrac><mo>,</mo></mtd><mtd><mo data-mjx-texclass="ORD" stretchy="false">|</mo><mi>τ</mi><mo data-mjx-texclass="ORD" stretchy="false">|</mo><mo>≥</mo><msub><mi>L</mi><mrow data-mjx-texclass="ORD"><mtext>thr</mtext></mrow></msub></mtd></mtr></mtable><mo data-mjx-texclass="CLOSE" fence="true" stretchy="true" symmetric="true"></mo></mrow></math></mjx-assistive-mml></mjx-container></li></ul><p><strong>GRPO 算法配置</strong></p><ul><li>整体同<a href="https://plmsmile.github.io/posts/llm/rl/theory/11-grpo-series.html#_2504-dapo-seed" target="_blank" rel="noreferrer">DAPO</a>：<code>token-level-loss</code></li><li>Group-10 计算，但<code>去掉优势为0的样本</code>。</li><li>rollout=10</li></ul></div><div class="custom-block important"><div class="custom-block-title">2阶段RL训练</div><p><strong>2阶段RL训练</strong></p><ul><li>阶段1：<code>65k</code>，<code>40轮</code>，<code>7.2k问题</code>，<code>bs=128</code>，<code>clip=[0.2,0.3]</code>，构建<code>baseline</code></li><li>阶段2：<code>131k</code>，<code>80轮</code>，<code>2k问题</code>，<code>bs=256</code>，<code>clip=[0.2,0.26]</code>，处理<code>更复杂问题</code></li></ul><p><strong>阶段2优化</strong></p><ul><li><code>降低clip上限</code>：更新更稳定，<code>防止模型跑偏</code>，(2506) <a href="https://www.alphaxiv.org/abs/2506.10910" target="_blank" rel="noreferrer">Magistral</a></li><li><code>增加问题难度</code>：(2506) <a href="https://www.alphaxiv.org/abs/2506.06632" target="_blank" rel="noreferrer">课程RL学习(E2H Reasoner)</a><ul><li>去掉<code>成功率&gt;2/3</code>的任务</li><li>去掉<code>成功率一直为0</code>的任务</li></ul></li><li><code>增大batch size</code>：<code>梯度计算更准确</code>，(2505) <a href="https://arxiv.org/abs/2505.22312" target="_blank" rel="noreferrer">Skywork-OR1</a></li><li><code>减少每次迭代采样的实例数量</code>：<code>平衡开销</code>。</li><li>以上来自推理模型训练经验</li></ul></div><h3 id="实验设置-sft-2阶段rl" tabindex="-1">实验设置(SFT+2阶段RL) <a class="header-anchor" href="#实验设置-sft-2阶段rl" aria-label="Permalink to &quot;实验设置(SFT+2阶段RL)&quot;">​</a></h3><p><strong>✍️实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li>Qwen2.5-72B-Instruct</li></ul><p><strong>训练任务/数据</strong></p><ul><li>从<code>SWE-rebench</code>清洗的<code>7.2k 数据</code></li></ul><p><strong>评测任务/数据</strong></p><ul><li>SWE-verified</li></ul><p><strong>算法/策略</strong></p><ul><li><code>RFT 冷启动</code> +<code>2阶段RL训练</code> (<code>65k</code> -&gt; <code>131k</code>上下文)</li><li><code>Scaffold</code>：<code>SWE-Agent</code></li></ul><p><strong>超参</strong></p><ul><li>具体见<code>RL算法配置</code></li><li>H200，<code>8卡 * 16节点</code>，每节点<code>32核CPU</code>、<code>960GB CPU内存</code>。</li></ul><p><strong>SWE环境</strong></p><ul><li>agent执行：<code>Kubernetes集群</code>，每个实例 <code>0.5 CPU</code> + <code>2GB内存</code></li><li>评估：<a href="https://tracto.ai/" target="_blank" rel="noreferrer">云平台 TractoAI</a></li></ul></div><h3 id="关键结果-qwen2-5-72b-inst-sft-2阶段rl" tabindex="-1">关键结果(Qwen2.5-72B-Inst + SFT+2阶段RL) <a class="header-anchor" href="#关键结果-qwen2-5-72b-inst-sft-2阶段rl" aria-label="Permalink to &quot;关键结果(Qwen2.5-72B-Inst + SFT+2阶段RL)&quot;">​</a></h3><p><strong>🍑关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><p><strong>模型效果 (Qwen2.5-72B-Instruct, RFT+2RL)</strong></p><ul><li><code>RFT 冷启动微调</code>：SWE-verified <code>达20分</code></li><li><code>2阶段 RL训练</code>：<code>pass@1达39分</code>，<code>pass@10达58分</code>。</li><li><code>RFT+2RL</code>后： <code>效果持平 DeepSeek-V3-0324</code>，低于235b-Inst-2507，超过Qwen3-235B。</li></ul><p><strong>重要结论</strong></p><ul><li><code>不要过滤丢弃超长样本</code>：实际丢弃了超长负样本，导致<code>死循环得不到惩罚</code>。</li><li><code>训推不一致</code>导致<code>训练崩溃</code><ul><li>原因：<code>top-k, top-p</code>导致<code>词表被截断</code>，计算<code>IS权重</code>时<code>分布不匹配</code>。</li><li>解法：<code>关闭filter</code>，温度设为1</li><li><a href="https://plmsmile.github.io/posts/llm/industry/mainllm/02-deepseek-series.html#%E4%BF%9D%E6%8C%81%E8%B7%AF%E7%94%B1%E5%92%8C%E9%87%87%E6%A0%B7mask-%E6%B6%88%E9%99%A4%E8%AE%AD%E6%8E%A8%E4%B8%8D%E4%B8%80%E8%87%B4" target="_blank" rel="noreferrer">DeepSeek-V3.2 保持采样Mask 解决训推不一致问题</a>：<code>保持采样Mask</code></li></ul></li></ul></div><img src="https://arxiv.org/html/2508.03501v1/figures/rl_iterations.png" style="display:block;margin:auto;" width="70%"><h3 id="swe-难题未来方向" tabindex="-1">SWE 难题未来方向 <a class="header-anchor" href="#swe-难题未来方向" aria-label="Permalink to &quot;SWE 难题未来方向&quot;">​</a></h3><p><strong>⛳ 未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div><p><strong>稀疏奖励和信用分配问题</strong></p><ul><li><p>背景：长轨迹难以分配奖励信号。</p></li><li><p>未来方向：</p><ul><li><p><code>Reward Shaping</code>：设计中间奖励，通过部分测试用例、减少编译器保持数量等。</p></li><li><p><code>训练辅助Critic</code>：提供step-level的优势估计，实现细粒度更新</p></li><li><p><code>前缀采样</code>：从<code>共享非空前缀</code>开始进行多次Rollout，更好知道中间动作哪个动作更好</p></li></ul></li></ul><p><strong>不确定性和风险感知(盲目自信)</strong></p><ul><li>背景：稀疏二值奖励 鼓励agent提交patch：可能<code>表现得很自信</code>，<code>但结果不正确</code></li><li>现实：需要<code>识别何时该放弃</code>。</li><li>方法： <ul><li>模型显示<code>输出置信度分数</code></li><li>Agent<code>自主决定是否重新尝试</code>：自主 Best-of-N 选择</li></ul></li></ul></div><h2 id="_2508-deepswe-42分-agentic" tabindex="-1">(2508) DeepSWE (42分, Agentic) <a class="header-anchor" href="#_2508-deepswe-42分-agentic" aria-label="Permalink to &quot;(2508) DeepSWE (42分, Agentic)&quot;">​</a></h2><p><strong>🌺 论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">DeepSWE 摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://pretty-radio-b75.notion.site/DeepSWE-Training-a-Fully-Open-sourced-State-of-the-Art-Coding-Agent-by-Scaling-RL-22281902c1468193aabbe9a8c59bbe33" target="_blank" rel="noreferrer">blog</a>, <a href="https://huggingface.co/agentica-org/DeepSWE-Preview" target="_blank" rel="noreferrer">DeepSWE</a>, <a href="https://rllm-project.readthedocs.io/en/latest/examples/swe/" target="_blank" rel="noreferrer">rllm-deepswe</a>, <a href="https://huggingface.co/datasets/R2E-Gym/R2E-Gym-Subset" target="_blank" rel="noreferrer">R2E-Gym-Subset</a>, <a href="https://github.com/agentica-project/rllm" target="_blank" rel="noreferrer">rllm</a>, <a href="http://plmsmile.github.io/posts/llm/industry/codellm/09-swe-series.html#_2508-deepswe-42%E5%88%86-agentic" target="_blank" rel="noreferrer">笔记</a></li></ul><p><strong>核心方法</strong></p><ul><li><code>Kubernates R2E环境集群</code> + <code>R2E-Gym 4.5k数据</code> + <code>环境执行反馈</code></li><li><code>GRPO++算法</code>： <ul><li>DAPO技巧：<code>Clip-Higher</code>+<code>去除KLloss</code>+ <code>去除熵loss</code> + <code>compact过滤</code></li><li>Dr.GRPO技巧：<code>优势不除以标准差</code> + <code>去掉序列内Token平均</code></li><li>RLOO技巧：<code>留一法计算优势</code></li></ul></li><li><code>Hybrid TTS</code>：执行验证 + 免执行验证</li><li><code>SWE-Agent</code></li></ul><p><strong>模型效果(Qwen3-32B, RL)</strong></p><ul><li>Qwen3-32B 经<code>GRPO++</code>优化后，SWE-verified 达<code>42分</code>，<code>TTS达59分</code>。</li></ul><p><strong>重要结论</strong></p><ul><li>用Claude蒸馏来<code>SFT模型</code>，<code>SWE仅34分</code>，低于<a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#%E5%85%B3%E9%94%AE%E7%BB%93%E6%9E%9C-swe-agent-lm-32b" target="_blank" rel="noreferrer">SWE-Agent-LM 40分</a>。</li><li>用<code>SWE-Smith</code>和<code>SWE-Gym</code>数据做RL，<code>提升有限</code>。</li><li><code>R2E-Gym</code> 很适合做RL，<code>较好课程学习</code>。</li></ul><p><strong>关键贡献</strong></p><ul><li>开源。</li></ul></div><h3 id="问题背景-2" tabindex="-1">问题背景 <a class="header-anchor" href="#问题背景-2" aria-label="Permalink to &quot;问题背景&quot;">​</a></h3><p><strong>❓问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">问题背景</div><ul><li>Agent：通过工具调用和真实环境交互，环境给予反馈、奖励信号。</li><li>Code Agent：IDE工具(<code>Bash</code>+<code>文件搜索</code>+<code>文件编辑</code> + <code>文件浏览</code>)等。</li></ul></div><p>Agent</p><img src="https://pretty-radio-b75.notion.site/image/attachment%3A3c883410-4cb9-40f3-aadd-7fa2a9ab6f4e%3Adeepswe-agent-example_(1).svg?table=block&amp;id=22281902-c146-81bb-a3a8-ed7613a539ff&amp;spaceId=3dea8845-5afd-4ee7-97ee-480e9ce47ccd&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><p>Code Agent</p><img src="https://pretty-radio-b75.notion.site/image/attachment%3Adfb76706-2797-4284-af8c-46ad6896daf8%3Asweagent-example_(1).svg?table=block&amp;id=22281902-c146-81bf-a11a-d3167a168c43&amp;spaceId=3dea8845-5afd-4ee7-97ee-480e9ce47ccd&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><h3 id="核心方法-1" tabindex="-1">核心方法 <a class="header-anchor" href="#核心方法-1" aria-label="Permalink to &quot;核心方法&quot;">​</a></h3><p><strong>📕核心方法</strong></p><h4 id="swe环境-kubernates集群" tabindex="-1">SWE环境(Kubernates集群) <a class="header-anchor" href="#swe环境-kubernates集群" aria-label="Permalink to &quot;SWE环境(Kubernates集群)&quot;">​</a></h4><div class="custom-block caution"><div class="custom-block-title">SWE 环境扩展 -Kubernates集群</div><p><strong>并发需求</strong></p><ul><li>每次RL迭代：512个Docker容器，BS=64、8passes。</li><li>并行RL实验：每时刻都有<code>几千个容器</code>在运行。</li></ul><p><strong>解决方法</strong></p><ul><li>Kubernates集群，每个节点：<code>200 CPU</code> + <code>6TB local NVME SSD</code>。</li><li>可扩展至1000 CPU 集群。</li></ul></div><h4 id="rl设置-动作空间-数据-稀疏奖励" tabindex="-1">RL设置(动作空间+数据+稀疏奖励) <a class="header-anchor" href="#rl设置-动作空间-数据-稀疏奖励" aria-label="Permalink to &quot;RL设置(动作空间+数据+稀疏奖励)&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">RL 环境和数据</div><p><strong>动作空间</strong></p><ul><li>执行Bash：执行命令，返回sdtout和sdterr</li><li>搜索：在目录下或对单文件进行搜索</li><li>文件编辑：查看、创建、替换字符串、插入、撤销修改等。</li><li>完成/提交：LLM决定已经解决PR，结束</li></ul><p><strong>数据</strong></p><ul><li><code>R2E-Gym 4.5k数据集</code>，过滤污染数据。</li></ul><p><strong>稀疏奖励</strong></p><ul><li>1：测试用例<code>全部通过</code>，(<strong>Pass2Pass, Fail2Pass</strong>)</li><li>0：<code>超时</code>或<code>至少有1个未通过</code></li><li>超时时间：<code>5分钟</code>，官方是30分钟。</li></ul></div><h4 id="grpo-算法-dapo-dr-grpo-rloo" tabindex="-1">GRPO++算法(DAPO+Dr.GRPO+RLOO) <a class="header-anchor" href="#grpo-算法-dapo-dr-grpo-rloo" aria-label="Permalink to &quot;GRPO++算法(DAPO+Dr.GRPO+RLOO)&quot;">​</a></h4><div class="custom-block important"><div class="custom-block-title">GRPO++ (DAPO+Dr.GRPO+RLOO)</div><p><strong>相关笔记</strong></p><ul><li><a href="https://plmsmile.github.io/posts/llm/rl/theory/11-grpo-series.html#_2504-dapo-seed" target="_blank" rel="noreferrer">DAPO 技巧</a>, <a href="https://plmsmile.github.io/posts/llm/rl/theory/11-grpo-series.html#_2503-dr-grpo" target="_blank" rel="noreferrer">Dr.GRPO 技巧</a>, <a href="https://plmsmile.github.io/posts/llm/rl/theory/10-ppo-series.html#_2402-rloo" target="_blank" rel="noreferrer">RLOO 技巧</a></li></ul><p><strong>采用 DAPO 技巧</strong></p><ul><li><p><code>Clip-Higher</code>：<code>鼓励探索</code>和防止熵崩塌</p></li><li><p><code>移除KL Loss</code>：避免LLM受<code>原始SFT影响限制</code>探索空间</p></li><li><p><code>移除熵 Loss</code>：会增加不稳定性，导致熵增加，训练崩溃。如果基模熵在0.3-1，就无需熵loss</p></li><li><p><code>Compact 过滤</code>：对达<code>最大长度</code>、<code>超时</code>、<code>达最大步数</code>的数据，<code>Mask Loss</code></p></li></ul><p><strong>采用Dr.GRPO 技巧</strong></p><ul><li><p><code>优势不除以标准差</code>：消除<code>任务难度偏差</code></p></li><li><p><code>去掉序列内平均</code>，消除<code>长度偏差</code>，其实就是<a href="https://plmsmile.github.io/posts/llm/rl/theory/11-grpo-series.html#token-level-loss" target="_blank" rel="noreferrer">DAPO的Token-Level-Loss</a></p></li></ul><p><strong>采用RLOO 技巧</strong></p><ul><li><code>留一法计算优势</code></li></ul></div><p>Compact 过滤：</p><img src="https://pretty-radio-b75.notion.site/image/attachment%3A08a07d52-596f-4f8c-b760-920308d47ca7%3Aimage.png?table=block&amp;id=22281902-c146-804c-bf06-f567e8827fc6&amp;spaceId=3dea8845-5afd-4ee7-97ee-480e9ce47ccd&amp;width=1140&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><img src="https://pretty-radio-b75.notion.site/image/attachment%3A4affb3ee-8fce-4544-95ed-06af7218cbf0%3Asteps-vs-response-length.png?table=block&amp;id=22281902-c146-80f9-9967-f239d76d44a8&amp;spaceId=3dea8845-5afd-4ee7-97ee-480e9ce47ccd&amp;width=770&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><h4 id="hybrid-tts-deepswe-verifier" tabindex="-1">Hybrid TTS (DeepSWE-Verifier) <a class="header-anchor" href="#hybrid-tts-deepswe-verifier" aria-label="Permalink to &quot;Hybrid TTS (DeepSWE-Verifier)&quot;">​</a></h4><div class="custom-block warning"><div class="custom-block-title">TTS 相关工作</div><ul><li><a href="http://plmsmile.github.io/posts/llm/industry/codellm/06-code-taskrl-reading.html#_2505-deepcoder-14b-preview" target="_blank" rel="noreferrer">DeepCoder-14B-Preview</a><ul><li><code>16k -&gt; 32k -&gt;64k</code>，LiveCodeBench效果：<code>54 -&gt; 58 -&gt; 60.6</code>，</li></ul></li><li><a href="http://plmsmile.github.io/posts/llm/industry/mainllm/15-skywork-series.html#_2506-skywork-swe" target="_blank" rel="noreferrer">Skywork-SWE</a><ul><li>从头<code>36</code>提升至<code>47分</code>，<code>Best-of-3</code></li><li><code>rollout3次</code>，由<a href="https://openhands.dev/blog/sota-on-swe-bench-verified-with-inference-time-scaling-and-critic-model" target="_blank" rel="noreferrer">OpenHands critic model</a>来<code>选择最优轨迹</code>评测。</li></ul></li><li><a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#hybrid-tts" target="_blank" rel="noreferrer">R2E-Gym TTS</a><ul><li>先基于<code>免执行验证</code>选出<code>top-n</code>，再基于<code>执行验证</code>做<code>最终排序</code>。</li><li>从<code>34.4</code>提升至<code>51分</code>。</li></ul></li></ul></div><div class="custom-block tip"><div class="custom-block-title">Hybrid TTS方法</div><p><strong>Hybrid TTS</strong></p><ul><li><strong>不执行验证</strong><ul><li>不执行，由<code>LLM选择最优轨迹</code>。</li><li><code>DeepSWE Verifier</code>：在<code>正确和错误patch</code>上，训练<code>2epoch</code>，识别<code>正确和错误</code></li></ul></li><li><strong>执行验证</strong><ul><li>由LLM生成<code>测试用例</code>，用例<code>通过最多</code>则为<code>最优轨迹</code></li></ul></li><li><code>混合方法</code>。</li></ul><p><strong>TTS 参数</strong></p><ul><li>上下文长度：16k -&gt; 32k -&gt; 128k，<code>超过32k</code> <code>收益就比较小</code></li><li>Rollout数量：8、16等</li></ul></div><p>不执行和执行两种方法对比：</p><img src="https://pretty-radio-b75.notion.site/image/attachment%3A2f60e8cc-d8b4-45db-ab91-2ab271e5e1e0%3Atest-time-scaling.svg?table=block&amp;id=22481902-c146-804b-a86b-f733987add11&amp;spaceId=3dea8845-5afd-4ee7-97ee-480e9ce47ccd&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><p>TTS 对比：</p><img src="https://pretty-radio-b75.notion.site/image/attachment%3A1fdf53cf-c67a-45f6-a168-a42d40a95b9d%3Abestk_plot_agent.png?table=block&amp;id=22281902-c146-80e3-b0b6-c6dec42a72cc&amp;spaceId=3dea8845-5afd-4ee7-97ee-480e9ce47ccd&amp;width=960&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><p>最大输出token对比</p><img src="https://pretty-radio-b75.notion.site/image/attachment%3A81da2c29-7656-43e3-be00-fb16991157f5%3Adeepscaler_clip_ratio.png?table=block&amp;id=22481902-c146-8050-9683-d4e48407d33e&amp;spaceId=3dea8845-5afd-4ee7-97ee-480e9ce47ccd&amp;width=840&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><h3 id="实验设置-grpo" tabindex="-1">实验设置(GRPO++) <a class="header-anchor" href="#实验设置-grpo" aria-label="Permalink to &quot;实验设置(GRPO++)&quot;">​</a></h3><p><strong>✍️实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li>Qwen3-32B</li></ul><p><strong>训练任务/数据</strong></p><ul><li><a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#_2504-r2e-gym" target="_blank" rel="noreferrer">R2E-Gym 子集</a> <code>4.5k任务</code>，并做<code>污染过滤</code></li></ul><p><strong>评测任务/数据</strong></p><ul><li>SWE-verified，<code>官方R2E-Gym</code>代码库来<code>评估</code></li><li>超参：<code>100步</code>，<code>64k上下文</code></li><li>指标：<code>pass@1 avg16</code>， best@8, best@16</li><li>TTS策略：<code>免执行方法</code> + <code>执行免执行混合方法</code></li></ul><p><strong>算法/策略</strong></p><ul><li><code>GRPO++</code> (多种策略)，<code>R2E-Gym Scaffold</code></li></ul><p><strong>超参</strong></p><ul><li>上下文长度：16k -&gt; 128k，其中<code>32k效果很好</code>了，后期收益不大</li><li>训练：<code>32k</code>、<code>50轮</code>；测试：<code>64k</code>、<code>100轮</code></li><li>Rollout：<code>16</code>、8等，做了多组实验</li><li><code>64张H100</code>，<code>训练6天</code>。</li></ul></div><h3 id="关键结果-qwen3-32b-rl" tabindex="-1">关键结果(Qwen3-32B + RL) <a class="header-anchor" href="#关键结果-qwen3-32b-rl" aria-label="Permalink to &quot;关键结果(Qwen3-32B + RL)&quot;">​</a></h3><p><strong>🍑关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><p><strong>模型效果(Qwen3-32B, RL, SWE-V指标)</strong></p><ul><li><code>GRPO++后</code>，SWE <code>pass@1 42.2分</code> ，<code>pass@16 71分</code>，<code>TTS best@16 59分</code></li><li>DeepSWE-Preview-32B</li></ul><p><strong>重要结论</strong></p><ul><li>使用Claude3-4蒸馏数据做SFT，<code>仅34.4分</code>，低于<a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#%E5%85%B3%E9%94%AE%E7%BB%93%E6%9E%9C-swe-agent-lm-32b" target="_blank" rel="noreferrer">SWE-Agent-LM 40分</a>。</li><li>使用<a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#_2504-swe-smith-swe-agent-lm" target="_blank" rel="noreferrer">SWE-Smith</a>和<a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#_2412-swe-gym" target="_blank" rel="noreferrer">SWE-Gym</a>数据集，但<code>提升有限</code>，<code>训练中无解率很高</code></li><li>相反<a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#_2504-r2e-gym" target="_blank" rel="noreferrer">R2E-Gym</a>很适合<code>RL</code>，提供<code>足够的课程学习</code>，随时间推移<code>解决越来越难的问题</code>。</li></ul></div><h3 id="未来方向-2" tabindex="-1">未来方向 <a class="header-anchor" href="#未来方向-2" aria-label="Permalink to &quot;未来方向&quot;">​</a></h3><p><strong>⛳ 未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div><ul><li><code>更大模型</code>：比如DeepSeek-R1</li><li><code>更长上下文</code>：</li><li><code>扩展到不同领域</code>的agent</li></ul></div><h2 id="_2512-devstral2-72-2分" tabindex="-1">(2512) Devstral2(72.2分) <a class="header-anchor" href="#_2512-devstral2-72-2分" aria-label="Permalink to &quot;(2512) Devstral2(72.2分)&quot;">​</a></h2><div class="custom-block danger"><div class="custom-block-title">Devstral2 摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://huggingface.co/mistralai/Devstral-Small-2-24B-Instruct-2512" target="_blank" rel="noreferrer">Devstral-Small-2-24B-Instruct-2512</a>, <a href="https://mistral.ai/news/devstral-2-vibe-cli" target="_blank" rel="noreferrer">devstral-2-vibe-cli</a>, <a href="http://plmsmile.github.io/posts/llm/industry/codellm/09-swe-series.html#_2512-devstral2-72-2%E5%88%86" target="_blank" rel="noreferrer">笔记</a></li></ul><p><strong>模型效果</strong></p><ul><li><code>模型小</code>且<code>效果好</code><ul><li><code>256k</code>、<code>Dense模型</code>，比Kimi/DeepSeek<code>都小很多</code>。</li><li>Devstral2：<code>123B</code>，<code>72.2 SWE-verified</code>。</li><li>Devstral Small2：<code>24B</code>，<code>68 SWE-verified</code>。</li></ul></li><li>但<code>仍落后于闭源模型</code>。</li></ul><p><strong>关键结论</strong></p><ul><li>支持<code>探索代码库</code>、<code>跨文件协调更改</code>、<code>架构级上下文</code></li><li>支持 <code>Mistral Vibe CLI 工具</code>。</li></ul></div><img src="https://cms.mistral.ai/assets/d295e716-acbe-4d05-8764-861ca2f2a2eb.png?width=1686&amp;height=1093" style="display:block;margin:auto;" width="70%"><img src="https://cms.mistral.ai/assets/3c7a5ea7-d83f-4dc4-9129-965c321bb379.png?width=1686&amp;height=969" style="display:block;margin:auto;" width="70%"><h2 id="_2505-devstral-46分-tts3指标" tabindex="-1">(2505) Devstral(46分, tts3指标) <a class="header-anchor" href="#_2505-devstral-46分-tts3指标" aria-label="Permalink to &quot;(2505) Devstral(46分, tts3指标)&quot;">​</a></h2><p><strong>🌺 论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">Devstral 摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://mistral.ai/news/devstral" target="_blank" rel="noreferrer">devstral</a>, <a href="https://huggingface.co/mistralai/Devstral-Small-2505" target="_blank" rel="noreferrer">mistralai/Devstral-Small-2505</a>, <a href="https://www.alphaxiv.org/abs/2509.25193" target="_blank" rel="noreferrer">paper</a>, <a href="http://plmsmile.github.io/posts/llm/industry/codellm/09-swe-series.html#_2505-devstral-46%E5%88%86-tts3%E6%8C%87%E6%A0%87" target="_blank" rel="noreferrer">笔记</a></li></ul><p><strong>核心方法</strong></p><ul><li>SFT轨迹数据合成方法：基于<code>环境探索</code>+<code>单元测试验证</code>， 保留<code>正确轨迹</code><ul><li>模式：<code>CoT</code>+<code>代码执行</code>，<code>OpenHands</code> + <code>SWE-Gym</code></li><li>具体数据没细讲，类似 <a href="http://plmsmile.github.io/posts/llm/industry/mainllm/02-deepseek-series.html#%E8%87%AA%E8%92%B8%E9%A6%8F%E5%86%B7%E5%90%AF%E5%8A%A8" target="_blank" rel="noreferrer">DeepSeekV3.2 自蒸馏冷启动</a></li></ul></li><li><code>Post-Training方法</code>：<code>简单过滤SFT</code>、<code>严格过滤SFT</code>、<code>RL训练</code>。</li><li><code>OpenHands</code></li></ul><p><strong>模型效果</strong></p><ul><li>Devstral-small-24B模型，<code>SWE达46分</code>，<code>迭代式 Best-of-3</code>指标。</li></ul></div><p><strong>❓问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">问题背景</div><ul><li>开源模型在<code>代码片段</code>生成效果好，但在<code>复杂</code>、<code>多步骤SWE任务</code>表现不好。</li><li><code>Coding Agent</code>需要<code>迭代开发</code>、<code>debug</code>、<code>集成软件工具</code>等能力，<code>大都依赖闭源模型</code>。</li></ul></div><h3 id="核心方法-环境探索sft数据-多阶段sft-rl" tabindex="-1">核心方法(环境探索SFT数据+多阶段SFT+RL) <a class="header-anchor" href="#核心方法-环境探索sft数据-多阶段sft-rl" aria-label="Permalink to &quot;核心方法(环境探索SFT数据+多阶段SFT+RL)&quot;">​</a></h3><p><strong>📕核心方法</strong></p><div class="custom-block note"><div class="custom-block-title">核心方法</div><p><strong>模型架构</strong></p><ul><li>基于Mistral-Small3 开发：24B，40层，GQA，128k</li></ul><p><strong>基于环境探索构建SFT数据</strong></p><ul><li>目标：<code>Cot推理</code>+<code>code执行能力</code></li><li>Agent框架：<code>OpenHands CodeAct scaffold</code>；SWE环境：<code>SWE-Gym</code></li><li>模型基于<code>以上环境去探索</code>，基于<code>单元测试验证</code>，仅保留<code>高质量正确轨迹数据</code>。</li></ul><p><strong>Post-Train(SFT+RL)</strong></p><ul><li>SFT：大量数据微调(<code>简单过滤</code>)，高质量数据微调(<code>严格过滤</code>)</li><li>RL：使用SFT模型生成新数据，再去做RL训练。</li><li>论文不清楚。</li></ul></div><h3 id="实验设置-sft-rl" tabindex="-1">实验设置(SFT+RL) <a class="header-anchor" href="#实验设置-sft-rl" aria-label="Permalink to &quot;实验设置(SFT+RL)&quot;">​</a></h3><p><strong>✍️实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li>Mistral-Small3 24B</li></ul><p><strong>训练任务/数据</strong></p><ul><li>没说</li></ul><p><strong>评测任务/数据 (SWE-Verified)</strong></p><ul><li><p><code>OpenHands Scaffold</code>：安全的沙盒环境，代码、bash、网页浏览(本实验禁用)。</p></li><li><p><code>Best-of-3</code>作为<code>pass@1</code>：<code>第1次(温度=0)</code>，<code>第2、3次(温度=0.1)</code></p><ul><li>一般做法：多次取<code>avg</code> 作为<code>pass@1</code></li></ul></li><li><p>评测时的交互轮数：50轮效果好，100轮也没有提升。30轮低10个点。</p></li></ul><p><strong>算法/策略</strong></p><ul><li>SFT + RL</li><li><code>OpenHands</code></li></ul><p><strong>超参</strong></p><ul><li>128k</li></ul></div><h3 id="关键结果-devstral-small-24b-sft-rl" tabindex="-1">关键结果(Devstral-small-24B + SFT+RL) <a class="header-anchor" href="#关键结果-devstral-small-24b-sft-rl" aria-label="Permalink to &quot;关键结果(Devstral-small-24B + SFT+RL)&quot;">​</a></h3><p><strong>🍑关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><p><strong>模型效果</strong></p><ul><li>Devstral-small-24B <code>SWE达46分</code>，超越一众顶尖模型。 <ul><li>Qwen3-235B(25), DeepseekR1V3(40+), GPT-4.1-mini(23.6), Claude3.5-Haiku(40.6)。</li></ul></li></ul><p><strong>重要结论</strong></p><ul><li>评测交互轮数：<code>50轮</code> 效果好<code>46分</code>，<code>30轮</code>仅<code>36分</code>。</li><li>温度<code>0.1</code>和<code>0.4</code>比较好，0.7和1.0反而Pass@4还低了。</li></ul></div><img src="https://paper-assets.alphaxiv.org/figures/2509.25193v1/img-1.jpeg" style="display:block;margin:auto;" width="70%"><p><strong>⛳ 未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div><ul><li>新版本优化：2507比2505好 <ul><li>优化数据生成和筛选过程：提升数据质量 <ul><li>微调数据过滤机制：可能不仅看是否单元测试，还会看代码风格、步骤冗余度等。</li></ul></li><li>不同脚手架支持：构造伪脚手架.</li><li>多格式训练：增加XML格式、原生函数调用格式等。</li></ul></li></ul></div><img src="https://paper-assets.alphaxiv.org/figures/2509.25193v1/img-3.jpeg" style="display:block;margin:auto;" width="70%"><h2 id="_2502-swe-rl-meta" tabindex="-1">(2502) SWE-RL (Meta) <a class="header-anchor" href="#_2502-swe-rl-meta" aria-label="Permalink to &quot;(2502) SWE-RL (Meta)&quot;">​</a></h2><p><strong>🌺 论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">SWE-RL 摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2502.18449" target="_blank" rel="noreferrer">paper</a>, <a href="https://github.com/facebookresearch/swe-rl" target="_blank" rel="noreferrer">swe-rl</a>, <a href="http://plmsmile.github.io/posts/llm/industry/codellm/09-swe-series.html#_2502-swe-rl-meta" target="_blank" rel="noreferrer">笔记</a></li></ul><p><strong>核心方法</strong></p><ul><li><code>GithubPR数据收集构建方法</code>：<code>仓库事件克隆</code> + <code>PR聚合</code> + <code>预测相关文件</code> + <code>数据过滤</code><ul><li>SWE-RL PR数据：<code>27.3w </code></li></ul></li><li><code>AgentSFT数据合成方法</code>：<code>PR种子筛选</code> + <code>定位数据合成</code> + <code>编辑数据合成</code></li><li>SWE-RL方法：<code>LLama3-70B</code> + <code>GRPO</code>，<code>不执行环境</code>，采用<code>Patch相似度</code>来做<code>奖励信号</code></li><li><code>Agentless Scaffold</code></li></ul><p><strong>模型效果(LLaMA3-70B, RL, SWE-Verified)</strong></p><ul><li>LLama3-SWE-RL-70B：<code>SWE-Verified 41分</code>，在<code>100B模型下效果最好</code>，</li><li><code>SFT 达36.2分</code>，效果也不错。</li><li><code>未使用闭源LLM蒸馏技术</code>，<code>纯开源数据</code>。</li></ul><p><strong>重要结论</strong></p><ul><li><code>RL比SFT效果好</code>。</li><li><code>Best-of-N</code> 越大越好，但后期逐渐收敛。</li><li><code>DenseReward</code> 比Sparse Reward好。</li></ul></div><p>整体流程如下</p><img src="https://arxiv.org/html/2502.18449v1/x1.png" style="display:block;margin:auto;" width="70%"><h3 id="问题背景-3" tabindex="-1">问题背景 <a class="header-anchor" href="#问题背景-3" aria-label="Permalink to &quot;问题背景&quot;">​</a></h3><p><strong>❓问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">问题背景</div><p><strong>问题</strong></p><ul><li>SWE 进展：<code>repo-level 代码生成</code>、<code>Issue Resolution</code>(SWE Bench)。</li><li>SWE-Bench：<code>主要依赖私有模型</code>GPT-4o, Calude-3.5，开源模型很少。 <ul><li>DeepSeekR1 RuleRL很强，但是<code>SWE任务效果不行</code>。</li></ul></li><li>传统规则奖励<code>难以直接应用到SWE任务</code>。 <ul><li>数学：<code>EM匹配</code>；</li><li>代码：竞赛题，<code>单代码文件</code>、<code>容易执行</code>；SWE：有依赖，不是自包含的。</li></ul></li></ul><p><strong>SWE 相关工作</strong></p><ul><li>(2411)<a href="https://www.alphaxiv.org/abs/2411.00622" target="_blank" rel="noreferrer">Lingma-SWE-GPT</a>：迭代开发过程，基于Qwen2.5-Coder-7B和Qwen2.5-72B-Instruct 构建。</li><li>(2412)<a href="https://www.alphaxiv.org/abs/2412.21139" target="_blank" rel="noreferrer">SWE-gym</a>：第一个用于<code>开放训练的环境</code>，提升Qwen2.5-Coder-7B/32B效果。</li><li>(2501)<a href="https://www.alphaxiv.org/abs/2501.05040" target="_blank" rel="noreferrer">SWE-fixer</a>：微调Qwen2.5 base，提升best@1性能。</li></ul></div><h3 id="github-pr数据收集构建方法" tabindex="-1">GitHub PR数据收集构建方法 <a class="header-anchor" href="#github-pr数据收集构建方法" aria-label="Permalink to &quot;GitHub PR数据收集构建方法&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">Github PR 数据 概览</div><ul><li>最终：<code>27.3w 高质量 Gihub PR</code></li><li>每个PR包含： <ul><li><code>Issue描述</code>：问题</li><li><code>Code Context</code>：<code>所有相关文件</code> (<code>需要修改</code> + <code>不需要修改的</code>)</li><li><code>Oracle Patch</code>：GT解决方法</li></ul></li></ul></div><div class="custom-block note"><div class="custom-block-title">Github PR数据收集构建方法</div><p><strong>Github Events Clone</strong></p><ul><li>目标PR数据：PR中的<code>所有事件</code>、<code>PR之前的源代码</code>。</li><li>通过 <a href="https://www.gharchive.org/" target="_blank" rel="noreferrer">GHAchive</a> 拉取事件：1501-2412共10年数据</li><li>通过GitClone 仓库：包含历史所有commit，共460w repo。</li></ul><p><strong>PR 数据聚合</strong></p><ul><li>从PR出发，关联<code>Github事件</code>和<code>代码库</code>，仅<code>保留已合并的PR</code>，聚合以下内容 <ul><li>Issue、用户讨论、Review Comment、出事代码、Commits、代码变更。</li></ul></li><li>保存从<code>merge base</code>到 <code>head commit</code>所有的<code>中间提交</code>和<code>代码变更</code></li><li>扫描所有PR，<code>识别Issue</code>并<code>与对应PR</code> 匹配 (Prompt, Response)。累计 <code>240w PR</code>。</li></ul><p><strong>预测相关但未修改文件</strong></p><ul><li>问题 <ul><li>目前PR<code>仅包含被修改过的文件</code>，但实际预测<code>会检索到很多无关文件</code></li><li>如果训练时，只看修改文件，会产生bias。</li></ul></li><li>方法 <ul><li>根据Issue+已修改文件，使用<code>Prompt+LLM</code>预测 <code>相关但未被修改</code>的<code>文件列表</code></li><li>把这部分 <code>相关但未修改文件列表</code> 加入数据集中。</li></ul></li></ul><p><strong>数据过滤</strong></p><ul><li>背景：PR有噪音，需剔除有害PR。但允许一定噪音，尽量召回高质量PR。</li><li>过滤规则： <ul><li>过滤<code>机器人PR</code></li><li>过滤<code>变更极大的PR</code></li><li><code>细粒度过滤</code>：检查<code>每个代码块 Hunk</code> (参考CodeLLaMA )，确保是在写代码，去掉版本、锁定等内容。</li></ul></li><li>最终：<code>1100w PR</code> -&gt; <code>27.3w 高质量PR </code></li></ul></div><img src="https://arxiv.org/html/2502.18449v1/x2.png" style="display:block;margin:auto;" width="70%"><h3 id="agentsft-数据合成" tabindex="-1">AgentSFT 数据合成 <a class="header-anchor" href="#agentsft-数据合成" aria-label="Permalink to &quot;AgentSFT 数据合成&quot;">​</a></h3><div class="custom-block important"><div class="custom-block-title">SFT 数据合成</div><p><strong>PR 种子数据筛选</strong></p><ul><li><code>收集高质量PR种子数据</code>：启发式规则筛选</li></ul><p><strong>问题定位数据-合成</strong></p><ul><li>LLM合成 <ul><li>输入：<code>Issue描述</code> + <code>仓库结构</code> + <code>目标编辑文件</code> + <code>相关文件</code></li><li>输出： <code>CoT推理</code>生成<code>需要编辑的文件</code>。</li><li>LLama-3.3-70B-Instruct</li></ul></li><li>过滤：<code>仅保留推理正确的答案</code></li></ul><p><strong>代码编辑数据-合成</strong></p><ul><li>LLM 合成 <ul><li>输入：<code>标准答案</code>和<code>Patch</code>，</li><li>输出： <code>Search/Replace</code>格式的<code>代码编辑数据</code>。</li></ul></li><li>过滤：保留<code>格式正确</code> 且 <code>search/replace内容正确</code> (能搜索到)的数据。</li></ul><p><strong>相关工作</strong></p><ul><li>整体采样Magicoder的OSS-Instruct技术，同<a href="https://plmsmile.github.io/posts/llm/industry/codellm/07-code-fulltrain-reading.html#%E5%90%88%E6%88%90%E6%95%B0%E6%8D%AE-%E5%A4%9A%E6%A0%B7%E6%80%A7-%E8%B4%A8%E9%87%8F-%E9%9A%BE%E5%BA%A6" target="_blank" rel="noreferrer">Seed-Coder合成数据技术</a></li></ul></div><img src="https://arxiv.org/html/2502.18449v1/x8.png" style="display:block;margin:auto;" width="70%"><h3 id="核心方法-2" tabindex="-1">核心方法 <a class="header-anchor" href="#核心方法-2" aria-label="Permalink to &quot;核心方法&quot;">​</a></h3><h4 id="任务prompt-设计" tabindex="-1">任务Prompt 设计 <a class="header-anchor" href="#任务prompt-设计" aria-label="Permalink to &quot;任务Prompt 设计&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">Prompt 设计</div><p><strong>整体</strong></p><ul><li><code>Reasoning</code> + <code>Tool Use</code> 风格。<a href="https://github.com/facebookresearch/swe-rl/blob/main/src/swerl/core/prompts.py" target="_blank" rel="noreferrer">prompts.py</a></li><li>THINKING_SYSTEM + AGENTLESS_REPAIR</li></ul><p><strong>THINKING_SYSTEM</strong></p><ul><li>强调输出思考过程</li></ul><p><strong>AGENTLESS_REPAIR</strong></p><ul><li>--- BEGIN ISSUE ---：{problem_statement}，<code>Issue 定义</code></li><li>--- BEGIN FILE ---：{content}，包含<code>相关文</code>件的<code>全部源代码</code></li><li>任务指令：<code>先定位</code>、<code>再修复</code></li><li>输出格式：<code>Search/Replace 协议</code>，严格的<code>Diff格式</code></li><li>样例：</li></ul></div><p><strong>输出样例</strong></p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes one-light one-dark-pro vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#000000;--shiki-dark:#FFFFFF;">```python</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">### mathweb/flask/app.py</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;"> SEARCH</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> flask </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Flask</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=======</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> math</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> flask </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Flask</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&gt;&gt;&gt;&gt;&gt;&gt;&gt;</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;"> REPLACE</span></span>
<span class="line"><span style="--shiki-light:#000000;--shiki-dark:#FFFFFF;">```</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><img src="https://arxiv.org/html/2502.18449v1/x3.png" style="display:block;margin:auto;" width="70%"><h4 id="rl-设计" tabindex="-1">RL 设计 <a class="header-anchor" href="#rl-设计" aria-label="Permalink to &quot;RL 设计&quot;">​</a></h4><p><strong>📕核心方法</strong></p><div class="custom-block note"><div class="custom-block-title">核心方法</div><p><strong>任务</strong></p><ul><li>给定<code>Issue</code> +<code>上下文</code>，进行推理，<code>生成代码变更</code>，把代码变更<code>应用到Patch中</code>。</li></ul><p><strong>奖励</strong></p><ul><li><code>不去真正执行</code>，而是<code>对比Patch 相似度</code>。Python.difflib.SequenceMatcher。<mjx-container tabindex="0" class="MathJax" jax="SVG" display="true" style="direction:ltr;display:block;text-align:center;margin:1em 0;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-2.148ex;" xmlns="http://www.w3.org/2000/svg" width="52.763ex" height="5.428ex" role="img" focusable="false" viewBox="0 -1449.5 23321.3 2399" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mstyle" fill="blue" stroke="blue"><g data-mml-node="mtext"><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(392,0)" style="stroke-width:3;"></path><path data-c="77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z" transform="translate(836,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1558,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(2058,0)" style="stroke-width:3;"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(2450,0)" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(3283.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mrow" transform="translate(4339.6,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7B" d="M618 -943L612 -949H582L568 -943Q472 -903 411 -841T332 -703Q327 -682 327 -653T325 -350Q324 -28 323 -18Q317 24 301 61T264 124T221 171T179 205T147 225T132 234Q130 238 130 250Q130 255 130 258T131 264T132 267T134 269T139 272T144 275Q207 308 256 367Q310 436 323 519Q324 529 325 851Q326 1124 326 1154T332 1205Q369 1358 566 1443L582 1450H612L618 1444V1429Q618 1413 616 1411L608 1406Q599 1402 585 1393T552 1372T515 1343T479 1305T449 1257T429 1200Q425 1180 425 1152T423 851Q422 579 422 549T416 498Q407 459 388 424T346 364T297 318T250 284T214 264T197 254L188 251L205 242Q290 200 345 138T416 3Q421 -18 421 -48T423 -349Q423 -397 423 -472Q424 -677 428 -694Q429 -697 429 -699Q434 -722 443 -743T465 -782T491 -816T519 -845T548 -868T574 -886T595 -899T610 -908L616 -910Q618 -912 618 -928V-943Z" style="stroke-width:3;"></path></g><g data-mml-node="mtable" transform="translate(750,0)"><g data-mml-node="mtr" transform="translate(0,662.5)"><g data-mml-node="mtd"><g data-mml-node="mstyle" fill="blue" stroke="blue"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(1278,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mtd" transform="translate(13231.7,0)"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">格</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">式</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">不</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">正</text><text data-variant="normal" transform="translate(4000,0) scale(1,-1)" font-size="884px" font-family="serif">确</text></g></g></g><g data-mml-node="mtr" transform="translate(0,-537.5)"><g data-mml-node="mtd"><g data-mml-node="mstyle" fill="red" stroke="red"><g data-mml-node="mtext"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" style="stroke-width:3;"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)" style="stroke-width:3;"></path><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(944,0)" style="stroke-width:3;"></path><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" transform="translate(1777,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2333,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(2833,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(3225,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3669,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(4058,0)"><g data-mml-node="mtext"><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(556,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1056,0)" style="stroke-width:3;"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(1445,0)" style="stroke-width:3;"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1889,0)" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(2478,-229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(556,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(948,0)" style="stroke-width:3;"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(1392,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(7963.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(8408.1,0)"><g data-mml-node="mtext"><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(556,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1056,0)" style="stroke-width:3;"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(1445,0)" style="stroke-width:3;"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1889,0)" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(2478,-229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(500,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(11564.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(11953.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mtd" transform="translate(13231.7,0)"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">格</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">式</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">正</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">确</text></g></g></g></g><g data-mml-node="mo" transform="translate(18981.7,0) translate(0 250)"></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;overflow:hidden;width:100%;"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mstyle mathcolor="blue"><mtext>reward</mtext></mstyle><mo>=</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><mtable columnalign="left left" columnspacing="1em" rowspacing=".2em"><mtr><mtd><mstyle mathcolor="blue"><mo>−</mo><mn>1</mn></mstyle><mo>,</mo></mtd><mtd><mtext>格式不正确</mtext></mtd></mtr><mtr><mtd><mstyle mathcolor="red"><mtext>compare</mtext><mo stretchy="false">(</mo><msub><mtext>patch</mtext><mrow data-mjx-texclass="ORD"><mtext>pred</mtext></mrow></msub><mo>,</mo><msub><mtext>patch</mtext><mrow data-mjx-texclass="ORD"><mtext>gt</mtext></mrow></msub><mo stretchy="false">)</mo></mstyle><mo>,</mo></mtd><mtd><mtext>格式正确</mtext></mtd></mtr></mtable><mo data-mjx-texclass="CLOSE" fence="true" stretchy="true" symmetric="true"></mo></mrow></math></mjx-assistive-mml></mjx-container></li></ul><p><strong>算法</strong></p><ul><li>GRPO + KLLoss</li></ul></div><h4 id="训练和测试存在不同点" tabindex="-1">训练和测试存在不同点 <a class="header-anchor" href="#训练和测试存在不同点" aria-label="Permalink to &quot;训练和测试存在不同点&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">训练vs测试不同点</div><p><strong>训练</strong></p><ul><li>给出所有相关代码文件，隐式强迫模型<code>先找Bug</code>、<code>再做修复</code>。</li></ul><p><strong>评测时 (Agentless mini 框架)</strong></p><ul><li>完整Pipeline <ul><li>Step1 <code>文件定位</code>：bug在哪个文件？</li><li>Step2 <code>测试生成</code>：生成测试用例，来复现bug</li><li>Step3 <code>回归测试</code>：挑出哪些旧测试用例跑一遍，防止改坏了别的地方。</li><li>Step4 <code>修复代码</code>：请写出修复代码</li></ul></li><li><code>SWE-RL 训练时仅有4</code>，没有1、2、3。但在测试时，<code>有泛化性</code>。</li></ul></div><h3 id="实验设置-rl" tabindex="-1">实验设置(RL) <a class="header-anchor" href="#实验设置-rl" aria-label="Permalink to &quot;实验设置(RL)&quot;">​</a></h3><p><strong>✍️实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li>Llama-3.3-70B-Instruct</li></ul><p><strong>训练任务/数据</strong></p><ul><li><code>RL</code>：<code>27.3w 构建的PR数据</code></li><li><code>SFT(Baseline)</code>：<code>合成代码编辑SFT数据</code> + <code>LLama3代码SFT数据</code> + <code>LLama3通用SFT数据</code></li></ul><p><strong>评测任务/数据</strong></p><ul><li>SWE-Bench-Verified。</li><li>温度=1，每个问题<code>生成500个patch</code></li><li>使用<code>top-30测试用例</code>去测试<code>排序</code>，选择<code>第1名的patch</code>去报告 <code>pass@1</code>，其实是Best-of-N。</li></ul><p><strong>算法/策略</strong></p><ul><li><code>GRPO</code>，混合SFT(Baseline)</li></ul><p><strong>Scaffolding</strong></p><ul><li>基于<code>Agentless</code>开发的简化<code>Agentless mini</code>，专注于<code>文件级定位</code></li></ul><p><strong>超参</strong></p><ul><li><code>16k 上下文</code>，<code>batch_size=32</code>，<code>rollout=16</code>，real_batch_size=512</li><li><code>512 张H100</code>，32小时。</li></ul></div><h3 id="关键结果-llama-3-70b-rl" tabindex="-1">关键结果(LLaMA-3-70B + RL) <a class="header-anchor" href="#关键结果-llama-3-70b-rl" aria-label="Permalink to &quot;关键结果(LLaMA-3-70B + RL)&quot;">​</a></h3><p><strong>🍑关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><p><strong>模型效果(LLaMA3-70B, RL, SWE-Verified)</strong></p><ul><li>LLama3-SWE-RL-70B：<code>SWE-Verified 41分</code>，在<code>100B模型下效果最好</code>，</li><li><code>SFT 达36.2分</code>，效果也不错。</li><li><code>未使用闭源LLM蒸馏技术</code>，<code>纯开源数据</code>。</li></ul><p><strong>重要结论</strong></p><ul><li>测试 <code>Best-of-N</code> N越大效果越好，后期逐渐收敛。20 -&gt; 160 -&gt; 500：33.6 -&gt; 40 -&gt; 41</li><li><code>DenseReward</code>比Sparse <code>效果好</code>一些，促进格式和修复。</li></ul></div><h3 id="未来方向-3" tabindex="-1">未来方向 <a class="header-anchor" href="#未来方向-3" aria-label="Permalink to &quot;未来方向&quot;">​</a></h3><p><strong>⛳ 未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div><ul><li>奖励太僵硬：奖励仅靠GT相似度会限制模型探索其他方案，没有真正的执行奖励。</li><li>定位粗糙：Agentless Mini 缺乏复杂上下文信息。</li><li>流程割裂：Agentless 固定Pipeline，但理想Agent应该是E2E的。</li></ul></div><h2 id="_2405-swe-agent" tabindex="-1">(2405) SWE-agent <a class="header-anchor" href="#_2405-swe-agent" aria-label="Permalink to &quot;(2405) SWE-agent&quot;">​</a></h2><p><strong>🌺 论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">SWE-agent 摘要</div><p><strong>参考链接</strong></p><ul><li><a href="http://plmsmile.github.io/posts/llm/industry/codellm/09-swe-series.html#_2405-swe-agent" target="_blank" rel="noreferrer">论文笔记</a>, <a href="https://www.alphaxiv.org/abs/2405.15793" target="_blank" rel="noreferrer">paper</a></li></ul><p><strong>核心方法</strong></p><ul><li>设计<code>Agent-Computer-Interface 范式</code></li></ul><p><strong>模型效果</strong></p><ul><li>基于<code>SWE-Agent框架</code>，GPT4-Turbo，<code>SWE-Full-12分</code>，<code>Light-18分</code></li><li><code>SWE-Agent</code>比<code>标准Shell提高7pt</code>，<code>比RAG提高16pt</code>。</li></ul></div><p><strong>📕核心方法</strong></p><h3 id="aci-接口" tabindex="-1">ACI 接口 <a class="header-anchor" href="#aci-接口" aria-label="Permalink to &quot;ACI 接口&quot;">​</a></h3><div class="custom-block note"><div class="custom-block-title">Agent-Computer-Interface 范式</div><p><strong>搜索和导航工具</strong></p><ul><li><code>find_file</code>, <code>search_file</code>, <code>search_dir</code> ..</li></ul><p><strong>文件查看器</strong></p><ul><li><code>open</code>, <code>scroll_down</code>, <code>scroll_up</code>, <code>goto</code>等</li></ul><p><strong>智能文件编辑器</strong></p><ul><li><code>edit</code>：在单次操作中进行范围替换，启动自动静态代码检查等(flake8工具)</li></ul><p><strong>上下文管理</strong></p><ul><li>采用ReAct框架，每个步骤模型给出思考和行动，</li><li>仅<code>保留最近5轮交互</code>，历史观察折叠显示，降低上下文窗口压力。</li></ul></div><img src="https://paper-assets.alphaxiv.org/figures/2405.15793v3/img-0.jpeg" style="display:block;margin:auto;" width="70%"><h3 id="实验设置" tabindex="-1">实验设置 <a class="header-anchor" href="#实验设置" aria-label="Permalink to &quot;实验设置&quot;">​</a></h3><p><strong>✍️实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li><strong>GPT-4 Turbo</strong> (gpt-4-1106-preview)</li><li><strong>Claude 3 Opus</strong> (claude-3-opus-20240229)</li></ul><p><strong>训练任务/数据</strong></p><ul><li>无训练</li></ul><p><strong>评测任务/数据</strong></p><ul><li><code>SWE-bench (Full &amp; Lite)</code>：真实Python问题，2.2k-Full, 300-Lite</li><li><code>HumanEvalFix</code>：代码调试/修复任务。</li></ul><p><strong>算法/策略</strong></p><ul><li><code>SWE-agent</code>：基于 <code>ACI 的交互式 Agent</code>。</li><li><code>Shell-only</code>：<code>基线 Agent</code>，仅使用标准 Linux Shell。</li><li><strong>RAG</strong>：基线方法，检索相关文件后直接生成补丁（非交互）。</li></ul><p><strong>超参</strong></p><ul><li>上下文窗口限制：<code>128k (GPT-4)</code> / <code>200k (Claude 3)</code>。</li><li>预算限制：每个任务最多 $4.00 推理成本。</li></ul></div><h3 id="关键结果" tabindex="-1">关键结果 <a class="header-anchor" href="#关键结果" aria-label="Permalink to &quot;关键结果&quot;">​</a></h3><p><strong>🍑关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><ul><li>SWE-Agent 通过ACI显著提升SWE分数，GPT4-Turbo分数如下： <ul><li><code>SWE-Agent</code>：<code>Full-12分</code>，<code>Lite-18分</code>。</li><li>标准Shell：FUll-, <code>Lite-11分</code>。</li><li>RAG：Full-1.3分，<code>Lite-2.67分</code>。</li></ul></li><li>SWE-Agent：<code>HumanEvalFix 87.7% pass@1</code></li><li>消融实验 <ul><li>Linter：移除<code>编辑时语法检查</code>，会下降3pt</li><li>搜索工具：<code>总结性工具</code>比没有搜索工具或繁杂迭代搜索工具效果好。</li><li>文件查看：<code>显示100行</code> 比 全部显示 或 仅显示30行 好。</li></ul></li></ul></div><h3 id="未来方向-4" tabindex="-1">未来方向 <a class="header-anchor" href="#未来方向-4" aria-label="Permalink to &quot;未来方向&quot;">​</a></h3><p><strong>⛳ 未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div><ul><li><strong>工具扩展</strong>：引入<code>更多开发工具</code>，如<code>网页浏览</code>（用于查阅文档）或<code>静态分析工具</code>。</li><li><strong>自动化 ACI 设计</strong>：目前 ACI 是手动设计的，未来可探索自动化生成针对特定模型或领域最优的接口。</li><li><strong>跨领域应用</strong>：将 ACI 的设计原则（简化命令、压缩反馈、错误护栏）应用到数据分析、网页导航等其他 Agent 领域。</li><li><strong>安全性</strong>：研究在沙盒环境中限制 Agent 的行为，防止生成恶意代码或误删文件。</li></ul></div></div></div></main><footer class="VPDocFooter" data-v-5a64a79a data-v-54a90a4a><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-54a90a4a><span class="visually-hidden" id="doc-footer-aria-label" data-v-54a90a4a>Pager</span><div class="pager" data-v-54a90a4a><a class="VPLink link pager-link prev" href="/posts/llm/industry/codellm/01-survey.html" data-v-54a90a4a><!--[--><span class="desc" data-v-54a90a4a>上一页</span><span class="title" data-v-54a90a4a>Code Survey</span><!--]--></a></div><div class="pager" data-v-54a90a4a><a class="VPLink link pager-link next" href="/posts/llm/industry/codellm/08-code-pretrain-summary.html" data-v-54a90a4a><!--[--><span class="desc" data-v-54a90a4a>下一页</span><span class="title" data-v-54a90a4a>Code 预训练相关</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--[--><div class="busuanzi"> 总访客数： <span id="busuanzi_value_site_uv"></span>   ·   总访问量： <span id="busuanzi_value_site_pv"></span></div><div class="busuanzi"> PLM&#39;s Blog @ 2016 - 2026</div><!--]--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api-examples.md\":\"Bt59YpwR\",\"index.md\":\"DmRGHmj9\",\"markdown-examples.md\":\"CPJSv--2\",\"posts_archive.md\":\"pZWQT7dp\",\"posts_exps_env_01-blog-env.md\":\"CcTUm41j\",\"posts_exps_env_index.md\":\"BJEZeoT-\",\"posts_exps_mind_index.md\":\"naOB3-Mb\",\"posts_llm_agent_basic_01-lhy-agent-notes.md\":\"BK_CsHNC\",\"posts_llm_agent_basic_02-evaluation-agent.md\":\"Dn02cVtP\",\"posts_llm_agent_basic_03-current-agents.md\":\"C25gmbg8\",\"posts_llm_agent_basic_04-agent-blogs.md\":\"_QbL2Plv\",\"posts_llm_agent_basic_05-comuter-agent.md\":\"D0gJpId6\",\"posts_llm_agent_basic_06-deepresearch-evaluation.md\":\"DdRDcxUJ\",\"posts_llm_agent_basic_index.md\":\"ClGtwUqg\",\"posts_llm_agent_rl_01-agent-rl.md\":\"wOF9bz66\",\"posts_llm_agent_rl_02-agent-tool.md\":\"IB_AqkSe\",\"posts_llm_agent_rl_03-agent-search.md\":\"Cim7OGxb\",\"posts_llm_agent_rl_04-agent-env.md\":\"C_O9BVi3\",\"posts_llm_agent_rl_index.md\":\"BudtoDK9\",\"posts_llm_basic_01-lm-define-information-theory.md\":\"Bl38RTdm\",\"posts_llm_basic_02-llm-components.md\":\"CGM_jRUE\",\"posts_llm_basic_03-transformer-detail.md\":\"BgLyAVDZ\",\"posts_llm_basic_04-llm-architecture.md\":\"jk4T-c21\",\"posts_llm_basic_05-llm-basic-info.md\":\"bdnM02bn\",\"posts_llm_basic_06-llm-attention.md\":\"BRJ9jR-M\",\"posts_llm_basic_07-decode.md\":\"BRytPqZo\",\"posts_llm_basic_08-llm-position-embedding.md\":\"d9dN_RuO\",\"posts_llm_basic_index.md\":\"DjX2HRXy\",\"posts_llm_industry_codellm_01-survey.md\":\"DIZQiOWr\",\"posts_llm_industry_codellm_02-eval-task-benchmark.md\":\"B-okIRAD\",\"posts_llm_industry_codellm_03-rl-task.md\":\"vQDqALFA\",\"posts_llm_industry_codellm_04-safety-code.md\":\"mkEFLxnr\",\"posts_llm_industry_codellm_05-open-codellm.md\":\"C6UU6qcZ\",\"posts_llm_industry_codellm_06-code-taskrl-reading.md\":\"BJI-7ypF\",\"posts_llm_industry_codellm_07-code-fulltrain-reading.md\":\"BjyYsnTY\",\"posts_llm_industry_codellm_08-code-pretrain-summary.md\":\"DfgRUz6a\",\"posts_llm_industry_codellm_09-swe-series.md\":\"njRlhnZH\",\"posts_llm_industry_codellm_10-swe-summary.md\":\"CmzPFSW7\",\"posts_llm_industry_codellm_11-swe-data-series.md\":\"BkWEB2x6\",\"posts_llm_industry_mainllm_01-kimi-series.md\":\"B03hc7IE\",\"posts_llm_industry_mainllm_02-deepseek-series.md\":\"B04zRtyw\",\"posts_llm_industry_mainllm_03-glm-series.md\":\"8i7VdpW8\",\"posts_llm_industry_mainllm_04-minimax-series.md\":\"DjQwki4V\",\"posts_llm_industry_mainllm_05-qwen-series.md\":\"B4DMxRmo\",\"posts_llm_industry_mainllm_06-seed-series.md\":\"BNsIBjBZ\",\"posts_llm_industry_mainllm_07-openai-series.md\":\"ZBquCwKO\",\"posts_llm_industry_mainllm_08-gemini-series.md\":\"Bdm2kU-I\",\"posts_llm_industry_mainllm_09-claude-series.md\":\"0YnEaaXS\",\"posts_llm_industry_mainllm_10-longcat-series.md\":\"DroIAFXW\",\"posts_llm_industry_mainllm_11-tencent-series.md\":\"BVkGSYEM\",\"posts_llm_industry_mainllm_12-kwai-series.md\":\"o6Hut3bE\",\"posts_llm_industry_mainllm_13-nvidia-series.md\":\"BFgUmWZk\",\"posts_llm_industry_mainllm_14-mimo-series.md\":\"DDj7XRZV\",\"posts_llm_industry_mainllm_15-skywork-series.md\":\"BMrtN_ri\",\"posts_llm_infra_01-parrallel.md\":\"2i82l-rT\",\"posts_llm_infra_02-speed-framework.md\":\"_bUH-n3t\",\"posts_llm_infra_03-inference-tech.md\":\"Hpk9YmXF\",\"posts_llm_infra_04-verl.md\":\"8XtGz01J\",\"posts_llm_infra_05-verl-practice.md\":\"CpYgON5R\",\"posts_llm_infra_06-verl-code.md\":\"D5bZg4dm\",\"posts_llm_infra_07-verl-core.md\":\"3RS___SF\",\"posts_llm_infra_08-verl-train-loop.md\":\"DzepHNlu\",\"posts_llm_rl_index.md\":\"iUgEsMU1\",\"posts_llm_rl_theory_01-reinforce-learning.md\":\"Ch0rtQCM\",\"posts_llm_rl_theory_01-rl-introduction.md\":\"CmW63EkM\",\"posts_llm_rl_theory_02-markove-process.md\":\"DVY5XgWd\",\"posts_llm_rl_theory_02-value-learning.md\":\"CeOlmbeS\",\"posts_llm_rl_theory_03-model-based-prediction-control.md\":\"BhVRmo7C\",\"posts_llm_rl_theory_03-strategy-learning.md\":\"DWNvEZXH\",\"posts_llm_rl_theory_04-model-free-prediction-control.md\":\"Cg3qo2Fk\",\"posts_llm_rl_theory_04-reinforce-conclusion-simple.md\":\"C6yTAxwQ\",\"posts_llm_rl_theory_05-dqn.md\":\"BatSdlnZ\",\"posts_llm_rl_theory_06-policy-gradient.md\":\"BXI-eY8I\",\"posts_llm_rl_theory_07-actor-critic.md\":\"B1-83sen\",\"posts_llm_rl_theory_08-deterministic-policy-gradient.md\":\"Dgvru3JE\",\"posts_llm_rl_theory_09-policy-trpo-ppo.md\":\"DU-7PSqU\",\"posts_llm_rl_theory_10-ppo-series.md\":\"B-5Hsj_J\",\"posts_llm_rl_theory_11-grpo-series.md\":\"sXtqvv0Z\",\"posts_llm_rl_theory_12-entropy.md\":\"BH45bCLH\",\"posts_llm_rl_theory_13-agentrl-algo.md\":\"EDVx1EmY\",\"posts_me.md\":\"B9W6CMag\",\"posts_olds_algo_aim2offer.md\":\"jCwzQ4BU\",\"posts_olds_algo_aim2offer2.md\":\"Ga2XS6dR\",\"posts_olds_algo_aim2offer3.md\":\"BP0rCZaJ\",\"posts_olds_algo_aim2offer4.md\":\"BXurWO8W\",\"posts_olds_algo_algorithm-dfs.md\":\"CkUFsStz\",\"posts_olds_algo_index.md\":\"CmdF0Gg2\",\"posts_olds_algo_leetcode-01.md\":\"C_2G2jJT\",\"posts_olds_algo_sort-algorithms.md\":\"tFMUVlmH\",\"posts_olds_bigdata_16-spark-baserdd.md\":\"CBxdArgI\",\"posts_olds_bigdata_17-spark-pairrdd.md\":\"C3n8_zMO\",\"posts_olds_bigdata_18-spark-sql.md\":\"tsaWQLcp\",\"posts_olds_bigdata_19-spark-programming.md\":\"DG5ZAF85\",\"posts_olds_bigdata_20-numpy.md\":\"DucCD22z\",\"posts_olds_bigdata_index.md\":\"CWrZwWPb\",\"posts_olds_dl_23-pytorch-start.md\":\"BokpNeAw\",\"posts_olds_dl_35-nerual-network-optim.md\":\"Cp2SpLoE\",\"posts_olds_dl_38-convolution.md\":\"CC_SQ57z\",\"posts_olds_dl_cs224n-assignment-1.md\":\"BZMSZqOS\",\"posts_olds_dl_cs224n-notes3-neural-networks-2.md\":\"Wd9TmSyb\",\"posts_olds_dl_cs224n-notes3-neural-networks.md\":\"CDZWc4X6\",\"posts_olds_dl_cs231n-linear-notes.md\":\"DLRyzcwJ\",\"posts_olds_dl_index.md\":\"C1dyLGNS\",\"posts_olds_dl_rnn.md\":\"CwYYWZ7N\",\"posts_olds_env_09-linux-notes.md\":\"CyjifvcN\",\"posts_olds_env_12-ide-envs.md\":\"YeELWzR2\",\"posts_olds_env_13-old-blog-problems.md\":\"qamPyucB\",\"posts_olds_env_24-hexo-problems.md\":\"CzxhyjW1\",\"posts_olds_env_index.md\":\"DQpgTXVj\",\"posts_olds_ml_10-trees.md\":\"BkNaj6fL\",\"posts_olds_ml_14-em.md\":\"DIufCP0H\",\"posts_olds_ml_21-lr.md\":\"C-1ms511\",\"posts_olds_ml_22-ml-ch03-bayes.md\":\"Q_M6Gn-a\",\"posts_olds_ml_27-svm-notes.md\":\"C96WS6CL\",\"posts_olds_ml_28-ml-interview-notes.md\":\"0bgezw3n\",\"posts_olds_ml_29-desicion-tree.md\":\"CtwmlbWl\",\"posts_olds_ml_crf.md\":\"CEE5oTqd\",\"posts_olds_ml_index.md\":\"BLMEziB1\",\"posts_olds_ml_maxentmodel.md\":\"CSbOumJx\",\"posts_olds_ml_pgm-01.md\":\"BTwybTMD\",\"posts_olds_nlp_11-nlp-labels.md\":\"Cl0Lb8OT\",\"posts_olds_nlp_25-google-nmt.md\":\"BOM-hoYN\",\"posts_olds_nlp_26-wordpieacemodel.md\":\"Q8-L5j15\",\"posts_olds_nlp_30-dynamic-memory-network.md\":\"wp5ucVxW\",\"posts_olds_nlp_31-co-attention-vqa.md\":\"lzwuVKG5\",\"posts_olds_nlp_32-dynamic-coattention-network.md\":\"Bxl4ABWd\",\"posts_olds_nlp_33-attention-summary.md\":\"DT6np0xG\",\"posts_olds_nlp_36-alime-chat.md\":\"Cu2xkcdT\",\"posts_olds_nlp_39-squard-models.md\":\"B1L3iDEv\",\"posts_olds_nlp_45-match-lstm.md\":\"DkpQKM5B\",\"posts_olds_nlp_46-rnet-selfmatch.md\":\"CzGHQ-PZ\",\"posts_olds_nlp_47-bidaf.md\":\"DFJaLh2v\",\"posts_olds_nlp_48-attention-is-all-you-need.md\":\"BY6XvFQ5\",\"posts_olds_nlp_49-qanet.md\":\"BPKWHzTf\",\"posts_olds_nlp_50-elmo.md\":\"WuOt1elN\",\"posts_olds_nlp_51-opengpt.md\":\"B9pQ3h5W\",\"posts_olds_nlp_52-bert.md\":\"5q3t5Qqh\",\"posts_olds_nlp_53-mrc-brief.md\":\"D9CkYrea\",\"posts_olds_nlp_54-mrc-models.md\":\"Ak4bDf1J\",\"posts_olds_nlp_attention-based-nmt.md\":\"BHef6tM6\",\"posts_olds_nlp_attention-model.md\":\"-xLhHhJE\",\"posts_olds_nlp_cs224n-lecture2-word2vec.md\":\"_MmBTADr\",\"posts_olds_nlp_cs224n-notes1-word2vec.md\":\"DXSi5KGh\",\"posts_olds_nlp_index.md\":\"Bfo4Lwn3\",\"posts_olds_nlp_nlp-notes.md\":\"BUmOZxzi\",\"posts_olds_nlp_nmt.md\":\"DUgy6vHF\",\"posts_olds_nlp_subword-units.md\":\"fR_3dRXr\",\"posts_olds_nlp_word2vec-math.md\":\"agvHiE1x\",\"posts_olds_nlp_word2vec.md\":\"D2TKUstm\",\"posts_olds_other_15-cpp-pointer-object-reference.md\":\"BKRTr8QZ\",\"posts_olds_other_index.md\":\"C1T-ubsz\",\"posts_olds_rl_37-reinforce-learning.md\":\"Cf2nny8k\",\"posts_olds_rl_40-value-learning.md\":\"DcnHvvpH\",\"posts_olds_rl_41-strategy-learning.md\":\"CStMrB-q\",\"posts_olds_rl_42-reinforce-conclusion-simple.md\":\"flRZUmJZ\",\"posts_olds_rl_43-intent-detection-slot-filling.md\":\"DcAUbaZU\",\"posts_olds_rl_44-reinforce-nlp.md\":\"Br2ShITL\",\"posts_olds_rl_index.md\":\"CUsxM3zO\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"📚 plmblog\",\"description\":\"记录一些学习笔记。\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"首页\",\"link\":\"/\"},{\"text\":\"🐲LLM\",\"items\":[{\"text\":\"Basic\",\"items\":[{\"text\":\"🦋基础知识\",\"link\":\"/posts/llm/basic/01-lm-define-information-theory\"},{\"text\":\"🛠基建框架\",\"link\":\"/posts/llm/infra/01-parrallel\"}]},{\"text\":\"强化学习\",\"items\":[{\"text\":\"🎓RL理论基础\",\"link\":\"/posts/llm/rl/theory/01-reinforce-learning\"},{\"text\":\"🚄Agent-RL\",\"link\":\"/posts/llm/agent/rl/02-agent-tool\"}]},{\"text\":\"行业方向\",\"items\":[{\"text\":\"🚀主流模型\",\"link\":\"/posts/llm/industry/mainllm/01-kimi-series\"},{\"text\":\"💻代码模型\",\"link\":\"/posts/llm/industry/codellm/01-survey\"}]},{\"text\":\"Agent\",\"items\":[{\"text\":\"🤖概念及应用\",\"link\":\"/posts/llm/agent/basic\"}]}]},{\"text\":\"📙旧文章\",\"items\":[{\"text\":\"🍓NLP\",\"items\":[{\"text\":\"自然语言处理\",\"link\":\"/posts/olds/nlp\"}]},{\"text\":\"🍑基础知识\",\"items\":[{\"text\":\"深度学习\",\"link\":\"/posts/olds/dl\"},{\"text\":\"强化学习\",\"link\":\"/posts/olds/rl\"},{\"text\":\"机器学习\",\"link\":\"/posts/olds/ml\"}]},{\"text\":\"🍎算法\",\"items\":[{\"text\":\"算法题\",\"link\":\"/posts/olds/algo/\"},{\"text\":\"大数据\",\"link\":\"/posts/olds/bigdata/\"}]},{\"text\":\"🍒其他\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/olds/env/\"},{\"text\":\"其他\",\"link\":\"/posts/olds/other/\"}]}]},{\"text\":\"经验\",\"items\":[{\"text\":\"环境\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/exps/env/01-blog-env\"}]},{\"text\":\"心得\",\"items\":[{\"text\":\"心得体会\",\"link\":\"/posts/exps/mind\"}]}]},{\"text\":\"归档\",\"link\":\"/posts/archive.md\"},{\"text\":\"关于我\",\"link\":\"/posts/me\"}],\"outline\":{\"level\":[1,4],\"label\":\"当前页大纲\"},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/plmsmile\"}],\"search\":{\"provider\":\"local\"},\"docFooter\":{\"prev\":\"上一页\",\"next\":\"下一页\"},\"sidebar\":{\"/posts/olds/nlp/\":{\"base\":\"/posts/olds/nlp/\",\"items\":[{\"text\":\"NLP\",\"items\":[{\"text\":\"机器阅读(二)--模型(未完成)\",\"link\":\"54-mrc-models\"},{\"text\":\"机器阅读(一)--整体概述\",\"link\":\"53-mrc-brief\"},{\"text\":\"BERT 详解\",\"link\":\"52-bert\"},{\"text\":\"OpenAI GPT：Improving Language Understanding by Generative Pre-Training\",\"link\":\"51-opengpt\"},{\"text\":\"ELMo：Deep Contextualized Word Representations\",\"link\":\"50-elmo\"},{\"text\":\"QANet\",\"link\":\"49-qanet\"},{\"text\":\"Transformer\",\"link\":\"48-attention-is-all-you-need\"},{\"text\":\"Bidirectional Attention Flow\",\"link\":\"47-bidaf\"},{\"text\":\"R-Net (Gated Self-Matching Networks)\",\"link\":\"46-rnet-selfmatch\"},{\"text\":\"Match-LSTM and Answer Pointer\",\"link\":\"45-match-lstm\"},{\"text\":\"阅读理解模型总结\",\"link\":\"39-squard-models\"},{\"text\":\"阿里小蜜论文\",\"link\":\"36-alime-chat\"},{\"text\":\"各种注意力总结\",\"link\":\"33-attention-summary\"},{\"text\":\"Dynamic Coattention Network (Plus)\",\"link\":\"32-dynamic-coattention-network\"},{\"text\":\"协同注意力简介\",\"link\":\"31-co-attention-vqa\"},{\"text\":\"使用Dynamic Memory Network实现一个简单QA\",\"link\":\"30-dynamic-memory-network\"},{\"text\":\"词性标注和句法依存的表示符号\",\"link\":\"11-nlp-labels\"},{\"text\":\"Word2vec之总体介绍\",\"link\":\"cs224n-notes1-word2vec\"},{\"text\":\"Word2vec之数学模型\",\"link\":\"word2vec-math\"},{\"text\":\"Word2vec之公式推导笔记\",\"link\":\"cs224n-lecture2-word2vec\"},{\"text\":\"subword-units\",\"link\":\"subword-units\"},{\"text\":\"Wordpiece模型\",\"link\":\"26-wordpieacemodel\"},{\"text\":\"谷歌RNN翻译模型\",\"link\":\"25-google-nmt\"},{\"text\":\"机器翻译注意力机制及其PyTorch实现\",\"link\":\"Attention-based-NMT\"},{\"text\":\"图文介绍RNN注意力机制\",\"link\":\"attention-model\"},{\"text\":\"最初RNN神经翻译简略笔记\",\"link\":\"NMT\"},{\"text\":\"语言模型和平滑方法\",\"link\":\"nlp-notes\"},{\"text\":\"利用tensorflow实现简版word2vec\",\"link\":\"word2vec\"}]}]},\"/posts/olds/dl/\":{\"base\":\"/posts/olds/dl/\",\"items\":[{\"text\":\"DL\",\"items\":[{\"text\":\"卷积神经网络总结\",\"link\":\"38-convolution\"},{\"text\":\"网络优化\",\"link\":\"35-nerual-network-optim\"},{\"text\":\"cs224n作业一\",\"link\":\"cs224n-assignment-1\"},{\"text\":\"cs231n线性分类器和损失函数\",\"link\":\"cs231n-linear-notes\"},{\"text\":\"神经网络-过拟合-预处理-BN\",\"link\":\"cs224n-notes3-neural-networks-2\"},{\"text\":\"神经网络基础-反向传播-激活函数\",\"link\":\"cs224n-notes3-neural-networks\"},{\"text\":\"循环神经网络\",\"link\":\"rnn\"},{\"text\":\"PyTorch快速上手\",\"link\":\"23-pytorch-start\"}]}]},\"/posts/olds/rl/\":{\"base\":\"/posts/olds/rl/\",\"items\":[{\"text\":\"RL\",\"items\":[{\"text\":\"强化学习在NLP中的应用\",\"link\":\"44-reinforce-nlp\"},{\"text\":\"意图识别和槽填充\",\"link\":\"43-intent-detection-slot-filling\"},{\"text\":\"强化学习算法小结\",\"link\":\"42-reinforce-conclusion-simple\"},{\"text\":\"基于策略函数的学习方法\",\"link\":\"41-strategy-learning\"},{\"text\":\"基于值函数的学习\",\"link\":\"40-value-learning\"},{\"text\":\"强化学习\",\"link\":\"37-reinforce-learning\"}]}]},\"/posts/olds/ml/\":{\"base\":\"/posts/olds/ml/\",\"items\":[{\"text\":\"ML\",\"items\":[{\"text\":\"决策树笔记\",\"link\":\"29-desicion-tree\"},{\"text\":\"机器学习知识点汇总整理\",\"link\":\"28-ml-interview-notes\"},{\"text\":\"SVM笔记\",\"link\":\"27-svm-notes\"},{\"text\":\"树的总结\",\"link\":\"10-trees\"},{\"text\":\"条件随机场\",\"link\":\"crf\"},{\"text\":\"最大熵模型\",\"link\":\"maxentmodel\"},{\"text\":\"线性回归和逻辑回归\",\"link\":\"21-lr\"},{\"text\":\"最大期望算法\",\"link\":\"14-em\"},{\"text\":\"马尔可夫模型\",\"link\":\"pgm-01\"},{\"text\":\"朴素贝叶斯算法及其代码实现\",\"link\":\"22-ml-ch03-bayes\"}]}]},\"/posts/olds/algo/\":{\"base\":\"/posts/olds/algo/\",\"items\":[{\"text\":\"ALGO\",\"items\":[{\"text\":\"剑指offer4(51-64)\",\"link\":\"aim2offer4\"},{\"text\":\"剑指offer3(21-40)\",\"link\":\"aim2offer3\"},{\"text\":\"数据结构之搜索算法\",\"link\":\"algorithm-dfs\"},{\"text\":\"leetcode-01\",\"link\":\"leetcode-01\"},{\"text\":\"剑指offer(11-20)\",\"link\":\"aim2offer2\"},{\"text\":\"排序算法总结\",\"link\":\"sort-algorithms\"},{\"text\":\"剑指Offer(1-10)\",\"link\":\"aim2offer\"}]}]},\"/posts/olds/bigdata/\":{\"base\":\"/posts/olds/bigdata/\",\"items\":[{\"text\":\"BIG Data\",\"items\":[{\"text\":\"NumPy\",\"link\":\"20-numpy\"},{\"text\":\"Spark基础编程核心思想介绍\",\"link\":\"19-spark-programming\"},{\"text\":\"Spark-SQL的简略笔记\",\"link\":\"18-spark-sql\"},{\"text\":\"Spark键值对RDD的常用API\",\"link\":\"17-spark-pairrdd\"},{\"text\":\"Spark基础RDD的常用API\",\"link\":\"16-Spark-BaseRDD\"}]}]},\"/posts/olds/env/\":{\"base\":\"/posts/olds/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"IDE配置\",\"link\":\"12-ide-envs\"},{\"text\":\"Linux使用笔记\",\"link\":\"09-linux-notes\"},{\"text\":\"博客搭建及相关问题\",\"link\":\"24-hexo-problems\"},{\"text\":\"旧版博客搭建过程及其问题\",\"link\":\"13-old-blog-problems\"}]}]},\"/posts/olds/other/\":{\"base\":\"/posts/olds/other/\",\"items\":[{\"text\":\"其他\",\"items\":[{\"text\":\"C++类对象和指针的区别\",\"link\":\"15-cpp-pointer-object-reference\"}]}]},\"/posts/llm/agent/rl/\":{\"base\":\"/posts/llm/agent/rl/\",\"items\":[{\"text\":\"Agent-RL\",\"items\":[{\"text\":\"Agent-Interaction-RL 笔记\",\"link\":\"04-agent-env\"},{\"text\":\"Agent-Search-RL 笔记\",\"link\":\"03-agent-search\"},{\"text\":\"Agent-Tool-RL 笔记\",\"link\":\"02-agent-tool\"},{\"text\":\"Agent-RL 综述型笔记\",\"link\":\"01-agent-rl\"}]}]},\"/posts/llm/agent/basic/\":{\"base\":\"/posts/llm/agent/basic/\",\"items\":[{\"text\":\"Agent-基础\",\"items\":[{\"text\":\"DeepResearch 评估\",\"link\":\"06-deepresearch-evaluation\"},{\"text\":\"Computer-Agent\",\"link\":\"05-comuter-agent\"},{\"text\":\"Agent 思考性文章\",\"link\":\"04-agent-blogs\"},{\"text\":\"一些流行的Agents\",\"link\":\"03-current-agents\"},{\"text\":\"Agent 评估 Benchmarks\",\"link\":\"02-evaluation-agent\"},{\"text\":\"Agent基础概念 (李宏毅笔记)\",\"link\":\"01-lhy-agent-notes\"}]}]},\"/posts/llm/rl/theory/\":{\"base\":\"/posts/llm/rl/theory/\",\"items\":[{\"text\":\"RL-Theory\",\"items\":[{\"text\":\"Agent-RL 相关算法\",\"link\":\"13-agentrl-algo\"},{\"text\":\"熵和RL相关文章\",\"link\":\"12-entropy\"},{\"text\":\"GRPO 改进系列\",\"link\":\"11-grpo-series\"},{\"text\":\"PPO 改进系列\",\"link\":\"10-ppo-series\"},{\"text\":\"典型策略提升方法：TRPO+PPO+DPO+GRPO\",\"link\":\"09-policy-trpo-ppo\"},{\"text\":\"确定性策略梯度\",\"link\":\"08-deterministic-policy-gradient\"},{\"text\":\"Actor-Critic 算法\",\"link\":\"07-actor-critic\"},{\"text\":\"策略梯度算法\",\"link\":\"06-policy-gradient\"},{\"text\":\"DQN算法及进阶\",\"link\":\"05-dqn\"},{\"text\":\"免模型预测和控制\",\"link\":\"04-model-free-prediction-control\"},{\"text\":\"有模型预测和控制\",\"link\":\"03-model-based-prediction-control\"},{\"text\":\"马尔可夫决策过程\",\"link\":\"02-markove-process\"},{\"text\":\"强化学习基本概念\",\"link\":\"01-rl-introduction\"},{\"text\":\"(18年笔记)强化学习算法小结\",\"link\":\"04-reinforce-conclusion-simple\"},{\"text\":\"(18年笔记)基于策略函数的学习方法\",\"link\":\"03-strategy-learning\"},{\"text\":\"(18年笔记)基于值函数的学习\",\"link\":\"02-value-learning\"},{\"text\":\"(18年笔记)强化学习基础\",\"link\":\"01-reinforce-learning\"}]}]},\"/posts/llm/rl/rlhf/\":{\"base\":\"/posts/llm/rl/rlhf/\",\"items\":[{\"text\":\"RLHF\",\"items\":[]}]},\"/posts/llm/rl/o1llm/\":{\"base\":\"/posts/llm/rl/o1llm/\",\"items\":[{\"text\":\"推理模型\",\"items\":[]}]},\"/posts/llm/industry/mainllm/\":{\"base\":\"/posts/llm/industry/mainllm/\",\"items\":[{\"text\":\"🚀主流模型\",\"items\":[{\"text\":\"快手系列\",\"link\":\"12-kwai-series\"},{\"text\":\"腾讯系列\",\"link\":\"11-tencent-series\"},{\"text\":\"Claude 系列\",\"link\":\"09-claude-series\"},{\"text\":\"LongCat 系列\",\"link\":\"10-longcat-series\"},{\"text\":\"Gemini 系列\",\"link\":\"08-gemini-series\"},{\"text\":\"Seed 系列\",\"link\":\"06-seed-series\"},{\"text\":\"OpenAI 系列\",\"link\":\"07-openai-series\"},{\"text\":\"Qwen 系列\",\"link\":\"05-qwen-series\"},{\"text\":\"MiniMax 系列\",\"link\":\"04-minimax-series\"},{\"text\":\"GLM 系列\",\"link\":\"03-glm-series\"},{\"text\":\"DeepSeek 系列\",\"link\":\"02-deepseek-series\"},{\"text\":\"Kimi 系列\",\"link\":\"01-kimi-series\"},{\"text\":\"SkyWork 系列\",\"link\":\"15-skywork-series\"},{\"text\":\"小米系列\",\"link\":\"14-mimo-series\"},{\"text\":\"Nvidia 系列\",\"link\":\"13-nvidia-series\"}]}]},\"/posts/llm/industry/codellm/\":{\"base\":\"/posts/llm/industry/codellm/\",\"items\":[{\"text\":\"💻代码模型\",\"items\":[{\"text\":\"SWE 合成数据 系列\",\"link\":\"11-swe-data-series\"},{\"text\":\"SWE 总结索引\",\"link\":\"10-swe-summary\"},{\"text\":\"Code 全训练 论文阅读\",\"link\":\"07-code-fulltrain-reading\"},{\"text\":\"Code TaskRL 论文阅读\",\"link\":\"06-code-taskrl-reading\"},{\"text\":\"CodeLLM 索引简记\",\"link\":\"05-open-codellm\"},{\"text\":\"Code 安全相关\",\"link\":\"04-safety-code\"},{\"text\":\"Code RL 任务\",\"link\":\"03-rl-task\"},{\"text\":\"Code 任务Bench相关\",\"link\":\"02-eval-task-benchmark\"},{\"text\":\"Code Survey\",\"link\":\"01-survey\"},{\"text\":\"SWE 训练方法 系列\",\"link\":\"09-swe-series\"},{\"text\":\"Code 预训练相关\",\"link\":\"08-code-pretrain-summary\"}]}]},\"/posts/llm/basic/\":{\"base\":\"/posts/llm/basic/\",\"items\":[{\"text\":\"LLM-basic\",\"items\":[{\"text\":\"LLM位置编码和长度外推系列\",\"link\":\"08-llm-position-embedding\"},{\"text\":\"LLM 解码相关\",\"link\":\"07-decode\"},{\"text\":\"LLM Attention 系列\",\"link\":\"06-llm-attention\"},{\"text\":\"LLM 基础知识\",\"link\":\"05-llm-basic-info\"},{\"text\":\"LLM 架构相关\",\"link\":\"04-llm-architecture\"},{\"text\":\"Transformer细节\",\"link\":\"03-transformer-detail\"},{\"text\":\"语言模型重要组件\",\"link\":\"02-llm-components\"},{\"text\":\"语言模型定义及信息理论\",\"link\":\"01-lm-define-information-theory\"}]}]},\"/posts/llm/infra/\":{\"base\":\"/posts/llm/infra/\",\"items\":[{\"text\":\"🛠LLM-基建框架\",\"items\":[{\"text\":\"Verl 训练流程源代码阅读\",\"link\":\"08-verl-train-loop\"},{\"text\":\"Verl 有趣的功能\",\"link\":\"07-verl-core\"},{\"text\":\"Verl AgentLoop Rollout 相关\",\"link\":\"06-verl-code\"},{\"text\":\"Verl 常见参数配置和理解\",\"link\":\"05-verl-practice\"},{\"text\":\"Verl 早期概念型学习文章\",\"link\":\"04-verl\"},{\"text\":\"推理优化技术\",\"link\":\"03-inference-tech\"},{\"text\":\"分布式训练框架\",\"link\":\"02-speed-framework\"},{\"text\":\"分布式并行策略\",\"link\":\"01-parrallel\"}]}]},\"/posts/exps/env/\":{\"base\":\"/posts/exps/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"环境搭建的一些坑\",\"link\":\"01-blog-env\"}]}]},\"/posts/exps/mind/\":{\"base\":\"/posts/exps/mind/\",\"items\":[{\"text\":\"心得体会\",\"items\":[]}]}}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>
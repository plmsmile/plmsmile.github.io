<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>SWE 系列 论文阅读 | 📚 plmblog</title>
    <meta name="description" content="记录一些学习笔记。">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/assets/style.CuIOXX7t.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.CS3CoyVq.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.DF7QIu43.js">
    <link rel="modulepreload" href="/assets/chunks/framework.CvbyeFFO.js">
    <link rel="modulepreload" href="/assets/posts_llm_industry_codellm_09-swe-series.md.ChL1bQ3P.lean.js">
    <link rel="icon" href="/plm.png">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-cecb633e><!--[--><!--]--><!--[--><span tabindex="-1" data-v-c979f278></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-c979f278>Skip to content</a><!--]--><!----><header class="VPNav" data-v-cecb633e data-v-0ad68676><div class="VPNavBar" data-v-0ad68676 data-v-ce71e4ef><div class="wrapper" data-v-ce71e4ef><div class="container" data-v-ce71e4ef><div class="title" data-v-ce71e4ef><div class="VPNavBarTitle has-sidebar" data-v-ce71e4ef data-v-7e906684><a class="title" href="/" data-v-7e906684><!--[--><!--]--><!----><span data-v-7e906684>📚 plmblog</span><!--[--><!--]--></a></div></div><div class="content" data-v-ce71e4ef><div class="content-body" data-v-ce71e4ef><!--[--><!--]--><div class="VPNavBarSearch search" data-v-ce71e4ef><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-ce71e4ef data-v-e0cd9371><span id="main-nav-aria-label" class="visually-hidden" data-v-e0cd9371> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>首页</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>🐲LLM</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Basic</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/basic/01-lm-define-information-theory.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🦋基础知识</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/infra/01-parrallel.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🛠基建框架</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>强化学习</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/rl/theory/01-reinforce-learning.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🎓RL理论基础</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/rl/02-agent-tool.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚄Agent-RL</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>行业方向</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/industry/mainllm/01-kimi-series.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚀主流模型</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/industry/codellm/01-survey.html" data-v-dc987abe><!--[--><span data-v-dc987abe>💻代码模型</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Agent</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/basic.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🤖概念及应用</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>📙旧文章</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍓NLP</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/nlp.html" data-v-dc987abe><!--[--><span data-v-dc987abe>自然语言处理</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍑基础知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/dl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>深度学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/rl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>强化学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/ml.html" data-v-dc987abe><!--[--><span data-v-dc987abe>机器学习</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍎算法</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/algo/" data-v-dc987abe><!--[--><span data-v-dc987abe>算法题</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/bigdata/" data-v-dc987abe><!--[--><span data-v-dc987abe>大数据</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍒其他</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/env/" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/other/" data-v-dc987abe><!--[--><span data-v-dc987abe>其他</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>经验</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>环境</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/env/01-blog-env.html" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>心得</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/mind.html" data-v-dc987abe><!--[--><span data-v-dc987abe>心得体会</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/archive.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>归档</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/me.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>关于我</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-ce71e4ef data-v-b59ebfac><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-b59ebfac data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-ce71e4ef data-v-e0f2db57 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-ce71e4ef data-v-8897e953 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-ffaaba87><span class="vpi-more-horizontal icon" data-v-ffaaba87></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><!----><!--[--><!--[--><!----><div class="group" data-v-8897e953><div class="item appearance" data-v-8897e953><p class="label" data-v-8897e953>Appearance</p><div class="appearance-action" data-v-8897e953><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-8897e953 data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div></div></div><div class="group" data-v-8897e953><div class="item social-links" data-v-8897e953><div class="VPSocialLinks social-links-list" data-v-8897e953 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-ce71e4ef data-v-37e0f734><span class="container" data-v-37e0f734><span class="top" data-v-37e0f734></span><span class="middle" data-v-37e0f734></span><span class="bottom" data-v-37e0f734></span></span></button></div></div></div></div><div class="divider" data-v-ce71e4ef><div class="divider-line" data-v-ce71e4ef></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-cecb633e data-v-1b409c8b><div class="container" data-v-1b409c8b><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-1b409c8b><span class="vpi-align-left menu-icon" data-v-1b409c8b></span><span class="menu-text" data-v-1b409c8b>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-1b409c8b data-v-a203161a><button data-v-a203161a>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-cecb633e data-v-18f7b5ca><div class="curtain" data-v-18f7b5ca></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-18f7b5ca><span class="visually-hidden" id="sidebar-aria-label" data-v-18f7b5ca> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-7f5b9a39><section class="VPSidebarItem level-0 has-active" data-v-7f5b9a39 data-v-a4affe07><div class="item" role="button" tabindex="0" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><h2 class="text" data-v-a4affe07>💻代码模型</h2><!----></div><div class="items" data-v-a4affe07><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/11-swe-data-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>SWE 合成数据 系列</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/10-swe-summary.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>SWE 相关总结</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/07-code-fulltrain-reading.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 全训练 论文阅读</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/06-code-taskrl-reading.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code TaskRL 论文阅读</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/05-open-codellm.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>CodeLLM 索引简记</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/04-safety-code.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 安全相关</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/03-rl-task.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code RL 任务</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/02-eval-task-benchmark.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 任务Bench相关</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/01-survey.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code Survey</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/09-swe-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>SWE 系列 论文阅读</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/codellm/08-code-pretrain-summary.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Code 预训练相关</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-cecb633e data-v-53a9cb18><div class="VPDoc has-sidebar has-aside" data-v-53a9cb18 data-v-5a64a79a><!--[--><!--]--><div class="container" data-v-5a64a79a><div class="aside" data-v-5a64a79a><div class="aside-curtain" data-v-5a64a79a></div><div class="aside-container" data-v-5a64a79a><div class="aside-content" data-v-5a64a79a><div class="VPDocAside" data-v-5a64a79a data-v-f8ea3c28><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-f8ea3c28 data-v-b94d89ac><div class="content" data-v-b94d89ac><div class="outline-marker" data-v-b94d89ac></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-b94d89ac>当前页大纲</div><ul class="VPDocOutlineItem root" data-v-b94d89ac data-v-80b46526><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-f8ea3c28></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-5a64a79a><div class="content-container" data-v-5a64a79a><!--[--><!--[--><!--[--><article class="post-header" data-v-a99fd7c9><h1 class="title" data-v-a99fd7c9>SWE 系列 论文阅读</h1><div class="stats-container" data-v-a99fd7c9><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 📅 发表于 <span class="stat-text" data-v-a99fd7c9>2025/01/02</span></div><div class="stat-item" data-v-a99fd7c9> 🔄 更新于 <span class="stat-text" data-v-a99fd7c9>2025/01/02</span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 👁️ <span class="stat-text" data-v-a99fd7c9>-- 次访问</span><span id="busuanzi_value_page_pv" style="display:none;" data-page="/posts/llm/industry/codellm/09-swe-series.html" data-v-a99fd7c9></span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 📝 <span class="stat-text" data-v-a99fd7c9>0 字</span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> ⏳ <span class="stat-text" data-v-a99fd7c9>0 分钟</span></div><div class="stat-divider" data-v-a99fd7c9></div></div><div class="tag-group" data-v-a99fd7c9><!--[--><div class="category-item" data-v-a99fd7c9>swe</div><!--]--><!--[--><div class="tag-item" data-v-a99fd7c9> #Self-play SWE-RL</div><div class="tag-item" data-v-a99fd7c9> #SKyRL-Agent</div><div class="tag-item" data-v-a99fd7c9> #InfoCode</div><div class="tag-item" data-v-a99fd7c9> #NEBIUS-SWE</div><div class="tag-item" data-v-a99fd7c9> #Devstral2</div><div class="tag-item" data-v-a99fd7c9> #Devstral</div><div class="tag-item" data-v-a99fd7c9> #SWE-RL</div><!--]--></div></article><!--]--><!--]--><!--]--><main class="main" data-v-5a64a79a><div style="position:relative;" class="vp-doc _posts_llm_industry_codellm_09-swe-series" data-v-5a64a79a><div><h2 id="_2512-self-play-swe-rl-meta" tabindex="-1">(2512) Self-Play SWE-RL (Meta) <a class="header-anchor" href="#_2512-self-play-swe-rl-meta" aria-label="Permalink to &quot;(2512) Self-Play SWE-RL (Meta)&quot;">​</a></h2><div class="custom-block danger"><div class="custom-block-title">摘要</div><ul><li><a href="https://www.alphaxiv.org/abs/2512.18552" target="_blank" rel="noreferrer">paper</a></li></ul></div><h2 id="_2511-skyrl-agent" tabindex="-1">(2511) SkyRL-Agent <a class="header-anchor" href="#_2511-skyrl-agent" aria-label="Permalink to &quot;(2511) SkyRL-Agent&quot;">​</a></h2><p><strong>🌺 论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">论文摘要</div><ul><li><a href="https://www.alphaxiv.org/abs/2511.16108" target="_blank" rel="noreferrer">paper</a></li><li></li></ul></div><h2 id="_2511-infcode" tabindex="-1">(2511) InfCode <a class="header-anchor" href="#_2511-infcode" aria-label="Permalink to &quot;(2511) InfCode&quot;">​</a></h2><p><strong>🌺 论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">论文摘要</div><ul><li><p><a href="https://www.alphaxiv.org/abs/2511.16004" target="_blank" rel="noreferrer">paper</a></p></li><li><p>InfCode提出对抗式多智能体框架，通过测试补丁与代码补丁生成器的迭代互搏解决仓库级缺陷修复中验证信号弱、补丁易过拟合的问题。Test Patch Generator持续构造更强测试用例以暴露缺陷，Code Patch Generator则针对性改进代码，形成动态强化闭环；Selector智能体最终在容器化环境中评估多候选方案，筛选最可靠补丁。</p></li><li><p>该方法在SWE-bench Verified上以79.4%准确率刷新SOTA，在SWE-bench Lite上达40.33%，领先基线11例。消融实验表明对抗迭代与选择器分别贡献4.0和8.0个百分点提升。</p></li><li><p>核心贡献在于将对抗训练思想引入代码修复领域，通过可复现的执行环境与多维度评估机制，显著提升了LLM生成补丁的真实可靠性与泛化能力，为自动化软件维护建立了新的质量保障范式。</p></li></ul></div><h3 id="问题背景" tabindex="-1">问题背景 <a class="header-anchor" href="#问题背景" aria-label="Permalink to &quot;问题背景&quot;">​</a></h3><p><strong>❓问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">问题背景</div></div><h3 id="核心方法" tabindex="-1">核心方法 <a class="header-anchor" href="#核心方法" aria-label="Permalink to &quot;核心方法&quot;">​</a></h3><p><strong>📕核心方法</strong></p><div class="custom-block note"><div class="custom-block-title">核心方法</div></div><h3 id="实验设置" tabindex="-1">实验设置 <a class="header-anchor" href="#实验设置" aria-label="Permalink to &quot;实验设置&quot;">​</a></h3><p><strong>✍️实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li></li></ul><p><strong>训练任务/数据</strong></p><ul><li></li></ul><p><strong>评测任务/数据</strong></p><ul><li></li></ul><p><strong>算法/策略</strong></p><ul><li></li></ul><p><strong>超参</strong></p><ul><li></li><li></li></ul></div><h3 id="关键结果" tabindex="-1">关键结果 <a class="header-anchor" href="#关键结果" aria-label="Permalink to &quot;关键结果&quot;">​</a></h3><p><strong>🍑关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div></div><h3 id="未来方向" tabindex="-1">未来方向 <a class="header-anchor" href="#未来方向" aria-label="Permalink to &quot;未来方向&quot;">​</a></h3><p><strong>⛳ 未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div></div><h2 id="_2509-kimi-dev" tabindex="-1">(2509) Kimi-Dev <a class="header-anchor" href="#_2509-kimi-dev" aria-label="Permalink to &quot;(2509) Kimi-Dev&quot;">​</a></h2><p>🌺 <strong>论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">论文摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2509.23045" target="_blank" rel="noreferrer">paper</a>, <a href="https://huggingface.co/moonshotai/Kimi-Dev-72B" target="_blank" rel="noreferrer">Kimi-Dev-72B</a></li></ul><p><strong>模型效果</strong></p><ul><li></li></ul><p><strong>核心方法</strong></p><ul><li></li></ul><p><strong>重要结论</strong></p><ul><li></li></ul><p><strong>关键贡献</strong></p><ul><li></li></ul></div><h3 id="问题背景-1" tabindex="-1">问题背景 <a class="header-anchor" href="#问题背景-1" aria-label="Permalink to &quot;问题背景&quot;">​</a></h3><p>❓<strong>问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">问题背景</div></div><h3 id="核心方法-1" tabindex="-1">核心方法 <a class="header-anchor" href="#核心方法-1" aria-label="Permalink to &quot;核心方法&quot;">​</a></h3><p>📕<strong>核心方法</strong></p><div class="custom-block note"><div class="custom-block-title">核心方法</div></div><h3 id="实验设置-1" tabindex="-1">实验设置 <a class="header-anchor" href="#实验设置-1" aria-label="Permalink to &quot;实验设置&quot;">​</a></h3><p>✍️<strong>实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li></li></ul><p><strong>训练任务/数据</strong></p><ul><li></li></ul><p><strong>评测任务/数据</strong></p><ul><li></li></ul><p><strong>算法/策略</strong></p><ul><li></li></ul><p><strong>超参</strong></p><ul><li></li><li></li></ul></div><h3 id="关键结果-1" tabindex="-1">关键结果 <a class="header-anchor" href="#关键结果-1" aria-label="Permalink to &quot;关键结果&quot;">​</a></h3><p>🍑<strong>关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><p><strong>模型效果</strong></p><ul><li></li></ul><p><strong>重要结论</strong></p><ul><li></li></ul><p><strong>关键贡献</strong></p><ul><li></li></ul></div><h3 id="未来方向-1" tabindex="-1">未来方向 <a class="header-anchor" href="#未来方向-1" aria-label="Permalink to &quot;未来方向&quot;">​</a></h3><p>⛳ <strong>未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div></div><h2 id="_2508-swe-swiss" tabindex="-1">(2508) SWE-Swiss <a class="header-anchor" href="#_2508-swe-swiss" aria-label="Permalink to &quot;(2508) SWE-Swiss&quot;">​</a></h2><p>🌺 <strong>论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">SWE-Swiss 论文摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.notion.so/SWE-Swiss-A-Multi-Task-Fine-Tuning-and-RL-Recipe-for-High-Performance-Issue-Resolution-21e174dedd4880ea829ed4c861c44f88" target="_blank" rel="noreferrer">SWE-Swiss Blog</a>, <a href="https://github.com/zhenyuhe00/SWE-Swiss" target="_blank" rel="noreferrer">SWE-Siwss</a></li></ul><p><strong>核心方法</strong></p><ul><li>3任务SFT数据构建方法：<code>问题定位</code>+ <code>问题修复</code>+ <code>测试生成</code>，蒸馏DeepSeekR1共<code>10k数据</code>。</li><li>2阶段训练方法：<code>3任务SFT</code> + <code>2阶段RL 课程学习</code>，难样本：过滤<code>正确率&gt;90</code>的数据。</li><li>TTS方法：EM + <code>GT代码相似度</code>。</li></ul><p><strong>模型效果(Qwen2.5-32B-Instruct)</strong></p><ul><li>SWE-Verified <code>SFT达36</code>，<code>RL达45</code>，<code>RL提升9pt</code>，增加TTS(best-120) 达60分。</li><li>在<code>通用任务</code>、<code>Math任务</code>、<code>代码生成任务</code>上，<code>均有提升</code>。</li></ul><p><strong>重要结论</strong></p><ul><li>虽然工作用SFT，但<code>基于RL做定位</code>，也很有效果</li></ul><p><strong>关键贡献</strong></p><ul><li>开源数据</li></ul></div><img src="https://www.notion.so/image/attachment%3A491020da-2334-4ce6-9d4a-6c95d88dbb59%3Afigure1.png?table=block&amp;id=226174de-dd48-801a-8fb7-c2cda8e12d3f&amp;spaceId=558c58f3-e263-4a36-8c1e-9fd21d8fda44&amp;width=1420&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><p>❓<strong>问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">问题背景</div><ul><li><code>Agentless</code> 把SWE分解为<code>固定workflow</code></li><li>如何通过提升<code>各子任务能力</code>，来<code>提升SWE效果</code>？</li></ul></div><p>📕<strong>核心方法</strong></p><div class="custom-block note"><div class="custom-block-title">核心方法</div><p><strong>核心思想</strong></p><ul><li><p>提升<code>3技能</code>：<code>定位</code>、<code>修复</code>、<code>单元测试生成</code>。</p></li><li><p><strong>2阶段训练</strong></p><ul><li><p><code>3任务SFT</code>：分别构造SFT数据</p></li><li><p><code>2阶段RL</code>：通过<code>执行反馈</code> 提升<code>修复能力</code></p></li></ul></li></ul></div><h3 id="_3任务sft数据构建-定位-修复-测试生成" tabindex="-1">3任务SFT数据构建(定位+修复+测试生成) <a class="header-anchor" href="#_3任务sft数据构建-定位-修复-测试生成" aria-label="Permalink to &quot;3任务SFT数据构建(定位+修复+测试生成)&quot;">​</a></h3><div class="custom-block note"><div class="custom-block-title">定位+修复+测试生成 SFT数据构建</div><p><strong>背景</strong></p><ul><li>通过提升3任务能力，来提升SWE能力。</li><li>模型：均使用<code>DeepSeek-R1-0528</code>做<code>蒸馏模型</code>。</li></ul><p><strong>问题定位</strong></p><ul><li>数据源：SWE-Bench、SWE-Gym-Raw</li><li>提取GT修改文件。</li><li><strong>LLM预测修改文件</strong>。 <ul><li>输入：Issue + 项目结构；输出：需要修改的文件</li></ul></li><li>筛选标准：<code>recall=1</code> + <code>预测文件数&lt;5</code></li><li>最终：<code>5.3k 定位数据</code>。</li></ul><p><strong>问题修复</strong></p><ul><li><strong>数据+环境</strong>：SWE-gym、SWE-smith。</li><li><strong>LLM预测Patch</strong>。 <ul><li>输入： <code>Issue </code>+ <code>GT修改文件</code> + <code>相关文件</code>；输出：<code>Patch</code></li></ul></li><li>筛选标准：单元测试。保留通过的。</li><li>最终：<code>3.9k 修复数据</code>。</li></ul><p><strong>测试生成</strong></p><ul><li>数据源：SWE-gym、SWE-smith，同问题修复数据。</li><li><strong>LLM生成单元测试</strong>。</li><li>筛选标准：实际执行测试结果，需和原测试保持一致。</li><li>最终：<code>1k 单元测试生成数据</code>。</li></ul></div><img src="https://www.notion.so/image/attachment%3A24d3c1fd-2566-4a39-804d-99defb9fffa8%3AWX20250707-1428302x.png?table=block&amp;id=226174de-dd48-80bf-9730-ca54187ed782&amp;spaceId=558c58f3-e263-4a36-8c1e-9fd21d8fda44&amp;width=1420&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><h3 id="_2阶段训练-3任务sft-2阶段rl" tabindex="-1">2阶段训练(3任务SFT + 2阶段RL) <a class="header-anchor" href="#_2阶段训练-3任务sft-2阶段rl" aria-label="Permalink to &quot;2阶段训练(3任务SFT + 2阶段RL)&quot;">​</a></h3><div class="custom-block info"><div class="custom-block-title">2阶段训练 (SFT + RL)</div><p><strong>3任务SFT</strong></p><ul><li>10k SFT数据集。</li><li>把不同的多任务能力，训进一个单模型。</li></ul><p><strong>2阶段RL (课程学习)</strong></p><ul><li>奖励设计：通过单元测试：1，其他：-1</li><li>阶段1：训200步，<code>全部数据</code>。</li><li>阶段2：训90步，<code>过滤正确率超90%的样本</code>。</li></ul></div><img src="https://www.notion.so/image/attachment%3Af77aac41-24be-4d6f-befd-3a5be530979f%3Aswe_bench_performance_with_dashed_line.png?table=block&amp;id=240174de-dd48-80f7-bf2a-d6af90915244&amp;spaceId=558c58f3-e263-4a36-8c1e-9fd21d8fda44&amp;width=1420&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><h3 id="测试和tts" tabindex="-1">测试和TTS <a class="header-anchor" href="#测试和tts" aria-label="Permalink to &quot;测试和TTS&quot;">​</a></h3><div class="custom-block info"><div class="custom-block-title">TTS</div><p><strong>单Patch生成</strong></p><ul><li>2阶段 <code>定位</code> + <code>修复</code>。 <ul><li>定位模块：先<code>预测相关文件</code></li><li>修复模块：<code>预测文件</code> + <code>检索文件</code> --&gt; <code>生成修复Patch</code>，检索使用text-embedding3-small</li></ul></li></ul><p><strong>多Patch + TTS</strong></p><ul><li><p>核心：<code>生成多个patch</code> + <code>过滤patch</code> + <code>选择最优patch</code>。</p></li><li><p>过滤patch：<code>原测试过滤</code> + <code>生成测试过滤</code></p><ul><li>生成测试：Issue+预测相关文件，生成测试用例。测试用例通过一致性选择过滤。</li></ul></li><li><p>最优patch选择：</p><ul><li><p>传统self-consistency：基于EM做投票选择，数学居多。</p></li><li><p>增强self-consitency：除<code>EM</code>以外，增加与<code>GT代码相似度</code>得分。</p><mjx-container tabindex="0" class="MathJax" jax="SVG" display="true" style="direction:ltr;display:block;text-align:center;margin:1em 0;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.566ex;" xmlns="http://www.w3.org/2000/svg" width="35.456ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 15671.7 1000" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z" style="stroke-width:3;"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(556,0)" style="stroke-width:3;"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1000,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(1500,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1892,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(2336,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2725,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3158,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3824.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(4880.6,0)"><g data-mml-node="mtext"><path data-c="53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z" style="stroke-width:3;"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(556,0)" style="stroke-width:3;"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1000,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(1500,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1892,0)" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(2369,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="45" d="M128 619Q121 626 117 628T101 631T58 634H25V680H597V676Q599 670 611 560T625 444V440H585V444Q584 447 582 465Q578 500 570 526T553 571T528 601T498 619T457 629T411 633T353 634Q266 634 251 633T233 622Q233 622 233 621Q232 619 232 497V376H286Q359 378 377 385Q413 401 416 469Q416 471 416 473V493H456V213H416V233Q415 268 408 288T383 317T349 328T297 330Q290 330 286 330H232V196V114Q232 57 237 52Q243 47 289 47H340H391Q428 47 452 50T505 62T552 92T584 146Q594 172 599 200T607 247T612 270V273H652V270Q651 267 632 137T610 3V0H25V46H58Q100 47 109 49T128 61V619Z" style="stroke-width:3;"></path><path data-c="4D" d="M132 622Q125 629 121 631T105 634T62 637H29V683H135Q221 683 232 682T249 675Q250 674 354 398L458 124L562 398Q666 674 668 675Q671 681 683 682T781 683H887V637H854Q814 636 803 634T785 622V61Q791 51 802 49T854 46H887V0H876Q855 3 736 3Q605 3 596 0H585V46H618Q660 47 669 49T688 61V347Q688 424 688 461T688 546T688 613L687 632Q454 14 450 7Q446 1 430 1T410 7Q409 9 292 316L176 624V606Q175 588 175 543T175 463T175 356L176 86Q187 50 261 46H278V0H269Q254 3 154 3Q52 3 37 0H29V46H46Q78 48 98 56T122 69T132 86V622Z" transform="translate(681,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(8429.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(8818.5,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(9251.5,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(9862.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(10863,0)"><g data-mml-node="mtext"><path data-c="53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z" style="stroke-width:3;"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(556,0)" style="stroke-width:3;"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(1000,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(1500,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1892,0)" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(2369,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z" style="stroke-width:3;"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(556,0)" style="stroke-width:3;"></path><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(834,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(14460.7,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(14849.7,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(15282.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;overflow:hidden;width:100%;"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Score</mtext><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mtext>Score</mtext><mrow data-mjx-texclass="ORD"><mtext>EM</mtext></mrow></msub><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo><mo>+</mo><msub><mtext>Score</mtext><mrow data-mjx-texclass="ORD"><mtext>Sim</mtext></mrow></msub><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container></li></ul></li></ul></div><img src="https://www.notion.so/image/attachment%3Abeeb51dc-f5c8-48b3-bf28-48e4892d223d%3A%E5%9B%BE4.png?table=block&amp;id=242174de-dd48-80fd-8cd8-d89961f18e46&amp;spaceId=558c58f3-e263-4a36-8c1e-9fd21d8fda44&amp;width=1420&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><h3 id="实验设置和结果" tabindex="-1">实验设置和结果 <a class="header-anchor" href="#实验设置和结果" aria-label="Permalink to &quot;实验设置和结果&quot;">​</a></h3><p>✍️<strong>实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li>Qwen2.5-32B-Instruct</li></ul><p><strong>训练任务/数据</strong></p><ul><li>SFT(定位+修复+测试生成)：10k 数据</li><li>RL(修复)：<code>SWE-Gym</code>, <code>SWE-smith</code></li></ul><p><strong>评测任务/数据</strong></p><ul><li>SWE-verified</li></ul><p><strong>算法/策略</strong></p><ul><li><code>3任务SFT</code> + <code>RL</code></li><li>DAPO技巧：<code>no kl loss</code>，<code>clip_higher</code>, <code>动态采样</code>，<code>token-level loss</code></li></ul><p><strong>超参</strong></p></div><p>🍑<strong>关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><p><strong>模型效果(Qwen2.5-32B-Instruct)</strong></p><ul><li>SWE-Verified <code>SFT达36</code>，<code>RL达45</code>，<code>RL提升9pt</code>。</li><li>增加TTS后，<code>Best-of-120</code>：<code>达60分</code>。</li><li>在<code>通用任务</code>、<code>Math任务</code>、<code>代码生成任务</code>上，<code>均有提升</code>。 <ul><li>Instruct &lt; SFT &lt; SFT + RL</li></ul></li></ul><p><strong>重要结论</strong></p><ul><li>虽然工作用SFT，但基于RL做定位，也很有效果。预测正确：给+1奖励。</li></ul><p><strong>关键贡献</strong></p><ul><li>完全开源。</li></ul></div><p>⛳ <strong>未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div></div><h2 id="_2508-nebius-长上下文多轮swe-筛选swe-rebench数据" tabindex="-1">(2508) NEBIUS 长上下文多轮SWE (筛选SWE-rebench数据) <a class="header-anchor" href="#_2508-nebius-长上下文多轮swe-筛选swe-rebench数据" aria-label="Permalink to &quot;(2508) NEBIUS 长上下文多轮SWE (筛选SWE-rebench数据)&quot;">​</a></h2><p><strong>🌺 论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">论文摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2508.03501" target="_blank" rel="noreferrer">paper</a></li></ul><p><strong>核心方法</strong></p><ul><li><code>SWE-rebench数据筛选策略</code>：<code>过滤有误数据</code>+<code>控制复杂度</code>+<code>LLM质量评估</code>+<code>确定性测试</code><ul><li>选出<code>7k数据</code> 做训练，用<code>Verified-50</code>做快速验证。</li></ul></li><li><code>RFT冷启动方法</code>： <code>自蒸馏6.5k</code>轨迹数据 + SFT <code>Mask错误格式动作</code>，仅学习有效动作。</li><li><code>2阶段RL课程学习</code>：<code>65k</code> -&gt; <code>131k</code>，<code>全部样本</code> -&gt; <code>难度样本</code><ul><li>难样本：过滤阶段1期后 <code>正确率 &gt; 2/3</code>、<code>正确率=0</code>的样本</li></ul></li><li><code>部分DAPO技巧</code>：<code>超长步数惩罚</code> + <code>去掉0优势样本</code> + Token-level Loss <ul><li><strong>步数惩罚</strong>：鼓励高效和<code>惩罚死循环</code>动作</li></ul></li></ul><p><strong>模型效果 (Qwen2.5-72B-Inst)</strong></p><ul><li>训练后，SWE <code>pass@1达39分</code>，<code>pass@10达58分</code>，<code>持平DeeepSeek-V3-0324</code></li></ul><p><strong>重要结论</strong></p><ul><li><code>不要过滤超长样本</code>，<code>要惩罚死循环</code>。</li><li><code>训推不一致</code>：采样<code>topk, topp</code>导致<code>词表被截断</code>，解法：<code>关闭filter</code>。</li><li>未来难题方向：<code>长程信用分配问题</code>、<code>盲目自信问题</code>。</li></ul></div><h3 id="swe方法及挑战" tabindex="-1">SWE方法及挑战 <a class="header-anchor" href="#swe方法及挑战" aria-label="Permalink to &quot;SWE方法及挑战&quot;">​</a></h3><p><strong>❓问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">目前SWE方法</div><ul><li>复杂的scaffold + 闭源LLM</li><li>大量的<code>Test-Time-Scaling</code>技术，(2410)<a href="https://arxiv.org/abs/2410.20285" target="_blank" rel="noreferrer">SWE-search</a></li><li>使用<code>强LLM做数据蒸馏</code> <code>微调小模型</code><ul><li>(2504) <a href="https://arxiv.org/abs/2504.21798" target="_blank" rel="noreferrer">SWE-smith</a>, (2506) <a href="http://plmsmile.github.io/posts/llm/industry/mainllm/15-skywork-series.html#_2506-skywork-swe" target="_blank" rel="noreferrer">Skywork-SWE</a>, (2412) <a href="https://arxiv.org/abs/2412.21139" target="_blank" rel="noreferrer">SWE-Gym</a></li></ul></li></ul></div><div class="custom-block warning"><div class="custom-block-title">SWE 存在挑战</div><ul><li><code>Long-Horizon 多轮交互</code><ul><li>2阶段RL，YaRN 技术 扩展至131k</li></ul></li><li><code>反馈复杂</code>：反馈一大堆报错，可能看不懂 <ul><li>RFT 冷启动</li></ul></li><li><code>数据难以构建</code><ul><li>对策：使用ReBench做清洗，一套清洗策略</li></ul></li><li><code>奖励稀疏</code><ul><li>对策：GRPO/DAPO，Token-Level Loss</li></ul></li><li><code>评估贵且有噪声</code>：跑1次要几分钟，还学不到东西； <ul><li>对策：<code>Verified-50子集</code>、<code>去掉Noisy不稳定数据</code></li></ul></li></ul></div><img src="https://arxiv.org/html/2508.03501v1/figures/problem_illustration.png" style="display:block;margin:auto;" width="70%"><h3 id="核心方法-2" tabindex="-1">核心方法 <a class="header-anchor" href="#核心方法-2" aria-label="Permalink to &quot;核心方法&quot;">​</a></h3><p><strong>📕核心方法</strong></p><h4 id="筛选-swe-rebench数据" tabindex="-1">筛选 SWE-rebench数据 <a class="header-anchor" href="#筛选-swe-rebench数据" aria-label="Permalink to &quot;筛选 SWE-rebench数据&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">SWE-ReBench 数据筛选</div><p><strong>SWE-ReBench</strong></p><ul><li>原始：<code>21k任务</code> + <code>3.4k python仓库</code></li><li>筛选后：<code>7.2k 任务</code></li></ul><p><strong>数据筛选策略</strong></p><ul><li><code>过滤任务本身有误的数据</code>：如属性错误、引用错误导致不能通过测试等。</li><li><code>控制复杂度</code>：<code>修改文件数&lt;7</code> + <code>修改代码数&lt;500行</code></li><li><code>LLM评估质量</code>：去掉问题<code>描述不清楚</code>、任务<code>过于复杂</code>、<code>test patch有问题</code>的数据。</li><li><code>确定性测试</code>：执行50次，需要结果一致，不一致则过滤。</li></ul><p><strong>评测集</strong></p><ul><li><code>Verified-50</code>：从SWE-verified 随机选择 <code>50个任务</code>，做训练时验证。</li><li><code>SWE-rebench 5月和6月版</code>：</li></ul></div><h4 id="环境动作空间-swe-agent-scaffold-react" tabindex="-1">环境动作空间 (SWE-Agent Scaffold + ReAct) <a class="header-anchor" href="#环境动作空间-swe-agent-scaffold-react" aria-label="Permalink to &quot;环境动作空间 (SWE-Agent Scaffold + ReAct)&quot;">​</a></h4><div class="custom-block info"><div class="custom-block-title">SWE-Agent Scaffold + ReAct</div><p><strong>动作空间</strong></p><ul><li><code>任意shell命令</code>：ls, cat, grep等。</li><li><code>编辑命令</code>：新闻部替换指定行</li><li><code>自定义搜索和查找</code>：search_file、open、`goto</li><li><code>submit</code>：终止</li></ul><p><strong>SWE Task</strong></p><ul><li><code>Issue描述</code>、<code>测试套件</code>、<code>sandbox 环境快照</code></li></ul></div><h4 id="rft冷启动-筛选正确轨迹-mask错误动作" tabindex="-1">RFT冷启动 (筛选正确轨迹+Mask错误动作) <a class="header-anchor" href="#rft冷启动-筛选正确轨迹-mask错误动作" aria-label="Permalink to &quot;RFT冷启动 (筛选正确轨迹+Mask错误动作)&quot;">​</a></h4><div class="custom-block info"><div class="custom-block-title">Rejection Finetuning 冷启动</div><p><strong>背景</strong></p><ul><li>Qwen2.5-72B-Instruct：<code>SWE 仅11分</code>，因为<code>指令格式不遵循</code>。</li></ul><p><strong>方法</strong></p><ul><li>在选定的<code>SWE-rebench任务</code>上，<code>Rollout 10次</code>，仅保留<code>成功的6.5k轨迹</code></li><li>SFT <code>1个epoch</code>：<code>Mask 错误格式动作</code>，<code>只学习有效动作</code>。</li><li>准确率由<code>11</code>提升至<code>20分</code>。</li></ul></div><img src="https://arxiv.org/html/2508.03501v1/figures/rft_trajectory_example.png" style="display:block;margin:auto;" width="70%"><h4 id="dapo算法-2阶段rl训练" tabindex="-1">DAPO算法+2阶段RL训练 <a class="header-anchor" href="#dapo算法-2阶段rl训练" aria-label="Permalink to &quot;DAPO算法+2阶段RL训练&quot;">​</a></h4><div class="custom-block important"><div class="custom-block-title">GRPO 算法配置</div><p><strong>奖励配置</strong></p><ul><li><p>整体奖励：<code>稀疏奖励</code> + <code>步数超长惩罚</code>，全部正确才为1</p><mjx-container tabindex="0" class="MathJax" jax="SVG" display="true" style="direction:ltr;display:block;text-align:center;margin:1em 0;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.8ex;" xmlns="http://www.w3.org/2000/svg" width="27.454ex" height="2.497ex" role="img" focusable="false" viewBox="0 -750 12134.7 1103.5" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mstyle" fill="blue" stroke="blue"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(792,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" style="stroke-width:3;"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(306,0)" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(584,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1140,0)" style="stroke-width:3;"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(1640,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(2198.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2587.2,0)"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3104.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(3771,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(4826.8,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(792,-176.7) scale(0.707)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mi" transform="translate(5943.9,0)"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(6460.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(7072.1,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mstyle" fill="red" stroke="red" transform="translate(8072.3,0)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(792,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(722,0)" style="stroke-width:3;"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(1278,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1778,0)" style="stroke-width:3;"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(2167,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(2767.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(3156.5,0)"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3673.5,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;overflow:hidden;width:100%;"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mstyle mathcolor="blue"><msub><mi>R</mi><mrow data-mjx-texclass="ORD"><mtext>final</mtext></mrow></msub><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo></mstyle><mo>=</mo><msub><mi>R</mi><mo stretchy="false">(</mo></msub><mi>τ</mi><mo stretchy="false">)</mo><mo>+</mo><mstyle mathcolor="red"><msub><mi>R</mi><mrow data-mjx-texclass="ORD"><mtext>length</mtext></mrow></msub><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo></mstyle></math></mjx-assistive-mml></mjx-container></li><li><p><code>步数超长惩罚</code>：<code>惩罚死循环</code> + <code>鼓励高效方案</code></p><ul><li><mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.357ex;" xmlns="http://www.w3.org/2000/svg" width="4.486ex" height="1.889ex" role="img" focusable="false" viewBox="0 -677 1982.9 834.8" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(617,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(833,0)" style="stroke-width:3;"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(1333,0)" style="stroke-width:3;"></path></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>T</mi><mrow data-mjx-texclass="ORD"><mtext>max</mtext></mrow></msub></math></mjx-assistive-mml></mjx-container>：<code>最大步数</code>，<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.355ex;" xmlns="http://www.w3.org/2000/svg" width="3.867ex" height="1.901ex" role="img" focusable="false" viewBox="0 -683 1709.4 840.1" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" style="stroke-width:3;"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(389,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(945,0)" style="stroke-width:3;"></path></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>L</mi><mrow data-mjx-texclass="ORD"><mtext>thr</mtext></mrow></msub></math></mjx-assistive-mml></mjx-container>：<code>开始惩罚的阈值</code>。类似<a href="https://plmsmile.github.io/posts/llm/rl/theory/11-grpo-series.html#overlong-%E5%A5%96%E5%8A%B1%E8%AE%BE%E8%AE%A1" target="_blank" rel="noreferrer">DAPO 长度超长惩罚</a>。</li></ul><mjx-container tabindex="0" class="MathJax" jax="SVG" display="true" style="direction:ltr;display:block;text-align:center;margin:1em 0;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-2.827ex;" xmlns="http://www.w3.org/2000/svg" width="34.382ex" height="6.785ex" role="img" focusable="false" viewBox="0 -1749.5 15197 2999" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(792,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(722,0)" style="stroke-width:3;"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(1278,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1778,0)" style="stroke-width:3;"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(2167,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(2767.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(3156.5,0)"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3673.5,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(4340.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mrow" transform="translate(5396,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7B" d="M661 -1243L655 -1249H622L604 -1240Q503 -1190 434 -1107T348 -909Q346 -897 346 -499L345 -98L343 -82Q335 3 287 87T157 223Q146 232 145 236Q144 240 144 250Q144 265 145 268T157 278Q242 333 288 417T343 583L345 600L346 1001Q346 1398 348 1410Q379 1622 600 1739L622 1750H655L661 1744V1727V1721Q661 1712 661 1710T657 1705T648 1700T630 1690T602 1668Q589 1659 574 1643T531 1593T484 1508T459 1398Q458 1389 458 1001Q458 614 457 605Q441 435 301 316Q254 277 202 251L250 222Q260 216 301 185Q443 66 457 -104Q458 -113 458 -501Q458 -888 459 -897Q463 -944 478 -988T509 -1060T548 -1114T580 -1149T602 -1167Q620 -1183 634 -1192T653 -1202T659 -1207T661 -1220V-1226V-1243Z" style="stroke-width:3;"></path></g><g data-mml-node="mtable" transform="translate(806,0)"><g data-mml-node="mtr" transform="translate(0,851.5)"><g data-mml-node="mtd"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(500,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mtd" transform="translate(4879,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(278,0)"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(795,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1350.8,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(2406.6,0)"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" style="stroke-width:3;"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(389,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(945,0)" style="stroke-width:3;"></path></g></g></g></g></g><g data-mml-node="mtr" transform="translate(0,-644.9)"><g data-mml-node="mtd"><g data-mml-node="mfrac"><g data-mml-node="mstyle" transform="translate(541.7,516.4) scale(0.707)" fill="red" stroke="red"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" style="stroke-width:3;"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(389,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(945,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(1709.4,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(2487.4,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2765.4,0)"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3282.4,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mstyle" transform="translate(220,-345) scale(0.707)" fill="blue" stroke="blue"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(617,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(833,0)" style="stroke-width:3;"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(1333,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(1982.9,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(2760.9,0)"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" style="stroke-width:3;"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(389,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(945,0)" style="stroke-width:3;"></path></g></g></g></g><rect width="3361" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(3601,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mtd" transform="translate(4879,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(278,0)"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(795,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1350.8,0)"><path data-c="2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(2406.6,0)"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" style="stroke-width:3;"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(389,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(945,0)" style="stroke-width:3;"></path></g></g></g></g></g></g><g data-mml-node="mo" transform="translate(9801,0) translate(0 250)"></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;overflow:hidden;width:100%;"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>R</mi><mrow data-mjx-texclass="ORD"><mtext>length</mtext></mrow></msub><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo><mo>=</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><mtable columnalign="left left" columnspacing="1em" rowspacing=".2em"><mtr><mtd><mn>0</mn><mo>,</mo></mtd><mtd><mo data-mjx-texclass="ORD" stretchy="false">|</mo><mi>τ</mi><mo data-mjx-texclass="ORD" stretchy="false">|</mo><mo>&lt;</mo><msub><mi>L</mi><mrow data-mjx-texclass="ORD"><mtext>thr</mtext></mrow></msub></mtd></mtr><mtr><mtd><mfrac><mstyle mathcolor="red"><msub><mi>L</mi><mrow data-mjx-texclass="ORD"><mtext>thr</mtext></mrow></msub><mo>−</mo><mo data-mjx-texclass="ORD" stretchy="false">|</mo><mi>τ</mi><mo data-mjx-texclass="ORD" stretchy="false">|</mo></mstyle><mstyle mathcolor="blue"><msub><mi>T</mi><mrow data-mjx-texclass="ORD"><mtext>max</mtext></mrow></msub><mo>−</mo><msub><mi>L</mi><mrow data-mjx-texclass="ORD"><mtext>thr</mtext></mrow></msub></mstyle></mfrac><mo>,</mo></mtd><mtd><mo data-mjx-texclass="ORD" stretchy="false">|</mo><mi>τ</mi><mo data-mjx-texclass="ORD" stretchy="false">|</mo><mo>≥</mo><msub><mi>L</mi><mrow data-mjx-texclass="ORD"><mtext>thr</mtext></mrow></msub></mtd></mtr></mtable><mo data-mjx-texclass="CLOSE" fence="true" stretchy="true" symmetric="true"></mo></mrow></math></mjx-assistive-mml></mjx-container></li></ul><p><strong>GRPO 算法配置</strong></p><ul><li>整体同<a href="https://plmsmile.github.io/posts/llm/rl/theory/11-grpo-series.html#_2504-dapo-seed" target="_blank" rel="noreferrer">DAPO</a>：<code>token-level-loss</code></li><li>Group-10 计算，但<code>去掉优势为0的样本</code>。</li><li>rollout=10</li></ul></div><div class="custom-block important"><div class="custom-block-title">2阶段RL训练</div><p><strong>2阶段RL训练</strong></p><ul><li>阶段1：65k，构建baseline</li><li>阶段2：<code>131k</code>，<code>交互轮数T_max翻倍</code>，处理<code>更复杂问题</code></li></ul><p><strong>阶段2优化</strong></p><ul><li><code>降低clip上限</code>：更新更稳定，<code>防止模型跑偏</code>，(2506) <a href="https://www.alphaxiv.org/abs/2506.10910" target="_blank" rel="noreferrer">Magistral</a></li><li><code>增加问题难度</code>：(2506) <a href="https://www.alphaxiv.org/abs/2506.06632" target="_blank" rel="noreferrer">课程RL学习(E2H Reasoner)</a><ul><li>去掉<code>成功率&gt;2/3</code>的任务</li><li>去掉<code>成功率一直为0</code>的任务</li></ul></li><li><code>增大batch size</code>：<code>梯度计算更准确</code>，(2505) <a href="https://arxiv.org/abs/2505.22312" target="_blank" rel="noreferrer">Skywork-OR1</a></li><li><code>减少每次迭代采样的实例数量</code>：<code>平衡开销</code>。</li><li>以上来自推理模型训练经验</li></ul></div><h3 id="实验设置-2" tabindex="-1">实验设置 <a class="header-anchor" href="#实验设置-2" aria-label="Permalink to &quot;实验设置&quot;">​</a></h3><p><strong>✍️实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li>Qwen2.5-72B-Instruct</li></ul><p><strong>训练任务/数据</strong></p><ul><li>从<code>SWE-rebench</code>清洗的<code>7.2k 数据</code></li></ul><p><strong>评测任务/数据</strong></p><ul><li>SWE-verified</li></ul><p><strong>算法/策略</strong></p><ul><li><code>RFT 冷启动</code> +<code>2阶段RL训练</code> (<code>65k</code> -&gt; <code>131k</code>上下文)</li></ul><p><strong>超参</strong></p><ul><li>具体见<code>RL算法配置</code></li><li>H200，<code>8卡 * 16节点</code>，每节点<code>32核CPU</code>、<code>960GB CPU内存</code>。</li></ul><p><strong>SWE环境</strong></p><ul><li>agent执行：<code>Kubernetes集群</code>，每个实例 <code>0.5 CPU</code> + <code>2GB内存</code></li><li>评估：<a href="https://tracto.ai/" target="_blank" rel="noreferrer">云平台 TractoAI</a></li></ul></div><h3 id="关键结果-qwen2-5-72b-inst" tabindex="-1">关键结果(Qwen2.5-72B-Inst) <a class="header-anchor" href="#关键结果-qwen2-5-72b-inst" aria-label="Permalink to &quot;关键结果(Qwen2.5-72B-Inst)&quot;">​</a></h3><p><strong>🍑关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><p><strong>模型效果 (Qwen2.5-72B-Instruct)</strong></p><ul><li><code>RFT 冷启动微调</code>：SWE-verified <code>达20分</code></li><li><code>2阶段 RL训练</code>：<code>pass@1达39分</code>，<code>pass@10达58分</code>。</li><li><code>RFT+2RL</code>后： <code>效果持平 DeepSeek-V3-0324</code>，低于235b-Inst-2507，超过Qwen3-235B。</li></ul><p><strong>重要结论</strong></p><ul><li><code>不要过滤丢弃超长样本</code>：实际丢弃了超长负样本，导致<code>死循环得不到惩罚</code>。</li><li><code>训推不一致</code>导致<code>训练崩溃</code><ul><li>原因：<code>top-k, top-p</code>导致<code>词表被截断</code>，计算<code>IS权重</code>时<code>分布不匹配</code>。</li><li>解法：<code>关闭filter</code>，温度设为1</li><li><a href="https://plmsmile.github.io/posts/llm/industry/mainllm/02-deepseek-series.html#%E4%BF%9D%E6%8C%81%E8%B7%AF%E7%94%B1%E5%92%8C%E9%87%87%E6%A0%B7mask-%E6%B6%88%E9%99%A4%E8%AE%AD%E6%8E%A8%E4%B8%8D%E4%B8%80%E8%87%B4" target="_blank" rel="noreferrer">DeepSeek-V3.2 保持采样Mask 解决训推不一致问题</a>：<code>保持采样Mask</code></li></ul></li></ul></div><img src="https://arxiv.org/html/2508.03501v1/figures/rl_iterations.png" style="display:block;margin:auto;" width="70%"><h3 id="swe-难题未来方向" tabindex="-1">SWE 难题未来方向 <a class="header-anchor" href="#swe-难题未来方向" aria-label="Permalink to &quot;SWE 难题未来方向&quot;">​</a></h3><p><strong>⛳ 未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div><p><strong>稀疏奖励和信用分配问题</strong></p><ul><li><p>背景：长轨迹难以分配奖励信号。</p></li><li><p>未来方向：</p><ul><li><p><code>Reward Shaping</code>：设计中间奖励，通过部分测试用例、减少编译器保持数量等。</p></li><li><p><code>训练辅助Critic</code>：提供step-level的优势估计，实现细粒度更新</p></li><li><p><code>前缀采样</code>：从<code>共享非空前缀</code>开始进行多次Rollout，更好知道中间动作哪个动作更好</p></li></ul></li></ul><p><strong>不确定性和风险感知(盲目自信)</strong></p><ul><li>背景：稀疏二值奖励 鼓励agent提交patch：可能<code>表现得很自信</code>，<code>但结果不正确</code></li><li>现实：需要<code>识别何时该放弃</code>。</li><li>方法： <ul><li>模型显示<code>输出置信度分数</code></li><li>Agent<code>自主决定是否重新尝试</code>：自主 Best-of-N 选择</li></ul></li></ul></div><h2 id="_2508-deepswe-agentic" tabindex="-1">(2508) DeepSWE (Agentic) <a class="header-anchor" href="#_2508-deepswe-agentic" aria-label="Permalink to &quot;(2508) DeepSWE (Agentic)&quot;">​</a></h2><p><strong>🌺 论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">DeepSWE 摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://pretty-radio-b75.notion.site/DeepSWE-Training-a-Fully-Open-sourced-State-of-the-Art-Coding-Agent-by-Scaling-RL-22281902c1468193aabbe9a8c59bbe33" target="_blank" rel="noreferrer">DeepSWE-blog</a>, <a href="https://huggingface.co/agentica-org/DeepSWE-Preview" target="_blank" rel="noreferrer">agentica-org/DeepSWE-Preview</a></li></ul><p><strong>核心方法</strong></p><ul><li><code>Kubernates R2E环境集群</code> + <code>R2E-Gym 4.5k数据</code> + <code>环境执行反馈</code></li><li><code>GRPO++算法</code>： <ul><li>DAPO技巧：<code>Clip-Higher</code>+<code>去除KL Loss</code>+ <code>去除熵loss</code> + <code>compact过滤</code></li><li>Dr.GRPO技巧：<code>优势不除以标准差</code> + <code>去掉序列内Token平均</code></li><li>RLOO技巧：<code>留一法计算优势</code></li></ul></li><li><code>Hybrid TTS</code></li></ul><p><strong>模型效果</strong></p><ul><li>Qwen3-32B 经<code>GRPO++</code>优化后，SWE-verified 达<code>42分</code>，<code>TTS达59分</code>。</li></ul><p><strong>重要结论</strong></p><ul><li>用Claude蒸馏来SFT模型，<code>SWE仅34分</code>，低于<a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#%E5%85%B3%E9%94%AE%E7%BB%93%E6%9E%9C-swe-agent-lm-32b" target="_blank" rel="noreferrer">SWE-Agent-LM 40分</a>。</li><li>用<code>SWE-Smith</code>和<code>SWE-Gym</code>数据做RL，<code>提升有限</code>。</li><li><code>R2E-Gym</code> 很适合做RL，<code>较好课程学习</code>。</li></ul><p><strong>关键贡献</strong></p></div><h3 id="问题背景-2" tabindex="-1">问题背景 <a class="header-anchor" href="#问题背景-2" aria-label="Permalink to &quot;问题背景&quot;">​</a></h3><p><strong>❓问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">问题背景</div><ul><li>Agent：通过工具调用和真实环境交互，环境给予反馈、奖励信号。</li><li>Code Agent：IDE工具(<code>Bash</code>+<code>文件搜索</code>+<code>文件编辑</code> + <code>文件浏览</code>)等。</li></ul></div><p>Agent</p><img src="https://pretty-radio-b75.notion.site/image/attachment%3A3c883410-4cb9-40f3-aadd-7fa2a9ab6f4e%3Adeepswe-agent-example_(1).svg?table=block&amp;id=22281902-c146-81bb-a3a8-ed7613a539ff&amp;spaceId=3dea8845-5afd-4ee7-97ee-480e9ce47ccd&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><p>Code Agent</p><img src="https://pretty-radio-b75.notion.site/image/attachment%3Adfb76706-2797-4284-af8c-46ad6896daf8%3Asweagent-example_(1).svg?table=block&amp;id=22281902-c146-81bf-a11a-d3167a168c43&amp;spaceId=3dea8845-5afd-4ee7-97ee-480e9ce47ccd&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><h3 id="核心方法-3" tabindex="-1">核心方法 <a class="header-anchor" href="#核心方法-3" aria-label="Permalink to &quot;核心方法&quot;">​</a></h3><p><strong>📕核心方法</strong></p><h4 id="swe环境-kubernates集群" tabindex="-1">SWE环境(Kubernates集群) <a class="header-anchor" href="#swe环境-kubernates集群" aria-label="Permalink to &quot;SWE环境(Kubernates集群)&quot;">​</a></h4><div class="custom-block caution"><div class="custom-block-title">SWE 环境扩展 -Kubernates集群</div><p><strong>并发需求</strong></p><ul><li>每次RL迭代：512个Docker容器，BS=64、8passes。</li><li>并行RL实验：每时刻都有<code>几千个容器</code>在运行。</li></ul><p><strong>解决方法</strong></p><ul><li>Kubernates集群，每个节点：<code>200 CPU</code> + <code>6TB local NVME SSD</code>。</li><li>可扩展至1000 CPU 集群。</li></ul></div><h4 id="rl设置-动作空间-数据-稀疏奖励" tabindex="-1">RL设置(动作空间+数据+稀疏奖励) <a class="header-anchor" href="#rl设置-动作空间-数据-稀疏奖励" aria-label="Permalink to &quot;RL设置(动作空间+数据+稀疏奖励)&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">RL 环境和数据</div><p><strong>动作空间</strong></p><ul><li>执行Bash：执行命令，返回sdtout和sdterr</li><li>搜索：在目录下或对单文件进行搜索</li><li>文件编辑：查看、创建、替换字符串、插入、撤销修改等。</li><li>完成/提交：LLM决定已经解决PR，结束</li></ul><p><strong>数据</strong></p><ul><li><code>R2E-Gym 4.5k数据集</code>，过滤污染数据。</li></ul><p><strong>稀疏奖励</strong></p><ul><li>1：测试用例<code>全部通过</code>，(<strong>Pass2Pass, Fail2Pass</strong>)</li><li>0：<code>超时</code>或<code>至少有1个未通过</code></li><li>超时时间：<code>5分钟</code>，官方是30分钟。</li></ul></div><h4 id="grpo-算法-dapo-dr-grpo-rloo" tabindex="-1">GRPO++算法(DAPO+Dr.GRPO+RLOO) <a class="header-anchor" href="#grpo-算法-dapo-dr-grpo-rloo" aria-label="Permalink to &quot;GRPO++算法(DAPO+Dr.GRPO+RLOO)&quot;">​</a></h4><div class="custom-block important"><div class="custom-block-title">GRPO++ (DAPO+Dr.GRPO+RLOO)</div><p><strong>相关笔记</strong></p><ul><li><a href="https://plmsmile.github.io/posts/llm/rl/theory/11-grpo-series.html#_2504-dapo-seed" target="_blank" rel="noreferrer">DAPO 技巧</a>, <a href="https://plmsmile.github.io/posts/llm/rl/theory/11-grpo-series.html#_2503-dr-grpo" target="_blank" rel="noreferrer">Dr.GRPO 技巧</a>, <a href="https://plmsmile.github.io/posts/llm/rl/theory/10-ppo-series.html#_2402-rloo" target="_blank" rel="noreferrer">RLOO 技巧</a></li></ul><p><strong>采用 DAPO 技巧</strong></p><ul><li><p><code>Clip-Higher</code>：<code>鼓励探索</code>和防止熵崩塌</p></li><li><p><code>移除KL Loss</code>：避免LLM受<code>原始SFT影响限制</code>探索空间</p></li><li><p><code>移除熵 Loss</code>：会增加不稳定性，导致熵增加，训练崩溃。如果基模熵在0.3-1，就无需熵loss</p></li><li><p><code>Compact 过滤</code>：对达<code>最大长度</code>、<code>超时</code>、<code>达最大步数</code>的数据，<code>Mask Loss</code></p></li></ul><p><strong>采用Dr.GRPO 技巧</strong></p><ul><li><p><code>优势不除以标准差</code>：消除<code>任务难度偏差</code></p></li><li><p><code>去掉序列内平均</code>，消除<code>长度偏差</code>，其实就是<a href="https://plmsmile.github.io/posts/llm/rl/theory/11-grpo-series.html#token-level-loss" target="_blank" rel="noreferrer">DAPO的Token-Level-Loss</a></p></li></ul><p><strong>采用RLOO 技巧</strong></p><ul><li><code>留一法计算优势</code></li></ul></div><p>Compact 过滤：</p><img src="https://pretty-radio-b75.notion.site/image/attachment%3A08a07d52-596f-4f8c-b760-920308d47ca7%3Aimage.png?table=block&amp;id=22281902-c146-804c-bf06-f567e8827fc6&amp;spaceId=3dea8845-5afd-4ee7-97ee-480e9ce47ccd&amp;width=1140&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><img src="https://pretty-radio-b75.notion.site/image/attachment%3A4affb3ee-8fce-4544-95ed-06af7218cbf0%3Asteps-vs-response-length.png?table=block&amp;id=22281902-c146-80f9-9967-f239d76d44a8&amp;spaceId=3dea8845-5afd-4ee7-97ee-480e9ce47ccd&amp;width=770&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><h4 id="hybrid-tts-deepswe-verifier" tabindex="-1">Hybrid TTS (DeepSWE-Verifier) <a class="header-anchor" href="#hybrid-tts-deepswe-verifier" aria-label="Permalink to &quot;Hybrid TTS (DeepSWE-Verifier)&quot;">​</a></h4><div class="custom-block warning"><div class="custom-block-title">TTS 相关工作</div><ul><li><a href="http://plmsmile.github.io/posts/llm/industry/codellm/06-code-taskrl-reading.html#_2505-deepcoder-14b-preview" target="_blank" rel="noreferrer">DeepCoder-14B-Preview</a><ul><li><code>16k -&gt; 32k -&gt;64k</code>，LiveCodeBench效果：<code>54 -&gt; 58 -&gt; 60.6</code>，</li></ul></li><li><a href="http://plmsmile.github.io/posts/llm/industry/mainllm/15-skywork-series.html#_2506-skywork-swe" target="_blank" rel="noreferrer">Skywork-SWE</a><ul><li>从头<code>36</code>提升至<code>47分</code>，<code>Best-of-3</code></li><li><code>rollout3次</code>，由<a href="https://openhands.dev/blog/sota-on-swe-bench-verified-with-inference-time-scaling-and-critic-model" target="_blank" rel="noreferrer">OpenHands critic model</a>来<code>选择最优轨迹</code>评测。</li></ul></li><li><a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#hybrid-tts" target="_blank" rel="noreferrer">R2E-Gym TTS</a><ul><li>先基于<code>免执行验证</code>选出<code>top-n</code>，再基于<code>执行验证</code>做<code>最终排序</code>。</li><li>从<code>34.4</code>提升至<code>51分</code>。</li></ul></li></ul></div><div class="custom-block tip"><div class="custom-block-title">Hybrid TTS方法</div><p><strong>Hybrid TTS</strong></p><ul><li><strong>不执行验证</strong><ul><li>不执行，由<code>LLM选择最优轨迹</code>。</li><li><code>DeepSWE Verifier</code>：在<code>正确和错误patch</code>上，训练<code>2epoch</code>，识别<code>正确和错误</code></li></ul></li><li><strong>执行验证</strong><ul><li>由LLM生成<code>测试用例</code>，用例<code>通过最多</code>则为<code>最优轨迹</code></li></ul></li><li><code>混合方法</code>。</li></ul><p><strong>TTS 参数</strong></p><ul><li>上下文长度：16k -&gt; 32k -&gt; 128k，<code>超过32k</code> <code>收益就比较小</code></li><li>Rollout数量：8、16等</li></ul></div><p>不执行和执行两种方法对比：</p><img src="https://pretty-radio-b75.notion.site/image/attachment%3A2f60e8cc-d8b4-45db-ab91-2ab271e5e1e0%3Atest-time-scaling.svg?table=block&amp;id=22481902-c146-804b-a86b-f733987add11&amp;spaceId=3dea8845-5afd-4ee7-97ee-480e9ce47ccd&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><p>TTS 对比：</p><img src="https://pretty-radio-b75.notion.site/image/attachment%3A1fdf53cf-c67a-45f6-a168-a42d40a95b9d%3Abestk_plot_agent.png?table=block&amp;id=22281902-c146-80e3-b0b6-c6dec42a72cc&amp;spaceId=3dea8845-5afd-4ee7-97ee-480e9ce47ccd&amp;width=960&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><p>最大输出token对比</p><img src="https://pretty-radio-b75.notion.site/image/attachment%3A81da2c29-7656-43e3-be00-fb16991157f5%3Adeepscaler_clip_ratio.png?table=block&amp;id=22481902-c146-8050-9683-d4e48407d33e&amp;spaceId=3dea8845-5afd-4ee7-97ee-480e9ce47ccd&amp;width=840&amp;userId=&amp;cache=v2" style="display:block;margin:auto;" width="70%"><h3 id="实验设置-3" tabindex="-1">实验设置 <a class="header-anchor" href="#实验设置-3" aria-label="Permalink to &quot;实验设置&quot;">​</a></h3><p><strong>✍️实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li>Qwen3-32B</li></ul><p><strong>训练任务/数据</strong></p><ul><li><a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#_2504-r2e-gym" target="_blank" rel="noreferrer">R2E-Gym 子集</a> <code>4.5k任务</code>，并做<code>污染过滤</code></li></ul><p><strong>评测任务/数据</strong></p><ul><li>SWE-verified，<code>官方R2E-Gym</code>代码库来<code>评估</code></li><li>超参：<code>100步</code>，<code>64k上下文</code></li><li>指标：<code>pass@1 avg16</code>， best@8, best@16</li><li>TTS策略：<code>免执行方法</code> + <code>执行免执行混合方法</code></li></ul><p><strong>算法/策略</strong></p><ul><li><code>GRPO++</code> (多种策略)，<code>R2E-Gym Scaffold</code></li></ul><p><strong>超参</strong></p><ul><li>上下文长度：16k -&gt; 128k，其中<code>32k效果很好</code>了，后期收益不大</li><li>训练：<code>32k</code>、<code>50轮</code>；测试：<code>64k</code>、<code>100轮</code></li><li>Rollout：<code>16</code>、8等，做了多组实验</li><li><code>64张H100</code>，<code>训练6天</code>。</li></ul></div><h3 id="关键结果-qwen3-32b" tabindex="-1">关键结果(Qwen3-32B) <a class="header-anchor" href="#关键结果-qwen3-32b" aria-label="Permalink to &quot;关键结果(Qwen3-32B)&quot;">​</a></h3><p><strong>🍑关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><p><strong>模型效果</strong></p><ul><li><code>GRPO++</code> 微调<code>Qwen3-32B</code>，得DeepSWE-Preview-32B，<code>SWE得分59分</code>，效果提升20pt。 <ul><li><code>pass@1 42.2分</code> ，<code>pass@16 71分</code>，<code>TTS best@16 59分</code>。</li></ul></li></ul><p><strong>重要结论</strong></p><ul><li>使用Claude3-4蒸馏数据做SFT，<code>仅34.4分</code>，低于<a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#%E5%85%B3%E9%94%AE%E7%BB%93%E6%9E%9C-swe-agent-lm-32b" target="_blank" rel="noreferrer">SWE-Agent-LM 40分</a>。</li><li>使用<a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#_2504-swe-smith-swe-agent-lm" target="_blank" rel="noreferrer">SWE-Smith</a>和<a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#_2412-swe-gym" target="_blank" rel="noreferrer">SWE-Gym</a>数据集，但<code>提升有限</code>，<code>训练中无解率很高</code></li><li>相反<a href="http://plmsmile.github.io/posts/llm/industry/codellm/11-swe-data-series.html#_2504-r2e-gym" target="_blank" rel="noreferrer">R2E-Gym</a>很适合<code>RL</code>，提供<code>足够的课程学习</code>，随时间推移<code>解决越来越难的问题</code>。</li></ul></div><h3 id="未来方向-2" tabindex="-1">未来方向 <a class="header-anchor" href="#未来方向-2" aria-label="Permalink to &quot;未来方向&quot;">​</a></h3><p><strong>⛳ 未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div><ul><li><code>更大模型</code>：比如DeepSeek-R1</li><li><code>更长上下文</code>：</li><li><code>扩展到不同领域</code>的agent</li></ul></div><h2 id="_2512-devstral2" tabindex="-1">(2512) Devstral2 <a class="header-anchor" href="#_2512-devstral2" aria-label="Permalink to &quot;(2512) Devstral2&quot;">​</a></h2><div class="custom-block danger"><div class="custom-block-title">Devstral2 摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://huggingface.co/mistralai/Devstral-Small-2-24B-Instruct-2512" target="_blank" rel="noreferrer">mistralai/Devstral-Small-2-24B-Instruct-2512</a>, <a href="https://mistral.ai/news/devstral-2-vibe-cli" target="_blank" rel="noreferrer">devstral-2-vibe-cli</a></li></ul><p><strong>模型效果</strong></p><ul><li><code>模型小</code>且<code>效果好</code><ul><li><code>256k</code>、<code>Dense模型</code>，比Kimi/DeepSeek<code>都小很多</code>。</li><li>Devstral2：<code>123B</code>，<code>72.2 SWE-verified</code>。</li><li>Devstral Small2：<code>24B</code>，<code>68 SWE-verified</code>。</li></ul></li><li>但<code>仍落后于闭源模型</code>。</li></ul><p><strong>关键结论</strong></p><ul><li>支持<code>探索代码库</code>、<code>跨文件协调更改</code>、<code>架构级上下文</code></li><li>支持 <code>Mistral Vibe CLI 工具</code>。</li></ul></div><img src="https://cms.mistral.ai/assets/d295e716-acbe-4d05-8764-861ca2f2a2eb.png?width=1686&amp;height=1093" style="display:block;margin:auto;" width="70%"><img src="https://cms.mistral.ai/assets/3c7a5ea7-d83f-4dc4-9129-965c321bb379.png?width=1686&amp;height=969" style="display:block;margin:auto;" width="70%"><h2 id="_2505-devstral" tabindex="-1">(2505) Devstral <a class="header-anchor" href="#_2505-devstral" aria-label="Permalink to &quot;(2505) Devstral&quot;">​</a></h2><p><strong>🌺 论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">Devstral 摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://mistral.ai/news/devstral" target="_blank" rel="noreferrer">devstral</a>, <a href="https://huggingface.co/mistralai/Devstral-Small-2505" target="_blank" rel="noreferrer">mistralai/Devstral-Small-2505</a>, <a href="https://www.alphaxiv.org/abs/2509.25193" target="_blank" rel="noreferrer">paper</a></li></ul><p><strong>核心方法</strong></p><ul><li>SFT轨迹数据合成方法：基于<code>环境探索</code>+<code>单元测试验证</code>， 保留<code>正确轨迹</code><ul><li>模式：<code>CoT</code>+<code>代码执行</code>，<code>OpenHands</code> + <code>SWE-Gym</code></li><li>具体数据没细讲，类似 <a href="http://plmsmile.github.io/posts/llm/industry/mainllm/02-deepseek-series.html#%E8%87%AA%E8%92%B8%E9%A6%8F%E5%86%B7%E5%90%AF%E5%8A%A8" target="_blank" rel="noreferrer">DeepSeekV3.2 自蒸馏冷启动</a></li></ul></li><li><code>Post-Training方法</code>：<code>简单过滤SFT</code>、<code>严格过滤SFT</code>、<code>RL训练</code>。</li></ul><p><strong>模型效果</strong></p><ul><li>Devstral-small-24B模型，<code>SWE达46分</code>，<code>迭代式 Best-of-3</code>指标。</li></ul></div><p><strong>❓问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">问题背景</div><ul><li>开源模型在<code>代码片段</code>生成效果好，但在<code>复杂</code>、<code>多步骤SWE任务</code>表现不好。</li><li><code>Coding Agent</code>需要<code>迭代开发</code>、<code>debug</code>、<code>集成软件工具</code>等能力，<code>大都依赖闭源模型</code>。</li></ul></div><h3 id="核心方法-环境探索sft数据-posttrain" tabindex="-1">核心方法(环境探索SFT数据+PostTrain) <a class="header-anchor" href="#核心方法-环境探索sft数据-posttrain" aria-label="Permalink to &quot;核心方法(环境探索SFT数据+PostTrain)&quot;">​</a></h3><p><strong>📕核心方法</strong></p><div class="custom-block note"><div class="custom-block-title">核心方法</div><p><strong>模型架构</strong></p><ul><li>基于Mistral-Small3 开发：24B，40层，GQA，128k</li></ul><p><strong>数据构建方法</strong></p><ul><li>目标：<code>Cot推理</code>+<code>code执行能力</code></li><li>Agent框架：<code>OpenHands CodeAct scaffold</code>；SWE环境：<code>SWE-Gym</code></li><li>模型基于<code>以上环境去探索</code>，基于<code>单元测试验证</code>，仅保留<code>高质量正确轨迹数据</code>。</li></ul><p><strong>Post-Train</strong></p><ul><li>SFT：大量数据微调(<code>简单过滤</code>)，高质量数据微调(<code>严格过滤</code>)</li><li>RL：使用SFT模型生成新数据，再去做RL训练。</li><li>论文不清楚。</li></ul></div><h3 id="实验设置-4" tabindex="-1">实验设置 <a class="header-anchor" href="#实验设置-4" aria-label="Permalink to &quot;实验设置&quot;">​</a></h3><p><strong>✍️实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li>Mistral-Small3 24B</li></ul><p><strong>训练任务/数据</strong></p><ul><li>没说</li></ul><p><strong>评测任务/数据</strong></p><ul><li><p>SWE</p></li><li><p><code>OpenHands Scaffold</code>：安全的沙盒环境，代码、bash、网页浏览(本实验禁用)。</p></li><li><p><code>Best-of-3</code>作为<code>pass@1</code>：<code>第1次(温度=0)</code>，<code>第2、3次(温度=0.1)</code></p><ul><li>一般做法：多次取<code>avg</code> 作为<code>pass@1</code></li></ul></li><li><p>评测时的交互轮数：50轮效果好，100轮也没有提升。30轮低10个点。</p></li></ul><p><strong>算法/策略</strong></p><ul><li>SFT + RL</li></ul><p><strong>超参</strong></p><ul><li>128k</li></ul></div><h3 id="关键结果-devstral-small-24b" tabindex="-1">关键结果(Devstral-small-24B) <a class="header-anchor" href="#关键结果-devstral-small-24b" aria-label="Permalink to &quot;关键结果(Devstral-small-24B)&quot;">​</a></h3><p><strong>🍑关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><p><strong>模型效果</strong></p><ul><li>Devstral-small-24B <code>SWE达46分</code>，超越一众顶尖模型。 <ul><li>Qwen3-235B(25), DeepseekR1V3(40+), GPT-4.1-mini(23.6), Claude3.5-Haiku(40.6)。</li></ul></li></ul><p><strong>重要结论</strong></p><ul><li>评测交互轮数：<code>50轮</code> 效果好<code>46分</code>，<code>30轮</code>仅<code>36分</code>。</li><li>温度<code>0.1</code>和<code>0.4</code>比较好，0.7和1.0反而Pass@4还低了。</li></ul></div><img src="https://paper-assets.alphaxiv.org/figures/2509.25193v1/img-1.jpeg" style="display:block;margin:auto;" width="70%"><p><strong>⛳ 未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div><ul><li>新版本优化：2507比2505好 <ul><li>优化数据生成和筛选过程：提升数据质量 <ul><li>微调数据过滤机制：可能不仅看是否单元测试，还会看代码风格、步骤冗余度等。</li></ul></li><li>不同脚手架支持：构造伪脚手架.</li><li>多格式训练：增加XML格式、原生函数调用格式等。</li></ul></li></ul></div><img src="https://paper-assets.alphaxiv.org/figures/2509.25193v1/img-3.jpeg" style="display:block;margin:auto;" width="70%"><h2 id="_2502-swe-rl-meta" tabindex="-1">(2502) SWE-RL (Meta) <a class="header-anchor" href="#_2502-swe-rl-meta" aria-label="Permalink to &quot;(2502) SWE-RL (Meta)&quot;">​</a></h2><p><strong>🌺 论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">SWE-RL 摘要</div><p><strong>参考链接</strong></p><ul><li><a href="https://www.alphaxiv.org/abs/2502.18449" target="_blank" rel="noreferrer">paper</a>, <a href="https://github.com/facebookresearch/swe-rl" target="_blank" rel="noreferrer">https://github.com/facebookresearch/swe-rl</a></li></ul><p><strong>核心方法</strong></p><ul><li>1套<code>GithubPR数据收集构建方法</code>：<code>仓库事件克隆</code> + <code>PR聚合</code> + <code>预测相关文件</code> + <code>数据过滤</code><ul><li>SWE-RL PR数据：<code>27.3w </code></li></ul></li><li>1套<code>AgentSFT数据合成方法</code>：<code>PR种子筛选</code> + <code>定位数据合成</code> + <code>编辑数据合成</code></li><li>SWE-RL方法：<code>LLama3-70B</code> + <code>GRPO</code>，<code>不执行环境</code>，采用<code>Patch相似度</code>来做<code>奖励信号</code></li></ul><p><strong>模型效果</strong></p><ul><li>SWE-RL-70B 达<code>41分</code>，<code>Best-of-500</code>。</li></ul><p><strong>重要结论</strong></p><ul><li><code>RL比SFT效果好</code>。</li><li><code>Best-of-N</code> 越大越好，但后期逐渐收敛。</li><li><code>DenseReward</code> 比Sparse Reward好。</li></ul></div><p>整体流程如下</p><img src="https://arxiv.org/html/2502.18449v1/x1.png" style="display:block;margin:auto;" width="70%"><h3 id="问题背景-3" tabindex="-1">问题背景 <a class="header-anchor" href="#问题背景-3" aria-label="Permalink to &quot;问题背景&quot;">​</a></h3><p><strong>❓问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">问题背景</div><p><strong>问题</strong></p><ul><li>SWE 进展：<code>repo-level 代码生成</code>、<code>Issue Resolution</code>(SWE Bench)。</li><li>SWE-Bench：<code>主要依赖私有模型</code>GPT-4o, Calude-3.5，开源模型很少。 <ul><li>DeepSeekR1 RuleRL很强，但是<code>SWE任务效果不行</code>。</li></ul></li><li>传统规则奖励<code>难以直接应用到SWE任务</code>。 <ul><li>数学：<code>EM匹配</code>；</li><li>代码：竞赛题，<code>单代码文件</code>、<code>容易执行</code>；SWE：有依赖，不是自包含的。</li></ul></li></ul><p><strong>SWE 相关工作</strong></p><ul><li>(2411)<a href="https://www.alphaxiv.org/abs/2411.00622" target="_blank" rel="noreferrer">Lingma-SWE-GPT</a>：迭代开发过程，基于Qwen2.5-Coder-7B和Qwen2.5-72B-Instruct 构建。</li><li>(2412)<a href="https://www.alphaxiv.org/abs/2412.21139" target="_blank" rel="noreferrer">SWE-gym</a>：第一个用于<code>开放训练的环境</code>，提升Qwen2.5-Coder-7B/32B效果。</li><li>(2501)<a href="https://www.alphaxiv.org/abs/2501.05040" target="_blank" rel="noreferrer">SWE-fixer</a>：微调Qwen2.5 base，提升best@1性能。</li></ul></div><h3 id="github-pr数据收集构建方法" tabindex="-1">GitHub PR数据收集构建方法 <a class="header-anchor" href="#github-pr数据收集构建方法" aria-label="Permalink to &quot;GitHub PR数据收集构建方法&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">Github PR 数据 概览</div><ul><li>最终：<code>27.3w 高质量 Gihub PR</code></li><li>每个PR包含： <ul><li><code>Issue描述</code>：问题</li><li><code>Code Context</code>：<code>所有相关文件</code> (<code>需要修改</code> + <code>不需要修改的</code>)</li><li><code>Oracle Patch</code>：GT解决方法</li></ul></li></ul></div><div class="custom-block note"><div class="custom-block-title">Github PR数据收集构建方法</div><p><strong>Github Events Clone</strong></p><ul><li>目标PR数据：PR中的<code>所有事件</code>、<code>PR之前的源代码</code>。</li><li>通过 <a href="https://www.gharchive.org/" target="_blank" rel="noreferrer">GHAchive</a> 拉取事件：1501-2412共10年数据</li><li>通过GitClone 仓库：包含历史所有commit，共460w repo。</li></ul><p><strong>PR 数据聚合</strong></p><ul><li>从PR出发，关联<code>Github事件</code>和<code>代码库</code>，仅<code>保留已合并的PR</code>，聚合以下内容 <ul><li>Issue、用户讨论、Review Comment、出事代码、Commits、代码变更。</li></ul></li><li>保存从<code>merge base</code>到 <code>head commit</code>所有的<code>中间提交</code>和<code>代码变更</code></li><li>扫描所有PR，<code>识别Issue</code>并<code>与对应PR</code> 匹配 (Prompt, Response)。累计 <code>240w PR</code>。</li></ul><p><strong>预测相关但未修改文件</strong></p><ul><li>问题 <ul><li>目前PR<code>仅包含被修改过的文件</code>，但实际预测<code>会检索到很多无关文件</code></li><li>如果训练时，只看修改文件，会产生bias。</li></ul></li><li>方法 <ul><li>根据Issue+已修改文件，使用<code>Prompt+LLM</code>预测 <code>相关但未被修改</code>的<code>文件列表</code></li><li>把这部分 <code>相关但未修改文件列表</code> 加入数据集中。</li></ul></li></ul><p><strong>数据过滤</strong></p><ul><li>背景：PR有噪音，需剔除有害PR。但允许一定噪音，尽量召回高质量PR。</li><li>过滤规则： <ul><li>过滤<code>机器人PR</code></li><li>过滤<code>变更极大的PR</code></li><li><code>细粒度过滤</code>：检查<code>每个代码块 Hunk</code> (参考CodeLLaMA )，确保是在写代码，去掉版本、锁定等内容。</li></ul></li><li>最终：<code>1100w PR</code> -&gt; <code>27.3w 高质量PR </code></li></ul></div><img src="https://arxiv.org/html/2502.18449v1/x2.png" style="display:block;margin:auto;" width="70%"><h3 id="agentsft-数据合成" tabindex="-1">AgentSFT 数据合成 <a class="header-anchor" href="#agentsft-数据合成" aria-label="Permalink to &quot;AgentSFT 数据合成&quot;">​</a></h3><div class="custom-block important"><div class="custom-block-title">SFT 数据合成</div><p><strong>PR 种子数据筛选</strong></p><ul><li><code>收集高质量PR种子数据</code>：启发式规则筛选</li></ul><p><strong>问题定位数据-合成</strong></p><ul><li>LLM合成 <ul><li>输入：<code>Issue描述</code> + <code>仓库结构</code> + <code>目标编辑文件</code> + <code>相关文件</code></li><li>输出： <code>CoT推理</code>生成<code>需要编辑的文件</code>。</li><li>LLama-3.3-70B-Instruct</li></ul></li><li>过滤：<code>仅保留推理正确的答案</code></li></ul><p><strong>代码编辑数据-合成</strong></p><ul><li>LLM 合成 <ul><li>输入：<code>标准答案</code>和<code>Patch</code>，</li><li>输出： <code>Search/Replace</code>格式的<code>代码编辑数据</code>。</li></ul></li><li>过滤：保留<code>格式正确</code> 且 <code>search/replace内容正确</code> (能搜索到)的数据。</li></ul><p><strong>相关工作</strong></p><ul><li>整体采样Magicoder的OSS-Instruct技术，同<a href="https://plmsmile.github.io/posts/llm/industry/codellm/07-code-fulltrain-reading.html#%E5%90%88%E6%88%90%E6%95%B0%E6%8D%AE-%E5%A4%9A%E6%A0%B7%E6%80%A7-%E8%B4%A8%E9%87%8F-%E9%9A%BE%E5%BA%A6" target="_blank" rel="noreferrer">Seed-Coder合成数据技术</a></li></ul></div><img src="https://arxiv.org/html/2502.18449v1/x8.png" style="display:block;margin:auto;" width="70%"><h3 id="核心方法-4" tabindex="-1">核心方法 <a class="header-anchor" href="#核心方法-4" aria-label="Permalink to &quot;核心方法&quot;">​</a></h3><h4 id="任务prompt-设计" tabindex="-1">任务Prompt 设计 <a class="header-anchor" href="#任务prompt-设计" aria-label="Permalink to &quot;任务Prompt 设计&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">Prompt 设计</div><p><strong>整体</strong></p><ul><li><code>Reasoning</code> + <code>Tool Use</code> 风格。<a href="https://github.com/facebookresearch/swe-rl/blob/main/src/swerl/core/prompts.py" target="_blank" rel="noreferrer">prompts.py</a></li><li>THINKING_SYSTEM + AGENTLESS_REPAIR</li></ul><p><strong>THINKING_SYSTEM</strong></p><ul><li>强调输出思考过程</li></ul><p><strong>AGENTLESS_REPAIR</strong></p><ul><li>--- BEGIN ISSUE ---：{problem_statement}，<code>Issue 定义</code></li><li>--- BEGIN FILE ---：{content}，包含<code>相关文</code>件的<code>全部源代码</code></li><li>任务指令：<code>先定位</code>、<code>再修复</code></li><li>输出格式：<code>Search/Replace 协议</code>，严格的<code>Diff格式</code></li><li>样例：</li></ul></div><p><strong>输出样例</strong></p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes one-light one-dark-pro vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#000000;--shiki-dark:#FFFFFF;">```python</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">### mathweb/flask/app.py</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;"> SEARCH</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> flask </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Flask</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=======</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> math</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> flask </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Flask</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&gt;&gt;&gt;&gt;&gt;&gt;&gt;</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;"> REPLACE</span></span>
<span class="line"><span style="--shiki-light:#000000;--shiki-dark:#FFFFFF;">```</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><img src="https://arxiv.org/html/2502.18449v1/x3.png" style="display:block;margin:auto;" width="70%"><h4 id="rl-设计" tabindex="-1">RL 设计 <a class="header-anchor" href="#rl-设计" aria-label="Permalink to &quot;RL 设计&quot;">​</a></h4><p><strong>📕核心方法</strong></p><div class="custom-block note"><div class="custom-block-title">核心方法</div><p><strong>任务</strong></p><ul><li>给定<code>Issue</code> +<code>上下文</code>，进行推理，<code>生成代码变更</code>，把代码变更<code>应用到Patch中</code>。</li></ul><p><strong>奖励</strong></p><ul><li><code>不去真正执行</code>，而是<code>对比Patch 相似度</code>。Python.difflib.SequenceMatcher。<mjx-container tabindex="0" class="MathJax" jax="SVG" display="true" style="direction:ltr;display:block;text-align:center;margin:1em 0;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-2.148ex;" xmlns="http://www.w3.org/2000/svg" width="52.763ex" height="5.428ex" role="img" focusable="false" viewBox="0 -1449.5 23321.3 2399" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mstyle" fill="blue" stroke="blue"><g data-mml-node="mtext"><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(392,0)" style="stroke-width:3;"></path><path data-c="77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z" transform="translate(836,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1558,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(2058,0)" style="stroke-width:3;"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(2450,0)" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(3283.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mrow" transform="translate(4339.6,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7B" d="M618 -943L612 -949H582L568 -943Q472 -903 411 -841T332 -703Q327 -682 327 -653T325 -350Q324 -28 323 -18Q317 24 301 61T264 124T221 171T179 205T147 225T132 234Q130 238 130 250Q130 255 130 258T131 264T132 267T134 269T139 272T144 275Q207 308 256 367Q310 436 323 519Q324 529 325 851Q326 1124 326 1154T332 1205Q369 1358 566 1443L582 1450H612L618 1444V1429Q618 1413 616 1411L608 1406Q599 1402 585 1393T552 1372T515 1343T479 1305T449 1257T429 1200Q425 1180 425 1152T423 851Q422 579 422 549T416 498Q407 459 388 424T346 364T297 318T250 284T214 264T197 254L188 251L205 242Q290 200 345 138T416 3Q421 -18 421 -48T423 -349Q423 -397 423 -472Q424 -677 428 -694Q429 -697 429 -699Q434 -722 443 -743T465 -782T491 -816T519 -845T548 -868T574 -886T595 -899T610 -908L616 -910Q618 -912 618 -928V-943Z" style="stroke-width:3;"></path></g><g data-mml-node="mtable" transform="translate(750,0)"><g data-mml-node="mtr" transform="translate(0,662.5)"><g data-mml-node="mtd"><g data-mml-node="mstyle" fill="blue" stroke="blue"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(1278,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mtd" transform="translate(13231.7,0)"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">格</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">式</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">不</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">正</text><text data-variant="normal" transform="translate(4000,0) scale(1,-1)" font-size="884px" font-family="serif">确</text></g></g></g><g data-mml-node="mtr" transform="translate(0,-537.5)"><g data-mml-node="mtd"><g data-mml-node="mstyle" fill="red" stroke="red"><g data-mml-node="mtext"><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" style="stroke-width:3;"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(444,0)" style="stroke-width:3;"></path><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(944,0)" style="stroke-width:3;"></path><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" transform="translate(1777,0)" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2333,0)" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(2833,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(3225,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3669,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(4058,0)"><g data-mml-node="mtext"><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(556,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1056,0)" style="stroke-width:3;"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(1445,0)" style="stroke-width:3;"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1889,0)" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(2478,-229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" style="stroke-width:3;"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(556,0)" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(948,0)" style="stroke-width:3;"></path><path data-c="64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z" transform="translate(1392,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(7963.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(8408.1,0)"><g data-mml-node="mtext"><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" style="stroke-width:3;"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(556,0)" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1056,0)" style="stroke-width:3;"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(1445,0)" style="stroke-width:3;"></path><path data-c="68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1889,0)" style="stroke-width:3;"></path></g><g data-mml-node="TeXAtom" transform="translate(2478,-229.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" style="stroke-width:3;"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(500,0)" style="stroke-width:3;"></path></g></g></g><g data-mml-node="mo" transform="translate(11564.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(11953.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mtd" transform="translate(13231.7,0)"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">格</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">式</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">正</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">确</text></g></g></g></g><g data-mml-node="mo" transform="translate(18981.7,0) translate(0 250)"></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;overflow:hidden;width:100%;"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mstyle mathcolor="blue"><mtext>reward</mtext></mstyle><mo>=</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><mtable columnalign="left left" columnspacing="1em" rowspacing=".2em"><mtr><mtd><mstyle mathcolor="blue"><mo>−</mo><mn>1</mn></mstyle><mo>,</mo></mtd><mtd><mtext>格式不正确</mtext></mtd></mtr><mtr><mtd><mstyle mathcolor="red"><mtext>compare</mtext><mo stretchy="false">(</mo><msub><mtext>patch</mtext><mrow data-mjx-texclass="ORD"><mtext>pred</mtext></mrow></msub><mo>,</mo><msub><mtext>patch</mtext><mrow data-mjx-texclass="ORD"><mtext>gt</mtext></mrow></msub><mo stretchy="false">)</mo></mstyle><mo>,</mo></mtd><mtd><mtext>格式正确</mtext></mtd></mtr></mtable><mo data-mjx-texclass="CLOSE" fence="true" stretchy="true" symmetric="true"></mo></mrow></math></mjx-assistive-mml></mjx-container></li></ul><p><strong>算法</strong></p><ul><li>GRPO + KLLoss</li></ul></div><h4 id="训练和测试存在不同点" tabindex="-1">训练和测试存在不同点 <a class="header-anchor" href="#训练和测试存在不同点" aria-label="Permalink to &quot;训练和测试存在不同点&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">训练vs测试不同点</div><p><strong>训练</strong></p><ul><li>给出所有相关代码文件，隐式强迫模型<code>先找Bug</code>、<code>再做修复</code>。</li></ul><p><strong>评测时 (Agentless mini 框架)</strong></p><ul><li>完整Pipeline <ul><li>Step1 <code>文件定位</code>：bug在哪个文件？</li><li>Step2 <code>测试生成</code>：生成测试用例，来复现bug</li><li>Step3 <code>回归测试</code>：挑出哪些旧测试用例跑一遍，防止改坏了别的地方。</li><li>Step4 <code>修复代码</code>：请写出修复代码</li></ul></li><li><code>SWE-RL 训练时仅有4</code>，没有1、2、3。但在测试时，<code>有泛化性</code>。</li></ul></div><h3 id="实验设置-5" tabindex="-1">实验设置 <a class="header-anchor" href="#实验设置-5" aria-label="Permalink to &quot;实验设置&quot;">​</a></h3><p><strong>✍️实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li>Llama-3.3-70B-Instruct</li></ul><p><strong>训练任务/数据</strong></p><ul><li>RL：27.3w 构建的PR数据</li><li>SFT：<code>合成代码编辑SFT数据</code> + <code>LLama3代码SFT数据</code> + <code>LLama3通用SFT数据</code></li></ul><p><strong>评测任务/数据</strong></p><ul><li>SWE-Bench-Verified。</li><li>温度=1，每个问题<code>生成500个patch</code></li><li>使用<code>top-30测试用例</code>去测试<code>排序</code>，选择<code>第1名的patch</code>去报告 <code>pass@1</code>，其实是Best-of-N。</li></ul><p><strong>算法/策略</strong></p><ul><li>GRPO、混合SFT</li></ul><p><strong>Scaffolding</strong></p><ul><li>基于Agentless开发的简化<code>Agentless mini</code>，专注于<code>文件级定位</code></li></ul><p><strong>超参</strong></p><ul><li><code>16k 上下文</code>，<code>batch_size=32</code>，<code>rollout=16</code>，real_batch_size=512</li><li><code>512 张H100</code>，32小时。</li></ul></div><h3 id="关键结果-llama-3-70b" tabindex="-1">关键结果(LLaMA-3-70B) <a class="header-anchor" href="#关键结果-llama-3-70b" aria-label="Permalink to &quot;关键结果(LLaMA-3-70B)&quot;">​</a></h3><p><strong>🍑关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><p><strong>模型效果</strong></p><ul><li><code>未使用闭源LLM蒸馏技术</code>，<code>纯开源数据</code>。</li><li>LLama3-SWE-RL-70B：<code>SWE-Verified 41分</code>，在<code>100B模型下效果最好</code>，</li><li><code>SFT 达36.2分</code>，效果也不错。</li></ul><p><strong>重要结论</strong></p><ul><li>测试 <code>Best-of-N</code> N越大效果越好，后期逐渐收敛。20 -&gt; 160 -&gt; 500：33.6 -&gt; 40 -&gt; 41</li><li><code>DenseReward</code>比Sparse <code>效果好</code>一些，促进格式和修复。</li></ul></div><h3 id="未来方向-3" tabindex="-1">未来方向 <a class="header-anchor" href="#未来方向-3" aria-label="Permalink to &quot;未来方向&quot;">​</a></h3><p><strong>⛳ 未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div><ul><li>奖励太僵硬：奖励仅靠GT相似度会限制模型探索其他方案，没有真正的执行奖励。</li><li>定位粗糙：Agentless Mini 缺乏复杂上下文信息。</li><li>流程割裂：Agentless 固定Pipeline，但理想Agent应该是E2E的。</li></ul></div></div></div></main><footer class="VPDocFooter" data-v-5a64a79a data-v-54a90a4a><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-54a90a4a><span class="visually-hidden" id="doc-footer-aria-label" data-v-54a90a4a>Pager</span><div class="pager" data-v-54a90a4a><a class="VPLink link pager-link prev" href="/posts/llm/industry/codellm/01-survey.html" data-v-54a90a4a><!--[--><span class="desc" data-v-54a90a4a>上一页</span><span class="title" data-v-54a90a4a>Code Survey</span><!--]--></a></div><div class="pager" data-v-54a90a4a><a class="VPLink link pager-link next" href="/posts/llm/industry/codellm/08-code-pretrain-summary.html" data-v-54a90a4a><!--[--><span class="desc" data-v-54a90a4a>下一页</span><span class="title" data-v-54a90a4a>Code 预训练相关</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--[--><div class="busuanzi"> 总访客数： <span id="busuanzi_value_site_uv"></span>   ·   总访问量： <span id="busuanzi_value_site_pv"></span></div><div class="busuanzi"> PLM&#39;s Blog @ 2016 - 2026</div><!--]--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api-examples.md\":\"Bt59YpwR\",\"index.md\":\"DmRGHmj9\",\"markdown-examples.md\":\"CPJSv--2\",\"posts_archive.md\":\"pZWQT7dp\",\"posts_exps_env_01-blog-env.md\":\"CcTUm41j\",\"posts_exps_env_index.md\":\"BJEZeoT-\",\"posts_exps_mind_index.md\":\"naOB3-Mb\",\"posts_llm_agent_basic_01-lhy-agent-notes.md\":\"BK_CsHNC\",\"posts_llm_agent_basic_02-evaluation-agent.md\":\"Dn02cVtP\",\"posts_llm_agent_basic_03-current-agents.md\":\"C25gmbg8\",\"posts_llm_agent_basic_04-agent-blogs.md\":\"_QbL2Plv\",\"posts_llm_agent_basic_05-comuter-agent.md\":\"D0gJpId6\",\"posts_llm_agent_basic_06-deepresearch-evaluation.md\":\"DdRDcxUJ\",\"posts_llm_agent_basic_index.md\":\"ClGtwUqg\",\"posts_llm_agent_rl_01-agent-rl.md\":\"wOF9bz66\",\"posts_llm_agent_rl_02-agent-tool.md\":\"IB_AqkSe\",\"posts_llm_agent_rl_03-agent-search.md\":\"Cim7OGxb\",\"posts_llm_agent_rl_04-agent-env.md\":\"C_O9BVi3\",\"posts_llm_agent_rl_index.md\":\"BudtoDK9\",\"posts_llm_basic_01-lm-define-information-theory.md\":\"Bl38RTdm\",\"posts_llm_basic_02-llm-components.md\":\"CGM_jRUE\",\"posts_llm_basic_03-transformer-detail.md\":\"BgLyAVDZ\",\"posts_llm_basic_04-llm-architecture.md\":\"jk4T-c21\",\"posts_llm_basic_05-llm-basic-info.md\":\"bdnM02bn\",\"posts_llm_basic_06-llm-attention.md\":\"BRJ9jR-M\",\"posts_llm_basic_07-decode.md\":\"BRytPqZo\",\"posts_llm_basic_08-llm-position-embedding.md\":\"d9dN_RuO\",\"posts_llm_basic_index.md\":\"DjX2HRXy\",\"posts_llm_industry_codellm_01-survey.md\":\"DIZQiOWr\",\"posts_llm_industry_codellm_02-eval-task-benchmark.md\":\"B-okIRAD\",\"posts_llm_industry_codellm_03-rl-task.md\":\"vQDqALFA\",\"posts_llm_industry_codellm_04-safety-code.md\":\"mkEFLxnr\",\"posts_llm_industry_codellm_05-open-codellm.md\":\"C6UU6qcZ\",\"posts_llm_industry_codellm_06-code-taskrl-reading.md\":\"BJI-7ypF\",\"posts_llm_industry_codellm_07-code-fulltrain-reading.md\":\"BjyYsnTY\",\"posts_llm_industry_codellm_08-code-pretrain-summary.md\":\"DfgRUz6a\",\"posts_llm_industry_codellm_09-swe-series.md\":\"ChL1bQ3P\",\"posts_llm_industry_codellm_10-swe-summary.md\":\"DapJfHgI\",\"posts_llm_industry_codellm_11-swe-data-series.md\":\"D7tcDgjn\",\"posts_llm_industry_mainllm_01-kimi-series.md\":\"B03hc7IE\",\"posts_llm_industry_mainllm_02-deepseek-series.md\":\"B04zRtyw\",\"posts_llm_industry_mainllm_03-glm-series.md\":\"8i7VdpW8\",\"posts_llm_industry_mainllm_04-minimax-series.md\":\"DjQwki4V\",\"posts_llm_industry_mainllm_05-qwen-series.md\":\"B4DMxRmo\",\"posts_llm_industry_mainllm_06-seed-series.md\":\"BNsIBjBZ\",\"posts_llm_industry_mainllm_07-openai-series.md\":\"ZBquCwKO\",\"posts_llm_industry_mainllm_08-gemini-series.md\":\"Bdm2kU-I\",\"posts_llm_industry_mainllm_09-claude-series.md\":\"0YnEaaXS\",\"posts_llm_industry_mainllm_10-longcat-series.md\":\"DroIAFXW\",\"posts_llm_industry_mainllm_11-tencent-series.md\":\"BVkGSYEM\",\"posts_llm_industry_mainllm_12-kwai-series.md\":\"o6Hut3bE\",\"posts_llm_industry_mainllm_13-nvidia-series.md\":\"BFgUmWZk\",\"posts_llm_industry_mainllm_14-mimo-series.md\":\"DDj7XRZV\",\"posts_llm_industry_mainllm_15-skywork-series.md\":\"BMrtN_ri\",\"posts_llm_infra_01-parrallel.md\":\"2i82l-rT\",\"posts_llm_infra_02-speed-framework.md\":\"_bUH-n3t\",\"posts_llm_infra_03-inference-tech.md\":\"Hpk9YmXF\",\"posts_llm_infra_04-verl.md\":\"8XtGz01J\",\"posts_llm_infra_05-verl-practice.md\":\"CpYgON5R\",\"posts_llm_infra_06-verl-code.md\":\"D5bZg4dm\",\"posts_llm_infra_07-verl-core.md\":\"3RS___SF\",\"posts_llm_infra_08-verl-train-loop.md\":\"DzepHNlu\",\"posts_llm_rl_index.md\":\"iUgEsMU1\",\"posts_llm_rl_theory_01-reinforce-learning.md\":\"Ch0rtQCM\",\"posts_llm_rl_theory_01-rl-introduction.md\":\"CmW63EkM\",\"posts_llm_rl_theory_02-markove-process.md\":\"DVY5XgWd\",\"posts_llm_rl_theory_02-value-learning.md\":\"CeOlmbeS\",\"posts_llm_rl_theory_03-model-based-prediction-control.md\":\"BhVRmo7C\",\"posts_llm_rl_theory_03-strategy-learning.md\":\"DWNvEZXH\",\"posts_llm_rl_theory_04-model-free-prediction-control.md\":\"Cg3qo2Fk\",\"posts_llm_rl_theory_04-reinforce-conclusion-simple.md\":\"C6yTAxwQ\",\"posts_llm_rl_theory_05-dqn.md\":\"BatSdlnZ\",\"posts_llm_rl_theory_06-policy-gradient.md\":\"BXI-eY8I\",\"posts_llm_rl_theory_07-actor-critic.md\":\"B1-83sen\",\"posts_llm_rl_theory_08-deterministic-policy-gradient.md\":\"Dgvru3JE\",\"posts_llm_rl_theory_09-policy-trpo-ppo.md\":\"DU-7PSqU\",\"posts_llm_rl_theory_10-ppo-series.md\":\"B-5Hsj_J\",\"posts_llm_rl_theory_11-grpo-series.md\":\"Ctl1G-Yd\",\"posts_llm_rl_theory_12-entropy.md\":\"BH45bCLH\",\"posts_llm_rl_theory_13-agentrl-algo.md\":\"BfctbxM6\",\"posts_me.md\":\"B9W6CMag\",\"posts_olds_algo_aim2offer.md\":\"jCwzQ4BU\",\"posts_olds_algo_aim2offer2.md\":\"Ga2XS6dR\",\"posts_olds_algo_aim2offer3.md\":\"BP0rCZaJ\",\"posts_olds_algo_aim2offer4.md\":\"BXurWO8W\",\"posts_olds_algo_algorithm-dfs.md\":\"CkUFsStz\",\"posts_olds_algo_index.md\":\"CmdF0Gg2\",\"posts_olds_algo_leetcode-01.md\":\"C_2G2jJT\",\"posts_olds_algo_sort-algorithms.md\":\"tFMUVlmH\",\"posts_olds_bigdata_16-spark-baserdd.md\":\"CBxdArgI\",\"posts_olds_bigdata_17-spark-pairrdd.md\":\"C3n8_zMO\",\"posts_olds_bigdata_18-spark-sql.md\":\"tsaWQLcp\",\"posts_olds_bigdata_19-spark-programming.md\":\"DG5ZAF85\",\"posts_olds_bigdata_20-numpy.md\":\"DucCD22z\",\"posts_olds_bigdata_index.md\":\"CWrZwWPb\",\"posts_olds_dl_23-pytorch-start.md\":\"BokpNeAw\",\"posts_olds_dl_35-nerual-network-optim.md\":\"Cp2SpLoE\",\"posts_olds_dl_38-convolution.md\":\"CC_SQ57z\",\"posts_olds_dl_cs224n-assignment-1.md\":\"BZMSZqOS\",\"posts_olds_dl_cs224n-notes3-neural-networks-2.md\":\"Wd9TmSyb\",\"posts_olds_dl_cs224n-notes3-neural-networks.md\":\"CDZWc4X6\",\"posts_olds_dl_cs231n-linear-notes.md\":\"DLRyzcwJ\",\"posts_olds_dl_index.md\":\"C1dyLGNS\",\"posts_olds_dl_rnn.md\":\"CwYYWZ7N\",\"posts_olds_env_09-linux-notes.md\":\"CyjifvcN\",\"posts_olds_env_12-ide-envs.md\":\"YeELWzR2\",\"posts_olds_env_13-old-blog-problems.md\":\"qamPyucB\",\"posts_olds_env_24-hexo-problems.md\":\"CzxhyjW1\",\"posts_olds_env_index.md\":\"DQpgTXVj\",\"posts_olds_ml_10-trees.md\":\"BkNaj6fL\",\"posts_olds_ml_14-em.md\":\"DIufCP0H\",\"posts_olds_ml_21-lr.md\":\"C-1ms511\",\"posts_olds_ml_22-ml-ch03-bayes.md\":\"Q_M6Gn-a\",\"posts_olds_ml_27-svm-notes.md\":\"C96WS6CL\",\"posts_olds_ml_28-ml-interview-notes.md\":\"0bgezw3n\",\"posts_olds_ml_29-desicion-tree.md\":\"CtwmlbWl\",\"posts_olds_ml_crf.md\":\"CEE5oTqd\",\"posts_olds_ml_index.md\":\"BLMEziB1\",\"posts_olds_ml_maxentmodel.md\":\"CSbOumJx\",\"posts_olds_ml_pgm-01.md\":\"BTwybTMD\",\"posts_olds_nlp_11-nlp-labels.md\":\"Cl0Lb8OT\",\"posts_olds_nlp_25-google-nmt.md\":\"BOM-hoYN\",\"posts_olds_nlp_26-wordpieacemodel.md\":\"Q8-L5j15\",\"posts_olds_nlp_30-dynamic-memory-network.md\":\"wp5ucVxW\",\"posts_olds_nlp_31-co-attention-vqa.md\":\"lzwuVKG5\",\"posts_olds_nlp_32-dynamic-coattention-network.md\":\"Bxl4ABWd\",\"posts_olds_nlp_33-attention-summary.md\":\"DT6np0xG\",\"posts_olds_nlp_36-alime-chat.md\":\"Cu2xkcdT\",\"posts_olds_nlp_39-squard-models.md\":\"B1L3iDEv\",\"posts_olds_nlp_45-match-lstm.md\":\"DkpQKM5B\",\"posts_olds_nlp_46-rnet-selfmatch.md\":\"CzGHQ-PZ\",\"posts_olds_nlp_47-bidaf.md\":\"DFJaLh2v\",\"posts_olds_nlp_48-attention-is-all-you-need.md\":\"BY6XvFQ5\",\"posts_olds_nlp_49-qanet.md\":\"BPKWHzTf\",\"posts_olds_nlp_50-elmo.md\":\"WuOt1elN\",\"posts_olds_nlp_51-opengpt.md\":\"B9pQ3h5W\",\"posts_olds_nlp_52-bert.md\":\"5q3t5Qqh\",\"posts_olds_nlp_53-mrc-brief.md\":\"D9CkYrea\",\"posts_olds_nlp_54-mrc-models.md\":\"Ak4bDf1J\",\"posts_olds_nlp_attention-based-nmt.md\":\"BHef6tM6\",\"posts_olds_nlp_attention-model.md\":\"-xLhHhJE\",\"posts_olds_nlp_cs224n-lecture2-word2vec.md\":\"_MmBTADr\",\"posts_olds_nlp_cs224n-notes1-word2vec.md\":\"DXSi5KGh\",\"posts_olds_nlp_index.md\":\"Bfo4Lwn3\",\"posts_olds_nlp_nlp-notes.md\":\"BUmOZxzi\",\"posts_olds_nlp_nmt.md\":\"DUgy6vHF\",\"posts_olds_nlp_subword-units.md\":\"fR_3dRXr\",\"posts_olds_nlp_word2vec-math.md\":\"agvHiE1x\",\"posts_olds_nlp_word2vec.md\":\"D2TKUstm\",\"posts_olds_other_15-cpp-pointer-object-reference.md\":\"BKRTr8QZ\",\"posts_olds_other_index.md\":\"C1T-ubsz\",\"posts_olds_rl_37-reinforce-learning.md\":\"Cf2nny8k\",\"posts_olds_rl_40-value-learning.md\":\"DcnHvvpH\",\"posts_olds_rl_41-strategy-learning.md\":\"CStMrB-q\",\"posts_olds_rl_42-reinforce-conclusion-simple.md\":\"flRZUmJZ\",\"posts_olds_rl_43-intent-detection-slot-filling.md\":\"DcAUbaZU\",\"posts_olds_rl_44-reinforce-nlp.md\":\"Br2ShITL\",\"posts_olds_rl_index.md\":\"CUsxM3zO\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"📚 plmblog\",\"description\":\"记录一些学习笔记。\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"首页\",\"link\":\"/\"},{\"text\":\"🐲LLM\",\"items\":[{\"text\":\"Basic\",\"items\":[{\"text\":\"🦋基础知识\",\"link\":\"/posts/llm/basic/01-lm-define-information-theory\"},{\"text\":\"🛠基建框架\",\"link\":\"/posts/llm/infra/01-parrallel\"}]},{\"text\":\"强化学习\",\"items\":[{\"text\":\"🎓RL理论基础\",\"link\":\"/posts/llm/rl/theory/01-reinforce-learning\"},{\"text\":\"🚄Agent-RL\",\"link\":\"/posts/llm/agent/rl/02-agent-tool\"}]},{\"text\":\"行业方向\",\"items\":[{\"text\":\"🚀主流模型\",\"link\":\"/posts/llm/industry/mainllm/01-kimi-series\"},{\"text\":\"💻代码模型\",\"link\":\"/posts/llm/industry/codellm/01-survey\"}]},{\"text\":\"Agent\",\"items\":[{\"text\":\"🤖概念及应用\",\"link\":\"/posts/llm/agent/basic\"}]}]},{\"text\":\"📙旧文章\",\"items\":[{\"text\":\"🍓NLP\",\"items\":[{\"text\":\"自然语言处理\",\"link\":\"/posts/olds/nlp\"}]},{\"text\":\"🍑基础知识\",\"items\":[{\"text\":\"深度学习\",\"link\":\"/posts/olds/dl\"},{\"text\":\"强化学习\",\"link\":\"/posts/olds/rl\"},{\"text\":\"机器学习\",\"link\":\"/posts/olds/ml\"}]},{\"text\":\"🍎算法\",\"items\":[{\"text\":\"算法题\",\"link\":\"/posts/olds/algo/\"},{\"text\":\"大数据\",\"link\":\"/posts/olds/bigdata/\"}]},{\"text\":\"🍒其他\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/olds/env/\"},{\"text\":\"其他\",\"link\":\"/posts/olds/other/\"}]}]},{\"text\":\"经验\",\"items\":[{\"text\":\"环境\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/exps/env/01-blog-env\"}]},{\"text\":\"心得\",\"items\":[{\"text\":\"心得体会\",\"link\":\"/posts/exps/mind\"}]}]},{\"text\":\"归档\",\"link\":\"/posts/archive.md\"},{\"text\":\"关于我\",\"link\":\"/posts/me\"}],\"outline\":{\"level\":[1,4],\"label\":\"当前页大纲\"},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/plmsmile\"}],\"search\":{\"provider\":\"local\"},\"docFooter\":{\"prev\":\"上一页\",\"next\":\"下一页\"},\"sidebar\":{\"/posts/olds/nlp/\":{\"base\":\"/posts/olds/nlp/\",\"items\":[{\"text\":\"NLP\",\"items\":[{\"text\":\"机器阅读(二)--模型(未完成)\",\"link\":\"54-mrc-models\"},{\"text\":\"机器阅读(一)--整体概述\",\"link\":\"53-mrc-brief\"},{\"text\":\"BERT 详解\",\"link\":\"52-bert\"},{\"text\":\"OpenAI GPT：Improving Language Understanding by Generative Pre-Training\",\"link\":\"51-opengpt\"},{\"text\":\"ELMo：Deep Contextualized Word Representations\",\"link\":\"50-elmo\"},{\"text\":\"QANet\",\"link\":\"49-qanet\"},{\"text\":\"Transformer\",\"link\":\"48-attention-is-all-you-need\"},{\"text\":\"Bidirectional Attention Flow\",\"link\":\"47-bidaf\"},{\"text\":\"R-Net (Gated Self-Matching Networks)\",\"link\":\"46-rnet-selfmatch\"},{\"text\":\"Match-LSTM and Answer Pointer\",\"link\":\"45-match-lstm\"},{\"text\":\"阅读理解模型总结\",\"link\":\"39-squard-models\"},{\"text\":\"阿里小蜜论文\",\"link\":\"36-alime-chat\"},{\"text\":\"各种注意力总结\",\"link\":\"33-attention-summary\"},{\"text\":\"Dynamic Coattention Network (Plus)\",\"link\":\"32-dynamic-coattention-network\"},{\"text\":\"协同注意力简介\",\"link\":\"31-co-attention-vqa\"},{\"text\":\"使用Dynamic Memory Network实现一个简单QA\",\"link\":\"30-dynamic-memory-network\"},{\"text\":\"词性标注和句法依存的表示符号\",\"link\":\"11-nlp-labels\"},{\"text\":\"Word2vec之总体介绍\",\"link\":\"cs224n-notes1-word2vec\"},{\"text\":\"Word2vec之数学模型\",\"link\":\"word2vec-math\"},{\"text\":\"Word2vec之公式推导笔记\",\"link\":\"cs224n-lecture2-word2vec\"},{\"text\":\"subword-units\",\"link\":\"subword-units\"},{\"text\":\"Wordpiece模型\",\"link\":\"26-wordpieacemodel\"},{\"text\":\"谷歌RNN翻译模型\",\"link\":\"25-google-nmt\"},{\"text\":\"机器翻译注意力机制及其PyTorch实现\",\"link\":\"Attention-based-NMT\"},{\"text\":\"图文介绍RNN注意力机制\",\"link\":\"attention-model\"},{\"text\":\"最初RNN神经翻译简略笔记\",\"link\":\"NMT\"},{\"text\":\"语言模型和平滑方法\",\"link\":\"nlp-notes\"},{\"text\":\"利用tensorflow实现简版word2vec\",\"link\":\"word2vec\"}]}]},\"/posts/olds/dl/\":{\"base\":\"/posts/olds/dl/\",\"items\":[{\"text\":\"DL\",\"items\":[{\"text\":\"卷积神经网络总结\",\"link\":\"38-convolution\"},{\"text\":\"网络优化\",\"link\":\"35-nerual-network-optim\"},{\"text\":\"cs224n作业一\",\"link\":\"cs224n-assignment-1\"},{\"text\":\"cs231n线性分类器和损失函数\",\"link\":\"cs231n-linear-notes\"},{\"text\":\"神经网络-过拟合-预处理-BN\",\"link\":\"cs224n-notes3-neural-networks-2\"},{\"text\":\"神经网络基础-反向传播-激活函数\",\"link\":\"cs224n-notes3-neural-networks\"},{\"text\":\"循环神经网络\",\"link\":\"rnn\"},{\"text\":\"PyTorch快速上手\",\"link\":\"23-pytorch-start\"}]}]},\"/posts/olds/rl/\":{\"base\":\"/posts/olds/rl/\",\"items\":[{\"text\":\"RL\",\"items\":[{\"text\":\"强化学习在NLP中的应用\",\"link\":\"44-reinforce-nlp\"},{\"text\":\"意图识别和槽填充\",\"link\":\"43-intent-detection-slot-filling\"},{\"text\":\"强化学习算法小结\",\"link\":\"42-reinforce-conclusion-simple\"},{\"text\":\"基于策略函数的学习方法\",\"link\":\"41-strategy-learning\"},{\"text\":\"基于值函数的学习\",\"link\":\"40-value-learning\"},{\"text\":\"强化学习\",\"link\":\"37-reinforce-learning\"}]}]},\"/posts/olds/ml/\":{\"base\":\"/posts/olds/ml/\",\"items\":[{\"text\":\"ML\",\"items\":[{\"text\":\"决策树笔记\",\"link\":\"29-desicion-tree\"},{\"text\":\"机器学习知识点汇总整理\",\"link\":\"28-ml-interview-notes\"},{\"text\":\"SVM笔记\",\"link\":\"27-svm-notes\"},{\"text\":\"树的总结\",\"link\":\"10-trees\"},{\"text\":\"条件随机场\",\"link\":\"crf\"},{\"text\":\"最大熵模型\",\"link\":\"maxentmodel\"},{\"text\":\"线性回归和逻辑回归\",\"link\":\"21-lr\"},{\"text\":\"最大期望算法\",\"link\":\"14-em\"},{\"text\":\"马尔可夫模型\",\"link\":\"pgm-01\"},{\"text\":\"朴素贝叶斯算法及其代码实现\",\"link\":\"22-ml-ch03-bayes\"}]}]},\"/posts/olds/algo/\":{\"base\":\"/posts/olds/algo/\",\"items\":[{\"text\":\"ALGO\",\"items\":[{\"text\":\"剑指offer4(51-64)\",\"link\":\"aim2offer4\"},{\"text\":\"剑指offer3(21-40)\",\"link\":\"aim2offer3\"},{\"text\":\"数据结构之搜索算法\",\"link\":\"algorithm-dfs\"},{\"text\":\"leetcode-01\",\"link\":\"leetcode-01\"},{\"text\":\"剑指offer(11-20)\",\"link\":\"aim2offer2\"},{\"text\":\"排序算法总结\",\"link\":\"sort-algorithms\"},{\"text\":\"剑指Offer(1-10)\",\"link\":\"aim2offer\"}]}]},\"/posts/olds/bigdata/\":{\"base\":\"/posts/olds/bigdata/\",\"items\":[{\"text\":\"BIG Data\",\"items\":[{\"text\":\"NumPy\",\"link\":\"20-numpy\"},{\"text\":\"Spark基础编程核心思想介绍\",\"link\":\"19-spark-programming\"},{\"text\":\"Spark-SQL的简略笔记\",\"link\":\"18-spark-sql\"},{\"text\":\"Spark键值对RDD的常用API\",\"link\":\"17-spark-pairrdd\"},{\"text\":\"Spark基础RDD的常用API\",\"link\":\"16-Spark-BaseRDD\"}]}]},\"/posts/olds/env/\":{\"base\":\"/posts/olds/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"IDE配置\",\"link\":\"12-ide-envs\"},{\"text\":\"Linux使用笔记\",\"link\":\"09-linux-notes\"},{\"text\":\"博客搭建及相关问题\",\"link\":\"24-hexo-problems\"},{\"text\":\"旧版博客搭建过程及其问题\",\"link\":\"13-old-blog-problems\"}]}]},\"/posts/olds/other/\":{\"base\":\"/posts/olds/other/\",\"items\":[{\"text\":\"其他\",\"items\":[{\"text\":\"C++类对象和指针的区别\",\"link\":\"15-cpp-pointer-object-reference\"}]}]},\"/posts/llm/agent/rl/\":{\"base\":\"/posts/llm/agent/rl/\",\"items\":[{\"text\":\"Agent-RL\",\"items\":[{\"text\":\"Agent-Interaction-RL 笔记\",\"link\":\"04-agent-env\"},{\"text\":\"Agent-Search-RL 笔记\",\"link\":\"03-agent-search\"},{\"text\":\"Agent-Tool-RL 笔记\",\"link\":\"02-agent-tool\"},{\"text\":\"Agent-RL 综述型笔记\",\"link\":\"01-agent-rl\"}]}]},\"/posts/llm/agent/basic/\":{\"base\":\"/posts/llm/agent/basic/\",\"items\":[{\"text\":\"Agent-基础\",\"items\":[{\"text\":\"DeepResearch 评估\",\"link\":\"06-deepresearch-evaluation\"},{\"text\":\"Computer-Agent\",\"link\":\"05-comuter-agent\"},{\"text\":\"Agent 思考性文章\",\"link\":\"04-agent-blogs\"},{\"text\":\"一些流行的Agents\",\"link\":\"03-current-agents\"},{\"text\":\"Agent 评估 Benchmarks\",\"link\":\"02-evaluation-agent\"},{\"text\":\"Agent基础概念 (李宏毅笔记)\",\"link\":\"01-lhy-agent-notes\"}]}]},\"/posts/llm/rl/theory/\":{\"base\":\"/posts/llm/rl/theory/\",\"items\":[{\"text\":\"RL-Theory\",\"items\":[{\"text\":\"Agent-RL 相关算法\",\"link\":\"13-agentrl-algo\"},{\"text\":\"熵和RL相关文章\",\"link\":\"12-entropy\"},{\"text\":\"GRPO 改进系列\",\"link\":\"11-grpo-series\"},{\"text\":\"PPO 改进系列\",\"link\":\"10-ppo-series\"},{\"text\":\"典型策略提升方法：TRPO+PPO+DPO+GRPO\",\"link\":\"09-policy-trpo-ppo\"},{\"text\":\"确定性策略梯度\",\"link\":\"08-deterministic-policy-gradient\"},{\"text\":\"Actor-Critic 算法\",\"link\":\"07-actor-critic\"},{\"text\":\"策略梯度算法\",\"link\":\"06-policy-gradient\"},{\"text\":\"DQN算法及进阶\",\"link\":\"05-dqn\"},{\"text\":\"免模型预测和控制\",\"link\":\"04-model-free-prediction-control\"},{\"text\":\"有模型预测和控制\",\"link\":\"03-model-based-prediction-control\"},{\"text\":\"马尔可夫决策过程\",\"link\":\"02-markove-process\"},{\"text\":\"强化学习基本概念\",\"link\":\"01-rl-introduction\"},{\"text\":\"(18年笔记)强化学习算法小结\",\"link\":\"04-reinforce-conclusion-simple\"},{\"text\":\"(18年笔记)基于策略函数的学习方法\",\"link\":\"03-strategy-learning\"},{\"text\":\"(18年笔记)基于值函数的学习\",\"link\":\"02-value-learning\"},{\"text\":\"(18年笔记)强化学习基础\",\"link\":\"01-reinforce-learning\"}]}]},\"/posts/llm/rl/rlhf/\":{\"base\":\"/posts/llm/rl/rlhf/\",\"items\":[{\"text\":\"RLHF\",\"items\":[]}]},\"/posts/llm/rl/o1llm/\":{\"base\":\"/posts/llm/rl/o1llm/\",\"items\":[{\"text\":\"推理模型\",\"items\":[]}]},\"/posts/llm/industry/mainllm/\":{\"base\":\"/posts/llm/industry/mainllm/\",\"items\":[{\"text\":\"🚀主流模型\",\"items\":[{\"text\":\"快手系列\",\"link\":\"12-kwai-series\"},{\"text\":\"腾讯系列\",\"link\":\"11-tencent-series\"},{\"text\":\"Claude 系列\",\"link\":\"09-claude-series\"},{\"text\":\"LongCat 系列\",\"link\":\"10-longcat-series\"},{\"text\":\"Gemini 系列\",\"link\":\"08-gemini-series\"},{\"text\":\"Seed 系列\",\"link\":\"06-seed-series\"},{\"text\":\"OpenAI 系列\",\"link\":\"07-openai-series\"},{\"text\":\"Qwen 系列\",\"link\":\"05-qwen-series\"},{\"text\":\"MiniMax 系列\",\"link\":\"04-minimax-series\"},{\"text\":\"GLM 系列\",\"link\":\"03-glm-series\"},{\"text\":\"DeepSeek 系列\",\"link\":\"02-deepseek-series\"},{\"text\":\"Kimi 系列\",\"link\":\"01-kimi-series\"},{\"text\":\"SkyWork 系列\",\"link\":\"15-skywork-series\"},{\"text\":\"小米系列\",\"link\":\"14-mimo-series\"},{\"text\":\"Nvidia 系列\",\"link\":\"13-nvidia-series\"}]}]},\"/posts/llm/industry/codellm/\":{\"base\":\"/posts/llm/industry/codellm/\",\"items\":[{\"text\":\"💻代码模型\",\"items\":[{\"text\":\"SWE 合成数据 系列\",\"link\":\"11-swe-data-series\"},{\"text\":\"SWE 相关总结\",\"link\":\"10-swe-summary\"},{\"text\":\"Code 全训练 论文阅读\",\"link\":\"07-code-fulltrain-reading\"},{\"text\":\"Code TaskRL 论文阅读\",\"link\":\"06-code-taskrl-reading\"},{\"text\":\"CodeLLM 索引简记\",\"link\":\"05-open-codellm\"},{\"text\":\"Code 安全相关\",\"link\":\"04-safety-code\"},{\"text\":\"Code RL 任务\",\"link\":\"03-rl-task\"},{\"text\":\"Code 任务Bench相关\",\"link\":\"02-eval-task-benchmark\"},{\"text\":\"Code Survey\",\"link\":\"01-survey\"},{\"text\":\"SWE 系列 论文阅读\",\"link\":\"09-swe-series\"},{\"text\":\"Code 预训练相关\",\"link\":\"08-code-pretrain-summary\"}]}]},\"/posts/llm/basic/\":{\"base\":\"/posts/llm/basic/\",\"items\":[{\"text\":\"LLM-basic\",\"items\":[{\"text\":\"LLM位置编码和长度外推系列\",\"link\":\"08-llm-position-embedding\"},{\"text\":\"LLM 解码相关\",\"link\":\"07-decode\"},{\"text\":\"LLM Attention 系列\",\"link\":\"06-llm-attention\"},{\"text\":\"LLM 基础知识\",\"link\":\"05-llm-basic-info\"},{\"text\":\"LLM 架构相关\",\"link\":\"04-llm-architecture\"},{\"text\":\"Transformer细节\",\"link\":\"03-transformer-detail\"},{\"text\":\"语言模型重要组件\",\"link\":\"02-llm-components\"},{\"text\":\"语言模型定义及信息理论\",\"link\":\"01-lm-define-information-theory\"}]}]},\"/posts/llm/infra/\":{\"base\":\"/posts/llm/infra/\",\"items\":[{\"text\":\"🛠LLM-基建框架\",\"items\":[{\"text\":\"Verl 训练流程源代码阅读\",\"link\":\"08-verl-train-loop\"},{\"text\":\"Verl 有趣的功能\",\"link\":\"07-verl-core\"},{\"text\":\"Verl AgentLoop Rollout 相关\",\"link\":\"06-verl-code\"},{\"text\":\"Verl 常见参数配置和理解\",\"link\":\"05-verl-practice\"},{\"text\":\"Verl 早期概念型学习文章\",\"link\":\"04-verl\"},{\"text\":\"推理优化技术\",\"link\":\"03-inference-tech\"},{\"text\":\"分布式训练框架\",\"link\":\"02-speed-framework\"},{\"text\":\"分布式并行策略\",\"link\":\"01-parrallel\"}]}]},\"/posts/exps/env/\":{\"base\":\"/posts/exps/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"环境搭建的一些坑\",\"link\":\"01-blog-env\"}]}]},\"/posts/exps/mind/\":{\"base\":\"/posts/exps/mind/\",\"items\":[{\"text\":\"心得体会\",\"items\":[]}]}}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>
<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>GLM 系列 | 📚 plmblog</title>
    <meta name="description" content="记录一些学习笔记。">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/assets/style.CuIOXX7t.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.CpFa0R23.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.DrNSUXfy.js">
    <link rel="modulepreload" href="/assets/chunks/framework.CvbyeFFO.js">
    <link rel="modulepreload" href="/assets/posts_llm_industry_mainllm_03-glm-series.md.8i7VdpW8.lean.js">
    <link rel="icon" href="/plm.png">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-cecb633e><!--[--><!--]--><!--[--><span tabindex="-1" data-v-c979f278></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-c979f278>Skip to content</a><!--]--><!----><header class="VPNav" data-v-cecb633e data-v-0ad68676><div class="VPNavBar" data-v-0ad68676 data-v-ce71e4ef><div class="wrapper" data-v-ce71e4ef><div class="container" data-v-ce71e4ef><div class="title" data-v-ce71e4ef><div class="VPNavBarTitle has-sidebar" data-v-ce71e4ef data-v-7e906684><a class="title" href="/" data-v-7e906684><!--[--><!--]--><!----><span data-v-7e906684>📚 plmblog</span><!--[--><!--]--></a></div></div><div class="content" data-v-ce71e4ef><div class="content-body" data-v-ce71e4ef><!--[--><!--]--><div class="VPNavBarSearch search" data-v-ce71e4ef><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-ce71e4ef data-v-e0cd9371><span id="main-nav-aria-label" class="visually-hidden" data-v-e0cd9371> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>首页</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>🐲LLM</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Basic</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/basic/01-lm-define-information-theory.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🦋基础知识</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/infra/01-parrallel.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🛠基建框架</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>强化学习</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/rl/theory/01-reinforce-learning.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🎓RL理论基础</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/rl/02-agent-tool.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚄Agent-RL</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>行业方向</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/industry/mainllm/01-kimi-series.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🚀主流模型</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/industry/codellm/01-survey.html" data-v-dc987abe><!--[--><span data-v-dc987abe>💻代码模型</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>Agent</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/llm/agent/basic.html" data-v-dc987abe><!--[--><span data-v-dc987abe>🤖概念及应用</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>📙旧文章</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍓NLP</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/nlp.html" data-v-dc987abe><!--[--><span data-v-dc987abe>自然语言处理</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍑基础知识</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/dl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>深度学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/rl.html" data-v-dc987abe><!--[--><span data-v-dc987abe>强化学习</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/ml.html" data-v-dc987abe><!--[--><span data-v-dc987abe>机器学习</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍎算法</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/algo/" data-v-dc987abe><!--[--><span data-v-dc987abe>算法题</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/bigdata/" data-v-dc987abe><!--[--><span data-v-dc987abe>大数据</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>🍒其他</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/env/" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/olds/other/" data-v-dc987abe><!--[--><span data-v-dc987abe>其他</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e0cd9371 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-ffaaba87><span class="text" data-v-ffaaba87><!----><span data-v-ffaaba87>经验</span><span class="vpi-chevron-down text-icon" data-v-ffaaba87></span></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><div class="items" data-v-798b97ca><!--[--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>环境</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/env/01-blog-env.html" data-v-dc987abe><!--[--><span data-v-dc987abe>环境搭建</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-798b97ca data-v-a2651156><p class="title" data-v-a2651156>心得</p><!--[--><!--[--><div class="VPMenuLink" data-v-a2651156 data-v-dc987abe><a class="VPLink link" href="/posts/exps/mind.html" data-v-dc987abe><!--[--><span data-v-dc987abe>心得体会</span><!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/archive.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>归档</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/posts/me.html" tabindex="0" data-v-e0cd9371 data-v-4aa19863><!--[--><span data-v-4aa19863>关于我</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-ce71e4ef data-v-b59ebfac><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-b59ebfac data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-ce71e4ef data-v-e0f2db57 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-ce71e4ef data-v-8897e953 data-v-ffaaba87><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-ffaaba87><span class="vpi-more-horizontal icon" data-v-ffaaba87></span></button><div class="menu" data-v-ffaaba87><div class="VPMenu" data-v-ffaaba87 data-v-798b97ca><!----><!--[--><!--[--><!----><div class="group" data-v-8897e953><div class="item appearance" data-v-8897e953><p class="label" data-v-8897e953>Appearance</p><div class="appearance-action" data-v-8897e953><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-8897e953 data-v-809b7594 data-v-3591f5e2><span class="check" data-v-3591f5e2><span class="icon" data-v-3591f5e2><!--[--><span class="vpi-sun sun" data-v-809b7594></span><span class="vpi-moon moon" data-v-809b7594></span><!--]--></span></span></button></div></div></div><div class="group" data-v-8897e953><div class="item social-links" data-v-8897e953><div class="VPSocialLinks social-links-list" data-v-8897e953 data-v-7a4bfff1><!--[--><a class="VPSocialLink no-icon" href="https://github.com/plmsmile" aria-label="github" target="_blank" rel="noopener" data-v-7a4bfff1 data-v-8e5dce54><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-ce71e4ef data-v-37e0f734><span class="container" data-v-37e0f734><span class="top" data-v-37e0f734></span><span class="middle" data-v-37e0f734></span><span class="bottom" data-v-37e0f734></span></span></button></div></div></div></div><div class="divider" data-v-ce71e4ef><div class="divider-line" data-v-ce71e4ef></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-cecb633e data-v-1b409c8b><div class="container" data-v-1b409c8b><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-1b409c8b><span class="vpi-align-left menu-icon" data-v-1b409c8b></span><span class="menu-text" data-v-1b409c8b>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-1b409c8b data-v-a203161a><button data-v-a203161a>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-cecb633e data-v-18f7b5ca><div class="curtain" data-v-18f7b5ca></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-18f7b5ca><span class="visually-hidden" id="sidebar-aria-label" data-v-18f7b5ca> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-7f5b9a39><section class="VPSidebarItem level-0 has-active" data-v-7f5b9a39 data-v-a4affe07><div class="item" role="button" tabindex="0" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><h2 class="text" data-v-a4affe07>🚀主流模型</h2><!----></div><div class="items" data-v-a4affe07><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/mainllm/12-kwai-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>快手系列</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/mainllm/11-tencent-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>腾讯系列</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/mainllm/09-claude-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Claude 系列</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/mainllm/10-longcat-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>LongCat 系列</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/mainllm/08-gemini-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Gemini 系列</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/mainllm/06-seed-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Seed 系列</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/mainllm/07-openai-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>OpenAI 系列</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/mainllm/05-qwen-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Qwen 系列</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/mainllm/04-minimax-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>MiniMax 系列</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/mainllm/03-glm-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>GLM 系列</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/mainllm/02-deepseek-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>DeepSeek 系列</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/mainllm/01-kimi-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Kimi 系列</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/mainllm/15-skywork-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>SkyWork 系列</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/mainllm/14-mimo-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>小米系列</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4affe07 data-v-a4affe07><div class="item" data-v-a4affe07><div class="indicator" data-v-a4affe07></div><a class="VPLink link link" href="/posts/llm/industry/mainllm/13-nvidia-series.html" data-v-a4affe07><!--[--><p class="text" data-v-a4affe07>Nvidia 系列</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-cecb633e data-v-53a9cb18><div class="VPDoc has-sidebar has-aside" data-v-53a9cb18 data-v-5a64a79a><!--[--><!--]--><div class="container" data-v-5a64a79a><div class="aside" data-v-5a64a79a><div class="aside-curtain" data-v-5a64a79a></div><div class="aside-container" data-v-5a64a79a><div class="aside-content" data-v-5a64a79a><div class="VPDocAside" data-v-5a64a79a data-v-f8ea3c28><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-f8ea3c28 data-v-b94d89ac><div class="content" data-v-b94d89ac><div class="outline-marker" data-v-b94d89ac></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-b94d89ac>当前页大纲</div><ul class="VPDocOutlineItem root" data-v-b94d89ac data-v-80b46526><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-f8ea3c28></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-5a64a79a><div class="content-container" data-v-5a64a79a><!--[--><!--[--><!--[--><article class="post-header" data-v-a99fd7c9><h1 class="title" data-v-a99fd7c9>GLM 系列</h1><div class="stats-container" data-v-a99fd7c9><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 📅 发表于 <span class="stat-text" data-v-a99fd7c9>2025/09/24</span></div><div class="stat-item" data-v-a99fd7c9> 🔄 更新于 <span class="stat-text" data-v-a99fd7c9>2025/09/24</span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 👁️ <span class="stat-text" data-v-a99fd7c9>-- 次访问</span><span id="busuanzi_value_page_pv" style="display:none;" data-page="/posts/llm/industry/mainllm/03-glm-series.html" data-v-a99fd7c9></span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> 📝 <span class="stat-text" data-v-a99fd7c9>0 字</span></div><div class="stat-divider" data-v-a99fd7c9></div><div class="stat-item" data-v-a99fd7c9> ⏳ <span class="stat-text" data-v-a99fd7c9>0 分钟</span></div><div class="stat-divider" data-v-a99fd7c9></div></div><div class="tag-group" data-v-a99fd7c9><!--[--><div class="category-item" data-v-a99fd7c9>mainllm</div><!--]--><!--[--><div class="tag-item" data-v-a99fd7c9> #glm4.5</div><div class="tag-item" data-v-a99fd7c9> #moe</div><div class="tag-item" data-v-a99fd7c9> #pretrain</div><div class="tag-item" data-v-a99fd7c9> #midtrain</div><div class="tag-item" data-v-a99fd7c9> #posttrain</div><div class="tag-item" data-v-a99fd7c9> #agentic sft</div><div class="tag-item" data-v-a99fd7c9> #reasoning rl</div><div class="tag-item" data-v-a99fd7c9> #Agentic RL</div><div class="tag-item" data-v-a99fd7c9> #WebSearcj</div><div class="tag-item" data-v-a99fd7c9> #SWE RL</div><div class="tag-item" data-v-a99fd7c9> #GeneralRL</div><div class="tag-item" data-v-a99fd7c9> #HolisticRL</div><div class="tag-item" data-v-a99fd7c9> #InstructionFollowing RL</div><div class="tag-item" data-v-a99fd7c9> #FunctionCall RL</div><div class="tag-item" data-v-a99fd7c9> #Pathology RL</div><!--]--></div></article><!--]--><!--]--><!--]--><main class="main" data-v-5a64a79a><div style="position:relative;" class="vp-doc _posts_llm_industry_mainllm_03-glm-series" data-v-5a64a79a><div><h2 id="_2512-glm-4-7" tabindex="-1">(2512) GLM-4.7 <a class="header-anchor" href="#_2512-glm-4-7" aria-label="Permalink to &quot;(2512) GLM-4.7&quot;">​</a></h2><h2 id="_2512-glm-4-6v" tabindex="-1">(2512) GLM-4.6V <a class="header-anchor" href="#_2512-glm-4-6v" aria-label="Permalink to &quot;(2512) GLM-4.6V&quot;">​</a></h2><h2 id="_2508-glm-4-5" tabindex="-1">(2508) GLM-4.5 <a class="header-anchor" href="#_2508-glm-4-5" aria-label="Permalink to &quot;(2508) GLM-4.5&quot;">​</a></h2><p><strong>🌺 论文摘要</strong></p><div class="custom-block danger"><div class="custom-block-title">论文摘要</div><ul><li><a href="https://www.alphaxiv.org/abs/2508.06471" target="_blank" rel="noreferrer">paper</a>, <a href="https://zhuanlan.zhihu.com/p/1955721176954443417" target="_blank" rel="noreferrer">技术报告</a></li><li>MoE架构，深而窄。<code>2阶段预训练</code>+<code>Mid-Training</code>。</li><li>PostTraining <ul><li>SFT：2阶段SFT，<code>自动AgenticSFT数据构造</code>。</li><li>Reasoning RL (数学+代码+科学)：<code>2阶段难度课程学习</code>，<code>动态采样温度</code>等。</li><li>Agentic RL (WebSearch + SWE RL)：<code>数据收集</code>，<code>自蒸馏迭代优化</code>。</li><li>General RL (综合+指令跟随+函数调用+问题RL)：<code>Rule+RLHF+RLAIF</code> 3种反馈信号。</li></ul></li></ul></div><h3 id="问题背景" tabindex="-1">问题背景 <a class="header-anchor" href="#问题背景" aria-label="Permalink to &quot;问题背景&quot;">​</a></h3><p><strong>❓问题背景</strong></p><div class="custom-block warning"><div class="custom-block-title">问题背景</div><ul><li>LLM变化：<code>通用问答</code> -&gt; <code>问题解决者</code></li><li>闭源模型在数学和代码修复领域有效果，开源模型有差距，难以解决复杂真实问题。</li><li>缺乏在<code>Agentic</code>(使用<code>外部工具和世界交互</code>), <code>Reasoning</code>(<code>多步推理</code>), <code>Coding</code>(<code>真实软件工程</code>) 同时优秀的开源模型。</li></ul></div><h3 id="模型架构" tabindex="-1">模型架构 <a class="header-anchor" href="#模型架构" aria-label="Permalink to &quot;模型架构&quot;">​</a></h3><div class="custom-block info"><div class="custom-block-title">模型架构</div><ul><li><strong>MoE 架构</strong><ul><li><code>loss-free balance routing</code>：无需<a href="http://plmsmile.github.io/posts/llm/basic/04-llm-architecture.html#%E4%B8%93%E5%AE%B6%E5%B9%B3%E8%A1%A1%E9%97%AE%E9%A2%98" target="_blank" rel="noreferrer">辅助loss</a>，来平衡路由。</li><li><code>sigmoid gates</code>：sigmoid决定token给哪些专家，传统是<a href="https://plmsmile.github.io/posts/llm/basic/04-llm-architecture.html#%E9%97%A8%E6%8E%A7-topk%E7%AD%96%E7%95%A5" target="_blank" rel="noreferrer">Softmax Topk</a></li></ul></li><li><strong>更深而窄</strong>：<code>层数变多</code>、<code>hidden_dim变小</code>。 <ul><li>实验发现：<code>深度</code>对<code>推理能力很重要</code>。</li><li>对比DeepSeek-V3, Kimi-K2：<code>由宽变窄</code>、<code>由浅变深</code></li></ul></li><li><strong>GQA</strong> + partial <a href="https://plmsmile.github.io/posts/llm/basic/08-llm-position-embedding.html#%E6%97%8B%E8%BD%AC%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81" target="_blank" rel="noreferrer">RoPE</a>.</li><li><strong>注意力头更多</strong>： 5120隐藏层维度 + 96个head，一般是64个 <ul><li>没降低训练loss，但提升了MMLU和BBH的分数</li></ul></li><li>稳定性：采用<code>QK-Norm</code>来<code>稳定attention logits的数值范围</code>，<code>防止训练不稳定</code>。</li><li>参数：355B-A32B, 106B-A12B</li></ul></div><img src="https://picx.zhimg.com/v2-f882eb29ab3d146180933302068bec67_r.jpg" style="display:block;margin:auto;" width="70%"><h3 id="预训练" tabindex="-1">预训练 <a class="header-anchor" href="#预训练" aria-label="Permalink to &quot;预训练&quot;">​</a></h3><p><strong>📕核心方法</strong></p><img src="https://pic4.zhimg.com/v2-bd099ff613fa6dbb627ff8a6dab8c685_r.jpg" style="display:block;margin:auto;" width="70%"><h4 id="预训练数据" tabindex="-1">预训练数据 <a class="header-anchor" href="#预训练数据" aria-label="Permalink to &quot;预训练数据&quot;">​</a></h4><div class="custom-block info"><div class="custom-block-title">预训练数据</div><ul><li><strong>Web数据</strong>：<code>中英文web网页</code>(爬取的)。 <ul><li>同Nemotron-CC，对网页<code>按质量打分</code>，<code>分桶</code>。</li><li><code>丢弃低质量</code>。<code>上采样高质量buckets</code>，贡献3.2个epoch训练，<code>覆盖推理高频知识</code>。</li><li>使用SemDedup去掉自动模板生成的网页。</li></ul></li><li><strong>多语言</strong>：爬取网页、Fineweb-2。做质量分类，对高质量进行上采样。</li><li><strong>代码</strong>： <ul><li><strong>Github+各种代码平台数据</strong>。 <ul><li>初步<code>规则过滤</code>，<code>按语言做质量分类</code>：高质、中等、低质量。</li><li><code>上采样高质量</code>、<code>去掉低质量代码</code>。<strong>所有源码数据</strong>应用<code>FIM任务</code>。</li></ul></li><li><strong>Code相关 Web数据</strong><ul><li>stage1：<code>HTML Code标签</code>，<code>FastText检索代码内容</code></li><li>stage2：做<code>质量评估</code>(高、中、低)，同源代码一样采样过滤。</li><li>stage3：使用<code>细粒度解析器</code>，重新解析选择的网页，<code>更好保留代码格式内容</code>。</li></ul></li></ul></li><li><strong>数学和科学</strong><ul><li>来源：web、书籍、论文等。</li><li>使用LLM，根据<code>数学和科学内容比例</code>，<code>对文档进行评分</code>，并训练<code>小分类器</code>来预测分数。</li><li><code>上采样高分数据</code></li></ul></li></ul></div><div class="custom-block info"><div class="custom-block-title">2阶段预训练</div><ul><li>阶段1：<code>通用数据</code>，做训练</li><li>阶段2：<code>上采样代码/数学/科学</code>等数据，做训练</li></ul></div><h4 id="mid-training" tabindex="-1">Mid-Training <a class="header-anchor" href="#mid-training" aria-label="Permalink to &quot;Mid-Training&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Mid-Training</div><p><strong>背景</strong></p><ul><li><code>增强特定领域能力</code>：使用<code>特定领域数据</code>(包括指令数据)，量少但质量高，注入<code>结构化知识</code>和<code>长逻辑</code>。</li><li>为后续SFT和RL打下基础。</li></ul><p><strong>Repo-Level Code训练</strong></p><ul><li><code>学习跨文件依赖关系</code>：<code>拼接</code>多个代码文件，</li><li><code>提高SWE能力</code>：学习代码如何被修改的。<code>学习diff</code>，<code>上下文(Issue+PR+Code)</code></li><li>4k -&gt; 32k</li></ul><p><strong>合成推理数据 训练</strong></p><ul><li>使用<code>强推理模型</code>，合成<code>数学/科学/代码推理过程</code>。</li><li>32k, 500B</li></ul><p><strong>长上下文和agent 训练</strong></p><ul><li><code>上采样长文档</code>、<code>大规模合成agent轨迹</code>。 <ul><li>尽量把完整文档塞进一个Batch，避免截断关键逻辑。<code>Best-fit Packing</code>。</li></ul></li><li>32k -&gt; <code>128k</code>, 100B</li></ul></div><h4 id="超参" tabindex="-1">超参 <a class="header-anchor" href="#超参" aria-label="Permalink to &quot;超参&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">预训练超参</div><p><strong>Muon 优化器</strong></p><ul><li>特点：基于Newton-Schulz迭代，具有二阶优化器的特性 <ul><li><code>收敛快</code>：比AdamW更快降低loss；<code>大batch友好</code>：承受极大batchsize，64M tokens。</li></ul></li><li>优化embedding, bias 和RMSNorm<code>之外的所有参数</code>。</li><li>超参：迭代步数N=5，动量<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.489ex;" xmlns="http://www.w3.org/2000/svg" width="8.404ex" height="1.995ex" role="img" focusable="false" viewBox="0 -666 3714.6 882" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(880.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1936.6,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" style="stroke-width:3;"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z" transform="translate(778,0)" style="stroke-width:3;"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(1278,0)" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>μ</mi><mo>=</mo><mn>0.95</mn></math></mjx-assistive-mml></mjx-container>，缩放的rms=0.2</li></ul><p><strong>学习率</strong></p><ul><li><p>放弃Warmup-Stable-Decay，回归Cosine Decay</p></li><li><p>学习率：0，预热到2.5e-4，衰减到2.5e-5，直到mid-train结束</p></li></ul><p><strong>Batch Size</strong></p><ul><li>前500B token，16M token，后期 64M token 保持不变。</li></ul><p><strong>序列长度</strong></p><ul><li>序列长度：<code>最初 4k</code>，mid-train <code>32k</code> -&gt; <code>128k</code></li><li>RoPE：base 由1w -&gt; 100w，<code>扩展上下文</code>。</li></ul><p><strong>MoE 路由</strong></p><ul><li>loss-free balance routing <ul><li>前15T token，有偏置更新，偏差更新率设为0.0001，强制负载均衡。</li><li>其余：设为0。模型专家分工形成后，停止人为干预偏置。</li></ul></li><li>辅助的序列级loss：极小权重0.0001，保底防止极端情况的负载崩塌</li></ul><p><strong>MTP loss</strong></p><ul><li>前15T token，<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.186ex;" xmlns="http://www.w3.org/2000/svg" width="7.228ex" height="1.756ex" role="img" focusable="false" viewBox="0 -694 3194.6 776" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(860.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1916.6,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" style="stroke-width:3;"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z" transform="translate(778,0)" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>λ</mi><mo>=</mo><mn>0.3</mn></math></mjx-assistive-mml></mjx-container>，其余token <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.186ex;" xmlns="http://www.w3.org/2000/svg" width="7.228ex" height="1.756ex" role="img" focusable="false" viewBox="0 -694 3194.6 776" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(860.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1916.6,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" style="stroke-width:3;"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(778,0)" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>λ</mi><mo>=</mo><mn>0.1</mn></math></mjx-assistive-mml></mjx-container></li></ul></div><h3 id="posttraining" tabindex="-1">PostTraining <a class="header-anchor" href="#posttraining" aria-label="Permalink to &quot;PostTraining&quot;">​</a></h3><div class="custom-block tip"><div class="custom-block-title">PostTraining</div><ul><li><strong>阶段1</strong> ：<code>Expert Training</code>, 构建<code>3个领域专家模型</code>，<code>推理</code>、<code>agent</code>、<code>通用聊天</code></li><li><strong>阶段2</strong>：<code>统一训练</code>，采取<code>自蒸馏技术</code> <code>整合多个专家</code>，最终交付<code>一个综合模型</code>。</li></ul></div><h4 id="sft-多阶段-自动数据构造等" tabindex="-1">SFT (多阶段/自动数据构造等) <a class="header-anchor" href="#sft-多阶段-自动数据构造等" aria-label="Permalink to &quot;SFT (多阶段/自动数据构造等)&quot;">​</a></h4><div class="custom-block tip"><div class="custom-block-title">SFT</div><p><strong>SFT 目的</strong></p><ul><li>阶段1(专家训练)：<code>冷启动</code>，后期被RL进一步提升。</li><li>阶段2(统一训练)：<code>蒸馏各专家模型</code>，到一个混合通用模型。</li></ul><p><strong>冷启动SFT</strong></p><ul><li><code>少量CoT数据</code>做SFT，确保每个专家<code>在RL之前</code> <code>有足够的基础能力</code>。</li></ul><p><strong>综合SFT</strong></p><ul><li>数据：推理任务、通用聊天、agent任务、长上下文理解任务。答案从<code>各专家模型蒸馏</code>而来。</li><li>模型：base model，长度：128k</li><li><strong>混合推理模式</strong>：混合<code>思考</code>和<code>直接回答</code>的两种数据。<code>难题做思考</code>，<code>简单任务直接回答</code>。</li></ul></div><div class="custom-block danger"><div class="custom-block-title">一些关键点</div><p><strong>XML 工具调用模板</strong></p><ul><li>由json改成XLM，避免太多转义字符，降低模型负担，更好支持agentic能力。</li></ul><p><strong>拒绝采样</strong></p><ul><li>从专家模型采样，采取<code>多阶段过滤机制</code><ul><li>过滤重复、超短、截断、不符合推理格式的。</li><li>客观验证：过滤数学/代码 答案不正确的。</li><li>主观过滤：使用RM过滤主观低分答案的样本。</li><li>工具过滤：工具调用要格式正确、真正解决问题。</li></ul></li></ul><p><strong>Prompt选择和ResponseScaling</strong></p><ul><li><code>过滤困难prompt</code> +<code> 过滤滤回复长度太短的prompt</code>，约<code>过滤50%</code></li><li>仅用50%数据训练，但在数学和科学任务山给提升2%-4%</li></ul><p><strong>自动 Agentic SFT 数据构造</strong></p><ul><li>Agent框架和收集工具 <ul><li>收集一套<code>agent框架</code>、<code>真实API</code>和<code>MCP Server</code>，以及使用<code>LLM 自动构建工具</code></li></ul></li><li><strong>合成任务</strong>：基于框架和工具，来合成<code>单步或多步任务</code><ul><li>对于成熟框架：使用LLM理解功能，自动生成query或任务。</li><li>对于零散工具：选择一个工具子集，使用LLM构建关于该子集的任务。</li></ul></li><li><strong>轨迹生成</strong>：对每个合成任务 <ul><li>使用<code>LLM生成工具调用轨迹</code>，<code>LLM模拟用户</code>。</li><li>使用<code>多个judge-agent</code> 来<code>评估任务是否完成</code>，<code>仅保留成功轨迹</code>。</li></ul></li></ul></div><h4 id="reasoning-rl-数学-代码-科学" tabindex="-1">Reasoning RL (数学+代码+科学) <a class="header-anchor" href="#reasoning-rl-数学-代码-科学" aria-label="Permalink to &quot;Reasoning RL (数学+代码+科学)&quot;">​</a></h4><div class="custom-block note"><div class="custom-block-title">Reasoning RL</div><p><strong>背景</strong></p><ul><li>专注于数学/代码/科学等领域，<code>有明确奖励信号</code>。</li><li>算法：GRPO + 去掉KL Loss。</li><li>核心解决：训练效率、样本多样性和数据质量等问题。</li></ul><p><strong>基于难度的2阶段课程学习</strong></p><ul><li>背景：太简单或太难，会导致梯度为0，无优势。</li><li>阶段1：<code>中等难度数据</code>，<code>rollout=16</code>。</li><li>阶段2：<code>高难度数据</code>，<code>rollout=512</code>，严格具有正确答案的样本。 <ul><li>AIME24：81.8 -&gt; 83.4</li></ul></li></ul><p><strong>直接使用最大长度64K</strong></p><ul><li><code>不用多阶段扩展长度</code>，因为SFT已经学过长输出了，限制逐渐扩展反而效果不好。</li></ul><p><strong>动态采样温度</strong></p><ul><li>温度低：缺乏探索；温度高：引入低质量噪声样本，影响训练效率。</li><li><code>动态调整温度</code>：<code>维持探索和利用平衡</code>。 <ul><li><code>平均奖励稳定</code>：<code>提升采样温度鼓励探索</code>。</li><li>基于质量选择高温：在性能不下降1%的情况下，所能选的最大温度。</li></ul></li></ul><p><strong>代码RL</strong></p><ul><li><code>Token-level Loss</code>：梯度信号更稳定，收敛更快，解决长度偏差问题。</li></ul><p><strong>科学RL</strong></p><ul><li><code>数据质量和类型很重要</code>：仅使用专家验证的多选题训练，效果比混合质量数据好。</li></ul></div><h4 id="agentic-rl-websearch-swe-rl" tabindex="-1">Agentic RL (WebSearch + SWE RL) <a class="header-anchor" href="#agentic-rl-websearch-swe-rl" aria-label="Permalink to &quot;Agentic RL (WebSearch + SWE RL)&quot;">​</a></h4><div class="custom-block danger"><div class="custom-block-title">AgenticRL</div><p><strong>任务</strong></p><ul><li><code>web-search</code>, <code>代码生成 </code>，答案可验证。</li></ul><p><strong>数据收集合成</strong></p><ul><li><strong>web搜索</strong>：需要搜索零散信息，<code>数据合成pipeline</code><ul><li>知识图谱法(多条推理)：利用知识图谱，找到较远的实体，生成问A和D关系的问题，必须A-&gt;B-&gt;C-&gt;D</li><li>捉迷藏方法：人工选择网页，<code>把关键信息抹掉</code>，模型<code>必须依赖这些信息</code>才能<code>回答问题</code>。</li></ul></li><li><strong>软件工程</strong><ul><li>收集Github <code>PR</code> + <code>Issue</code>，构建<code>prompt</code> + <code>单元测试</code></li><li><code>加固沙箱</code>：不会搞坏宿主机</li></ul></li></ul><p><strong>算法优化</strong></p><ul><li>GRPO：LLM-response才计算，环境返回被mask掉。</li><li><strong>奖励信号</strong>： <ul><li>搜索-<code>最终结果ACC</code>；SWE-<code>单元测试通过率</code>。</li><li>过程格式惩罚：在轨迹生成过程中，<code>只要工具格式错误</code>，就<code>立即停止</code>，<code>并给0分</code>。</li></ul></li><li><strong>自蒸馏迭代优化</strong>：SFT -&gt; RL -&gt; SFT -&gt; RL ... <ul><li>使用RL模型预测结果，<code>替换冷启动数据</code>，得到<code>更强SFT模型</code>，<code>再进行RL</code>，如此迭代。</li></ul></li><li>效果 <ul><li><code>搜索</code> + <code>SWE</code> RL提升，会使其他<code>工具调用</code>/<code>Terminal-Bench</code>也提升。</li><li>环境交互次数增加，效果也会增加</li></ul></li></ul></div><h4 id="general-rl-综合-指令跟随-函数调用-问题rl" tabindex="-1">General RL (综合+指令跟随+函数调用+问题RL) <a class="header-anchor" href="#general-rl-综合-指令跟随-函数调用-问题rl" aria-label="Permalink to &quot;General RL (综合+指令跟随+函数调用+问题RL)&quot;">​</a></h4><div class="custom-block caution"><div class="custom-block-title">General RL</div><p><strong>背景</strong></p><ul><li>提升模型整体性能，修复一些问题，加强关键能力。</li><li><strong>3种反馈信号</strong>：<code>Rule-based</code>, <code>RLHF</code>, <code>RLAIF</code>。 <ul><li>更鲁棒的训练信号，更好使用每一种数据。</li></ul></li></ul></div><div class="custom-block danger"><div class="custom-block-title">Holistic RL</div><p><strong>Holistic RL</strong></p><ul><li>目标：<code>泛领域效果提升</code>。</li><li>数据集：<code>5000prompt</code>，覆盖7个一级、33个二级、139个三级分类。</li><li><code>2种反馈信号</code>：更可靠效果更好 <ul><li><strong>人类反馈信号</strong>：在<code>偏好数据</code>训练<code>RewardModel</code>，基于<code>指令遵循</code>、<code>安全性</code>、<code>事实正确性</code>等多维度评估。</li><li><strong>AI反馈信号</strong>：设计<code>评分准则</code>。</li></ul></li></ul></div><div class="custom-block danger"><div class="custom-block-title">Instruction Following RL</div><p><strong>指令跟随 RL</strong></p><ul><li>目标：复杂指令。</li><li>数据集：专门构建的有挑战数据集，覆盖7类和151个细分类别。</li><li><code>3种反馈信号</code>：非常鲁棒，避免RewardHacking，带来效果提升。 <ul><li><code>规则验证</code>：</li><li><code>奖励模型</code>：</li><li><code>Critic模型</code>：</li></ul></li></ul></div><div class="custom-block danger"><div class="custom-block-title">Function Calling RL</div><p><strong>Step-Wise Rule RL</strong></p><ul><li>对<code>固定流程任务</code>，标注<code>每一轮的GT工具调用</code>。</li><li>奖励信号：<code>完全匹配GT结果</code>，才得1；其余为0。</li></ul><p><strong>端到端 多轮 RL</strong></p><ul><li><code>开放性任务</code><ul><li><code>单轮多步任务</code>：多步工具调用。 <ul><li>数据：<code>基于MCP合成的数据</code>+ <code>有运行环境的开源agent数据</code> (AgentGym等)</li></ul></li><li><code>多轮多步任务</code>： <ul><li><code>多步工具执行</code> + <code>多轮用户交互</code>。<code>LLM模拟用户</code></li></ul></li></ul></li><li>奖励信号：<code>格式正确</code>且<code>任务完成</code>，才为1；其余为0.</li></ul></div><div class="custom-block danger"><div class="custom-block-title">Pathology RL</div><p><strong>背景</strong></p><ul><li>后期存在<code>语言混合</code>、<code>过度重复</code>、<code>格式错误</code>等问题。</li><li>通用RL难以解决：<code>发生概率&lt;1%</code>，样本效率低</li></ul><p><strong>方法</strong></p><ul><li><code>识别高危prompt</code>，<code>构建专有数据集</code></li><li>再跑一轮RL，使用<code>极大负奖励做惩罚</code>，降低错误。</li></ul></div><h3 id="算法实验" tabindex="-1">算法实验 <a class="header-anchor" href="#算法实验" aria-label="Permalink to &quot;算法实验&quot;">​</a></h3><h4 id="实验设置" tabindex="-1">实验设置 <a class="header-anchor" href="#实验设置" aria-label="Permalink to &quot;实验设置&quot;">​</a></h4><p><strong>✍️实验设置</strong></p><div class="custom-block tip"><div class="custom-block-title">实验设置</div><p><strong>基础模型</strong></p><ul><li>GLM-4.5 (355B Total / 32B Active)</li><li>GLM-4.5-Air (106B Total / 12B Active)</li></ul><p><strong>训练任务/数据</strong></p><ul><li>预训练：23T tokens，包含网页、书籍、论文、GitHub 代码。</li><li>Mid训练：32K 到 128K 上下文扩展，Repo 级代码，合成推理数据。</li><li>后训练：SFT（冷启动+专家蒸馏），RL（GRPO 算法，针对推理、Agent、通用任务的不同策略）。</li></ul><p><strong>评测任务/数据</strong></p><ul><li><strong>ARC 基准 (12个)</strong>：Agentic (TAU-Bench, BFCL V3, BrowseComp), Reasoning (MMLU-Pro, AIME 24, MATH-500, SciCode, GPQA, HLE, LCB), Coding (SWE-Bench Verified, Terminal-Bench)。</li><li><strong>通用基准</strong>：MMLU, SimpleQA, IFEval, SysBench。</li><li><strong>人工评测</strong>：SafetyBench, CC-Bench (基于 Claude Code 的编码 Agent 评测), 翻译能力评测。</li></ul><p><strong>算法/策略</strong></p><ul><li><code>2阶段预训练</code>：<code>通用数据</code> + <code>上采样高质量数据</code>训练</li><li><code>MidTrain</code>：<code>仓库级</code> + <code>合成推理数据</code> +<code> 长上下文</code>，上采样+<code>逐步扩展长度</code></li><li><code>多阶段SFT</code>：<code>冷启动</code>+<code>统一训练</code>，混合推理模式。</li><li><code>多种RL训练</code>：ReasonRL <code>难度课程学习</code>；Agentic RL：<code>自蒸馏迭代优化</code>；General RL：<code>3种反馈信号</code>。</li></ul><p><strong>超参</strong></p><ul><li>优化器：Muon</li><li>学习率调度：Cosine decay (而非 WSD)</li><li>最大序列长度：128K (Post-training)</li></ul></div><h4 id="关键结果" tabindex="-1">关键结果 <a class="header-anchor" href="#关键结果" aria-label="Permalink to &quot;关键结果&quot;">​</a></h4><p><strong>🍑关键结果</strong></p><div class="custom-block important"><div class="custom-block-title">关键结果</div><ul><li><strong>总体排名</strong>：在 ARC 任务上，GLM-4.5 总体排名第 3，GLM-4.5-Air 排名第 6。GLM-4.5 在 Agentic 任务上排名第 2（仅次于 OpenAI o3），在 Coding 任务上排名第 3（接近 Claude Sonnet 4）。</li><li><strong>参数效率</strong>：GLM-4.5 在 SWE-bench Verified 上位于帕累托前沿，以 DeepSeek-R1 一半的参数量实现了与之相当甚至更好的性能。</li><li><strong>Agent 能力</strong>：在 TAU-Bench 上得分 70.1%，在 BFCL v3 上得分 77.8%，与 Claude Sonnet 4 持平。在 Web 浏览任务 BrowseComp 上明显优于 Claude Opus 4。</li><li><strong>推理能力</strong>：AIME 24 得分 91.0%（优于 o3），MATH-500 得分 98.2%。</li><li><strong>编码能力</strong>：SWE-bench Verified 得分 64.2%，Terminal-Bench 得分 37.5%，优于 GPT-4.1 和 Gemini-2.5-Pro。</li><li><strong>工具调用可靠性</strong>：在 CC-Bench 实测中，工具调用成功率高达 90.6%，高于 Claude Sonnet 4 (89.5%) 和 Kimi K2 (86.2%)。</li></ul></div><p>预训练评估</p><img src="https://pic4.zhimg.com/v2-b5060fc4610d95812b6195a3503512cd_r.jpg" style="display:block;margin:auto;" width="70%"><p>后训练评估</p><img src="https://pic2.zhimg.com/v2-8997436a909d380869b9fbe623e774d9_1440w.jpg" style="display:block;margin:auto;" width="70%"><p>Agent 评估</p><img src="https://pica.zhimg.com/v2-e1afbbee1184bcdcc06ab851080414d0_1440w.jpg" style="display:block;margin:auto;" width="70%"><p>SWE 评估</p><img src="https://pic4.zhimg.com/v2-d9c3064de8d1d3303e7c6839597071e5_1440w.jpg" style="display:block;margin:auto;" width="70%"><p>安全评估</p><img src="https://pic4.zhimg.com/v2-1435bf38e5819625b649bee76ed5cc1f_1440w.jpg" style="display:block;margin:auto;" width="70%"><h3 id="未来方向" tabindex="-1">未来方向 <a class="header-anchor" href="#未来方向" aria-label="Permalink to &quot;未来方向&quot;">​</a></h3><p><strong>⛳ 未来方向</strong></p><div class="custom-block info"><div class="custom-block-title">未来方向</div><ul><li><strong>解决偏见</strong>：虽然安全性得分高（Ethics, Safety），但<code>不公平与偏见</code>（Unfairness &amp; Bias）仍有改进空间。</li><li><strong>统一能力的深化</strong>：把Agent+Reasoning+Coding能力更深层次地融合到一个统一模型，不依赖分离的专家。</li><li><strong>开源生态</strong>：释放模型权重和 <code>glm-simple-evals</code> 评测工具，推动复杂推理和Agent方面的研究。</li></ul></div></div></div></main><footer class="VPDocFooter" data-v-5a64a79a data-v-54a90a4a><!--[--><!--]--><div class="edit-info" data-v-54a90a4a><!----><div class="last-updated" data-v-54a90a4a><p class="VPLastUpdated" data-v-54a90a4a data-v-08208c09>Last updated: <time datetime="2025-10-23T14:54:10.000Z" data-v-08208c09></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-54a90a4a><span class="visually-hidden" id="doc-footer-aria-label" data-v-54a90a4a>Pager</span><div class="pager" data-v-54a90a4a><a class="VPLink link pager-link prev" href="/posts/llm/industry/mainllm/04-minimax-series.html" data-v-54a90a4a><!--[--><span class="desc" data-v-54a90a4a>上一页</span><span class="title" data-v-54a90a4a>MiniMax 系列</span><!--]--></a></div><div class="pager" data-v-54a90a4a><a class="VPLink link pager-link next" href="/posts/llm/industry/mainllm/02-deepseek-series.html" data-v-54a90a4a><!--[--><span class="desc" data-v-54a90a4a>下一页</span><span class="title" data-v-54a90a4a>DeepSeek 系列</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--[--><div class="busuanzi"> 总访客数： <span id="busuanzi_value_site_uv"></span>   ·   总访问量： <span id="busuanzi_value_site_pv"></span></div><div class="busuanzi"> PLM&#39;s Blog @ 2016 - 2026</div><!--]--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api-examples.md\":\"Bt59YpwR\",\"index.md\":\"DmRGHmj9\",\"markdown-examples.md\":\"CPJSv--2\",\"posts_archive.md\":\"pZWQT7dp\",\"posts_exps_env_01-blog-env.md\":\"CcTUm41j\",\"posts_exps_env_index.md\":\"BJEZeoT-\",\"posts_exps_mind_index.md\":\"naOB3-Mb\",\"posts_llm_agent_basic_01-lhy-agent-notes.md\":\"BK_CsHNC\",\"posts_llm_agent_basic_02-evaluation-agent.md\":\"Dn02cVtP\",\"posts_llm_agent_basic_03-current-agents.md\":\"C25gmbg8\",\"posts_llm_agent_basic_04-agent-blogs.md\":\"_QbL2Plv\",\"posts_llm_agent_basic_05-comuter-agent.md\":\"D0gJpId6\",\"posts_llm_agent_basic_06-deepresearch-evaluation.md\":\"DdRDcxUJ\",\"posts_llm_agent_basic_index.md\":\"ClGtwUqg\",\"posts_llm_agent_rl_01-agent-rl.md\":\"wOF9bz66\",\"posts_llm_agent_rl_02-agent-tool.md\":\"IB_AqkSe\",\"posts_llm_agent_rl_03-agent-search.md\":\"Cim7OGxb\",\"posts_llm_agent_rl_04-agent-env.md\":\"C_O9BVi3\",\"posts_llm_agent_rl_index.md\":\"BudtoDK9\",\"posts_llm_basic_01-lm-define-information-theory.md\":\"Bl38RTdm\",\"posts_llm_basic_02-llm-components.md\":\"CGM_jRUE\",\"posts_llm_basic_03-transformer-detail.md\":\"BgLyAVDZ\",\"posts_llm_basic_04-llm-architecture.md\":\"jk4T-c21\",\"posts_llm_basic_05-llm-basic-info.md\":\"bdnM02bn\",\"posts_llm_basic_06-llm-attention.md\":\"BRJ9jR-M\",\"posts_llm_basic_07-decode.md\":\"BRytPqZo\",\"posts_llm_basic_08-llm-position-embedding.md\":\"d9dN_RuO\",\"posts_llm_basic_index.md\":\"DjX2HRXy\",\"posts_llm_industry_codellm_01-survey.md\":\"DIZQiOWr\",\"posts_llm_industry_codellm_02-eval-task-benchmark.md\":\"B-okIRAD\",\"posts_llm_industry_codellm_03-rl-task.md\":\"vQDqALFA\",\"posts_llm_industry_codellm_04-safety-code.md\":\"mkEFLxnr\",\"posts_llm_industry_codellm_05-open-codellm.md\":\"C6UU6qcZ\",\"posts_llm_industry_codellm_06-code-taskrl-reading.md\":\"BJI-7ypF\",\"posts_llm_industry_codellm_07-code-fulltrain-reading.md\":\"BjyYsnTY\",\"posts_llm_industry_codellm_08-code-pretrain-summary.md\":\"DfgRUz6a\",\"posts_llm_industry_codellm_09-swe-series.md\":\"njRlhnZH\",\"posts_llm_industry_codellm_10-swe-summary.md\":\"CmzPFSW7\",\"posts_llm_industry_codellm_11-swe-data-series.md\":\"BkWEB2x6\",\"posts_llm_industry_mainllm_01-kimi-series.md\":\"B03hc7IE\",\"posts_llm_industry_mainllm_02-deepseek-series.md\":\"B04zRtyw\",\"posts_llm_industry_mainllm_03-glm-series.md\":\"8i7VdpW8\",\"posts_llm_industry_mainllm_04-minimax-series.md\":\"DjQwki4V\",\"posts_llm_industry_mainllm_05-qwen-series.md\":\"B4DMxRmo\",\"posts_llm_industry_mainllm_06-seed-series.md\":\"BNsIBjBZ\",\"posts_llm_industry_mainllm_07-openai-series.md\":\"ZBquCwKO\",\"posts_llm_industry_mainllm_08-gemini-series.md\":\"Bdm2kU-I\",\"posts_llm_industry_mainllm_09-claude-series.md\":\"0YnEaaXS\",\"posts_llm_industry_mainllm_10-longcat-series.md\":\"DroIAFXW\",\"posts_llm_industry_mainllm_11-tencent-series.md\":\"BVkGSYEM\",\"posts_llm_industry_mainllm_12-kwai-series.md\":\"o6Hut3bE\",\"posts_llm_industry_mainllm_13-nvidia-series.md\":\"BFgUmWZk\",\"posts_llm_industry_mainllm_14-mimo-series.md\":\"DDj7XRZV\",\"posts_llm_industry_mainllm_15-skywork-series.md\":\"BMrtN_ri\",\"posts_llm_infra_01-parrallel.md\":\"2i82l-rT\",\"posts_llm_infra_02-speed-framework.md\":\"_bUH-n3t\",\"posts_llm_infra_03-inference-tech.md\":\"Hpk9YmXF\",\"posts_llm_infra_04-verl.md\":\"8XtGz01J\",\"posts_llm_infra_05-verl-practice.md\":\"CpYgON5R\",\"posts_llm_infra_06-verl-code.md\":\"D5bZg4dm\",\"posts_llm_infra_07-verl-core.md\":\"3RS___SF\",\"posts_llm_infra_08-verl-train-loop.md\":\"DzepHNlu\",\"posts_llm_rl_index.md\":\"iUgEsMU1\",\"posts_llm_rl_theory_01-reinforce-learning.md\":\"Ch0rtQCM\",\"posts_llm_rl_theory_01-rl-introduction.md\":\"CmW63EkM\",\"posts_llm_rl_theory_02-markove-process.md\":\"DVY5XgWd\",\"posts_llm_rl_theory_02-value-learning.md\":\"CeOlmbeS\",\"posts_llm_rl_theory_03-model-based-prediction-control.md\":\"BhVRmo7C\",\"posts_llm_rl_theory_03-strategy-learning.md\":\"DWNvEZXH\",\"posts_llm_rl_theory_04-model-free-prediction-control.md\":\"Cg3qo2Fk\",\"posts_llm_rl_theory_04-reinforce-conclusion-simple.md\":\"C6yTAxwQ\",\"posts_llm_rl_theory_05-dqn.md\":\"BatSdlnZ\",\"posts_llm_rl_theory_06-policy-gradient.md\":\"BXI-eY8I\",\"posts_llm_rl_theory_07-actor-critic.md\":\"B1-83sen\",\"posts_llm_rl_theory_08-deterministic-policy-gradient.md\":\"Dgvru3JE\",\"posts_llm_rl_theory_09-policy-trpo-ppo.md\":\"DU-7PSqU\",\"posts_llm_rl_theory_10-ppo-series.md\":\"B-5Hsj_J\",\"posts_llm_rl_theory_11-grpo-series.md\":\"sXtqvv0Z\",\"posts_llm_rl_theory_12-entropy.md\":\"BH45bCLH\",\"posts_llm_rl_theory_13-agentrl-algo.md\":\"EDVx1EmY\",\"posts_me.md\":\"B9W6CMag\",\"posts_olds_algo_aim2offer.md\":\"jCwzQ4BU\",\"posts_olds_algo_aim2offer2.md\":\"Ga2XS6dR\",\"posts_olds_algo_aim2offer3.md\":\"BP0rCZaJ\",\"posts_olds_algo_aim2offer4.md\":\"BXurWO8W\",\"posts_olds_algo_algorithm-dfs.md\":\"CkUFsStz\",\"posts_olds_algo_index.md\":\"CmdF0Gg2\",\"posts_olds_algo_leetcode-01.md\":\"C_2G2jJT\",\"posts_olds_algo_sort-algorithms.md\":\"tFMUVlmH\",\"posts_olds_bigdata_16-spark-baserdd.md\":\"CBxdArgI\",\"posts_olds_bigdata_17-spark-pairrdd.md\":\"C3n8_zMO\",\"posts_olds_bigdata_18-spark-sql.md\":\"tsaWQLcp\",\"posts_olds_bigdata_19-spark-programming.md\":\"DG5ZAF85\",\"posts_olds_bigdata_20-numpy.md\":\"DucCD22z\",\"posts_olds_bigdata_index.md\":\"CWrZwWPb\",\"posts_olds_dl_23-pytorch-start.md\":\"BokpNeAw\",\"posts_olds_dl_35-nerual-network-optim.md\":\"Cp2SpLoE\",\"posts_olds_dl_38-convolution.md\":\"CC_SQ57z\",\"posts_olds_dl_cs224n-assignment-1.md\":\"BZMSZqOS\",\"posts_olds_dl_cs224n-notes3-neural-networks-2.md\":\"Wd9TmSyb\",\"posts_olds_dl_cs224n-notes3-neural-networks.md\":\"CDZWc4X6\",\"posts_olds_dl_cs231n-linear-notes.md\":\"DLRyzcwJ\",\"posts_olds_dl_index.md\":\"C1dyLGNS\",\"posts_olds_dl_rnn.md\":\"CwYYWZ7N\",\"posts_olds_env_09-linux-notes.md\":\"CyjifvcN\",\"posts_olds_env_12-ide-envs.md\":\"YeELWzR2\",\"posts_olds_env_13-old-blog-problems.md\":\"qamPyucB\",\"posts_olds_env_24-hexo-problems.md\":\"CzxhyjW1\",\"posts_olds_env_index.md\":\"DQpgTXVj\",\"posts_olds_ml_10-trees.md\":\"BkNaj6fL\",\"posts_olds_ml_14-em.md\":\"DIufCP0H\",\"posts_olds_ml_21-lr.md\":\"C-1ms511\",\"posts_olds_ml_22-ml-ch03-bayes.md\":\"Q_M6Gn-a\",\"posts_olds_ml_27-svm-notes.md\":\"C96WS6CL\",\"posts_olds_ml_28-ml-interview-notes.md\":\"0bgezw3n\",\"posts_olds_ml_29-desicion-tree.md\":\"CtwmlbWl\",\"posts_olds_ml_crf.md\":\"CEE5oTqd\",\"posts_olds_ml_index.md\":\"BLMEziB1\",\"posts_olds_ml_maxentmodel.md\":\"CSbOumJx\",\"posts_olds_ml_pgm-01.md\":\"BTwybTMD\",\"posts_olds_nlp_11-nlp-labels.md\":\"Cl0Lb8OT\",\"posts_olds_nlp_25-google-nmt.md\":\"BOM-hoYN\",\"posts_olds_nlp_26-wordpieacemodel.md\":\"Q8-L5j15\",\"posts_olds_nlp_30-dynamic-memory-network.md\":\"wp5ucVxW\",\"posts_olds_nlp_31-co-attention-vqa.md\":\"lzwuVKG5\",\"posts_olds_nlp_32-dynamic-coattention-network.md\":\"Bxl4ABWd\",\"posts_olds_nlp_33-attention-summary.md\":\"DT6np0xG\",\"posts_olds_nlp_36-alime-chat.md\":\"Cu2xkcdT\",\"posts_olds_nlp_39-squard-models.md\":\"B1L3iDEv\",\"posts_olds_nlp_45-match-lstm.md\":\"DkpQKM5B\",\"posts_olds_nlp_46-rnet-selfmatch.md\":\"CzGHQ-PZ\",\"posts_olds_nlp_47-bidaf.md\":\"DFJaLh2v\",\"posts_olds_nlp_48-attention-is-all-you-need.md\":\"BY6XvFQ5\",\"posts_olds_nlp_49-qanet.md\":\"BPKWHzTf\",\"posts_olds_nlp_50-elmo.md\":\"WuOt1elN\",\"posts_olds_nlp_51-opengpt.md\":\"B9pQ3h5W\",\"posts_olds_nlp_52-bert.md\":\"5q3t5Qqh\",\"posts_olds_nlp_53-mrc-brief.md\":\"D9CkYrea\",\"posts_olds_nlp_54-mrc-models.md\":\"Ak4bDf1J\",\"posts_olds_nlp_attention-based-nmt.md\":\"BHef6tM6\",\"posts_olds_nlp_attention-model.md\":\"-xLhHhJE\",\"posts_olds_nlp_cs224n-lecture2-word2vec.md\":\"_MmBTADr\",\"posts_olds_nlp_cs224n-notes1-word2vec.md\":\"DXSi5KGh\",\"posts_olds_nlp_index.md\":\"Bfo4Lwn3\",\"posts_olds_nlp_nlp-notes.md\":\"BUmOZxzi\",\"posts_olds_nlp_nmt.md\":\"DUgy6vHF\",\"posts_olds_nlp_subword-units.md\":\"fR_3dRXr\",\"posts_olds_nlp_word2vec-math.md\":\"agvHiE1x\",\"posts_olds_nlp_word2vec.md\":\"D2TKUstm\",\"posts_olds_other_15-cpp-pointer-object-reference.md\":\"BKRTr8QZ\",\"posts_olds_other_index.md\":\"C1T-ubsz\",\"posts_olds_rl_37-reinforce-learning.md\":\"Cf2nny8k\",\"posts_olds_rl_40-value-learning.md\":\"DcnHvvpH\",\"posts_olds_rl_41-strategy-learning.md\":\"CStMrB-q\",\"posts_olds_rl_42-reinforce-conclusion-simple.md\":\"flRZUmJZ\",\"posts_olds_rl_43-intent-detection-slot-filling.md\":\"DcAUbaZU\",\"posts_olds_rl_44-reinforce-nlp.md\":\"Br2ShITL\",\"posts_olds_rl_index.md\":\"CUsxM3zO\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"📚 plmblog\",\"description\":\"记录一些学习笔记。\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"首页\",\"link\":\"/\"},{\"text\":\"🐲LLM\",\"items\":[{\"text\":\"Basic\",\"items\":[{\"text\":\"🦋基础知识\",\"link\":\"/posts/llm/basic/01-lm-define-information-theory\"},{\"text\":\"🛠基建框架\",\"link\":\"/posts/llm/infra/01-parrallel\"}]},{\"text\":\"强化学习\",\"items\":[{\"text\":\"🎓RL理论基础\",\"link\":\"/posts/llm/rl/theory/01-reinforce-learning\"},{\"text\":\"🚄Agent-RL\",\"link\":\"/posts/llm/agent/rl/02-agent-tool\"}]},{\"text\":\"行业方向\",\"items\":[{\"text\":\"🚀主流模型\",\"link\":\"/posts/llm/industry/mainllm/01-kimi-series\"},{\"text\":\"💻代码模型\",\"link\":\"/posts/llm/industry/codellm/01-survey\"}]},{\"text\":\"Agent\",\"items\":[{\"text\":\"🤖概念及应用\",\"link\":\"/posts/llm/agent/basic\"}]}]},{\"text\":\"📙旧文章\",\"items\":[{\"text\":\"🍓NLP\",\"items\":[{\"text\":\"自然语言处理\",\"link\":\"/posts/olds/nlp\"}]},{\"text\":\"🍑基础知识\",\"items\":[{\"text\":\"深度学习\",\"link\":\"/posts/olds/dl\"},{\"text\":\"强化学习\",\"link\":\"/posts/olds/rl\"},{\"text\":\"机器学习\",\"link\":\"/posts/olds/ml\"}]},{\"text\":\"🍎算法\",\"items\":[{\"text\":\"算法题\",\"link\":\"/posts/olds/algo/\"},{\"text\":\"大数据\",\"link\":\"/posts/olds/bigdata/\"}]},{\"text\":\"🍒其他\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/olds/env/\"},{\"text\":\"其他\",\"link\":\"/posts/olds/other/\"}]}]},{\"text\":\"经验\",\"items\":[{\"text\":\"环境\",\"items\":[{\"text\":\"环境搭建\",\"link\":\"/posts/exps/env/01-blog-env\"}]},{\"text\":\"心得\",\"items\":[{\"text\":\"心得体会\",\"link\":\"/posts/exps/mind\"}]}]},{\"text\":\"归档\",\"link\":\"/posts/archive.md\"},{\"text\":\"关于我\",\"link\":\"/posts/me\"}],\"outline\":{\"level\":[1,4],\"label\":\"当前页大纲\"},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/plmsmile\"}],\"search\":{\"provider\":\"local\"},\"docFooter\":{\"prev\":\"上一页\",\"next\":\"下一页\"},\"sidebar\":{\"/posts/olds/nlp/\":{\"base\":\"/posts/olds/nlp/\",\"items\":[{\"text\":\"NLP\",\"items\":[{\"text\":\"机器阅读(二)--模型(未完成)\",\"link\":\"54-mrc-models\"},{\"text\":\"机器阅读(一)--整体概述\",\"link\":\"53-mrc-brief\"},{\"text\":\"BERT 详解\",\"link\":\"52-bert\"},{\"text\":\"OpenAI GPT：Improving Language Understanding by Generative Pre-Training\",\"link\":\"51-opengpt\"},{\"text\":\"ELMo：Deep Contextualized Word Representations\",\"link\":\"50-elmo\"},{\"text\":\"QANet\",\"link\":\"49-qanet\"},{\"text\":\"Transformer\",\"link\":\"48-attention-is-all-you-need\"},{\"text\":\"Bidirectional Attention Flow\",\"link\":\"47-bidaf\"},{\"text\":\"R-Net (Gated Self-Matching Networks)\",\"link\":\"46-rnet-selfmatch\"},{\"text\":\"Match-LSTM and Answer Pointer\",\"link\":\"45-match-lstm\"},{\"text\":\"阅读理解模型总结\",\"link\":\"39-squard-models\"},{\"text\":\"阿里小蜜论文\",\"link\":\"36-alime-chat\"},{\"text\":\"各种注意力总结\",\"link\":\"33-attention-summary\"},{\"text\":\"Dynamic Coattention Network (Plus)\",\"link\":\"32-dynamic-coattention-network\"},{\"text\":\"协同注意力简介\",\"link\":\"31-co-attention-vqa\"},{\"text\":\"使用Dynamic Memory Network实现一个简单QA\",\"link\":\"30-dynamic-memory-network\"},{\"text\":\"词性标注和句法依存的表示符号\",\"link\":\"11-nlp-labels\"},{\"text\":\"Word2vec之总体介绍\",\"link\":\"cs224n-notes1-word2vec\"},{\"text\":\"Word2vec之数学模型\",\"link\":\"word2vec-math\"},{\"text\":\"Word2vec之公式推导笔记\",\"link\":\"cs224n-lecture2-word2vec\"},{\"text\":\"subword-units\",\"link\":\"subword-units\"},{\"text\":\"Wordpiece模型\",\"link\":\"26-wordpieacemodel\"},{\"text\":\"谷歌RNN翻译模型\",\"link\":\"25-google-nmt\"},{\"text\":\"机器翻译注意力机制及其PyTorch实现\",\"link\":\"Attention-based-NMT\"},{\"text\":\"图文介绍RNN注意力机制\",\"link\":\"attention-model\"},{\"text\":\"最初RNN神经翻译简略笔记\",\"link\":\"NMT\"},{\"text\":\"语言模型和平滑方法\",\"link\":\"nlp-notes\"},{\"text\":\"利用tensorflow实现简版word2vec\",\"link\":\"word2vec\"}]}]},\"/posts/olds/dl/\":{\"base\":\"/posts/olds/dl/\",\"items\":[{\"text\":\"DL\",\"items\":[{\"text\":\"卷积神经网络总结\",\"link\":\"38-convolution\"},{\"text\":\"网络优化\",\"link\":\"35-nerual-network-optim\"},{\"text\":\"cs224n作业一\",\"link\":\"cs224n-assignment-1\"},{\"text\":\"cs231n线性分类器和损失函数\",\"link\":\"cs231n-linear-notes\"},{\"text\":\"神经网络-过拟合-预处理-BN\",\"link\":\"cs224n-notes3-neural-networks-2\"},{\"text\":\"神经网络基础-反向传播-激活函数\",\"link\":\"cs224n-notes3-neural-networks\"},{\"text\":\"循环神经网络\",\"link\":\"rnn\"},{\"text\":\"PyTorch快速上手\",\"link\":\"23-pytorch-start\"}]}]},\"/posts/olds/rl/\":{\"base\":\"/posts/olds/rl/\",\"items\":[{\"text\":\"RL\",\"items\":[{\"text\":\"强化学习在NLP中的应用\",\"link\":\"44-reinforce-nlp\"},{\"text\":\"意图识别和槽填充\",\"link\":\"43-intent-detection-slot-filling\"},{\"text\":\"强化学习算法小结\",\"link\":\"42-reinforce-conclusion-simple\"},{\"text\":\"基于策略函数的学习方法\",\"link\":\"41-strategy-learning\"},{\"text\":\"基于值函数的学习\",\"link\":\"40-value-learning\"},{\"text\":\"强化学习\",\"link\":\"37-reinforce-learning\"}]}]},\"/posts/olds/ml/\":{\"base\":\"/posts/olds/ml/\",\"items\":[{\"text\":\"ML\",\"items\":[{\"text\":\"决策树笔记\",\"link\":\"29-desicion-tree\"},{\"text\":\"机器学习知识点汇总整理\",\"link\":\"28-ml-interview-notes\"},{\"text\":\"SVM笔记\",\"link\":\"27-svm-notes\"},{\"text\":\"树的总结\",\"link\":\"10-trees\"},{\"text\":\"条件随机场\",\"link\":\"crf\"},{\"text\":\"最大熵模型\",\"link\":\"maxentmodel\"},{\"text\":\"线性回归和逻辑回归\",\"link\":\"21-lr\"},{\"text\":\"最大期望算法\",\"link\":\"14-em\"},{\"text\":\"马尔可夫模型\",\"link\":\"pgm-01\"},{\"text\":\"朴素贝叶斯算法及其代码实现\",\"link\":\"22-ml-ch03-bayes\"}]}]},\"/posts/olds/algo/\":{\"base\":\"/posts/olds/algo/\",\"items\":[{\"text\":\"ALGO\",\"items\":[{\"text\":\"剑指offer4(51-64)\",\"link\":\"aim2offer4\"},{\"text\":\"剑指offer3(21-40)\",\"link\":\"aim2offer3\"},{\"text\":\"数据结构之搜索算法\",\"link\":\"algorithm-dfs\"},{\"text\":\"leetcode-01\",\"link\":\"leetcode-01\"},{\"text\":\"剑指offer(11-20)\",\"link\":\"aim2offer2\"},{\"text\":\"排序算法总结\",\"link\":\"sort-algorithms\"},{\"text\":\"剑指Offer(1-10)\",\"link\":\"aim2offer\"}]}]},\"/posts/olds/bigdata/\":{\"base\":\"/posts/olds/bigdata/\",\"items\":[{\"text\":\"BIG Data\",\"items\":[{\"text\":\"NumPy\",\"link\":\"20-numpy\"},{\"text\":\"Spark基础编程核心思想介绍\",\"link\":\"19-spark-programming\"},{\"text\":\"Spark-SQL的简略笔记\",\"link\":\"18-spark-sql\"},{\"text\":\"Spark键值对RDD的常用API\",\"link\":\"17-spark-pairrdd\"},{\"text\":\"Spark基础RDD的常用API\",\"link\":\"16-Spark-BaseRDD\"}]}]},\"/posts/olds/env/\":{\"base\":\"/posts/olds/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"IDE配置\",\"link\":\"12-ide-envs\"},{\"text\":\"Linux使用笔记\",\"link\":\"09-linux-notes\"},{\"text\":\"博客搭建及相关问题\",\"link\":\"24-hexo-problems\"},{\"text\":\"旧版博客搭建过程及其问题\",\"link\":\"13-old-blog-problems\"}]}]},\"/posts/olds/other/\":{\"base\":\"/posts/olds/other/\",\"items\":[{\"text\":\"其他\",\"items\":[{\"text\":\"C++类对象和指针的区别\",\"link\":\"15-cpp-pointer-object-reference\"}]}]},\"/posts/llm/agent/rl/\":{\"base\":\"/posts/llm/agent/rl/\",\"items\":[{\"text\":\"Agent-RL\",\"items\":[{\"text\":\"Agent-Interaction-RL 笔记\",\"link\":\"04-agent-env\"},{\"text\":\"Agent-Search-RL 笔记\",\"link\":\"03-agent-search\"},{\"text\":\"Agent-Tool-RL 笔记\",\"link\":\"02-agent-tool\"},{\"text\":\"Agent-RL 综述型笔记\",\"link\":\"01-agent-rl\"}]}]},\"/posts/llm/agent/basic/\":{\"base\":\"/posts/llm/agent/basic/\",\"items\":[{\"text\":\"Agent-基础\",\"items\":[{\"text\":\"DeepResearch 评估\",\"link\":\"06-deepresearch-evaluation\"},{\"text\":\"Computer-Agent\",\"link\":\"05-comuter-agent\"},{\"text\":\"Agent 思考性文章\",\"link\":\"04-agent-blogs\"},{\"text\":\"一些流行的Agents\",\"link\":\"03-current-agents\"},{\"text\":\"Agent 评估 Benchmarks\",\"link\":\"02-evaluation-agent\"},{\"text\":\"Agent基础概念 (李宏毅笔记)\",\"link\":\"01-lhy-agent-notes\"}]}]},\"/posts/llm/rl/theory/\":{\"base\":\"/posts/llm/rl/theory/\",\"items\":[{\"text\":\"RL-Theory\",\"items\":[{\"text\":\"Agent-RL 相关算法\",\"link\":\"13-agentrl-algo\"},{\"text\":\"熵和RL相关文章\",\"link\":\"12-entropy\"},{\"text\":\"GRPO 改进系列\",\"link\":\"11-grpo-series\"},{\"text\":\"PPO 改进系列\",\"link\":\"10-ppo-series\"},{\"text\":\"典型策略提升方法：TRPO+PPO+DPO+GRPO\",\"link\":\"09-policy-trpo-ppo\"},{\"text\":\"确定性策略梯度\",\"link\":\"08-deterministic-policy-gradient\"},{\"text\":\"Actor-Critic 算法\",\"link\":\"07-actor-critic\"},{\"text\":\"策略梯度算法\",\"link\":\"06-policy-gradient\"},{\"text\":\"DQN算法及进阶\",\"link\":\"05-dqn\"},{\"text\":\"免模型预测和控制\",\"link\":\"04-model-free-prediction-control\"},{\"text\":\"有模型预测和控制\",\"link\":\"03-model-based-prediction-control\"},{\"text\":\"马尔可夫决策过程\",\"link\":\"02-markove-process\"},{\"text\":\"强化学习基本概念\",\"link\":\"01-rl-introduction\"},{\"text\":\"(18年笔记)强化学习算法小结\",\"link\":\"04-reinforce-conclusion-simple\"},{\"text\":\"(18年笔记)基于策略函数的学习方法\",\"link\":\"03-strategy-learning\"},{\"text\":\"(18年笔记)基于值函数的学习\",\"link\":\"02-value-learning\"},{\"text\":\"(18年笔记)强化学习基础\",\"link\":\"01-reinforce-learning\"}]}]},\"/posts/llm/rl/rlhf/\":{\"base\":\"/posts/llm/rl/rlhf/\",\"items\":[{\"text\":\"RLHF\",\"items\":[]}]},\"/posts/llm/rl/o1llm/\":{\"base\":\"/posts/llm/rl/o1llm/\",\"items\":[{\"text\":\"推理模型\",\"items\":[]}]},\"/posts/llm/industry/mainllm/\":{\"base\":\"/posts/llm/industry/mainllm/\",\"items\":[{\"text\":\"🚀主流模型\",\"items\":[{\"text\":\"快手系列\",\"link\":\"12-kwai-series\"},{\"text\":\"腾讯系列\",\"link\":\"11-tencent-series\"},{\"text\":\"Claude 系列\",\"link\":\"09-claude-series\"},{\"text\":\"LongCat 系列\",\"link\":\"10-longcat-series\"},{\"text\":\"Gemini 系列\",\"link\":\"08-gemini-series\"},{\"text\":\"Seed 系列\",\"link\":\"06-seed-series\"},{\"text\":\"OpenAI 系列\",\"link\":\"07-openai-series\"},{\"text\":\"Qwen 系列\",\"link\":\"05-qwen-series\"},{\"text\":\"MiniMax 系列\",\"link\":\"04-minimax-series\"},{\"text\":\"GLM 系列\",\"link\":\"03-glm-series\"},{\"text\":\"DeepSeek 系列\",\"link\":\"02-deepseek-series\"},{\"text\":\"Kimi 系列\",\"link\":\"01-kimi-series\"},{\"text\":\"SkyWork 系列\",\"link\":\"15-skywork-series\"},{\"text\":\"小米系列\",\"link\":\"14-mimo-series\"},{\"text\":\"Nvidia 系列\",\"link\":\"13-nvidia-series\"}]}]},\"/posts/llm/industry/codellm/\":{\"base\":\"/posts/llm/industry/codellm/\",\"items\":[{\"text\":\"💻代码模型\",\"items\":[{\"text\":\"SWE 合成数据 系列\",\"link\":\"11-swe-data-series\"},{\"text\":\"SWE 总结索引\",\"link\":\"10-swe-summary\"},{\"text\":\"Code 全训练 论文阅读\",\"link\":\"07-code-fulltrain-reading\"},{\"text\":\"Code TaskRL 论文阅读\",\"link\":\"06-code-taskrl-reading\"},{\"text\":\"CodeLLM 索引简记\",\"link\":\"05-open-codellm\"},{\"text\":\"Code 安全相关\",\"link\":\"04-safety-code\"},{\"text\":\"Code RL 任务\",\"link\":\"03-rl-task\"},{\"text\":\"Code 任务Bench相关\",\"link\":\"02-eval-task-benchmark\"},{\"text\":\"Code Survey\",\"link\":\"01-survey\"},{\"text\":\"SWE 训练方法 系列\",\"link\":\"09-swe-series\"},{\"text\":\"Code 预训练相关\",\"link\":\"08-code-pretrain-summary\"}]}]},\"/posts/llm/basic/\":{\"base\":\"/posts/llm/basic/\",\"items\":[{\"text\":\"LLM-basic\",\"items\":[{\"text\":\"LLM位置编码和长度外推系列\",\"link\":\"08-llm-position-embedding\"},{\"text\":\"LLM 解码相关\",\"link\":\"07-decode\"},{\"text\":\"LLM Attention 系列\",\"link\":\"06-llm-attention\"},{\"text\":\"LLM 基础知识\",\"link\":\"05-llm-basic-info\"},{\"text\":\"LLM 架构相关\",\"link\":\"04-llm-architecture\"},{\"text\":\"Transformer细节\",\"link\":\"03-transformer-detail\"},{\"text\":\"语言模型重要组件\",\"link\":\"02-llm-components\"},{\"text\":\"语言模型定义及信息理论\",\"link\":\"01-lm-define-information-theory\"}]}]},\"/posts/llm/infra/\":{\"base\":\"/posts/llm/infra/\",\"items\":[{\"text\":\"🛠LLM-基建框架\",\"items\":[{\"text\":\"Verl 训练流程源代码阅读\",\"link\":\"08-verl-train-loop\"},{\"text\":\"Verl 有趣的功能\",\"link\":\"07-verl-core\"},{\"text\":\"Verl AgentLoop Rollout 相关\",\"link\":\"06-verl-code\"},{\"text\":\"Verl 常见参数配置和理解\",\"link\":\"05-verl-practice\"},{\"text\":\"Verl 早期概念型学习文章\",\"link\":\"04-verl\"},{\"text\":\"推理优化技术\",\"link\":\"03-inference-tech\"},{\"text\":\"分布式训练框架\",\"link\":\"02-speed-framework\"},{\"text\":\"分布式并行策略\",\"link\":\"01-parrallel\"}]}]},\"/posts/exps/env/\":{\"base\":\"/posts/exps/env/\",\"items\":[{\"text\":\"环境搭建\",\"items\":[{\"text\":\"环境搭建的一些坑\",\"link\":\"01-blog-env\"}]}]},\"/posts/exps/mind/\":{\"base\":\"/posts/exps/mind/\",\"items\":[{\"text\":\"心得体会\",\"items\":[]}]}}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>